[
  {
    "kind": "work-log",
    "title": "25_08_2024 - 31_08_2024.html",
    "fileName": "25_08_2024 - 31_08_2024.html",
    "url": "resources/work_logs/25_08_2024 - 31_08_2024.html",
    "createdDate": "2024-08-25",
    "text": "25/08/2024 - 31/08/2024 25/08/2024 - 31/08/2024 26/08/2024 15:08 Note to self: The IP of our fe01 machine is 192.168.102.46 Tried replacing the block RAM For the most part, I let the autoconnection do it's thing. We do indeed see the board with lspci after this [root@fe01 ~]# lspci -vv | grep -A 35 \"Xilinx\" pcilib: sysfs_read_vpd: read failed: Input/output error 04:00.0 Serial controller: Xilinx Corporation Device 7024 (prog-if 01 [16450]) Subsystem: Xilinx Corporation Device 0007 Control: I/O+ Mem+ BusMaster+ SpecCycle- MemWINV- VGASnoop- ParErr- Stepping- SERR- FastB2B- DisINTx+ Status: Cap+ 66MHz- UDF- FastB2B- ParErr- DEVSEL=fast >TAbort- <TAbort- <MAbort- >SERR- <PERR- INTx- Latency: 0, Cache Line Size: 64 bytes Interrupt: pin A routed to IRQ 36 Region 0: Memory at f5ff0000 (32-bit, non-prefetchable) [size=64K] Capabilities: [40] Power Management version 3 Flags: PMEClk- DSI- D1- D2- AuxCurrent=0mA PME(D0+,D1+,D2+,D3hot+,D3cold-) Status: D0 NoSoftRst+ PME-Enable- DSel=0 DScale=0 PME- Capabilities: [48] MSI: Enable+ Count=1/1 Maskable- 64bit+ Address: 00000000fee00000 Data: 4073 Capabilities: [60] Express (v2) Endpoint, MSI 00 DevCap: MaxPayload 512 bytes, PhantFunc 0, Latency L0s <64ns, L1 unlimited ExtTag+ AttnBtn- AttnInd- PwrInd- RBE+ FLReset- SlotPowerLimit 225.000W DevCtl: Report errors: Correctable- Non-Fatal+ Fatal+ Unsupported- RlxdOrd+ ExtTag- PhantFunc- AuxPwr- NoSnoop+ MaxPayload 256 bytes, MaxReadReq 512 bytes DevSta: CorrErr- UncorrErr- FatalErr- UnsuppReq- AuxPwr- TransPend- LnkCap: Port #0, Speed 5GT/s, Width x4, ASPM L0s, Exit Latency L0s unlimited, L1 unlimited ClockPM- Surprise- LLActRep- BwNot- ASPMOptComp- LnkCtl: ASPM Disabled; RCB 64 bytes Disabled- CommClk+ ExtSynch- ClockPM- AutWidDis- BWInt- AutBWInt- LnkSta: Speed 5GT/s, Width x4, TrErr- Train- SlotClk+ DLActive- BWMgmt- ABWMgmt- DevCap2: Completion Timeout: Range B, TimeoutDis-, LTR-, OBFF Not Supported DevCtl2: Completion Timeout: 50us to 50ms, TimeoutDis-, LTR-, OBFF Disabled LnkCtl2: Target Link Speed: 5GT/s, EnterCompliance- SpeedDis- Transmit Margin: Normal Operating Range, EnterModifiedCompliance- ComplianceSOS- Compliance De-emphasis: -6dB LnkSta2: Current De-emphasis Level: -6dB, EqualizationComplete-, EqualizationPhase1- EqualizationPhase2-, EqualizationPhase3-, LinkEqualizationRequest- Capabilities: [100 v1] Device Serial Number 00-00-00-00-00-00-00-00 Kernel driver in use: xdma Kernel modules: xdma 06:00.0 Ethernet controller: Broadcom Inc. and subsidiaries NetXtreme BCM5761 Gigabit Ethernet PCIe (rev 10) Subsystem: Broadcom Inc. and subsidiaries NetXtreme BCM5761 Gigabit Ethernet PCIe [root@fe01 ~]# [root@fe01 ~]# lspci -vv | grep -A 35 \"Xilinx\" pcilib: sysfs_read_vpd: read failed: Input/output error 04:00.0 Serial controller: Xilinx Corporation Device 7024 (prog-if 01 [16450]) Subsystem: Xilinx Corporation Device 0007 Control: I/O+ Mem+ BusMaster+ SpecCycle- MemWINV- VGASnoop- ParErr- Stepping- SERR- FastB2B- DisINTx+ Status: Cap+ 66MHz- UDF- FastB2B- ParErr- DEVSEL=fast >TAbort- <TAbort- <MAbort- >SERR- <PERR- INTx- Latency: 0, Cache Line Size: 64 bytes Interrupt: pin A routed to IRQ 36 Region 0: Memory at f5ff0000 (32-bit, non-prefetchable) [size=64K] Capabilities: [40] Power Management version 3 Flags: PMEClk- DSI- D1- D2- AuxCurrent=0mA PME(D0+,D1+,D2+,D3hot+,D3cold-) Status: D0 NoSoftRst+ PME-Enable- DSel=0 DScale=0 PME- Capabilities: [48] MSI: Enable+ Count=1/1 Maskable- 64bit+ Address: 00000000fee00000 Data: 4073 Capabilities: [60] Express (v2) Endpoint, MSI 00 DevCap: MaxPayload 512 bytes, PhantFunc 0, Latency L0s <64ns, L1 unlimited ExtTag+ AttnBtn- AttnInd- PwrInd- RBE+ FLReset- SlotPowerLimit 225.000W DevCtl: Report errors: Correctable- Non-Fatal+ Fatal+ Unsupported- RlxdOrd+ ExtTag- PhantFunc- AuxPwr- NoSnoop+ MaxPayload 256 bytes, MaxReadReq 512 bytes DevSta: CorrErr- UncorrErr- FatalErr- UnsuppReq- AuxPwr- TransPend- LnkCap: Port #0, Speed 5GT/s, Width x4, ASPM L0s, Exit Latency L0s unlimited, L1 unlimited ClockPM- Surprise- LLActRep- BwNot- ASPMOptComp- LnkCtl: ASPM Disabled; RCB 64 bytes Disabled- CommClk+ ExtSynch- ClockPM- AutWidDis- BWInt- AutBWInt- LnkSta: Speed 5GT/s, Width x4, TrErr- Train- SlotClk+ DLActive- BWMgmt- ABWMgmt- DevCap2: Completion Timeout: Range B, TimeoutDis-, LTR-, OBFF Not Supported DevCtl2: Completion Timeout: 50us to 50ms, TimeoutDis-, LTR-, OBFF Disabled LnkCtl2: Target Link Speed: 5GT/s, EnterCompliance- SpeedDis- Transmit Margin: Normal Operating Range, EnterModifiedCompliance- ComplianceSOS- Compliance De-emphasis: -6dB LnkSta2: Current De-emphasis Level: -6dB, EqualizationComplete-, EqualizationPhase1- EqualizationPhase2-, EqualizationPhase3-, LinkEqualizationRequest- Capabilities: [100 v1] Device Serial Number 00-00-00-00-00-00-00-00 Kernel driver in use: xdma Kernel modules: xdma 06:00.0 Ethernet controller: Broadcom Inc. and subsidiaries NetXtreme BCM5761 Gigabit Ethernet PCIe (rev 10) Subsystem: Broadcom Inc. and subsidiaries NetXtreme BCM5761 Gigabit Ethernet PCIe [root@fe01 ~]# Things seem to work [root@fe01 tests]# ./load_driver.sh xdma 47131 0 Loading driver... The Kernel module installed correctly and the xmda devices were recognized. DONE [root@fe01 tests]# sudo ./run_test.sh Info: Number of enabled h2c channels = 2 Info: Number of enabled c2h channels = 2 Info: The PCIe DMA core is memory mapped. Info: Running PCIe DMA memory mapped write read test transfer size: 1024 transfer count: 1 Info: Writing to h2c channel 0 at address offset 0. Info: Writing to h2c channel 1 at address offset 1024. Info: Wait for current transactions to complete. sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000000 sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000001 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_h2c_0, address = 0x00000000, size = 0x00000400, offset = 0x00000000, count = 1 device = /dev/xdma0_h2c_1, address = 0x00000400, size = 0x00000400, offset = 0x00000000, count = 1 host memory buffer = 0x19a0400 host memory buffer = 0xc50400 CLOCK_MONOTONIC reports 0.000038707 seconds (total) for last transfer of 1024 bytes Transfer speed: 25.23 MB/s CLOCK_MONOTONIC reports 0.000119755 seconds (total) for last transfer of 1024 bytes Transfer speed: 8.15 MB/s Info: Writing to h2c channel 0 at address offset 2048. Info: Writing to h2c channel 1 at address offset 3072. Info: Wait for current transactions to complete. sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000800 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_h2c_0, address = 0x00000800, size = 0x00000400, offset = 0x00000000, count = 1 host memory buffer = 0x783400 sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000c00 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_h2c_1, address = 0x00000c00, size = 0x00000400, offset = 0x00000000, count = 1 host memory buffer = 0x85d400 CLOCK_MONOTONIC reports 0.000121881 seconds (total) for last transfer of 1024 bytes Transfer speed: 8.01 MB/s CLOCK_MONOTONIC reports 0.000101627 seconds (total) for last transfer of 1024 bytes Transfer speed: 9.61 MB/s Info: Reading from c2h channel 0 at address offset 0. Info: Reading from c2h channel 1 at address offset 1024. Info: Wait for the current transactions to complete. sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_c2h_1, address = 0x00000400, size = 0x00000400, offset = 0x00000000, count = 1 sscanf() = 1, value = 0x00000400 host memory buffer = 0x2152000 sscanf() = 1, value = 0x00000000 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_c2h_0, address = 0x00000000, size = 0x00000400, offset = 0x00000000, count = 1 host memory buffer = 0x1e17000 CLOCK_MONOTONIC reports 0.000024211 seconds (total) for last transfer of 1024 bytes Transfer speed: 40.34 MB/s CLOCK_MONOTONIC reports 0.000039237 seconds (total) for last transfer of 1024 bytes Transfer speed: 24.89 MB/s Info: Reading from c2h channel 0 at address offset 2048. Info: Reading from c2h channel 1 at address offset 3072. Info: Wait for the current transactions to complete. sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000800 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_c2h_0, address = 0x00000800, size = 0x00000400, offset = 0x00000000, count = 1 host memory buffer = 0x8ea000 sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000c00 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_c2h_1, address = 0x00000c00, size = 0x00000400, offset = 0x00000000, count = 1 host memory buffer = 0x1ba8000 CLOCK_MONOTONIC reports 0.000026233 seconds (total) for last transfer of 1024 bytes Transfer speed: 37.23 MB/s CLOCK_MONOTONIC reports 0.000027351 seconds (total) for last transfer of 1024 bytes Transfer speed: 35.70 MB/s Info: Checking data integrity. Info: Data check passed for address range 0 - 1024. Info: Data check passed for address range 1024 - 2048. Info: Data check passed for address range 2048 - 3072. Info: Data check passed for address range 3072 - 4096. Info: All PCIe DMA memory mapped tests passed. Info: All tests in run_tests.sh passed. [root@fe01 tests]# [root@fe01 tests]# ./load_driver.sh xdma 47131 0 Loading driver... The Kernel module installed correctly and the xmda devices were recognized. DONE [root@fe01 tests]# sudo ./run_test.sh Info: Number of enabled h2c channels = 2 Info: Number of enabled c2h channels = 2 Info: The PCIe DMA core is memory mapped. Info: Running PCIe DMA memory mapped write read test transfer size: 1024 transfer count: 1 Info: Writing to h2c channel 0 at address offset 0. Info: Writing to h2c channel 1 at address offset 1024. Info: Wait for current transactions to complete. sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000000 sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000001 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_h2c_0, address = 0x00000000, size = 0x00000400, offset = 0x00000000, count = 1 device = /dev/xdma0_h2c_1, address = 0x00000400, size = 0x00000400, offset = 0x00000000, count = 1 host memory buffer = 0x19a0400 host memory buffer = 0xc50400 CLOCK_MONOTONIC reports 0.000038707 seconds (total) for last transfer of 1024 bytes Transfer speed: 25.23 MB/s CLOCK_MONOTONIC reports 0.000119755 seconds (total) for last transfer of 1024 bytes Transfer speed: 8.15 MB/s Info: Writing to h2c channel 0 at address offset 2048. Info: Writing to h2c channel 1 at address offset 3072. Info: Wait for current transactions to complete. sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000800 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_h2c_0, address = 0x00000800, size = 0x00000400, offset = 0x00000000, count = 1 host memory buffer = 0x783400 sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000c00 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_h2c_1, address = 0x00000c00, size = 0x00000400, offset = 0x00000000, count = 1 host memory buffer = 0x85d400 CLOCK_MONOTONIC reports 0.000121881 seconds (total) for last transfer of 1024 bytes Transfer speed: 8.01 MB/s CLOCK_MONOTONIC reports 0.000101627 seconds (total) for last transfer of 1024 bytes Transfer speed: 9.61 MB/s Info: Reading from c2h channel 0 at address offset 0. Info: Reading from c2h channel 1 at address offset 1024. Info: Wait for the current transactions to complete. sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_c2h_1, address = 0x00000400, size = 0x00000400, offset = 0x00000000, count = 1 sscanf() = 1, value = 0x00000400 host memory buffer = 0x2152000 sscanf() = 1, value = 0x00000000 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_c2h_0, address = 0x00000000, size = 0x00000400, offset = 0x00000000, count = 1 host memory buffer = 0x1e17000 CLOCK_MONOTONIC reports 0.000024211 seconds (total) for last transfer of 1024 bytes Transfer speed: 40.34 MB/s CLOCK_MONOTONIC reports 0.000039237 seconds (total) for last transfer of 1024 bytes Transfer speed: 24.89 MB/s Info: Reading from c2h channel 0 at address offset 2048. Info: Reading from c2h channel 1 at address offset 3072. Info: Wait for the current transactions to complete. sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000800 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_c2h_0, address = 0x00000800, size = 0x00000400, offset = 0x00000000, count = 1 host memory buffer = 0x8ea000 sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000c00 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_c2h_1, address = 0x00000c00, size = 0x00000400, offset = 0x00000000, count = 1 host memory buffer = 0x1ba8000 CLOCK_MONOTONIC reports 0.000026233 seconds (total) for last transfer of 1024 bytes Transfer speed: 37.23 MB/s CLOCK_MONOTONIC reports 0.000027351 seconds (total) for last transfer of 1024 bytes Transfer speed: 35.70 MB/s Info: Checking data integrity. Info: Data check passed for address range 0 - 1024. Info: Data check passed for address range 1024 - 2048. Info: Data check passed for address range 2048 - 3072. Info: Data check passed for address range 3072 - 4096. Info: All PCIe DMA memory mapped tests passed. Info: All tests in run_tests.sh passed. [root@fe01 tests]# 27/08/2024 17:42 Getting a midas python frontend running is fairly simple: Install midas package cd $MIDASSYS/python python setup.py install cd $MIDASSYS/ python python setup. py install Copy and run example frontend: cd $MIDASSYS/python/examples cp basic_frontend.py /path/to/new/desired/frontend/location cd $MIDASSYS/ python /examples cp basic_frontend. py /path/ to / new /desired/frontend/location Run the frontend python basic_frontend.py python basic_frontend. py It should appear on the midas webpage. 27/08/2024 18:56 Playing around, it seems like a python frontend will only poll at a max rate of ~100Hz [root@dhcp-10-163-105-238 frontend_simulator]# python frontend.py Loaded data from fake_data.txt: [1, 25344, 0, 6912, 268, 8716, -23208, 24865, 0, 0]... Initialized zero buffer with 5 zeros. Initialization complete Running... [DataSimulator-Python,INFO] Frontend has started run number 11 [DataSimulator-Python,INFO] Frontend has ended run number 11 Poll function was called 114 times. Average interval between poll calls: 0.103159 seconds [root@dhcp -10 -163 -105 -238 frontend_simulator] # python frontend.py Loaded data from fake_data.txt: [ 1 , 25344 , 0 , 6912 , 268 , 8716 , -23208 , 24865 , 0 , 0 ]... Initialized zero buffer with 5 zeros. Initialization complete Running... [DataSimulator-Python,INFO] Frontend has started run number 11 [DataSimulator-Python,INFO] Frontend has ended run number 11 Poll function was called 114 times . Average interval between poll calls: 0.103159 seconds Output of this frontend code: import midas import midas.frontend import midas.event import numpy as np import random import time class DataSimulatorEquipment(midas.frontend.EquipmentBase): def __init__(self, client, frontend): equip_name = \"Python Data Simulator\" default_common = midas.frontend.InitialEquipmentCommon() default_common.equip_type = midas.EQ_POLLED default_common.buffer_name = \"SYSTEM\" default_common.trigger_mask = 0 default_common.event_id = 2 default_common.period_ms = 100 default_common.read_when = midas.RO_RUNNING default_common.log_history = 1 midas.frontend.EquipmentBase.__init__(self, client, equip_name, default_common) print(\"Initialization complete\") self.set_status(\"Initialized\") self.frontend = frontend def readout_func(self): event = midas.event.Event() # Create a bank for zero buffer event.create_bank(\"CR00\", midas.TID_SHORT, self.frontend.zero_buffer) # Simulate the addition of `data` in the periodic event data_block = [] data_block.extend(self.frontend.data) # Append the simulated data to the event event.create_bank(\"CR00\", midas.TID_SHORT, data_block) return event def poll_func(self): current_time = time.time() if current_time - self.frontend.last_poll_time >= self.frontend.poll_time: self.frontend.last_poll_time = current_time self.frontend.poll_count += 1 self.frontend.poll_timestamps.append(current_time) return True # Indicate that an event is available return False # No event available yet class DataSimulatorFrontend(midas.frontend.FrontendBase): def __init__(self): midas.frontend.FrontendBase.__init__(self, \"DataSimulator-Python\") # Data and zero buffer initialization self.data = [] self.zero_buffer = [] self.generator = random.Random() self.load_data_from_file(\"fake_data.txt\") self.init_zero_buffer() # Polling variables self.poll_time = 0.1 # Poll time in seconds self.last_poll_time = time.time() self.poll_count = 0 self.poll_timestamps = [] self.add_equipment(DataSimulatorEquipment(self.client, self)) def load_data_from_file(self, filename): try: with open(filename, 'r') as file: for line in file: values = [int(value) for value in line.strip().split(',')] self.data.extend(values) print(f\"Loaded data from {filename}: {self.data[:10]}...\") # Display the first few values for verification except IOError as e: print(f\"Error opening file: {e}\") def init_zero_buffer(self): total_data_size = 5 # Adjust size as needed self.zero_buffer = [0] * total_data_size print(f\"Initialized zero buffer with {total_data_size} zeros.\") def begin_of_run(self, run_number): self.set_all_equipment_status(\"Running\", \"greenLight\") self.client.msg(f\"Frontend has started run number {run_number}\") return midas.status_codes[\"SUCCESS\"] def end_of_run(self, run_number): self.set_all_equipment_status(\"Finished\", \"greenLight\") self.client.msg(f\"Frontend has ended run number {run_number}\") # Print poll function statistics at the end of the run self.print_poll_stats() return midas.status_codes[\"SUCCESS\"] def frontend_exit(self): print(\"Frontend is exiting.\") def print_poll_stats(self): if len(self.poll_timestamps) > 1: intervals = [self.poll_timestamps[i] - self.poll_timestamps[i-1] for i in range(1, len(self.poll_timestamps))] avg_interval = sum(intervals) / len(intervals) print(f\"Poll function was called {self.poll_count} times.\") print(f\"Average interval between poll calls: {avg_interval:.6f} seconds\") else: print(f\"Poll function was called {self.poll_count} times. Not enough data for interval calculation.\") if __name__ == \"__main__\": with DataSimulatorFrontend() as my_fe: my_fe.run() import midas import midas.frontend import midas.event import numpy as np import random import time class DataSimulatorEquipment(midas.frontend.EquipmentBase): def __init__(self, client, frontend): equip_name = \"Python Data Simulator\" default_common = midas.frontend.InitialEquipmentCommon() default_common.equip_type = midas.EQ_POLLED default_common.buffer_name = \"SYSTEM\" default_common.trigger_mask = 0 default_common.event_id = 2 default_common.period_ms = 100 default_common.read_when = midas.RO_RUNNING default_common.log_history = 1 midas.frontend.EquipmentBase.__init__(self, client, equip_name, default_common) print(\"Initialization complete\") self.set_status(\"Initialized\") self.frontend = frontend def readout_func(self): event = midas.event.Event() # Create a bank for zero buffer event.create_bank(\"CR00\", midas.TID_SHORT, self.frontend.zero_buffer) # Simulate the addition of `data` in the periodic event data_block = [] data_block.extend(self.frontend.data) # Append the simulated data to the event event.create_bank(\"CR00\", midas.TID_SHORT, data_block) return event def poll_func(self): current_time = time.time() if current_time - self.frontend.last_poll_time >= self.frontend.poll_time: self.frontend.last_poll_time = current_time self.frontend.poll_count += 1 self.frontend.poll_timestamps.append(current_time) return True # Indicate that an event is available return False # No event available yet class DataSimulatorFrontend(midas.frontend.FrontendBase): def __init__(self): midas.frontend.FrontendBase.__init__(self, \"DataSimulator-Python\") # Data and zero buffer initialization self.data = [] self.zero_buffer = [] self.generator = random.Random() self.load_data_from_file(\"fake_data.txt\") self.init_zero_buffer() # Polling variables self.poll_time = 0.1 # Poll time in seconds self.last_poll_time = time.time() self.poll_count = 0 self.poll_timestamps = [] self.add_equipment(DataSimulatorEquipment(self.client, self)) def load_data_from_file(self, filename): try: with open(filename, 'r') as file: for line in file: values = [int(value) for value in line.strip().split(',')] self.data.extend(values) print(f\"Loaded data from {filename}: {self.data[:10]}...\") # Display the first few values for verification except IOError as e: print(f\"Error opening file: {e}\") def init_zero_buffer(self): total_data_size = 5 # Adjust size as needed self.zero_buffer = [0] * total_data_size print(f\"Initialized zero buffer with {total_data_size} zeros.\") def begin_of_run(self, run_number): self.set_all_equipment_status(\"Running\", \"greenLight\") self.client.msg(f\"Frontend has started run number {run_number}\") return midas.status_codes[\"SUCCESS\"] def end_of_run(self, run_number): self.set_all_equipment_status(\"Finished\", \"greenLight\") self.client.msg(f\"Frontend has ended run number {run_number}\") # Print poll function statistics at the end of the run self.print_poll_stats() return midas.status_codes[\"SUCCESS\"] def frontend_exit(self): print(\"Frontend is exiting.\") def print_poll_stats(self): if len(self.poll_timestamps) > 1: intervals = [self.poll_timestamps[i] - self.poll_timestamps[i-1] for i in range(1, len(self.poll_timestamps))] avg_interval = sum(intervals) / len(intervals) print(f\"Poll function was called {self.poll_count} times.\") print(f\"Average interval between poll calls: {avg_interval:.6f} seconds\") else: print(f\"Poll function was called {self.poll_count} times. Not enough data for interval calculation.\") if __name__ == \"__main__\": with DataSimulatorFrontend() as my_fe: my_fe.run() 27/08/2024 18:57 To verify the above, I stripped down the frontend as much as I could. I.e. I just timed the polling for the example frontend and came to the same conclusion [root@dhcp-10-163-105-238 frontend_simulator]# python example_frontend.py Running... [myfe_name,INFO] Frontend has seen start of run number 13 Run 13 Polling Statistics: Total polls: 1471 Average interval: 0.013 s Min interval: 0.010 s Max interval: 3.992 s [myfe_name,INFO] Frontend has seen end of run number 13 ^CReceived Ctrl-C, aborting... Goodbye from user code! Midas shutdown [root@dhcp-10-163-105-238 frontend_simulator]# [root@dhcp-10-163-105-238 frontend_simulator]# python example_frontend.py Running .. . [myfe_name, INFO ] Frontend has seen start of run number 13 Run 13 Polling Statistics: Total polls: 1471 Average interval: 0.013 s Min interval: 0.010 s Max interval: 3.992 s [myfe_name, INFO ] Frontend has seen end of run number 13 ^CReceived Ctrl-C, aborting .. . Goodbye from user code! Midas shutdown [root@dhcp-10-163-105-238 frontend_simulator]# I.e. with python frontends we can only poll at around 100Hz.",
    "textLength": 3197
  },
  {
    "kind": "work-log",
    "title": "04_08_2025 - 10_08_2025.html",
    "fileName": "04_08_2025 - 10_08_2025.html",
    "url": "resources/work_logs/04_08_2025 - 10_08_2025.html",
    "createdDate": "2025-08-04",
    "text": "04/08/2025 - 10/08/2025 04/08/2025 - 10/08/2025 06/08/2025 05:15 I was able to build the new musip DAQ. It is built in /home/pioneer/packages/experiments/musip Some things I had to do: Setup the environment to include root and a new version of midas. I provide a script scripts/environment_setup/setup_environment.sh [root@dhcp-10-163-102-46 environment_setup]# ./setup_environment.sh --help Usage: ./setup_environment.sh [-a|--add] [-r|--root [path]] Flags: -a, --add Add MIDASSYS/bin to PATH if MIDASSYS is defined. -r, --root [path] Source ROOT setup script at [path]. Default: /home/pioneer/packages/root/bin/thisroot.sh [root@dhcp-10-163-102-46 environment_setup]# source ./setup_environment.sh Sourced ROOT setup script: /home/pioneer/packages/root/bin/thisroot.sh MIDAS_EXPT_NAME environment variable set to: MUSIP_DAQ MIDASSYS environment variable set to: /home/pioneer/packages/midas MIDAS_EXPTAB environment variable set to: /home/pioneer/online/exptab [root@dhcp-10-163-102-46 environment_setup]# [root@dhcp-10-163-102-46 environment_setup]# ./setup_environment.sh --help Usage: ./setup_environment.sh [-a|-- add ] [-r|--root [path]] Flags: -a, -- add Add MIDASSYS/bin to PATH if MIDASSYS is defined. -r, --root [path] Source ROOT setup script at [path]. Default: /home/pioneer/packages/root/bin/thisroot.sh [root@dhcp-10-163-102-46 environment_setup]# source ./setup_environment.sh Sourced ROOT setup script: /home/pioneer/packages/root/bin/thisroot.sh MIDAS_EXPT_NAME environment variable set to : MUSIP_DAQ MIDASSYS environment variable set to : /home/pioneer/packages/midas MIDAS_EXPTAB environment variable set to : /home/pioneer/online/exptab [root@dhcp-10-163-102-46 environment_setup]# In /home/pioneer/packages/experiments/musip/midas_fe/missing_hardware.h I simply uncommented out the line #define NO_A10_BOARD 1 Build the project. I provide a script scripts/build.sh [root@dhcp-10-163-102-46 scripts]# ./build.sh --help Usage: ./build.sh [OPTIONS] Options: -o, --overwrite Remove existing build directory before building -j, --jobs <number> Specify number of processors to use (default: all available) -h, --help Display this help message [root@dhcp-10-163-102-46 scripts]# [root@dhcp -10 -163 -102 -46 scripts]# ./build.sh --help Usage : ./build.sh [OPTIONS] Options : -o, --overwrite Remove existing build directory before building -j, --jobs <number> Specify number of processors to use (default: all available) -h, --help Display this help message [root@dhcp -10 -163 -102 -46 scripts]# Enable the software dummy in the ODB at /Equipment/Quads Config/Settings/Readout/Software Dummy . I'm not sure what other settings there are to play with. Run the frontends: Command line: I setup a script scripts/run.sh [root@dhcp-10-163-102-46 scripts]# ./run.sh --help Usage: ./run.sh [OPTIONS] [-- <args>] Options: -h, --help Display this help message -d, --debug Run with gdb for debugging -v, --valgrind Run with valgrind for memory analysis --preload <libs> Comma-separated list of library paths to LD_PRELOAD --exe <name> Choose executable to run. Options: quads_data_fe quads_config_fe Arguments after '--' will be passed to the executable. Example: ./run.sh --exe quads_data_fe -- -c config.json [root@dhcp-10-163-102-46 scripts]# [root@dhcp -10 -163 -102 -46 scripts] # ./run.sh --help Usage: ./ run .sh [OPTIONS] [ -- <args>] Options: -h, --help Display this help message -d, --debug Run with gdb for debugging -v, --valgrind Run with valgrind for memory analysis --preload <libs> Comma-separated list of library paths to LD_PRELOAD --exe <name> Choose executable to run. Options: quads_data_fe quads_config_fe Arguments after ' --' will be passed to the executable. Example: ./ run .sh --exe quads_data_fe -- -c config.json [root@dhcp -10 -163 -102 -46 scripts] # Command line screen: I setup a script scripts/screen.sh [root@dhcp-10-163-102-46 scripts]# ./screen.sh --help Usage: ./run_screen.sh [OPTIONS] [-- <args>] Options: -h, --help Display this help message -d, --debug Run inside screen with gdb -v, --valgrind Run inside screen with valgrind --preload <libs> Comma-separated list of library paths to LD_PRELOAD --exe <name> Choose executable to run. Options: quads_data_fe quads_config_fe Arguments after '--' will be passed to the executable. Example: ./run_screen.sh --exe quads_data_fe -- -c config.json [root@dhcp-10-163-102-46 scripts]# [root@dhcp- 10 - 163 - 102 - 46 scripts]# ./screen. sh -- help Usage: ./run_screen. sh [OPTIONS] [-- <args> ] Options: -h, -- help Display this help message -d, -- debug Run inside screen with gdb -v, --valgrind Run inside screen with valgrind --preload <libs> Comma-separated list of library paths to LD_PRELOAD -- exe <name> Choose executable to run. Options: quads_data_fe quads_config_fe Arguments after '--' will be passed to the executable . Example: ./run_screen. sh -- exe quads_data_fe -- - c config.json [root@dhcp- 10 - 163 - 102 - 46 scripts]# On midas webpage : Go to Programs > Start Quads Config and Programs > Start Quads Data 06/08/2025 05:29 Example mdump of event [root@dhcp-10-163-102-46 environment_setup]# mdump - MIDAS revision: Fri Jul 25 10:38:47 2025 -0700 - midas-2025-01-a-312-g7e62a6d2 on branch develop -- Enter <!> to Exit ------- Midas Dump --- ------------------------ Event# 1 ------------------------ Evid:0001- Mask:0000- Serial:16- Time:0x68931ab7- Dsize:2504/0x9c8 #banks:2 - Bank list:-PCLSPCMS- Bank:PCLS Length: 2336(I*1)/584(I*4)/584(Type) Type:Unsigned Integer*4 1-> 0x00000000 0x00000024 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 9-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 17-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 25-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 33-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 41-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 49-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 57-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 65-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 73-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 81-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 89-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 97-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 105-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 113-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 121-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 129-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 137-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 145-> 0x00000000 0x00000000 0x00000001 0x00000024 0x00000000 0x00000000 0x00000000 0x00000000 153-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 161-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 169-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 177-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 185-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 193-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 201-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 209-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 217-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 225-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 233-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 241-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 249-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 257-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 265-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 273-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 281-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 289-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000002 0x00000024 0x00000000 0x00000000 297-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 305-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 313-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 321-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 329-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 337-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 345-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 353-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 361-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 369-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 377-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 385-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 393-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 401-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 409-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 417-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 425-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 433-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000003 0x00000024 441-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 449-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 457-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 465-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 473-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 481-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 489-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 497-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 505-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 513-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 521-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 529-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 537-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 545-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 553-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 561-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 569-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 577-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 Bank:PCMS Length: 128(I*1)/32(I*4)/32(Type) Type:Unsigned Integer*4 1-> 0x00000000 0x00000024 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 9-> 0x00000001 0x00000024 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 17-> 0x00000002 0x00000024 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 25-> 0x00000003 0x00000024 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 [root@dhcp-10-163-102-46 environment_setup]# mdump - MIDAS revision: Fri Jul 25 10:38:47 2025 -0700 - midas-2025-01-a-312-g7e62a6d2 on branch develop -- Enter <!> to Exit ------- Midas Dump --- ------------------------ Event# 1 ------------------------ Evid:0001- Mask:0000- Serial:16- Time:0x68931ab7- Dsize:2504/0x9c8 #banks:2 - Bank list:-PCLSPCMS- Bank:PCLS Length: 2336(I*1)/584(I*4)/584(Type) Type:Unsigned Integer*4 1-> 0x00000000 0x00000024 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 9-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 17-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 25-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 33-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 41-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 49-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 57-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 65-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 73-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 81-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 89-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 97-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 105-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 113-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 121-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 129-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 137-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 145-> 0x00000000 0x00000000 0x00000001 0x00000024 0x00000000 0x00000000 0x00000000 0x00000000 153-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 161-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 169-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 177-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 185-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 193-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 201-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 209-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 217-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 225-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 233-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 241-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 249-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 257-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 265-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 273-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 281-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 289-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000002 0x00000024 0x00000000 0x00000000 297-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 305-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 313-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 321-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 329-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 337-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 345-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 353-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 361-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 369-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 377-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 385-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 393-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 401-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 409-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 417-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 425-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 433-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000003 0x00000024 441-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 449-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 457-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 465-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 473-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 481-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 489-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 497-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 505-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 513-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 521-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 529-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 537-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 545-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 553-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 561-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 569-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 577-> 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 Bank:PCMS Length: 128(I*1)/32(I*4)/32(Type) Type:Unsigned Integer*4 1-> 0x00000000 0x00000024 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 9-> 0x00000001 0x00000024 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 17-> 0x00000002 0x00000024 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 25-> 0x00000003 0x00000024 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 So it appears the \"emulator\" mostly filles things up with empty data. Not sure what the non-zero PCMS data represents.",
    "textLength": 2336
  },
  {
    "kind": "work-log",
    "title": "27_10_2024 - 02_11_2024.html",
    "fileName": "27_10_2024 - 02_11_2024.html",
    "url": "resources/work_logs/27_10_2024 - 02_11_2024.html",
    "createdDate": "2024-10-27",
    "text": "27/10/2024 - 02/11/2024 27/10/2024 - 02/11/2024 30/10/2024 22:37 I tried following this guide as a first step to using the microblaze to communicate wtih DDR3: https://numato.com/kb/ddr3-memory-tests-on-nereid-k7-board/ Only the last part of the guide fails, my PuTTy terminal prints: --Starting Memory Test Application-- NOTE: This application runs with D-Cache disabled.As a result, cacheline requests will not be generated Testing memory region: mig_7series_0_memaddr Memory Controller: mig_7series_0 Base Address: 0x80000000 Size: 0x80000000 bytes --Starting Memory Test Application-- NOTE: This application runs with D-Cache disabled.As a result, cacheline requests will not be generated Testing memory region: mig _7series_0_memaddr Memory Controller: mig_7series_ 0 Base Address: 0x80000000 Size: 0x80000000 bytes When it should print: Somehow it's getting stuck communicating with the DDR3. I'm unsure why this is happening. 30/10/2024 22:48 Debugging with print statements tells me that this line is the culprit: status = Xil_TestMem32((u32*)range->base, 1024, 0xAAAA5555, XIL_TESTMEM_ALLMEMTESTS); status = Xil_TestMem32((u32*)range->base, 1024 , 0 xAAAA5555, XIL_TESTMEM_ALLMEMTESTS) ; in this file ( memorytest.c ): /****************************************************************************** * Copyright (c) 2021 Xilinx, Inc. All rights reserved. * SPDX-License-Identifier: MIT ******************************************************************************/ #include <stdio.h> #include \"xparameters.h\" #include \"xil_types.h\" #include \"xstatus.h\" #include \"xil_testmem.h\" #include \"platform.h\" #include \"memory_config.h\" #include \"xil_printf.h\" /* * memory_test.c: Test memory ranges present in the Hardware Design. * * This application runs with D-Caches disabled. As a result cacheline requests * will not be generated. * * For MicroBlaze/PowerPC, the BSP doesn't enable caches and this application * enables only I-Caches. For ARM, the BSP enables caches by default, so this * application disables D-Caches before running memory tests. */ void putnum(unsigned int num); void test_memory_range(struct memory_range_s *range) { XStatus status; /* This application uses print statements instead of xil_printf/printf * to reduce the text size. * * The default linker script generated for this application does not have * heap memory allocated. This implies that this program cannot use any * routines that allocate memory on heap (printf is one such function). * If you'd like to add such functions, then please generate a linker script * that does allocate sufficient heap memory. */ print(\"Testing memory region: \"); print(range->name); print(\"\\n\\r\"); print(\" Memory Controller: \"); print(range->ip); print(\"\\n\\r\"); #if defined(__MICROBLAZE__) && !defined(__arch64__) #if (XPAR_MICROBLAZE_ADDR_SIZE > 32) print(\" Base Address: 0x\"); putnum((range->base & UPPER_4BYTES_MASK) >> 32); putnum(range->base & LOWER_4BYTES_MASK);print(\"\\n\\r\"); #else print(\" Base Address: 0x\"); putnum(range->base); print(\"\\n\\r\"); #endif print(\" Size: 0x\"); putnum(range->size); print (\" \\n\\r\"); #else xil_printf(\" Base Address: 0x%lx \\n\\r\",range->base); xil_printf(\" Size: 0x%lx bytes \\n\\r\",range->size); #endif #if defined(__MICROBLAZE__) && !defined(__arch64__) && (XPAR_MICROBLAZE_ADDR_SIZE > 32) print(\"Performing tests (type 1)... \\n\\r\"); status = Xil_TestMem32((range->base & LOWER_4BYTES_MASK), ((range->base & UPPER_4BYTES_MASK) >> 32), 1024, 0xAAAA5555, XIL_TESTMEM_ALLMEMTESTS); print(\" 32-bit test: \"); print(status == XST_SUCCESS? \"PASSED!\":\"FAILED!\"); print(\"\\n\\r\"); status = Xil_TestMem16((range->base & LOWER_4BYTES_MASK), ((range->base & UPPER_4BYTES_MASK) >> 32), 2048, 0xAA55, XIL_TESTMEM_ALLMEMTESTS); print(\" 16-bit test: \"); print(status == XST_SUCCESS? \"PASSED!\":\"FAILED!\"); print(\"\\n\\r\"); status = Xil_TestMem8((range->base & LOWER_4BYTES_MASK), ((range->base & UPPER_4BYTES_MASK) >> 32), 4096, 0xA5, XIL_TESTMEM_ALLMEMTESTS); print(\" 8-bit test: \"); print(status == XST_SUCCESS? \"PASSED!\":\"FAILED!\"); print(\"\\n\\r\"); #else print(\"Performing tests (type 2)... \\n\\r\"); status = Xil_TestMem32((u32*)range->base, 1024, 0xAAAA5555, XIL_TESTMEM_ALLMEMTESTS); print(\" 32-bit test: \"); print(status == XST_SUCCESS? \"PASSED!\":\"FAILED!\"); print(\"\\n\\r\"); status = Xil_TestMem16((u16*)range->base, 2048, 0xAA55, XIL_TESTMEM_ALLMEMTESTS); print(\" 16-bit test: \"); print(status == XST_SUCCESS? \"PASSED!\":\"FAILED!\"); print(\"\\n\\r\"); status = Xil_TestMem8((u8*)range->base, 4096, 0xA5, XIL_TESTMEM_ALLMEMTESTS); print(\" 8-bit test: \"); print(status == XST_SUCCESS? \"PASSED!\":\"FAILED!\"); print(\"\\n\\r\"); #endif } int main() { sint32 i; init_platform(); print(\"--Starting Memory Test Application--\\n\\r\"); print(\"NOTE: This application runs with D-Cache disabled.\"); print(\"As a result, cacheline requests will not be generated\\n\\r\"); for (i = 0; i < n_memory_ranges; i++) { test_memory_range(&memory_ranges[i]); } print(\"--Memory Test Application Complete--\\n\\r\"); print(\"Successfully ran Memory Test Application\"); cleanup_platform(); return 0; } /****************************************************************************** * Copyright (c) 2021 Xilinx, Inc. All rights reserved. * SPDX-License-Identifier: MIT ******************************************************************************/ #include <stdio.h> #include \"xparameters.h\" #include \"xil_types.h\" #include \"xstatus.h\" #include \"xil_testmem.h\" #include \"platform.h\" #include \"memory_config.h\" #include \"xil_printf.h\" /* * memory_test.c: Test memory ranges present in the Hardware Design. * * This application runs with D-Caches disabled. As a result cacheline requests * will not be generated. * * For MicroBlaze/PowerPC, the BSP doesn't enable caches and this application * enables only I-Caches. For ARM, the BSP enables caches by default, so this * application disables D-Caches before running memory tests. */ void putnum(unsigned int num); void test_memory_range(struct memory_range_s *range) { XStatus status; /* This application uses print statements instead of xil_printf/printf * to reduce the text size. * * The default linker script generated for this application does not have * heap memory allocated. This implies that this program cannot use any * routines that allocate memory on heap (printf is one such function). * If you'd like to add such functions, then please generate a linker script * that does allocate sufficient heap memory. */ print(\"Testing memory region: \"); print(range->name); print(\"\\n\\r\"); print(\" Memory Controller: \"); print(range->ip); print(\"\\n\\r\"); #if defined(__MICROBLAZE__) && !defined(__arch64__) #if (XPAR_MICROBLAZE_ADDR_SIZE > 32) print(\" Base Address: 0x\"); putnum((range->base & UPPER_4BYTES_MASK) >> 32); putnum(range->base & LOWER_4BYTES_MASK);print(\"\\n\\r\"); #else print(\" Base Address: 0x\"); putnum(range->base); print(\"\\n\\r\"); #endif print(\" Size: 0x\"); putnum(range->size); print (\" \\n\\r\"); #else xil_printf(\" Base Address: 0x%lx \\n\\r\",range->base); xil_printf(\" Size: 0x%lx bytes \\n\\r\",range->size); #endif #if defined(__MICROBLAZE__) && !defined(__arch64__) && (XPAR_MICROBLAZE_ADDR_SIZE > 32) print(\"Performing tests (type 1)... \\n\\r\"); status = Xil_TestMem32((range->base & LOWER_4BYTES_MASK), ((range->base & UPPER_4BYTES_MASK) >> 32), 1024, 0xAAAA5555, XIL_TESTMEM_ALLMEMTESTS); print(\" 32-bit test: \"); print(status == XST_SUCCESS? \"PASSED!\":\"FAILED!\"); print(\"\\n\\r\"); status = Xil_TestMem16((range->base & LOWER_4BYTES_MASK), ((range->base & UPPER_4BYTES_MASK) >> 32), 2048, 0xAA55, XIL_TESTMEM_ALLMEMTESTS); print(\" 16-bit test: \"); print(status == XST_SUCCESS? \"PASSED!\":\"FAILED!\"); print(\"\\n\\r\"); status = Xil_TestMem8((range->base & LOWER_4BYTES_MASK), ((range->base & UPPER_4BYTES_MASK) >> 32), 4096, 0xA5, XIL_TESTMEM_ALLMEMTESTS); print(\" 8-bit test: \"); print(status == XST_SUCCESS? \"PASSED!\":\"FAILED!\"); print(\"\\n\\r\"); #else print(\"Performing tests (type 2)... \\n\\r\"); status = Xil_TestMem32((u32*)range->base, 1024, 0xAAAA5555, XIL_TESTMEM_ALLMEMTESTS); print(\" 32-bit test: \"); print(status == XST_SUCCESS? \"PASSED!\":\"FAILED!\"); print(\"\\n\\r\"); status = Xil_TestMem16((u16*)range->base, 2048, 0xAA55, XIL_TESTMEM_ALLMEMTESTS); print(\" 16-bit test: \"); print(status == XST_SUCCESS? \"PASSED!\":\"FAILED!\"); print(\"\\n\\r\"); status = Xil_TestMem8((u8*)range->base, 4096, 0xA5, XIL_TESTMEM_ALLMEMTESTS); print(\" 8-bit test: \"); print(status == XST_SUCCESS? \"PASSED!\":\"FAILED!\"); print(\"\\n\\r\"); #endif } int main() { sint32 i; init_platform(); print(\"--Starting Memory Test Application--\\n\\r\"); print(\"NOTE: This application runs with D-Cache disabled.\"); print(\"As a result, cacheline requests will not be generated\\n\\r\"); for (i = 0; i < n_memory_ranges; i++) { test_memory_range(&memory_ranges[i]); } print(\"--Memory Test Application Complete--\\n\\r\"); print(\"Successfully ran Memory Test Application\"); cleanup_platform(); return 0; } There's some warning about casting a pointer to an integer of different size. Let me try to debug that? 30/10/2024 22:56 /****************************************************************************** * Copyright (c) 2021 Xilinx, Inc. All rights reserved. * SPDX-License-Identifier: MIT ******************************************************************************/ #include <stdio.h> #include <stdint.h> // for uintptr_t #include \"xparameters.h\" #include \"xil_types.h\" #include \"xstatus.h\" #include \"xil_testmem.h\" #include \"platform.h\" #include \"memory_config.h\" #include \"xil_printf.h\" /* * memory_test.c: Test memory ranges present in the Hardware Design. * * This application runs with D-Caches disabled. As a result cacheline requests * will not be generated. * * For MicroBlaze/PowerPC, the BSP doesn't enable caches and this application * enables only I-Caches. For ARM, the BSP enables caches by default, so this * application disables D-Caches before running memory tests. */ void putnum(unsigned int num); void test_memory_range(struct memory_range_s *range) { XStatus status; print(\"Testing memory region: \"); print(range->name); print(\"\\n\\r\"); print(\" Memory Controller: \"); print(range->ip); print(\"\\n\\r\"); #if defined(__MICROBLAZE__) && !defined(__arch64__) && (XPAR_MICROBLAZE_ADDR_SIZE > 32) uintptr_t base_addr_lower = (uintptr_t)(range->base & LOWER_4BYTES_MASK); uintptr_t base_addr_upper = (uintptr_t)((range->base & UPPER_4BYTES_MASK) >> 32); print(\" Base Address: 0x\"); putnum(base_addr_upper); putnum(base_addr_lower); print(\"\\n\\r\"); #else // Use uintptr_t for cross-platform pointer-compatible integer uintptr_t base_addr = (uintptr_t)range->base; xil_printf(\" Base Address: 0x%lx \\n\\r\", base_addr); #endif print(\" Size: 0x\"); putnum(range->size); print (\" bytes\\n\\r\"); print(\"Performing tests (type 2)... \\n\\r\"); // Perform 32-bit test status = Xil_TestMem32((u32 *)base_addr, 1024, 0xAAAA5555, XIL_TESTMEM_ALLMEMTESTS); print(\" 32-bit test: \"); print(status == XST_SUCCESS ? \"PASSED!\" : \"FAILED!\"); print(\"\\n\\r\"); // Perform 16-bit test status = Xil_TestMem16((u16 *)base_addr, 2048, 0xAA55, XIL_TESTMEM_ALLMEMTESTS); print(\" 16-bit test: \"); print(status == XST_SUCCESS ? \"PASSED!\" : \"FAILED!\"); print(\"\\n\\r\"); // Perform 8-bit test status = Xil_TestMem8((u8 *)base_addr, 4096, 0xA5, XIL_TESTMEM_ALLMEMTESTS); print(\" 8-bit test: \"); print(status == XST_SUCCESS ? \"PASSED!\" : \"FAILED!\"); print(\"\\n\\r\"); } int main() { sint32 i; init_platform(); print(\"--Starting Memory Test Application--\\n\\r\"); print(\"NOTE: This application runs with D-Cache disabled.\"); print(\"As a result, cacheline requests will not be generated\\n\\r\"); for (i = 0; i < n_memory_ranges; i++) { test_memory_range(&memory_ranges[i]); } print(\"--Memory Test Application Complete--\\n\\r\"); print(\"Successfully ran Memory Test Application\"); cleanup_platform(); return 0; } /****************************************************************************** * Copyright (c) 2021 Xilinx, Inc. All rights reserved. * SPDX-License-Identifier: MIT ******************************************************************************/ #include <stdio.h> #include <stdint.h> // for uintptr_t #include \"xparameters.h\" #include \"xil_types.h\" #include \"xstatus.h\" #include \"xil_testmem.h\" #include \"platform.h\" #include \"memory_config.h\" #include \"xil_printf.h\" /* * memory_test.c: Test memory ranges present in the Hardware Design. * * This application runs with D-Caches disabled. As a result cacheline requests * will not be generated. * * For MicroBlaze/PowerPC, the BSP doesn't enable caches and this application * enables only I-Caches. For ARM, the BSP enables caches by default, so this * application disables D-Caches before running memory tests. */ void putnum(unsigned int num); void test_memory_range(struct memory_range_s *range) { XStatus status; print(\"Testing memory region: \"); print(range->name); print(\"\\n\\r\"); print(\" Memory Controller: \"); print(range->ip); print(\"\\n\\r\"); #if defined(__MICROBLAZE__) && !defined(__arch64__) && (XPAR_MICROBLAZE_ADDR_SIZE > 32) uintptr_t base_addr_lower = (uintptr_t)(range->base & LOWER_4BYTES_MASK); uintptr_t base_addr_upper = (uintptr_t)((range->base & UPPER_4BYTES_MASK) >> 32); print(\" Base Address: 0x\"); putnum(base_addr_upper); putnum(base_addr_lower); print(\"\\n\\r\"); #else // Use uintptr_t for cross-platform pointer-compatible integer uintptr_t base_addr = (uintptr_t)range->base; xil_printf(\" Base Address: 0x%lx \\n\\r\", base_addr); #endif print(\" Size: 0x\"); putnum(range->size); print (\" bytes\\n\\r\"); print(\"Performing tests (type 2)... \\n\\r\"); // Perform 32-bit test status = Xil_TestMem32((u32 *)base_addr, 1024, 0xAAAA5555, XIL_TESTMEM_ALLMEMTESTS); print(\" 32-bit test: \"); print(status == XST_SUCCESS ? \"PASSED!\" : \"FAILED!\"); print(\"\\n\\r\"); // Perform 16-bit test status = Xil_TestMem16((u16 *)base_addr, 2048, 0xAA55, XIL_TESTMEM_ALLMEMTESTS); print(\" 16-bit test: \"); print(status == XST_SUCCESS ? \"PASSED!\" : \"FAILED!\"); print(\"\\n\\r\"); // Perform 8-bit test status = Xil_TestMem8((u8 *)base_addr, 4096, 0xA5, XIL_TESTMEM_ALLMEMTESTS); print(\" 8-bit test: \"); print(status == XST_SUCCESS ? \"PASSED!\" : \"FAILED!\"); print(\"\\n\\r\"); } int main() { sint32 i; init_platform(); print(\"--Starting Memory Test Application--\\n\\r\"); print(\"NOTE: This application runs with D-Cache disabled.\"); print(\"As a result, cacheline requests will not be generated\\n\\r\"); for (i = 0; i < n_memory_ranges; i++) { test_memory_range(&memory_ranges[i]); } print(\"--Memory Test Application Complete--\\n\\r\"); print(\"Successfully ran Memory Test Application\"); cleanup_platform(); return 0; } I changed the code to this to remove the warnings; but no luck. The output is the same. 30/10/2024 23:01 I discovered the ddr3 was not getting the correct clock signal (it was getting the \"locked\" signal from the clock wizard, not sure how that happened or how it even generated a bitstream). I've fixed the error and will try again. 30/10/2024 23:18 I tried creating the same project on the Linux Mint computer in the lab as Vivado runs faster on linux. However, I couldn't open vitis. I found one person who had the same issue as me with no explanation other than \"this distro is not officially supported\": https://adaptivesupport.amd.com/s/question/0D54U00008mtLFpSAM/vitis-20232-exits-immediately-on-ubuntu-2404-no-error-messages-displayed?language=en_US 30/10/2024 23:26 I discovered the ddr3 was not getting the correct clock signal (it was getting the \"locked\" signal from the clock wizard, not sure how that happened or how it even generated a bitstream). I've fixed the error and will try again. This fix ended up working: --Starting Memory Test Application-- NOTE: This application runs with D-Cache disabled.As a result, cacheline requests will not be generated Testing memory region: mig_7series_0_memaddr Memory Controller: mig_7series_0 Base Address: 0x80000000 Size: 0x80000000 bytes 32-bit test: PASSED! 16-bit test: PASSED! 8-bit test: PASSED! --Memory Test Application Complete-- Successfully ran Memory Test Application --Starting Memory Test Application-- NOTE: This application runs with D-Cache disabled.As a result, cacheline requests will not be generated Testing memory region: mig _7series_0_memaddr Memory Controller: mig_7series_ 0 Base Address: 0x80000000 Size: 0x80000000 bytes 32-bit test: PASSED! 16-bit test: PASSED! 8-bit test: PASSED! --Memory Test Application Complete-- Successfully ran Memory Test Application 31/10/2024 00:20 I cratred the following block design I added a PCIe DMA bridge (XDMA) and an AXI smart connect to try to hook up M03A_XI of the microblaze axi periphereal and the PCIe DMA Bridge to the DDR3. This seems very naive to me. For instance, I don't know what the AXI smart connect does with the two clocks I put in. I also don't know if it's problematic that the aresetn port is linked to just the one provided by the PCIe DMA bridge when there is a arestn signal input from the microblaze to the microblaze peripheal for M03 which drives S00 of the AXI smart connect. This design passes valdation on both my windows and linux systems I'm trying it on. It succesfully generates a bitstream on linux, but not windows. I don't know why. The diagrams appear the same to me on window and linux but on windows I get this error: [DRC REQP-1619] IBUFDS_GTE2_driven_by_IBUF: IBUFDS_GTE2 ddr3_i/util_ds_buf/U0/USE_IBUFDS_GTE2.GEN_IBUFDS_GTE2[0].IBUFDS_GTE2_I pins I and IB should be driven by IBUFs. [DRC REQP-1619] IBUFDS_GTE2_driven_by_IBUF: IBUFDS_GTE2 ddr3_i/util_ds_buf/U0/USE_IBUFDS_GTE2 .GEN_IBUFDS_GTE2 [0] .IBUFDS_GTE2_I pins I and IB should be driven by IBUFs. looking it up it seems to be some gigabit transciever pad (whatever that means): https://docs.amd.com/r/en-US/ug953-vivado-7series-libraries/IBUFDS_GTE2 I have no idea how that applies to this design. The only thing I can figure is the error is due to differences in vivado (windows is on 2022.3 while Linux is on 2023.2). Looking in the netlist after opening the synthesized design, the netlist is not the same. So the all the ports in the constraints file are not there (but are present in the linux case). Maybe that's the issue? Who knows set_property -dict {PACKAGE_PIN K6} [get_ports pcie_refclk_clk_p] set_property -dict {PACKAGE_PIN K5} [get_ports pcie_refclk_clk_n] set_property -dict {PACKAGE_PIN R3} [get_ports {pcie_rxn[3]}] set_property -dict {PACKAGE_PIN R4} [get_ports {pcie_rxp[3]}] set_property -dict {PACKAGE_PIN N3} [get_ports {pcie_rxn[2]}] set_property -dict {PACKAGE_PIN N4} [get_ports {pcie_rxp[2]}] set_property -dict {PACKAGE_PIN L3} [get_ports {pcie_rxn[1]}] set_property -dict {PACKAGE_PIN L4} [get_ports {pcie_rxp[1]}] set_property -dict {PACKAGE_PIN J3} [get_ports {pcie_rxn[0]}] set_property -dict {PACKAGE_PIN J4} [get_ports {pcie_rxp[0]}] set_property -dict {PACKAGE_PIN P1} [get_ports {pcie_txn[3]}] set_property -dict {PACKAGE_PIN P2} [get_ports {pcie_txp[3]}] set_property -dict {PACKAGE_PIN M1} [get_ports {pcie_txn[2]}] set_property -dict {PACKAGE_PIN M2} [get_ports {pcie_txp[2]}] set_property -dict {PACKAGE_PIN K1} [get_ports {pcie_txn[1]}] set_property -dict {PACKAGE_PIN K2} [get_ports {pcie_txp[1]}] set_property -dict {PACKAGE_PIN H1} [get_ports {pcie_txn[0]}] set_property -dict {PACKAGE_PIN H2} [get_ports {pcie_txp[0]}] set_property -dict {PACKAGE_PIN E21 IOSTANDARD LVCMOS33} [get_ports pcie_reset] set_property -dict {PACKAGE_PIN J26 IOSTANDARD LVCMOS33} [get_ports red_blue_tri_o[0]] set_property -dict {PACKAGE_PIN H26 IOSTANDARD LVCMOS33} [get_ports green] set_property -dict {PACKAGE_PIN G26 IOSTANDARD LVCMOS33} [get_ports red_blue_tri_o[1]] set_property BITSTREAM.CONFIG.CONFIGRATE 16 [current_design] set_property BITSTREAM.GENERAL.COMPRESS TRUE [current_design] set_property BITSTREAM.CONFIG.SPI_BUSWIDTH 4 [current_design] set_property -dict {PACKAGE_PIN K6} [get_ports pcie_refclk_clk_p] set_property -dict {PACKAGE_PIN K5} [get_ports pcie_refclk_clk_n] set_property -dict {PACKAGE_PIN R3} [get_ports {pcie_rxn[3]}] set_property -dict {PACKAGE_PIN R4} [get_ports {pcie_rxp[3]}] set_property -dict {PACKAGE_PIN N3} [get_ports {pcie_rxn[2]}] set_property -dict {PACKAGE_PIN N4} [get_ports {pcie_rxp[2]}] set_property -dict {PACKAGE_PIN L3} [get_ports {pcie_rxn[1]}] set_property -dict {PACKAGE_PIN L4} [get_ports {pcie_rxp[1]}] set_property -dict {PACKAGE_PIN J3} [get_ports {pcie_rxn[0]}] set_property -dict {PACKAGE_PIN J4} [get_ports {pcie_rxp[0]}] set_property -dict {PACKAGE_PIN P1} [get_ports {pcie_txn[3]}] set_property -dict {PACKAGE_PIN P2} [get_ports {pcie_txp[3]}] set_property -dict {PACKAGE_PIN M1} [get_ports {pcie_txn[2]}] set_property -dict {PACKAGE_PIN M2} [get_ports {pcie_txp[2]}] set_property -dict {PACKAGE_PIN K1} [get_ports {pcie_txn[1]}] set_property -dict {PACKAGE_PIN K2} [get_ports {pcie_txp[1]}] set_property -dict {PACKAGE_PIN H1} [get_ports {pcie_txn[0]}] set_property -dict {PACKAGE_PIN H2} [get_ports {pcie_txp[0]}] set_property -dict {PACKAGE_PIN E21 IOSTANDARD LVCMOS33} [get_ports pcie_reset] set_property -dict {PACKAGE_PIN J26 IOSTANDARD LVCMOS33} [get_ports red_blue_tri_o[0]] set_property -dict {PACKAGE_PIN H26 IOSTANDARD LVCMOS33} [get_ports green] set_property -dict {PACKAGE_PIN G26 IOSTANDARD LVCMOS33} [get_ports red_blue_tri_o[1]] set_property BITSTREAM.CONFIG.CONFIGRATE 16 [current_design] set_property BITSTREAM.GENERAL.COMPRESS TRUE [current_design] set_property BITSTREAM.CONFIG.SPI_BUSWIDTH 4 [current_design] 31/10/2024 00:39 I exported the bitstream on the linux machine, and moved it over to vitis on the windows machine (yes this is a pain). I see the following over the serial line via PuTTy: NOTE: This application runs with D-Cache disabled.As a result, cacheline requests will not be generated Testing memory region: mig_7series_0_memaddr Memory Controller: mig_7series_0 Base Address: 0x80000000 Size: 0x80000000 bytes NOTE: This application runs with D-Cache disabled.As a result, cacheline requests will not be generated Testing memory region: mig _7series_0_memaddr Memory Controller: mig_7series_ 0 Base Address: 0x80000000 Size: 0x80000000 bytes This is the same symptom I had before where the microblaze can't reach the ddr3 because it's improperly configured. This is expected considering what I wrote in the above note. 31/10/2024 14:23 It seems the correct question to ask at this point is \"what is the best/proper way to connect two masters AXIs to a MIG IP block? Multipel MIG blocks? Multiple master ports on the MIG? Here are some forum links: A similar issue: https://adaptivesupport.amd.com/s/question/0D52E00006iHuLnSAK/multiple-mig-ips-or-multiple-controllers?language=en_US Poor efficiency for this guy using a MIG with two clients: https://adaptivesupport.amd.com/s/question/0D52E00006hpk77SAA/poor-mig-effiency-for-multiple-clients?language=en_US Evidence that the \"number of controllers\" is an artifact: https://adaptivesupport.amd.com/s/question/0D52E00006hpjL0SAI/bank-sharing-among-two-mig-controllers?language=en_US Something about multiple data ports: https://adaptivesupport.amd.com/s/question/0D52E00006hpUwwSAE/how-can-i-get-more-that-1-application-port-in-7-series-mig?language=en_US Multiport memory controller: https://docs.amd.com/v/u/en-US/xapp1164 I may also ask my own version of this question on some combination of the AMD support forums and Reddit r/FPGA forum.",
    "textLength": 3087
  },
  {
    "kind": "work-log",
    "title": "21_09_2025 - 27_09_2025.html",
    "fileName": "21_09_2025 - 27_09_2025.html",
    "url": "resources/work_logs/21_09_2025 - 27_09_2025.html",
    "createdDate": "2025-09-21",
    "text": "21/09/2025 - 27/09/2025 21/09/2025 - 27/09/2025 23/09/2025 15:33 1. SampicController The main controller that owns and manages global state of the SAMPIC crate and orchestrates initialization, configuration, and data collection. Likely needs to pass around: Crate parameters Frontend parameters Collector parameters Responsibilities Owns global objects : CrateInfoStruct info CrateParamStruct params void* eventBuffer ML_Frame* mlFrames EventStruct event Initialize settings Default mode \u2192 all settings Custom mode \u2192 some settings Apply settings Default mode \u2192 all settings Custom mode \u2192 selected settings Control data collection Start collection Default mode \u2192 launches thread Custom mode \u2192 TBD Stop collection \u2192 stops thread Cleanup resources 2. SampicCollector A dedicated class meant to run in its own thread to fill an event buffer. Behavior Collects events: Grabs a given number of events (while given read conditions) Default: current implementation in frontend Custom: needs design Adds events to event buffer Sleeps for a configurable time interval Repeats loop 3. SampicEventBuffer Configurable-size buffer for holding events. Provides methods to: Retrieve \u201clatest\u201d event Retrieve \u201cnext\u201d or other custom queries This mirrors the existing frontend_event_buffer structure in processing/sampic_processing/collector . 4. Custom User Methods Wrap controller logic in helper functions for simplified user workflows. sampic_custom_init_settings sampic_custom_apply_settings sampic_custom_collect File/Module Mapping (based on current tree) Controller include/integration/sampic/controller/sampic_controller.h src/integration/sampic/controller/sampic_controller.cpp Collector include/integration/sampic/collector/sampic_collector.h src/integration/sampic/collector/sampic_collector.cpp Event Buffer include/integration/sampic/collector/sampic_event_buffer.h src/integration/sampic/collector/sampic_event_buffer.cpp Configs include/integration/sampic/config/sampic_crate_config.h include/integration/sampic/config/sampic_collector_config.h 23/09/2025 20:08 (sampic_dev) pioneer@localhost:~/jcarlton/projects/midas_sampic/experiments/sampic_daq/scripts$ ./run.sh -i 0 [INFO] Running Sampic Frontend with index 00... Connect to experiment SAMPIC... OK [SAMPIC_Frontend00,INFO] Frontend \"SAMPIC_Frontend00\" started Init hardware... [02:06:21] [info] [SAMPIC_DAQ] Logger 'SAMPIC_DAQ' initialized at level info [02:06:21] [info] [SAMPIC_DAQ] InitSettingsModeExample: Initializing SAMPIC system... ************************************************* New socket (13) with IP address 192.168.0.4 and port 27015. ************************************************* Warning Rd(): only 15 bytes of 17 have actually been read [02:06:22] [info] [SAMPIC_DAQ] InitSettingsModeExample: Connection opened with 1 FE boards. [02:06:23] [warning] [SAMPIC_DAQ] InitSettingsModeExample: Calibration files missing, continuing anyway... [02:06:23] [info] [SAMPIC_DAQ] InitSettingsModeExample: Event memory allocated successfully. Frontend name : SAMPIC_Frontend00 Event buffer size : 671088640 User max event size : 134217728 User max frag. size : 671088640 # of events per buffer : 5 OK [02:06:30] [info] [SAMPIC_DAQ] Logger 'SAMPIC_DAQ' initialized at level info [02:06:30] [info] [SAMPIC_DAQ] Stopping SAMPIC run... [02:06:31] [info] [SAMPIC_DAQ] Cleaning up SAMPIC resources... [02:06:31] [info] [SAMPIC_DAQ] InitSettingsModeExample: Initializing SAMPIC system... ************************************************* New socket (13) with IP address 192.168.0.4 and port 27015. ************************************************* Warning Rd(): only 15 bytes of 17 have actually been read [02:06:31] [info] [SAMPIC_DAQ] InitSettingsModeExample: Connection opened with 1 FE boards. [02:06:32] [warning] [SAMPIC_DAQ] InitSettingsModeExample: Calibration files missing, continuing anyway... [02:06:32] [info] [SAMPIC_DAQ] InitSettingsModeExample: Event memory allocated successfully. [02:06:32] [info] [SAMPIC_DAQ] ApplySettingsModeExample: Setting trigger options... [02:06:32] [error] [SAMPIC_DAQ] SAMPIC error (FEB=1, chip=0, ch=0) in SetChannelMode (code=-8) [02:06:32] [error] [SAMPIC_DAQ] ApplySettingsModeExample: Exception during apply: SAMPIC error in SetChannelMode (code -8) [02:06:32] [error] [SAMPIC_DAQ] Apply settings failed: SAMPIC error in SetChannelMode (code -8) (sampic_dev) pioneer@localhost:~/jcarlton/projects/midas_sampic/experiments/sampic_daq/scripts$ ./run.sh -i 0 [INFO] Running Sampic Frontend with index 00... Connect to experiment SAMPIC... OK [SAMPIC_Frontend00,INFO] Frontend \"SAMPIC_Frontend00\" started Init hardware... [02:06:21] [info] [SAMPIC_DAQ] Logger 'SAMPIC_DAQ' initialized at level info [02:06:21] [info] [SAMPIC_DAQ] InitSettingsModeExample: Initializing SAMPIC system... ************************************************* New socket (13) with IP address 192.168.0.4 and port 27015. ************************************************* Warning Rd(): only 15 bytes of 17 have actually been read [02:06:22] [info] [SAMPIC_DAQ] InitSettingsModeExample: Connection opened with 1 FE boards. [02:06:23] [warning] [SAMPIC_DAQ] InitSettingsModeExample: Calibration files missing, continuing anyway... [02:06:23] [info] [SAMPIC_DAQ] InitSettingsModeExample: Event memory allocated successfully. Frontend name : SAMPIC_Frontend00 Event buffer size : 671088640 User max event size : 134217728 User max frag. size : 671088640 # of events per buffer : 5 OK [02:06:30] [info] [SAMPIC_DAQ] Logger 'SAMPIC_DAQ' initialized at level info [02:06:30] [info] [SAMPIC_DAQ] Stopping SAMPIC run... [02:06:31] [info] [SAMPIC_DAQ] Cleaning up SAMPIC resources... [02:06:31] [info] [SAMPIC_DAQ] InitSettingsModeExample: Initializing SAMPIC system... ************************************************* New socket (13) with IP address 192.168.0.4 and port 27015. ************************************************* Warning Rd(): only 15 bytes of 17 have actually been read [02:06:31] [info] [SAMPIC_DAQ] InitSettingsModeExample: Connection opened with 1 FE boards. [02:06:32] [warning] [SAMPIC_DAQ] InitSettingsModeExample: Calibration files missing, continuing anyway... [02:06:32] [info] [SAMPIC_DAQ] InitSettingsModeExample: Event memory allocated successfully. [02:06:32] [info] [SAMPIC_DAQ] ApplySettingsModeExample: Setting trigger options... [02:06:32] [error] [SAMPIC_DAQ] SAMPIC error (FEB=1, chip=0, ch=0) in SetChannelMode (code=-8) [02:06:32] [error] [SAMPIC_DAQ] ApplySettingsModeExample: Exception during apply: SAMPIC error in SetChannelMode (code -8) [02:06:32] [error] [SAMPIC_DAQ] Apply settings failed: SAMPIC error in SetChannelMode (code -8) My guess is this error is caused by (FEB=1, chip=0, ch=0) either being incorrectly formatted or not belonging to anything plugged in (I think there's only one frontend board plugged in, so this would make sense). 23/09/2025 20:55 I clicked run and was beginning to see events, but then the whole computer locked up (I can't even ssh or do anything). I'm not sure if this is coincidence or somehow my frontend locked up the whole computer... (sampic_dev) pioneer@localhost:~/jcarlton/projects/midas_sampic/experiments/sampic_daq/scripts$ ./run.sh -i 0 [INFO] Running Sampic Frontend with index 00... Connect to experiment SAMPIC... OK [SAMPIC_Frontend00,INFO] Frontend \"SAMPIC_Frontend00\" started Init hardware... [02:51:20] [info] [SAMPIC_DAQ] Logger 'SAMPIC_DAQ' initialized at level info [02:51:21] [info] [SAMPIC_DAQ] InitSettingsModeExample: Initializing SAMPIC system... ************************************************* New socket (13) with IP address 192.168.0.4 and port 27015. ************************************************* Warning Rd(): only 15 bytes of 17 have actually been read [02:51:21] [info] [SAMPIC_DAQ] InitSettingsModeExample: Connection opened with 1 FE boards. [02:51:22] [warning] [SAMPIC_DAQ] InitSettingsModeExample: Calibration files missing, continuing anyway... [02:51:22] [info] [SAMPIC_DAQ] InitSettingsModeExample: Event memory allocated successfully. Frontend name : SAMPIC_Frontend00 Event buffer size : 671088640 User max event size : 134217728 User max frag. size : 671088640 # of events per buffer : 5 OK [02:51:27] [info] [SAMPIC_DAQ] Logger 'SAMPIC_DAQ' initialized at level info [02:51:27] [info] [SAMPIC_DAQ] ApplySettingsModeExample: Setting trigger options... [02:51:27] [info] [SAMPIC_DAQ] ApplySettingsModeExample: Trigger options set successfully. [02:51:27] [info] [SAMPIC_DAQ] Collector rebuilt with new configuration [02:51:27] [info] [SAMPIC_DAQ] Starting SAMPIC run... Started run 17 [02:51:27] [info] [SAMPIC_DAQ] SAMPIC Collector started in mode 1 ss_timed_mutex_wait_for_sec: long wait for mutex buffer mutex, 2.9 seconds. 312.1 seconds until timeout (sampic_dev) pioneer@localhost:~/jcarlton/projects/midas_sampic/experiments/sampic_daq/scripts$ ./run.sh -i 0 [INFO] Running Sampic Frontend with index 00... Connect to experiment SAMPIC... OK [SAMPIC_Frontend00,INFO] Frontend \"SAMPIC_Frontend00\" started Init hardware... [02:51:20] [info] [SAMPIC_DAQ] Logger 'SAMPIC_DAQ' initialized at level info [02:51:21] [info] [SAMPIC_DAQ] InitSettingsModeExample: Initializing SAMPIC system... ************************************************* New socket (13) with IP address 192.168.0.4 and port 27015. ************************************************* Warning Rd(): only 15 bytes of 17 have actually been read [02:51:21] [info] [SAMPIC_DAQ] InitSettingsModeExample: Connection opened with 1 FE boards. [02:51:22] [warning] [SAMPIC_DAQ] InitSettingsModeExample: Calibration files missing, continuing anyway... [02:51:22] [info] [SAMPIC_DAQ] InitSettingsModeExample: Event memory allocated successfully. Frontend name : SAMPIC_Frontend00 Event buffer size : 671088640 User max event size : 134217728 User max frag. size : 671088640 # of events per buffer : 5 OK [02:51:27] [info] [SAMPIC_DAQ] Logger 'SAMPIC_DAQ' initialized at level info [02:51:27] [info] [SAMPIC_DAQ] ApplySettingsModeExample: Setting trigger options... [02:51:27] [info] [SAMPIC_DAQ] ApplySettingsModeExample: Trigger options set successfully. [02:51:27] [info] [SAMPIC_DAQ] Collector rebuilt with new configuration [02:51:27] [info] [SAMPIC_DAQ] Starting SAMPIC run... Started run 17 [02:51:27] [info] [SAMPIC_DAQ] SAMPIC Collector started in mode 1 ss_timed_mutex_wait_for_sec: long wait for mutex buffer mutex, 2.9 seconds. 312.1 seconds until timeout It's possible I ate up all the RAM causing the computer to become compeltely unresponsive? I have no idea. 23/09/2025 21:34 After about 30 minutes the computer corrected itself. So I tried running the frontend again and again the computer became unresponsive. So it is almost certainly something to do with the current frontend code. 24/09/2025 02:58 I slowed the rate down and added a sleep before the sampic retries. I'm guessing what happened in teh \"soft reset\" logic just took the whole network of the computer (probably have sampic plugged into the same NIC as the ethernet, causing a block up?). This seemed to stop the issues. 24/09/2025 03:54 / ====================================================================== // Readout (full-waveform, variable-length hits; one ADxx + one ATxx) // ====================================================================== INT read_sampic_event(char *pevent, INT) { if (!g_system_initialized || !g_controller) { spdlog::warn(\"read_sampic_event: system not initialized, skipping\"); return 0; } const auto new_events = g_controller->buffer().getSince(g_last_evt_ts); if (new_events.empty()) { spdlog::debug(\"read_sampic_event: no new events since last timestamp\"); return 0; } // Init MIDAS event container bk_init32(pevent); // ------------------------- DATA BANK (ADxx) ------------------------- { const auto data_bank = make_bank_name(g_fe_cfg.data_bank_prefix, g_frontend_index); uint8_t* pdata = nullptr; bk_create(pevent, data_bank.c_str(), TID_UINT8, (void**)&pdata); uint8_t* const pdata_start = pdata; // Pack each collected SAMPIC event in sequence for (size_t iev = 0; iev < new_events.size(); ++iev) { const auto& tse = new_events[iev]; if (!tse.event) { spdlog::warn(\"read_sampic_event: event {} has null pointer, skipping\", iev); continue; } const auto ev = tse.event; // --- Event header --- const SampicEventLite evhdr{ static_cast<uint32_t>(ev->NbOfHitsInEvent), static_cast<uint32_t>(ev->TriggerData.NbOfTriggers) }; std::memcpy(pdata, &evhdr, sizeof(evhdr)); pdata += sizeof(evhdr); spdlog::debug(\"Packing event {} \u2192 hits={}, triggers={}\", iev, evhdr.nb_hits, evhdr.nb_triggers); // --- Hits (variable-length) --- for (int i = 0; i < ev->NbOfHitsInEvent; ++i) { const auto& h = ev->Hit[i]; // Choose a sane clamp to avoid corrupt banks if upstream is wrong // (tweak if you know chip max samples; 4096 is conservative) constexpr int kMaxSafeSamples = 4096; int data_size = std::max(0, std::min(h.DataSize, kMaxSafeSamples)); SampicHitMeta meta{}; meta.fe_board = h.FeBoardIndex; meta.sampic_idx = h.SampicIndex; meta.channel = h.Channel; meta.hit_number = h.HitNumber; meta.data_size = data_size; meta.amplitude = h.Amplitude; meta.baseline = h.Baseline; meta.peak = h.Peak; meta.time_ns = h.TimeInstant; // Write meta std::memcpy(pdata, &meta, sizeof(meta)); pdata += sizeof(meta); // Write all samples (uint16_t) const size_t bytes_samples = static_cast<size_t>(data_size) * sizeof(uint16_t); if (data_size > 0) { std::memcpy(pdata, h.OrderedRawDataSamples, bytes_samples); pdata += bytes_samples; } spdlog::trace(\" hit {}: board={}, sampic={}, ch={}, hit#={}, nsamp={}, \" \"amp={:.2f}, base={:.2f}, peak={:.2f}, t={:.3f} ns \" \"(wrote {} + {} bytes)\", i, meta.fe_board, meta.sampic_idx, meta.channel, meta.hit_number, meta.data_size, meta.amplitude, meta.baseline, meta.peak, meta.time_ns, (int)sizeof(meta), (int)bytes_samples); } } bk_close(pevent, pdata); spdlog::debug(\"Closed data bank {} ({} bytes)\", data_bank, (int)(pdata - pdata_start)); } // ------------------------ TIMING BANK (ATxx) ------------------------ { const auto timing_bank = make_bank_name(g_fe_cfg.timing_bank_prefix, g_frontend_index); uint8_t* ptiming = nullptr; bk_create(pevent, timing_bank.c_str(), TID_UINT8, (void**)&ptiming); uint8_t* const ptiming_start = ptiming; struct TimingPayload { uint64_t timestamp_ns; uint32_t prepare_us, read_us, decode_us, total_us; }; for (const auto& tse : new_events) { TimingPayload tp; tp.timestamp_ns = std::chrono::duration_cast<std::chrono::nanoseconds>( tse.timestamp.time_since_epoch()).count(); tp.prepare_us = tse.timing.prepare_duration.count(); tp.read_us = tse.timing.read_duration.count(); tp.decode_us = tse.timing.decode_duration.count(); tp.total_us = tse.timing.total_duration.count(); std::memcpy(ptiming, &tp, sizeof(tp)); ptiming += sizeof(tp); spdlog::trace(\" timing: ts={} ns, prep={}us, read={}us, dec={}us, total={}us\", tp.timestamp_ns, tp.prepare_us, tp.read_us, tp.decode_us, tp.total_us); } bk_close(pevent, ptiming); spdlog::debug(\"Closed timing bank {} ({} bytes)\", timing_bank, (int)(ptiming - ptiming_start)); } // Advance watermark g_last_evt_ts = new_events.back().timestamp; const int total_size = bk_size(pevent); spdlog::debug(\"read_sampic_event: MIDAS event size {}\", total_size); return total_size; } / ====================================================================== // Readout (full-waveform, variable-length hits; one ADxx + one ATxx) // ====================================================================== INT read_sampic_event(char *pevent, INT) { if (!g_system_initialized || !g_controller) { spdlog::warn(\"read_sampic_event: system not initialized, skipping\"); return 0; } const auto new_events = g_controller->buffer().getSince(g_last_evt_ts); if (new_events.empty()) { spdlog::debug(\"read_sampic_event: no new events since last timestamp\"); return 0; } // Init MIDAS event container bk_init32(pevent); // ------------------------- DATA BANK (ADxx) ------------------------- { const auto data_bank = make_bank_name(g_fe_cfg.data_bank_prefix, g_frontend_index); uint8_t* pdata = nullptr; bk_create(pevent, data_bank.c_str(), TID_UINT8, (void**)&pdata); uint8_t* const pdata_start = pdata; // Pack each collected SAMPIC event in sequence for (size_t iev = 0; iev < new_events.size(); ++iev) { const auto& tse = new_events[iev]; if (!tse.event) { spdlog::warn(\"read_sampic_event: event {} has null pointer, skipping\", iev); continue; } const auto ev = tse.event; // --- Event header --- const SampicEventLite evhdr{ static_cast<uint32_t>(ev->NbOfHitsInEvent), static_cast<uint32_t>(ev->TriggerData.NbOfTriggers) }; std::memcpy(pdata, &evhdr, sizeof(evhdr)); pdata += sizeof(evhdr); spdlog::debug(\"Packing event {} \u2192 hits={}, triggers={}\", iev, evhdr.nb_hits, evhdr.nb_triggers); // --- Hits (variable-length) --- for (int i = 0; i < ev->NbOfHitsInEvent; ++i) { const auto& h = ev->Hit[i]; // Choose a sane clamp to avoid corrupt banks if upstream is wrong // (tweak if you know chip max samples; 4096 is conservative) constexpr int kMaxSafeSamples = 4096; int data_size = std::max(0, std::min(h.DataSize, kMaxSafeSamples)); SampicHitMeta meta{}; meta.fe_board = h.FeBoardIndex; meta.sampic_idx = h.SampicIndex; meta.channel = h.Channel; meta.hit_number = h.HitNumber; meta.data_size = data_size; meta.amplitude = h.Amplitude; meta.baseline = h.Baseline; meta.peak = h.Peak; meta.time_ns = h.TimeInstant; // Write meta std::memcpy(pdata, &meta, sizeof(meta)); pdata += sizeof(meta); // Write all samples (uint16_t) const size_t bytes_samples = static_cast<size_t>(data_size) * sizeof(uint16_t); if (data_size > 0) { std::memcpy(pdata, h.OrderedRawDataSamples, bytes_samples); pdata += bytes_samples; } spdlog::trace(\" hit {}: board={}, sampic={}, ch={}, hit#={}, nsamp={}, \" \"amp={:.2f}, base={:.2f}, peak={:.2f}, t={:.3f} ns \" \"(wrote {} + {} bytes)\", i, meta.fe_board, meta.sampic_idx, meta.channel, meta.hit_number, meta.data_size, meta.amplitude, meta.baseline, meta.peak, meta.time_ns, (int)sizeof(meta), (int)bytes_samples); } } bk_close(pevent, pdata); spdlog::debug(\"Closed data bank {} ({} bytes)\", data_bank, (int)(pdata - pdata_start)); } // ------------------------ TIMING BANK (ATxx) ------------------------ { const auto timing_bank = make_bank_name(g_fe_cfg.timing_bank_prefix, g_frontend_index); uint8_t* ptiming = nullptr; bk_create(pevent, timing_bank.c_str(), TID_UINT8, (void**)&ptiming); uint8_t* const ptiming_start = ptiming; struct TimingPayload { uint64_t timestamp_ns; uint32_t prepare_us, read_us, decode_us, total_us; }; for (const auto& tse : new_events) { TimingPayload tp; tp.timestamp_ns = std::chrono::duration_cast<std::chrono::nanoseconds>( tse.timestamp.time_since_epoch()).count(); tp.prepare_us = tse.timing.prepare_duration.count(); tp.read_us = tse.timing.read_duration.count(); tp.decode_us = tse.timing.decode_duration.count(); tp.total_us = tse.timing.total_duration.count(); std::memcpy(ptiming, &tp, sizeof(tp)); ptiming += sizeof(tp); spdlog::trace(\" timing: ts={} ns, prep={}us, read={}us, dec={}us, total={}us\", tp.timestamp_ns, tp.prepare_us, tp.read_us, tp.decode_us, tp.total_us); } bk_close(pevent, ptiming); spdlog::debug(\"Closed timing bank {} ({} bytes)\", timing_bank, (int)(ptiming - ptiming_start)); } // Advance watermark g_last_evt_ts = new_events.back().timestamp; const int total_size = bk_size(pevent); spdlog::debug(\"read_sampic_event: MIDAS event size {}\", total_size); return total_size; } Added some \"toy\" readout where we read out parts of the event into a midas bank. No event building yet, but it seems things are working. Example midas event: (sampic_dev) pioneer@localhost:~/jcarlton$ mdump - MIDAS revision: Thu Sep 4 08:58:15 2025 +0200 - midas-2025-01-a-327-gd2158fbd on branch develop -- Enter <!> to Exit ------- Midas Dump --- ------------------------ Event# 1 ------------------------ Evid:0001- Mask:0000- Serial:13- Time:0x68d3a2d1- Dsize:232/0xe8 #banks:2 - Bank list:-AD00AT00- Bank:AD00 Length: 176(I*1)/44(I*4)/176(Type) Type:Unsigned Bytes 1-> 0x01 0x00 0x00 0x00 0x00 0x00 0x00 0x00 0x00 0x00 0x00 0x00 0x02 0x00 0x00 0x00 17-> 0x22 0x00 0x00 0x00 0x00 0x00 0x00 0x00 0x40 0x00 0x00 0x00 0x00 0x00 0x80 0xbf 33-> 0x00 0x00 0x80 0xbf 0x00 0x00 0x80 0xbf 0x00 0x00 0x00 0x00 0x00 0x00 0xf0 0xbf 49-> 0xd8 0x03 0xc2 0x03 0xb9 0x03 0xc8 0x03 0xd1 0x03 0xdb 0x03 0x9b 0x03 0x9e 0x03 65-> 0xc4 0x03 0xb5 0x03 0xbe 0x03 0xd8 0x03 0xc4 0x03 0xbd 0x03 0xb2 0x03 0xa8 0x03 81-> 0xaf 0x03 0xc3 0x03 0xde 0x03 0xd3 0x03 0xdc 0x03 0xd7 0x03 0xc8 0x03 0xde 0x03 97-> 0xc2 0x03 0x9d 0x03 0xbb 0x03 0xd7 0x03 0xd3 0x03 0xca 0x03 0xda 0x03 0xbe 0x03 113-> 0xaa 0x03 0xd6 0x03 0xd2 0x03 0xcb 0x03 0xc7 0x03 0xbb 0x03 0xb0 0x03 0xb5 0x03 129-> 0xc2 0x03 0xc8 0x03 0xb4 0x03 0xbd 0x03 0xa0 0x03 0xb8 0x03 0xdc 0x03 0xce 0x03 145-> 0xe8 0x03 0xb1 0x03 0xb9 0x03 0xb6 0x03 0xd0 0x03 0xb6 0x03 0xa1 0x03 0xe4 0x03 161-> 0xc7 0x03 0xcf 0x03 0xaa 0x03 0xcb 0x03 0xb7 0x03 0xb2 0x03 0xa5 0x03 0xdb 0x03 Bank:AT00 Length: 24(I*1)/6(I*4)/24(Type) Type:Unsigned Bytes 1-> 0x2b 0xa7 0x0c 0xed 0x40 0x47 0x00 0x00 0x1c 0x00 0x00 0x00 0x0f 0x00 0x00 0x00 17-> 0x06 0x00 0x00 0x00 0xb2 0x0f 0x00 0x00 (sampic_dev) pioneer@localhost:~/jcarlton$ mdump - MIDAS revision: Thu Sep 4 08:58:15 2025 +0200 - midas-2025-01-a-327-gd2158fbd on branch develop -- Enter <!> to Exit ------- Midas Dump --- ------------------------ Event# 1 ------------------------ Evid:0001- Mask:0000- Serial:13- Time:0x68d3a2d1- Dsize:232/0xe8 #banks:2 - Bank list:-AD00AT00- Bank:AD00 Length: 176(I*1)/44(I*4)/176(Type) Type:Unsigned Bytes 1-> 0x01 0x00 0x00 0x00 0x00 0x00 0x00 0x00 0x00 0x00 0x00 0x00 0x02 0x00 0x00 0x00 17-> 0x22 0x00 0x00 0x00 0x00 0x00 0x00 0x00 0x40 0x00 0x00 0x00 0x00 0x00 0x80 0xbf 33-> 0x00 0x00 0x80 0xbf 0x00 0x00 0x80 0xbf 0x00 0x00 0x00 0x00 0x00 0x00 0xf0 0xbf 49-> 0xd8 0x03 0xc2 0x03 0xb9 0x03 0xc8 0x03 0xd1 0x03 0xdb 0x03 0x9b 0x03 0x9e 0x03 65-> 0xc4 0x03 0xb5 0x03 0xbe 0x03 0xd8 0x03 0xc4 0x03 0xbd 0x03 0xb2 0x03 0xa8 0x03 81-> 0xaf 0x03 0xc3 0x03 0xde 0x03 0xd3 0x03 0xdc 0x03 0xd7 0x03 0xc8 0x03 0xde 0x03 97-> 0xc2 0x03 0x9d 0x03 0xbb 0x03 0xd7 0x03 0xd3 0x03 0xca 0x03 0xda 0x03 0xbe 0x03 113-> 0xaa 0x03 0xd6 0x03 0xd2 0x03 0xcb 0x03 0xc7 0x03 0xbb 0x03 0xb0 0x03 0xb5 0x03 129-> 0xc2 0x03 0xc8 0x03 0xb4 0x03 0xbd 0x03 0xa0 0x03 0xb8 0x03 0xdc 0x03 0xce 0x03 145-> 0xe8 0x03 0xb1 0x03 0xb9 0x03 0xb6 0x03 0xd0 0x03 0xb6 0x03 0xa1 0x03 0xe4 0x03 161-> 0xc7 0x03 0xcf 0x03 0xaa 0x03 0xcb 0x03 0xb7 0x03 0xb2 0x03 0xa5 0x03 0xdb 0x03 Bank:AT00 Length: 24(I*1)/6(I*4)/24(Type) Type:Unsigned Bytes 1-> 0x2b 0xa7 0x0c 0xed 0x40 0x47 0x00 0x00 0x1c 0x00 0x00 0x00 0x0f 0x00 0x00 0x00 17-> 0x06 0x00 0x00 0x00 0xb2 0x0f 0x00 0x00",
    "textLength": 2999
  },
  {
    "kind": "work-log",
    "title": "28_04_2024 - 04_05_2024.html",
    "fileName": "28_04_2024 - 04_05_2024.html",
    "url": "resources/work_logs/28_04_2024 - 04_05_2024.html",
    "createdDate": "2024-04-28",
    "text": "28/04/2024 - 04/05/2024 28/04/2024 - 04/05/2024 29/04/2024 04:40 mbggpscap New capture: CH0: 2024-04-29 08:35:35.7975583 UTC New capture: CH0: 2024-04-29 08:35:35.7977584 UTC New capture: CH0: 2024-04-29 08:35:35.7979585 UTC New capture: CH0: 2024-04-29 08:35:35.7981586 UTC New capture: CH0: 2024-04-29 08:35:35.7983586 UTC New capture: CH0: 2024-04-29 08:35:35.7987588 UTC New capture: CH0: 2024-04-29 08:35:35.7989589 UTC New capture: CH0: 2024-04-29 08:35:35.7991589 UTC New capture: CH0: 2024-04-29 08:35:35.7993590 UTC New capture: CH0: 2024-04-29 08:35:35.7995591 UTC New capture: CH0: 2024-04-29 08:35:35.7997592 UTC New capture: CH0: 2024-04-29 08:35:35.7999592 UTC New capture: CH0: 2024-04-29 08:35:35.8003594 UTC New capture: CH0: 2024-04-29 08:35:35.8005595 UTC New capture: CH0: 2024-04-29 08:35:35.8007595 UTC New capture: CH0: 2024-04-29 08:35:35.8009596 UTC New capture: CH0: 2024-04-29 08:35:35.8011597 UTC New capture: CH0: 2024-04-29 08:35:35.8013598 UTC New capture: CH0: 2024-04-29 08:35:35.8015598 UTC New capture: CH0: 2024-04-29 08:35:35.8019600 UTC New capture: CH0: 2024 - 04 - 29 08 : 35 : 35 . 7975583 UTC New capture: CH0: 2024 - 04 - 29 08 : 35 : 35 . 7977584 UTC New capture: CH0: 2024 - 04 - 29 08 : 35 : 35 . 7979585 UTC New capture: CH0: 2024 - 04 - 29 08 : 35 : 35 . 7981586 UTC New capture: CH0: 2024 - 04 - 29 08 : 35 : 35 . 7983586 UTC New capture: CH0: 2024 - 04 - 29 08 : 35 : 35 . 7987588 UTC New capture: CH0: 2024 - 04 - 29 08 : 35 : 35 . 7989589 UTC New capture: CH0: 2024 - 04 - 29 08 : 35 : 35 . 7991589 UTC New capture: CH0: 2024 - 04 - 29 08 : 35 : 35 . 7993590 UTC New capture: CH0: 2024 - 04 - 29 08 : 35 : 35 . 7995591 UTC New capture: CH0: 2024 - 04 - 29 08 : 35 : 35 . 7997592 UTC New capture: CH0: 2024 - 04 - 29 08 : 35 : 35 . 7999592 UTC New capture: CH0: 2024 - 04 - 29 08 : 35 : 35 . 8003594 UTC New capture: CH0: 2024 - 04 - 29 08 : 35 : 35 . 8005595 UTC New capture: CH0: 2024 - 04 - 29 08 : 35 : 35 . 8007595 UTC New capture: CH0: 2024 - 04 - 29 08 : 35 : 35 . 8009596 UTC New capture: CH0: 2024 - 04 - 29 08 : 35 : 35 . 8011597 UTC New capture: CH0: 2024 - 04 - 29 08 : 35 : 35 . 8013598 UTC New capture: CH0: 2024 - 04 - 29 08 : 35 : 35 . 8015598 UTC New capture: CH0: 2024 - 04 - 29 08 : 35 : 35 . 8019600 UTC 29/04/2024 05:23 Some plots of timing data taken from mbggpscap as seen above running at an internal trigger rate of 5kHz. I only included data after lines like: New capture: CH0: 2024-04-29 09:38:02.1233820 UTC << BUF OVR New capture: CH0: 2024 - 04 - 29 09 : 38 : 02 . 1233820 UTC << BUF OVR stopped occuring (so sort of a \"steady state\"). All captures scatter All captures histogram \"Normal\" captures scatter \"Normal\" captures scatter with a break \"Normal\" captures histogram 29/04/2024 05:39 I repeated the \"exercise\" at 4kHz. Some output: New capture: CH0: 2024-04-29 09:38:05.5506653 UTC New capture: CH0: 2024-04-29 09:38:05.5509154 UTC New capture: CH0: 2024-04-29 09:38:05.5511655 UTC New capture: CH0: 2024-04-29 09:38:05.5581676 UTC New capture: CH0: 2024-04-29 09:38:05.5584176 UTC New capture: CH0: 2024-04-29 09:38:05.5586677 UTC New capture: CH0: 2024-04-29 09:38:05.5589178 UTC New capture: CH0: 2024-04-29 09:38:05.5591679 UTC New capture: CH0: 2024-04-29 09:38:05.5594179 UTC New capture: CH0: 2024-04-29 09:38:05.5599181 UTC New capture: CH0: 2024-04-29 09:38:05.5601682 UTC New capture: CH0: 2024-04-29 09:38:05.5604182 UTC New capture: CH0: 2024-04-29 09:38:05.5606683 UTC New capture: CH0: 2024-04-29 09:38:05.5609184 UTC New capture: CH0: 2024-04-29 09:38:05.5611685 UTC New capture: CH0: 2024-04-29 09:38:05.5614185 UTC New capture: CH0: 2024-04-29 09:38:05.5619187 UTC New capture: CH0: 2024-04-29 09:38:05.5621688 UTC New capture: CH0: 2024-04-29 09:38:05.5624189 UTC New capture: CH0: 2024 - 04 - 29 09 : 38 : 05 . 5506653 UTC New capture: CH0: 2024 - 04 - 29 09 : 38 : 05 . 5509154 UTC New capture: CH0: 2024 - 04 - 29 09 : 38 : 05 . 5511655 UTC New capture: CH0: 2024 - 04 - 29 09 : 38 : 05 . 5581676 UTC New capture: CH0: 2024 - 04 - 29 09 : 38 : 05 . 5584176 UTC New capture: CH0: 2024 - 04 - 29 09 : 38 : 05 . 5586677 UTC New capture: CH0: 2024 - 04 - 29 09 : 38 : 05 . 5589178 UTC New capture: CH0: 2024 - 04 - 29 09 : 38 : 05 . 5591679 UTC New capture: CH0: 2024 - 04 - 29 09 : 38 : 05 . 5594179 UTC New capture: CH0: 2024 - 04 - 29 09 : 38 : 05 . 5599181 UTC New capture: CH0: 2024 - 04 - 29 09 : 38 : 05 . 5601682 UTC New capture: CH0: 2024 - 04 - 29 09 : 38 : 05 . 5604182 UTC New capture: CH0: 2024 - 04 - 29 09 : 38 : 05 . 5606683 UTC New capture: CH0: 2024 - 04 - 29 09 : 38 : 05 . 5609184 UTC New capture: CH0: 2024 - 04 - 29 09 : 38 : 05 . 5611685 UTC New capture: CH0: 2024 - 04 - 29 09 : 38 : 05 . 5614185 UTC New capture: CH0: 2024 - 04 - 29 09 : 38 : 05 . 5619187 UTC New capture: CH0: 2024 - 04 - 29 09 : 38 : 05 . 5621688 UTC New capture: CH0: 2024 - 04 - 29 09 : 38 : 05 . 5624189 UTC All captures scatter All captures histogram \"Normal\" captures scatter \"Normal\" captures scatter with a break \"Normal\" captures histogram 29/04/2024 17:48 Added some timing to the trigger thread, here's a snippet of the output Time taken for receiving GPS trigger: 6 microseconds Time taken for sending EOF signal: 4 microseconds Total time taken: 35 microseconds UCAP event received: 1714427301 seconds, 1021635023 fractions Time taken for getting ucap event: 9 microseconds Time taken for printing event timestamp: 2 microseconds Trigger Time: 2024-04-29 21:48:21.2378679 Time taken for getting current timestamp: 4 microseconds Current Time: 2024-04-29 21:48:21.4653731, Latency: 0.5 us Time taken for getting status of buffer: 11 microseconds Buffers Used: 582, Buffers Capacity: 584 Time taken for getting time of receipt: 0 microseconds GPS End Of Fill trigger received Time taken for receiving GPS trigger: 6 microseconds Time taken for sending EOF signal: 4 microseconds Total time taken: 36 microseconds UCAP event received: 1714427301 seconds, 1023138605 fractions Time taken for getting ucap event: 9 microseconds Time taken for printing event timestamp: 2 microseconds Trigger Time: 2024-04-29 21:48:21.2382180 Time taken for getting current timestamp: 4 microseconds Current Time: 2024-04-29 21:48:21.4657363, Latency: 0.5 us Time taken for getting status of buffer: 10 microseconds Buffers Used: 582, Buffers Capacity: 584 Time taken for getting time of receipt: 0 microseconds GPS End Of Fill trigger received Time taken for receiving GPS trigger: 5 microseconds Time taken for sending EOF signal: 4 microseconds Total time taken: 34 microseconds UCAP event received: 1714427301 seconds, 1026145726 fractions Time taken for getting ucap event: 9 microseconds Time taken for printing event timestamp: 2 microseconds Trigger Time: 2024-04-29 21:48:21.2389181 Time taken for getting current timestamp: 4 microseconds Current Time: 2024-04-29 21:48:21.4661028, Latency: 0.5 us Time taken for getting status of buffer: 17 microseconds Buffers Used: 583, Buffers Capacity: 584 Time taken for getting time of receipt: 0 microseconds Time taken for receiving GPS trigger: 6 microseconds Time taken for sending EOF signal: 4 microseconds Total time taken: 35 microseconds UCAP event received: 1714427301 seconds, 1021635023 fractions Time taken for getting ucap event: 9 microseconds Time taken for printing event timestamp: 2 microseconds Trigger Time: 2024-04-29 21:48:21.2378679 Time taken for getting current timestamp: 4 microseconds Current Time: 2024-04-29 21:48:21.4653731, Latency: 0.5 us Time taken for getting status of buffer: 11 microseconds Buffers Used: 582, Buffers Capacity: 584 Time taken for getting time of receipt: 0 microseconds GPS End Of Fill trigger received Time taken for receiving GPS trigger: 6 microseconds Time taken for sending EOF signal: 4 microseconds Total time taken: 36 microseconds UCAP event received: 1714427301 seconds, 1023138605 fractions Time taken for getting ucap event: 9 microseconds Time taken for printing event timestamp: 2 microseconds Trigger Time: 2024-04-29 21:48:21.2382180 Time taken for getting current timestamp: 4 microseconds Current Time: 2024-04-29 21:48:21.4657363, Latency: 0.5 us Time taken for getting status of buffer: 10 microseconds Buffers Used: 582, Buffers Capacity: 584 Time taken for getting time of receipt: 0 microseconds GPS End Of Fill trigger received Time taken for receiving GPS trigger: 5 microseconds Time taken for sending EOF signal: 4 microseconds Total time taken: 34 microseconds UCAP event received: 1714427301 seconds, 1026145726 fractions Time taken for getting ucap event: 9 microseconds Time taken for printing event timestamp: 2 microseconds Trigger Time: 2024-04-29 21:48:21.2389181 Time taken for getting current timestamp: 4 microseconds Current Time: 2024-04-29 21:48:21.4661028, Latency: 0.5 us Time taken for getting status of buffer: 17 microseconds Buffers Used: 583, Buffers Capacity: 584 Time taken for getting time of receipt: 0 microseconds I don't see any bottleneck, here are the explicit timings made: else if(trigger_source==GPS){ PCPS_HR_TIME ucap; PCPS_TIME_STAMP ts_now; char ws[80]; int32_t mbg_latency = 0; int rc = mbg_get_ucap_event(dh_gps, &ucap); if (rc != MBG_SUCCESS) { printf(\"Error: mbg_get_ucap_event() FAILED !\\n\"); usleep(1000); continue; } auto start_time = std::chrono::steady_clock::now(); printf(\"UCAP event received: %ld seconds, %ld fractions\\n\", ucap.tstamp.sec, ucap.tstamp.frac); auto end_time = std::chrono::steady_clock::now(); auto elapsed_time = std::chrono::duration_cast<std::chrono::microseconds>(end_time - start_time).count(); printf(\"Time taken for getting ucap event: %ld microseconds\\n\", elapsed_time); long int total_time = elapsed_time; if ((ucap.tstamp.sec || ucap.tstamp.frac)) { gps_evnt_counter++; start_time = std::chrono::steady_clock::now(); mbg_snprint_hr_tstamp(ws, sizeof(ws), &ucap.tstamp, 0); end_time = std::chrono::steady_clock::now(); elapsed_time = std::chrono::duration_cast<std::chrono::microseconds>(end_time - start_time).count(); printf(\"Time taken for printing event timestamp: %ld microseconds\\n\", elapsed_time); total_time += elapsed_time; printf(\"Trigger Time: %s\\n\", ws); start_time = std::chrono::steady_clock::now(); mbg_get_fast_hr_timestamp_comp(dh_gps, &ts_now, &mbg_latency); end_time = std::chrono::steady_clock::now(); elapsed_time = std::chrono::duration_cast<std::chrono::microseconds>(end_time - start_time).count(); printf(\"Time taken for getting current timestamp: %ld microseconds\\n\", elapsed_time); total_time += elapsed_time; mbg_snprint_hr_tstamp(ws, sizeof(ws), &ts_now, 0); printf(\"Current Time: %s, Latency: %.1f us \\n\", ws, (double)mbg_latency / 10.); start_time = std::chrono::steady_clock::now(); PCPS_UCAP_ENTRIES p_entries; mbg_get_ucap_entries(dh_gps, &p_entries); end_time = std::chrono::steady_clock::now(); elapsed_time = std::chrono::duration_cast<std::chrono::microseconds>(end_time - start_time).count(); printf(\"Time taken for getting status of buffer: %ld microseconds\\n\", elapsed_time); total_time += elapsed_time; printf(\"Buffers Used: %3i, Buffers Capacity: %3i \\n\", p_entries.used, p_entries.max); gps_tstamp_cap = ucap.tstamp; gps_tstamp_now = ts_now; start_time = std::chrono::steady_clock::now(); struct timeval tv_poll; int status = gettimeofday(&tv_poll, NULL); if (status != 0) { printf(\"ERROR! gettimeofday() failed\\n\"); tv_poll.tv_sec = 0; tv_poll.tv_usec = 0; } end_time = std::chrono::steady_clock::now(); elapsed_time = std::chrono::duration_cast<std::chrono::microseconds>(end_time - start_time).count(); printf(\"Time taken for getting time of receipt: %ld microseconds\\n\", elapsed_time); total_time += elapsed_time; start_time = std::chrono::steady_clock::now(); printf(\"GPS End Of Fill trigger received\\n\"); end_time = std::chrono::steady_clock::now(); elapsed_time = std::chrono::duration_cast<std::chrono::microseconds>(end_time - start_time).count(); printf(\"Time taken for receiving GPS trigger: %ld microseconds\\n\", elapsed_time); total_time += elapsed_time; trigger_time_info.trigger_nr = trigger_counter; trigger_time_info.trigger_mask = trigger_info.mask; trigger_time_info.time_s = ucap.tstamp.sec; trigger_time_info.time_us = ucap.tstamp.frac; start_time = std::chrono::steady_clock::now(); BOOL eof_sent = send_eof(trigger_time_info.trigger_nr, trigger_time_info.trigger_mask, trigger_time_info.time_s, trigger_time_info.time_us); end_time = std::chrono::steady_clock::now(); elapsed_time = std::chrono::duration_cast<std::chrono::microseconds>(end_time - start_time).count(); printf(\"Time taken for sending EOF signal: %ld microseconds\\n\", elapsed_time); total_time += elapsed_time; if (eof_sent) trigger_counter++; } else{ usleep(1000); } printf(\"Total time taken: %ld microseconds\\n\", total_time); } else if(trigger_source==GPS){ PCPS_HR_TIME ucap; PCPS_TIME_STAMP ts_now; char ws[80]; int32_t mbg_latency = 0; int rc = mbg_get_ucap_event(dh_gps, &ucap); if (rc != MBG_SUCCESS) { printf(\"Error: mbg_get_ucap_event() FAILED !\\n\"); usleep(1000); continue; } auto start_time = std::chrono::steady_clock::now(); printf(\"UCAP event received: %ld seconds, %ld fractions\\n\", ucap.tstamp.sec, ucap.tstamp.frac); auto end_time = std::chrono::steady_clock::now(); auto elapsed_time = std::chrono::duration_cast<std::chrono::microseconds>(end_time - start_time).count(); printf(\"Time taken for getting ucap event: %ld microseconds\\n\", elapsed_time); long int total_time = elapsed_time; if ((ucap.tstamp.sec || ucap.tstamp.frac)) { gps_evnt_counter++; start_time = std::chrono::steady_clock::now(); mbg_snprint_hr_tstamp(ws, sizeof(ws), &ucap.tstamp, 0); end_time = std::chrono::steady_clock::now(); elapsed_time = std::chrono::duration_cast<std::chrono::microseconds>(end_time - start_time).count(); printf(\"Time taken for printing event timestamp: %ld microseconds\\n\", elapsed_time); total_time += elapsed_time; printf(\"Trigger Time: %s\\n\", ws); start_time = std::chrono::steady_clock::now(); mbg_get_fast_hr_timestamp_comp(dh_gps, &ts_now, &mbg_latency); end_time = std::chrono::steady_clock::now(); elapsed_time = std::chrono::duration_cast<std::chrono::microseconds>(end_time - start_time).count(); printf(\"Time taken for getting current timestamp: %ld microseconds\\n\", elapsed_time); total_time += elapsed_time; mbg_snprint_hr_tstamp(ws, sizeof(ws), &ts_now, 0); printf(\"Current Time: %s, Latency: %.1f us \\n\", ws, (double)mbg_latency / 10.); start_time = std::chrono::steady_clock::now(); PCPS_UCAP_ENTRIES p_entries; mbg_get_ucap_entries(dh_gps, &p_entries); end_time = std::chrono::steady_clock::now(); elapsed_time = std::chrono::duration_cast<std::chrono::microseconds>(end_time - start_time).count(); printf(\"Time taken for getting status of buffer: %ld microseconds\\n\", elapsed_time); total_time += elapsed_time; printf(\"Buffers Used: %3i, Buffers Capacity: %3i \\n\", p_entries.used, p_entries.max); gps_tstamp_cap = ucap.tstamp; gps_tstamp_now = ts_now; start_time = std::chrono::steady_clock::now(); struct timeval tv_poll; int status = gettimeofday(&tv_poll, NULL); if (status != 0) { printf(\"ERROR! gettimeofday() failed\\n\"); tv_poll.tv_sec = 0; tv_poll.tv_usec = 0; } end_time = std::chrono::steady_clock::now(); elapsed_time = std::chrono::duration_cast<std::chrono::microseconds>(end_time - start_time).count(); printf(\"Time taken for getting time of receipt: %ld microseconds\\n\", elapsed_time); total_time += elapsed_time; start_time = std::chrono::steady_clock::now(); printf(\"GPS End Of Fill trigger received\\n\"); end_time = std::chrono::steady_clock::now(); elapsed_time = std::chrono::duration_cast<std::chrono::microseconds>(end_time - start_time).count(); printf(\"Time taken for receiving GPS trigger: %ld microseconds\\n\", elapsed_time); total_time += elapsed_time; trigger_time_info.trigger_nr = trigger_counter; trigger_time_info.trigger_mask = trigger_info.mask; trigger_time_info.time_s = ucap.tstamp.sec; trigger_time_info.time_us = ucap.tstamp.frac; start_time = std::chrono::steady_clock::now(); BOOL eof_sent = send_eof(trigger_time_info.trigger_nr, trigger_time_info.trigger_mask, trigger_time_info.time_s, trigger_time_info.time_us); end_time = std::chrono::steady_clock::now(); elapsed_time = std::chrono::duration_cast<std::chrono::microseconds>(end_time - start_time).count(); printf(\"Time taken for sending EOF signal: %ld microseconds\\n\", elapsed_time); total_time += elapsed_time; if (eof_sent) trigger_counter++; } else{ usleep(1000); } printf(\"Total time taken: %ld microseconds\\n\", total_time); } This is further evidence the issue is with the meinberg card itself, as the code can keep up at a rate of ~40us = ~25kHz. 29/04/2024 19:43 By adding an \"ODB mode\" to the trigger_thread in master, I'm able to get the master to keep up with the AMC triggers. Of course, we lose the timestamp data. Relevant changes to code are mostly made here (MasterGM2/frontend.cpp:2233) else if(trigger_source==ODB){ //Update the \"current event_read\" to be consistent with the ODB int size = sizeof(current_event_read); char key[1024]; sprintf(key, \"/Equipment/%s/Statistics/Events sent\", master_settings_odb.encoder_fe); if (db_get_value(hDB, 0, key, &current_event_read, &size, TID_DOUBLE, FALSE) != DB_SUCCESS) { cm_msg(MERROR, __FUNCTION__, \"Cannot Get Value [%s] in ODB\", key); break; } // Print the values of last_event_read and current_event_read for debugging //std::cout << \"Last Event Read: \" << last_event_read << std::endl; //std::cout << \"Current Event Read: \" << current_event_read << std::endl; if (last_event_read != current_event_read) { //Cause an event to be made (?) // Calculate the difference between current_event_read and last_event_read int event_difference = static_cast<int>(current_event_read - last_event_read); // Cap the event difference to the maximum allowed value event_difference = std::min(event_difference, MAX_EVENT_DIFFERENCE); // Get time of day from system status = gettimeofday( &tv_poll, NULL); if ( status != 0) { printf(\"ERROR! gettimeofday() failed\\n\"); tv_poll.tv_sec = 0; tv_poll.tv_usec = 0; } //printf(\"trigger_thread: GPS End Of Fill trigger received\\n\"); for (int i = 0; i < event_difference; ++i) { trigger_time_info.trigger_nr = trigger_counter; trigger_time_info.trigger_mask = trigger_info.mask; trigger_time_info.time_s = tv_poll.tv_sec; trigger_time_info.time_us = tv_poll.tv_usec; trigger_time_info.time_recv_s = tv_poll.tv_sec; trigger_time_info.time_recv_us = tv_poll.tv_usec; // Send the EOF signal to slaves BOOL eof_sent = send_eof(trigger_time_info.trigger_nr, trigger_time_info.trigger_mask, trigger_time_info.time_s, trigger_time_info.time_us); // increment run-by-run trigger counter if ( eof_sent ) trigger_counter++; } last_event_read = current_event_read; } } else if(trigger_source==ODB){ //Update the \"current event_read\" to be consistent with the ODB int size = sizeof(current_event_read); char key[1024]; sprintf(key, \"/Equipment/%s/Statistics/Events sent\", master_settings_odb.encoder_fe); if (db_get_value(hDB, 0, key, &current_event_read, &size, TID_DOUBLE, FALSE) != DB_SUCCESS) { cm_msg(MERROR, __FUNCTION__, \"Cannot Get Value [%s] in ODB\", key); break; } // Print the values of last_event_read and current_event_read for debugging //std::cout << \"Last Event Read: \" << last_event_read << std::endl; //std::cout << \"Current Event Read: \" << current_event_read << std::endl; if (last_event_read != current_event_read) { //Cause an event to be made (?) // Calculate the difference between current_event_read and last_event_read int event_difference = static_cast<int>(current_event_read - last_event_read); // Cap the event difference to the maximum allowed value event_difference = std::min(event_difference, MAX_EVENT_DIFFERENCE); // Get time of day from system status = gettimeofday( &tv_poll, NULL); if ( status != 0) { printf(\"ERROR! gettimeofday() failed\\n\"); tv_poll.tv_sec = 0; tv_poll.tv_usec = 0; } //printf(\"trigger_thread: GPS End Of Fill trigger received\\n\"); for (int i = 0; i < event_difference; ++i) { trigger_time_info.trigger_nr = trigger_counter; trigger_time_info.trigger_mask = trigger_info.mask; trigger_time_info.time_s = tv_poll.tv_sec; trigger_time_info.time_us = tv_poll.tv_usec; trigger_time_info.time_recv_s = tv_poll.tv_sec; trigger_time_info.time_recv_us = tv_poll.tv_usec; // Send the EOF signal to slaves BOOL eof_sent = send_eof(trigger_time_info.trigger_nr, trigger_time_info.trigger_mask, trigger_time_info.time_s, trigger_time_info.time_us); // increment run-by-run trigger counter if ( eof_sent ) trigger_counter++; } last_event_read = current_event_read; } } 01/05/2024 04:45 20:26:20.521 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 20:26:20.521 2024/04/29 [AMC13001,TALK] Warning: DAQ | AMC13001 TCP Ring buffer close to full (100.000000%) 20:11:15.827 2024/04/29 [MasterGM2,TALK] Alarm: DAQ | MasterGM2 discovered severe fill number mismatch 20:09:33.048 2024/04/29 [mhttpd,INFO] Run #137 started 20:26:20.521 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 20:26:20.521 2024/04/29 [AMC13001,TALK] Warning: DAQ | AMC13001 TCP Ring buffer close to full (100.000000%) 20:11:15.827 2024/04/29 [MasterGM2,TALK] Alarm: DAQ | MasterGM2 discovered severe fill number mismatch 20:09:33.048 2024/04/29 [mhttpd,INFO] Run #137 started Then eventually: 23:40:05.004 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:40:00.100 2024/04/29 [MasterGM2,TALK] Alarm: CCC Run Aborted 23:40:00.010 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:39:55.005 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:39:50.011 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:39:45.006 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:39:40.012 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:39:35.007 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:39:30.002 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:39:25.008 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:39:20.003 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:39:15.009 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:39:10.004 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:39:05.010 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:39:00.013 2024/04/29 [MasterGM2,TALK] Alarm: CCC Run Aborted 23:39:00.005 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:38:55.011 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:38:50.006 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:38:45.012 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:38:40.007 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:38:35.002 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:38:30.008 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:38:25.003 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:38:20.009 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:38:15.004 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:38:10.010 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:38:05.005 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:38:00.640 2024/04/29 [MasterGM2,TALK] Alarm: CCC Run Aborted 23:38:00.011 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:37:55.006 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:37:50.012 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:37:45.007 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:37:40.002 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:37:35.008 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:37:30.003 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:37:25.009 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:37:20.004 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:37:15.010 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:37:10.005 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:37:05.011 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:37:00.006 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:36:55.012 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:36:50.007 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:36:45.002 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:36:40.008 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:36:35.003 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:36:30.009 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:36:25.004 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:36:20.010 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:36:15.005 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:36:10.011 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:36:05.006 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:36:00.012 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:35:55.007 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:35:50.002 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:35:45.008 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:35:40.003 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers 23:40:05.004 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:40:00.100 2024/04/29 [MasterGM2,TALK] Alarm: CCC Run Aborted 23:40:00.010 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:39:55.005 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:39:50.011 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:39:45.006 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:39:40.012 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:39:35.007 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:39:30.002 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:39:25.008 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:39:20.003 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:39:15.009 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:39:10.004 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:39:05.010 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:39:00.013 2024/04/29 [MasterGM2,TALK] Alarm: CCC Run Aborted 23:39:00.005 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:38:55.011 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:38:50.006 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:38:45.012 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:38:40.007 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:38:35.002 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:38:30.008 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:38:25.003 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:38:20.009 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:38:15.004 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:38:10.010 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:38:05.005 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:38:00.640 2024/04/29 [MasterGM2,TALK] Alarm: CCC Run Aborted 23:38:00.011 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:37:55.006 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:37:50.012 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:37:45.007 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:37:40.002 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:37:35.008 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:37:30.003 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:37:25.009 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:37:20.004 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:37:15.010 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:37:10.005 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:37:05.011 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:37:00.006 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:36:55.012 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:36:50.007 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:36:45.002 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:36:40.008 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:36:35.003 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:36:30.009 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:36:25.004 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:36:20.010 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:36:15.005 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:36:10.011 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:36:05.006 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:36:00.012 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:35:55.007 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:35:50.002 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:35:45.008 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 23:35:40.003 2024/04/29 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers",
    "textLength": 5554
  },
  {
    "kind": "work-log",
    "title": "11_02_2024 - 17_02_2024.html",
    "fileName": "11_02_2024 - 17_02_2024.html",
    "url": "resources/work_logs/11_02_2024 - 17_02_2024.html",
    "createdDate": "2024-02-11",
    "text": "11/02/2024 - 17/02/2024 11/02/2024 - 17/02/2024 14/02/2024 01:09 PuTTY does work rather simply. Here's the steps I got to open a serial terminal: Download PuTTY ( https://www.chiark.greenend.org.uk/~sgtatham/putty/latest.html ) After installation is done, launch PuTTY Under connection type, click the 'Serial' radio button We now need to find what serial line the cable is using. Open Device Manager on Windows, expand the 'Ports (COM & LPT)' section. If this section doesn't exist, there is no \"connection\" through the cable. If the 'Ports (COM & LPT)' section does exist, check for what COM lines are availible. I saw 'COM3' as my only option. In PuTTY, type the correct COM line under 'Serial Line' (ex. 'COM3'). Click open. An empty terminal window shoudl appear if all went well. 14/02/2024 01:45 To get past the other error complaining about the microblazer not being found, I found a few forum posts: https://forum.digilent.com/topic/22903-executables-selected-for-download-on-to-the-following-processors-doesnt-exist-or-incorrectly-specified-do-you-wish-to-ignore-and-proceed-1-microblaze_0/ https://support.xilinx.com/s/question/0D52E00006hpLB0SAM/vitis-warning-executable-selected-for-download-on-the-following-processor-doesnt-exist-1-ps7cortexa90?language=en_US Both suggested increasing the instruction memory. I tried following these steps from a comment in the second thread.: Here's the solution: Increase the bram_if_ctrl memory size for BOTH Data and Instruction In the Vivado Flow Navigator, select Open Block Design Select the Address Editor tab Select the pulldown menu for /microblaze_0_local_memory/dlmb_bram_if_cntlr Select 512k (or greater) Do this for BOTH microblaze_0/Data and microblaze_0/Instruction Save your design Generate the Block Design (select the Global option if you have inouts in your design) Generate the Bitstream Export Hardware (include bitstream) Select Tools -> Launch VITIS Create your design in VITIS Good Luck! Hope this helps. However, I had to no luck. I might try even more than 512k (I don't know how high I can go). I also don't generate 14/02/2024 02:01 Okay, I was able to get it to work. I noticed some of the forum pages said there must be a .elf file in your Debug folder. I didn't even have a Debug folder, so I looked up how to generate a .elf file and found this guide: https://docs.xilinx.com/r/en-US/pg322-v-scenechange-detect/Create-the-ELF-in-the-Vitis-Tools That basically just told me I need to actually build the project. Here are the updated steps: I \"mixed and matched\" these guides: https://numato.com/kb/vivado-design-suite-create-microblaze-based-design-using-ip-integrator-with-nereid-kintex-7-pci-express-development-board/ https://docs.xilinx.com/r/en-US/pg322-v-scenechange-detect/Create-the-ELF-in-the-Vitis-Tools https://www.youtube.com/watch?v=C-RtLnagFuQ To try to program the board with vitis. First, I followed the numato guide linked above. I additionally changed the \"microblaze_0_local_memory\" under bother /microblaze_0/Data and /microblaze_0/Instruction to 512K in the address editor before saving my diagram and creating the HDL wrapper (following the steps above). After generating a bitstream, I am able to program the board in Vitis with the following steps: In Vivado In the tools dropdown in the top left, Select Launch Vitis IDE Choose any folder for a workspace, click Launch Click 'Create Application Project' Hit Next In the top bar, click Create a new platform from hardware (XSA), click browse and select the .xsa file we made earlier (mine is in C:\\Users\\custo\\nereid_microblazer\\nereid_design_wrapper.xsa). click 'Next'. For application Project name, type \"hello_world\", click 'Next' twice. Select \"Hello World\" from the emebdded software developtment templates. Click 'Finish' Power on the board with 12V power supply. Have only the 12pin JTAG connected otherwise (not the microUSB). From the XIlinx dropdown in the top left sleect program device. Select the bitstream generated earlier. Mine is at C:\\Users\\custo\\nereid_microblazer\\nereid_microblazer.runs\\impl_1\\nereid_design_wrapper.bit. Do similar for hte bmm/mmi file, mine is at C:\\Users\\custo\\nereid_microblazer\\nereid_microblazer.runs\\impl_1\\nereid_design_wrapper.mmi. Leave everything else default. Click 'Program' (note: I had to autoconnect in the hardware manager in Vivado beforehand or else it complains it can't find the board) Now plug in the micro usb. Open PuTTY and create a serial window using the correct COM port (see steps above) Right click \"hello_world_system\" in the explorer tab on the left. Click 'Build Project' Check that there a Debug Folder now and that you see a hello_world.elf. Right click \"hello_world_system\" again, click \"Run As\"/\"Launch Hardware\". After some time, you should see the hello world output in the PuTTY serial window.",
    "textLength": 802
  },
  {
    "kind": "work-log",
    "title": "27_07_2025 - 03_08_2025.html",
    "fileName": "27_07_2025 - 03_08_2025.html",
    "url": "resources/work_logs/27_07_2025 - 03_08_2025.html",
    "createdDate": "2025-07-27",
    "text": "27/07/2025 - 03/08/2025 27/07/2025 - 03/08/2025 29/07/2025 00:45 These next few notes may be \"out of order\" but the sum of the information is the same. [root@dhcp-10-163-105-238 webpage_scripts]# iperf3 -s ----------------------------------------------------------- Server listening on 5201 ----------------------------------------------------------- Accepted connection from 10.163.102.46, port 41738 [ 5] local 10.163.105.238 port 5201 connected to 10.163.102.46 port 41746 [ ID] Interval Transfer Bitrate [ 5] 0.00-1.01 sec 10.9 MBytes 90.1 Mbits/sec [ 5] 1.01-2.02 sec 11.2 MBytes 94.0 Mbits/sec [ 5] 2.02-3.02 sec 11.2 MBytes 93.9 Mbits/sec [ 5] 3.02-4.02 sec 11.1 MBytes 94.0 Mbits/sec [ 5] 4.02-5.02 sec 11.2 MBytes 94.0 Mbits/sec [ 5] 5.02-6.01 sec 11.1 MBytes 94.0 Mbits/sec [ 5] 6.01-7.02 sec 11.2 MBytes 93.9 Mbits/sec [ 5] 7.02-8.02 sec 11.2 MBytes 94.0 Mbits/sec [ 5] 8.02-9.01 sec 11.1 MBytes 94.0 Mbits/sec [ 5] 9.01-10.02 sec 11.2 MBytes 94.0 Mbits/sec [ 5] 10.02-10.09 sec 768 KBytes 94.0 Mbits/sec - - - - - - - - - - - - - - - - - - - - - - - - - [ ID] Interval Transfer Bitrate [ 5] 0.00-10.09 sec 112 MBytes 93.6 Mbits/sec receiver ----------------------------------------------------------- Server listening on 5201 ----------------------------------------------------------- ^Ciperf3: interrupt - the server has terminated [root@dhcp-10-163-105-238 webpage_scripts]# [root@dhcp-10-163-105-238 webpage_scripts]# iperf3 -s ----------------------------------------------------------- Server listening on 5201 ----------------------------------------------------------- Accepted connection from 10.163.102.46, port 41738 [ 5] local 10.163.105.238 port 5201 connected to 10.163.102.46 port 41746 [ ID] Interval Transfer Bitrate [ 5] 0.00-1.01 sec 10.9 MBytes 90.1 Mbits/sec [ 5] 1.01-2.02 sec 11.2 MBytes 94.0 Mbits/sec [ 5] 2.02-3.02 sec 11.2 MBytes 93.9 Mbits/sec [ 5] 3.02-4.02 sec 11.1 MBytes 94.0 Mbits/sec [ 5] 4.02-5.02 sec 11.2 MBytes 94.0 Mbits/sec [ 5] 5.02-6.01 sec 11.1 MBytes 94.0 Mbits/sec [ 5] 6.01-7.02 sec 11.2 MBytes 93.9 Mbits/sec [ 5] 7.02-8.02 sec 11.2 MBytes 94.0 Mbits/sec [ 5] 8.02-9.01 sec 11.1 MBytes 94.0 Mbits/sec [ 5] 9.01-10.02 sec 11.2 MBytes 94.0 Mbits/sec [ 5] 10.02-10.09 sec 768 KBytes 94.0 Mbits/sec - - - - - - - - - - - - - - - - - - - - - - - - - [ ID] Interval Transfer Bitrate [ 5] 0.00-10.09 sec 112 MBytes 93.6 Mbits/sec receiver ----------------------------------------------------------- Server listening on 5201 ----------------------------------------------------------- ^Ciperf3: interrupt - the server has terminated [root@dhcp-10-163-105-238 webpage_scripts]# [root@dhcp-10-163-102-46 scripts]# iperf3 -c 10.163.105.238 Connecting to host 10.163.105.238, port 5201 [ 5] local 10.163.102.46 port 41746 connected to 10.163.105.238 port 5201 [ ID] Interval Transfer Bitrate Retr Cwnd [ 5] 0.00-1.00 sec 13.3 MBytes 111 Mbits/sec 14 356 KBytes [ 5] 1.00-2.00 sec 11.9 MBytes 100 Mbits/sec 0 416 KBytes [ 5] 2.00-3.00 sec 10.9 MBytes 91.7 Mbits/sec 0 457 KBytes [ 5] 3.00-4.00 sec 10.9 MBytes 91.7 Mbits/sec 0 482 KBytes [ 5] 4.00-5.00 sec 11.0 MBytes 92.3 Mbits/sec 2 370 KBytes [ 5] 5.00-6.00 sec 11.9 MBytes 100 Mbits/sec 0 392 KBytes [ 5] 6.00-7.00 sec 10.9 MBytes 91.8 Mbits/sec 0 404 KBytes [ 5] 7.00-8.00 sec 10.9 MBytes 91.7 Mbits/sec 0 424 KBytes [ 5] 8.00-9.00 sec 10.9 MBytes 91.7 Mbits/sec 0 444 KBytes [ 5] 9.00-10.00 sec 11.9 MBytes 100 Mbits/sec 0 462 KBytes - - - - - - - - - - - - - - - - - - - - - - - - - [ ID] Interval Transfer Bitrate Retr [ 5] 0.00-10.00 sec 115 MBytes 96.3 Mbits/sec 16 sender [ 5] 0.00-10.09 sec 112 MBytes 93.6 Mbits/sec receiver iperf Done. [root@dhcp-10-163-102-46 scripts]# [root@dhcp-10-163-102-46 scripts]# iperf3 -c 10.163.105.238 Connecting to host 10.163.105.238, port 5201 [ 5] local 10.163.102.46 port 41746 connected to 10.163.105.238 port 5201 [ ID] Interval Transfer Bitrate Retr Cwnd [ 5] 0.00-1.00 sec 13.3 MBytes 111 Mbits/sec 14 356 KBytes [ 5] 1.00-2.00 sec 11.9 MBytes 100 Mbits/sec 0 416 KBytes [ 5] 2.00-3.00 sec 10.9 MBytes 91.7 Mbits/sec 0 457 KBytes [ 5] 3.00-4.00 sec 10.9 MBytes 91.7 Mbits/sec 0 482 KBytes [ 5] 4.00-5.00 sec 11.0 MBytes 92.3 Mbits/sec 2 370 KBytes [ 5] 5.00-6.00 sec 11.9 MBytes 100 Mbits/sec 0 392 KBytes [ 5] 6.00-7.00 sec 10.9 MBytes 91.8 Mbits/sec 0 404 KBytes [ 5] 7.00-8.00 sec 10.9 MBytes 91.7 Mbits/sec 0 424 KBytes [ 5] 8.00-9.00 sec 10.9 MBytes 91.7 Mbits/sec 0 444 KBytes [ 5] 9.00-10.00 sec 11.9 MBytes 100 Mbits/sec 0 462 KBytes - - - - - - - - - - - - - - - - - - - - - - - - - [ ID] Interval Transfer Bitrate Retr [ 5] 0.00-10.00 sec 115 MBytes 96.3 Mbits/sec 16 sender [ 5] 0.00-10.09 sec 112 MBytes 93.6 Mbits/sec receiver iperf Done. [root@dhcp-10-163-102-46 scripts]# Using iperf, I was able to determine the \"maximum throughput\" of the be and fe01 machines over Wi-Fi. 29/07/2025 00:47 I'm running the g-2 at a rate that the DQM should be able to handle then... But I noticed it would get events in \"spurts\" of about 40 events, before not getting any for a few seconds, then returning to get events. I added some debug code to the receiver to try to see what was going on. 29/07/2025 00:48 Here's a snippet from the debug [DEBUG] getLatestMessages:585 - getLatestMessages(1, since 3.184 seconds ago) - buffer has 0 messages [DEBUG] getLatestMessages:598 - Found 0 messages after timestamp [DEBUG] getLatestMessages:604 - Returning 0 messages (start index: 0) [DEBUG] getLatestTransitions:676 - getLatestTransitions(1, since 3.184 seconds ago) - buffer has 0 transitions [DEBUG] getLatestTransitions:689 - Found 0 transitions after timestamp [DEBUG] getLatestTransitions:695 - Returning 0 transitions (start index: 0) [DEBUG] isListeningForEvents:734 - isListeningForEvents() returning: true [DEBUG] getInstance:39 - Returning existing singleton instance [DEBUG] getInstance:39 - Returning existing singleton instance [DEBUG] getLatestEvents:483 - getLatestEvents(1, since 0.007 seconds ago) - buffer has 613 events [DEBUG] getLatestEvents:496 - Found 3 events after timestamp [DEBUG] getLatestEvents:502 - Returning 1 events (start index: 2) === Midas Events (count=1) === [EVENT] Timestamp: Tue Jul 29 00:21:46 2025 Event ID: 1 Trigger Mask: 65535 Serial Number: 498574 Data Size: 8964 bytes Event Header Size: 16 bytes Bank Header Flags: 17 Banks (5): Name: CR01, Size: 8360 bytes Name: CA01, Size: 40 bytes Name: CB01, Size: 312 bytes Name: CZ01, Size: 8 bytes Name: CC01, Size: 176 bytes Data (first 32 bytes): 01 00 FF FF 8E 9B 07 00 5A 4C 88 68 04 23 00 00 FC 22 00 00 11 00 00 00 43 52 30 31 05 00 00 00 [DEBUG] getLatestMessages:585 - getLatestMessages(1, since 3.190 seconds ago) - buffer has 0 messages [DEBUG] getLatestMessages:598 - Found 0 messages after timestamp [DEBUG] getLatestMessages:604 - Returning 0 messages (start index: 0) [DEBUG] getLatestTransitions:676 - getLatestTransitions(1, since 3.190 seconds ago) - buffer has 0 transitions [DEBUG] getLatestTransitions:689 - Found 0 transitions after timestamp [DEBUG] getLatestTransitions:695 - Returning 0 transitions (start index: 0) [DEBUG] isListeningForEvents:734 - isListeningForEvents() returning: true [DEBUG] getInstance:39 - Returning existing singleton instance [DEBUG] run:226 - cm_yield returned error status: 414 [DEBUG] getLatestEvents:483 - getLatestEvents(1, since 0.007 seconds ago) - buffer has 614 events [DEBUG] getLatestEvents:496 - Found 1 events after timestamp [DEBUG] getLatestEvents:502 - Returning 1 events (start index: 0) === Midas Events (count=1) === [EVENT] Timestamp: Tue Jul 29 00:21:46 2025 Event ID: 1 Trigger Mask: 65535 Serial Number: 498575 Data Size: 8964 bytes Event Header Size: 16 bytes Bank Header Flags: 17 Banks (5): Name: CR01, Size: 8360 bytes Name: CA01, Size: 40 bytes Name: CB01, Size: 312 bytes Name: CZ01, Size: 8 bytes Name: CC01, Size: 176 bytes Data (first 32 bytes): 01 00 FF FF 8F 9B 07 00 5A 4C 88 68 04 23 00 00 FC 22 00 00 11 00 00 00 43 52 30 31 05 00 00 00 [DEBUG] getLatestMessages:585 - getLatestMessages(1, since 3.195 seconds ago) - buffer has 0 messages [DEBUG] getLatestMessages:598 - Found 0 messages after timestamp [DEBUG] getLatestMessages:604 - Returning 0 messages (start index: 0) [DEBUG] getLatestTransitions:676 - getLatestTransitions(1, since 3.195 seconds ago) - buffer has 0 transitions [DEBUG] getLatestTransitions:689 - Found 0 transitions after timestamp [DEBUG] getLatestTransitions:695 - Returning 0 transitions (start index: 0) [DEBUG] isListeningForEvents:734 - isListeningForEvents() returning: true [DEBUG] getLatestEvents:483 - getLatestEvents(1, since 0.009 seconds ago) - buffer has 614 events [DEBUG] getLatestEvents:496 - Found 0 events after timestamp [DEBUG] getLatestEvents:502 - Returning 0 events (start index: 0) [INFO] No new events. [DEBUG] getLatestMessages:585 - getLatestMessages(1, since 3.200 seconds ago) - buffer has 0 messages [DEBUG] getLatestMessages:598 - Found 0 messages after timestamp [DEBUG] getLatestMessages:604 - Returning 0 messages (start index: 0) [DEBUG] getLatestTransitions:676 - getLatestTransitions(1, since 3.200 seconds ago) - buffer has 0 transitions [DEBUG] getLatestTransitions:689 - Found 0 transitions after timestamp [DEBUG] getLatestTransitions:695 - Returning 0 transitions (start index: 0) [DEBUG] isListeningForEvents:734 - isListeningForEvents() returning: true [DEBUG] getLatestEvents:483 - getLatestEvents(1, since 0.014 seconds ago) - buffer has 614 events [DEBUG] getLatestEvents:496 - Found 0 events after timestamp [DEBUG] getLatestEvents:502 - Returning 0 events (start index: 0) [INFO] No new events. [DEBUG] getLatestMessages:585 - getLatestMessages(1, since 3.205 seconds ago) - buffer has 0 messages [DEBUG] getLatestMessages:598 - Found 0 messages after timestamp [DEBUG] getLatestMessages:604 - Returning 0 messages (start index: 0) [DEBUG] getLatestTransitions:676 - getLatestTransitions(1, since 3.205 seconds ago) - buffer has 0 transitions [DEBUG] getLatestTransitions:689 - Found 0 transitions after timestamp [DEBUG] getLatestTransitions:695 - Returning 0 transitions (start index: 0) [DEBUG] isListeningForEvents:734 - isListeningForEvents() returning: true [DEBUG] getLatestEvents:483 - getLatestEvents(1, since 0.020 seconds ago) - buffer has 614 events [DEBUG] getLatestEvents:496 - Found 0 events after timestamp [DEBUG] getLatestEvents:502 - Returning 0 events (start index: 0) [INFO] No new events. [DEBUG] getLatestMessages:585 - getLatestMessages(1, since 3.211 seconds ago) - buffer has 0 messages [DEBUG] getLatestMessages:598 - Found 0 messages after timestamp [DEBUG] getLatestMessages:604 - Returning 0 messages (start index: 0) [DEBUG] getLatestTransitions:676 - getLatestTransitions(1, since 3.211 seconds ago) - buffer has 0 transitions [DEBUG] getLatestTransitions:689 - Found 0 transitions after timestamp [DEBUG] getLatestTransitions:695 - Returning 0 transitions (start index: 0) [DEBUG] isListeningForEvents:734 - isListeningForEvents() returning: true [DEBUG] getLatestEvents:483 - getLatestEvents(1, since 0.025 seconds ago) - buffer has 614 events [DEBUG] getLatestEvents:496 - Found 0 events after timestamp [DEBUG] getLatestEvents:502 - Returning 0 events (start index: 0) [INFO] No new events. [DEBUG] getLatestMessages:585 - getLatestMessages(1, since 3.216 seconds ago) - buffer has 0 messages [DEBUG] getLatestMessages:598 - Found 0 messages after timestamp [DEBUG] getLatestMessages:604 - Returning 0 messages (start index: 0) [DEBUG] getLatestTransitions:676 - getLatestTransitions(1, since 3.216 seconds ago) - buffer has 0 transitions [DEBUG] getLatestTransitions:689 - Found 0 transitions after timestamp [DEBUG] getLatestTransitions:695 - Returning 0 transitions (start index: 0) [DEBUG] isListeningForEvents:734 - isListeningForEvents() returning: true [DEBUG] getLatestEvents:483 - getLatestEvents(1, since 0.030 seconds ago) - buffer has 614 events [DEBUG] getLatestEvents:496 - Found 0 events after timestamp [DEBUG] getLatestEvents:502 - Returning 0 events (start index: 0) [INFO] No new events. [DEBUG] getLatestMessages:585 - getLatestMessages(1, since 3.184 seconds ago) - buffer has 0 messages [DEBUG] getLatestMessages:598 - Found 0 messages after timestamp [DEBUG] getLatestMessages:604 - Returning 0 messages (start index: 0) [DEBUG] getLatestTransitions:676 - getLatestTransitions(1, since 3.184 seconds ago) - buffer has 0 transitions [DEBUG] getLatestTransitions:689 - Found 0 transitions after timestamp [DEBUG] getLatestTransitions:695 - Returning 0 transitions (start index: 0) [DEBUG] isListeningForEvents:734 - isListeningForEvents() returning: true [DEBUG] getInstance:39 - Returning existing singleton instance [DEBUG] getInstance:39 - Returning existing singleton instance [DEBUG] getLatestEvents:483 - getLatestEvents(1, since 0.007 seconds ago) - buffer has 613 events [DEBUG] getLatestEvents:496 - Found 3 events after timestamp [DEBUG] getLatestEvents:502 - Returning 1 events (start index: 2) === Midas Events (count=1) === [EVENT] Timestamp: Tue Jul 29 00:21:46 2025 Event ID: 1 Trigger Mask: 65535 Serial Number: 498574 Data Size: 8964 bytes Event Header Size: 16 bytes Bank Header Flags: 17 Banks (5): Name: CR01, Size: 8360 bytes Name: CA01, Size: 40 bytes Name: CB01, Size: 312 bytes Name: CZ01, Size: 8 bytes Name: CC01, Size: 176 bytes Data (first 32 bytes): 01 00 FF FF 8E 9B 07 00 5A 4C 88 68 04 23 00 00 FC 22 00 00 11 00 00 00 43 52 30 31 05 00 00 00 [DEBUG] getLatestMessages:585 - getLatestMessages(1, since 3.190 seconds ago) - buffer has 0 messages [DEBUG] getLatestMessages:598 - Found 0 messages after timestamp [DEBUG] getLatestMessages:604 - Returning 0 messages (start index: 0) [DEBUG] getLatestTransitions:676 - getLatestTransitions(1, since 3.190 seconds ago) - buffer has 0 transitions [DEBUG] getLatestTransitions:689 - Found 0 transitions after timestamp [DEBUG] getLatestTransitions:695 - Returning 0 transitions (start index: 0) [DEBUG] isListeningForEvents:734 - isListeningForEvents() returning: true [DEBUG] getInstance:39 - Returning existing singleton instance [DEBUG] run:226 - cm_yield returned error status: 414 [DEBUG] getLatestEvents:483 - getLatestEvents(1, since 0.007 seconds ago) - buffer has 614 events [DEBUG] getLatestEvents:496 - Found 1 events after timestamp [DEBUG] getLatestEvents:502 - Returning 1 events (start index: 0) === Midas Events (count=1) === [EVENT] Timestamp: Tue Jul 29 00:21:46 2025 Event ID: 1 Trigger Mask: 65535 Serial Number: 498575 Data Size: 8964 bytes Event Header Size: 16 bytes Bank Header Flags: 17 Banks (5): Name: CR01, Size: 8360 bytes Name: CA01, Size: 40 bytes Name: CB01, Size: 312 bytes Name: CZ01, Size: 8 bytes Name: CC01, Size: 176 bytes Data (first 32 bytes): 01 00 FF FF 8F 9B 07 00 5A 4C 88 68 04 23 00 00 FC 22 00 00 11 00 00 00 43 52 30 31 05 00 00 00 [DEBUG] getLatestMessages:585 - getLatestMessages(1, since 3.195 seconds ago) - buffer has 0 messages [DEBUG] getLatestMessages:598 - Found 0 messages after timestamp [DEBUG] getLatestMessages:604 - Returning 0 messages (start index: 0) [DEBUG] getLatestTransitions:676 - getLatestTransitions(1, since 3.195 seconds ago) - buffer has 0 transitions [DEBUG] getLatestTransitions:689 - Found 0 transitions after timestamp [DEBUG] getLatestTransitions:695 - Returning 0 transitions (start index: 0) [DEBUG] isListeningForEvents:734 - isListeningForEvents() returning: true [DEBUG] getLatestEvents:483 - getLatestEvents(1, since 0.009 seconds ago) - buffer has 614 events [DEBUG] getLatestEvents:496 - Found 0 events after timestamp [DEBUG] getLatestEvents:502 - Returning 0 events (start index: 0) [INFO] No new events. [DEBUG] getLatestMessages:585 - getLatestMessages(1, since 3.200 seconds ago) - buffer has 0 messages [DEBUG] getLatestMessages:598 - Found 0 messages after timestamp [DEBUG] getLatestMessages:604 - Returning 0 messages (start index: 0) [DEBUG] getLatestTransitions:676 - getLatestTransitions(1, since 3.200 seconds ago) - buffer has 0 transitions [DEBUG] getLatestTransitions:689 - Found 0 transitions after timestamp [DEBUG] getLatestTransitions:695 - Returning 0 transitions (start index: 0) [DEBUG] isListeningForEvents:734 - isListeningForEvents() returning: true [DEBUG] getLatestEvents:483 - getLatestEvents(1, since 0.014 seconds ago) - buffer has 614 events [DEBUG] getLatestEvents:496 - Found 0 events after timestamp [DEBUG] getLatestEvents:502 - Returning 0 events (start index: 0) [INFO] No new events. [DEBUG] getLatestMessages:585 - getLatestMessages(1, since 3.205 seconds ago) - buffer has 0 messages [DEBUG] getLatestMessages:598 - Found 0 messages after timestamp [DEBUG] getLatestMessages:604 - Returning 0 messages (start index: 0) [DEBUG] getLatestTransitions:676 - getLatestTransitions(1, since 3.205 seconds ago) - buffer has 0 transitions [DEBUG] getLatestTransitions:689 - Found 0 transitions after timestamp [DEBUG] getLatestTransitions:695 - Returning 0 transitions (start index: 0) [DEBUG] isListeningForEvents:734 - isListeningForEvents() returning: true [DEBUG] getLatestEvents:483 - getLatestEvents(1, since 0.020 seconds ago) - buffer has 614 events [DEBUG] getLatestEvents:496 - Found 0 events after timestamp [DEBUG] getLatestEvents:502 - Returning 0 events (start index: 0) [INFO] No new events. [DEBUG] getLatestMessages:585 - getLatestMessages(1, since 3.211 seconds ago) - buffer has 0 messages [DEBUG] getLatestMessages:598 - Found 0 messages after timestamp [DEBUG] getLatestMessages:604 - Returning 0 messages (start index: 0) [DEBUG] getLatestTransitions:676 - getLatestTransitions(1, since 3.211 seconds ago) - buffer has 0 transitions [DEBUG] getLatestTransitions:689 - Found 0 transitions after timestamp [DEBUG] getLatestTransitions:695 - Returning 0 transitions (start index: 0) [DEBUG] isListeningForEvents:734 - isListeningForEvents() returning: true [DEBUG] getLatestEvents:483 - getLatestEvents(1, since 0.025 seconds ago) - buffer has 614 events [DEBUG] getLatestEvents:496 - Found 0 events after timestamp [DEBUG] getLatestEvents:502 - Returning 0 events (start index: 0) [INFO] No new events. [DEBUG] getLatestMessages:585 - getLatestMessages(1, since 3.216 seconds ago) - buffer has 0 messages [DEBUG] getLatestMessages:598 - Found 0 messages after timestamp [DEBUG] getLatestMessages:604 - Returning 0 messages (start index: 0) [DEBUG] getLatestTransitions:676 - getLatestTransitions(1, since 3.216 seconds ago) - buffer has 0 transitions [DEBUG] getLatestTransitions:689 - Found 0 transitions after timestamp [DEBUG] getLatestTransitions:695 - Returning 0 transitions (start index: 0) [DEBUG] isListeningForEvents:734 - isListeningForEvents() returning: true [DEBUG] getLatestEvents:483 - getLatestEvents(1, since 0.030 seconds ago) - buffer has 614 events [DEBUG] getLatestEvents:496 - Found 0 events after timestamp [DEBUG] getLatestEvents:502 - Returning 0 events (start index: 0) [INFO] No new events. The line I particualry found interesting was: [DEBUG] run:226 - cm_yield returned error status: 414 which showed up every time before a pause. You can trace 414 back to mean SS_CLIENT_RECV in midas.h:675 #define SS_CLIENT_RECV 414 /**< - */ The only place where this is returned would be in ss_suspend /*------------------------------------------------------------------*/ INT ss_suspend(INT millisec, INT msg) /********************************************************************\\ Routine: ss_suspend Purpose: Suspend the calling thread for a specified time. If timeout (in millisec.) is negative, the thead is suspended indefinitely. It can only be resumed from another thread or process which calls ss_resume or by some data which arrives on the client or server sockets. If msg equals to one of MSG_BM, MSG_ODB, the function return whenever such a message is received. This is needed to break recursive calls to the event handler and db_watch() handler: Avoided recursion via ss_suspend(MSG_BM): ss_suspend(0) -> -> MSG_BM message arrives in the UDP socket -> ss_suspend_process_ipc() -> cm_dispatch_ipc() -> bm_push_event() -> bm_push_buffer() -> bm_read_buffer() -> bm_wait_for_more_events() -> ss_suspend(MSG_BM) <- event buffer code calls ss_suspend() with MSG_BM set -> MSG_BM arrives arrives in the UDP socket -> ss_suspend_process_ipc(MSG_BM) -> the newly arrived MSG_BM message is discarded, recursive call to cm_dispatch_ipc(), bm_push_buffer() & co avoided Incorrect recursion via the event handler where user called ss_suspend() without MSG_BM: analyzer -> -> cm_yield() in the main loop -> ss_suspend(0) -> MSG_BM message arrives in the UDP socket -> ss_suspend_process_ipc(0) -> cm_dispatch_ipc() -> bm_push_event() -> bm_push_buffer() -> bm_read_buffer() -> bm_dispatch_event() -> user event handler -> user event handler ROOT graphics main loop needs to sleep -> ss_suspend(0) <--- should be ss_suspend(MSG_BM)!!! -> MSG_BM message arrives in the UDP socket -> ss_suspend_process_ipc(0) <- should be ss_suspend_process_ipc(MSG_BM)!!! -> cm_dispatch_ipc() <- without MSG_BM, calling cm_dispatch_ipc() again -> bm_push_event() -> bm_push_buffer() -> bm_read_buffer() -> bm_dispatch_event() -> user event handler <---- called recursively, very bad! Input: INT millisec Timeout in milliseconds INT msg Return from ss_suspend when msg (MSG_BM, MSG_ODB) is received. Output: none Function value: SS_SUCCESS Requested message was received SS_TIMEOUT Timeout expired SS_SERVER_RECV Server channel got data SS_CLIENT_RECV Client channel got data SS_ABORT (RPC_ABORT) Connection lost SS_EXIT Connection closed \\********************************************************************/ { INT status, return_status; midas_thread_t thread_id = ss_gettid(); SUSPEND_STRUCT* psuspend = ss_suspend_get_struct(thread_id); //printf(\"ss_suspend: thread %s\\n\", ss_tid_to_string(thread_id).c_str()); return_status = SS_TIMEOUT; do { fd_set readfds; FD_ZERO(&readfds); if (ss_match_thread(_ss_listen_thread, thread_id)) { /* check listen sockets */ if (_ss_server_listen_socket) { FD_SET(_ss_server_listen_socket, &readfds); //printf(\"ss_suspend: thread %s listen ss_server socket %d\\n\", ss_tid_to_string(thread_id).c_str(), _ss_server_listen_socket); } if (_ss_client_listen_socket) { FD_SET(_ss_client_listen_socket, &readfds); //printf(\"ss_suspend: thread %s listen ss_client socket %d\\n\", ss_tid_to_string(thread_id).c_str(), _ss_client_listen_socket); } } /* check server channels */ if (ss_match_thread(_ss_server_thread, thread_id) && _ss_server_acceptions) { //printf(\"ss_suspend: thread %s server acceptions %d\\n\", ss_tid_to_string(thread_id).c_str(), _ss_server_num_acceptions); for (unsigned i = 0; i < _ss_server_acceptions->size(); i++) { /* RPC channel */ int sock = (*_ss_server_acceptions)[i]->recv_sock; if (!sock) continue; ///* only watch the event tcp connection belonging to this thread */ //if (_suspend_struct[idx].server_acception[i].tid != ss_gettid()) // continue; /* watch server socket if no data in cache */ if (recv_tcp_check(sock) == 0) FD_SET(sock, &readfds); /* set timeout to zero if data in cache (-> just quick check IPC) and not called from inside bm_send_event (-> wait for IPC) */ else if (msg == 0) millisec = 0; if (msg == 0 && msg != MSG_BM) { /* event channel */ sock = (*_ss_server_acceptions)[i]->event_sock; if (!sock) continue; /* check for buffered event */ status = rpc_server_receive_event(0, NULL, BM_NO_WAIT); if (status == BM_ASYNC_RETURN) { /* event buffer is full and rpc_server_receive_event() is holding on * to an event it cannot get rid of. Do not read more events from * the event socket, they have nowhere to go. K.O. */ } else if (status == RPC_SUCCESS) { FD_SET(sock, &readfds); } } } } /* watch for messages from the mserver */ if (ss_match_thread(_ss_client_thread, thread_id)) { if (_ss_client_connection) { FD_SET(_ss_client_connection->recv_sock, &readfds); } } /* watch for UDP messages in the IPC socket: buffer and odb notifications */ if (ss_match_thread(_ss_odb_thread, thread_id)) { if (_ss_suspend_odb && _ss_suspend_odb->ipc_recv_socket) FD_SET(_ss_suspend_odb->ipc_recv_socket, &readfds); } if (psuspend->ipc_recv_socket) FD_SET(psuspend->ipc_recv_socket, &readfds); struct timeval timeout; timeout.tv_sec = millisec / 1000; timeout.tv_usec = (millisec % 1000) * 1000; do { //printf(\"select millisec %d, tv_sec %d, tv_usec %d\\n\", millisec, (int)timeout.tv_sec, (int)timeout.tv_usec); if (millisec < 0) status = select(FD_SETSIZE, &readfds, NULL, NULL, NULL); /* blocking */ else status = select(FD_SETSIZE, &readfds, NULL, NULL, &timeout); /* if an alarm signal was cought, restart select with reduced timeout */ if (status == -1 && timeout.tv_sec >= WATCHDOG_INTERVAL / 1000) timeout.tv_sec -= WATCHDOG_INTERVAL / 1000; } while (status == -1); /* dont return if an alarm signal was cought */ /* check listener sockets */ if (_ss_server_listen_socket && FD_ISSET(_ss_server_listen_socket, &readfds)) { //printf(\"ss_suspend: thread %s rpc_server_accept socket %d\\n\", ss_tid_to_string(thread_id).c_str(), _ss_server_listen_socket); status = rpc_server_accept(_ss_server_listen_socket); if (status == RPC_SHUTDOWN) { return status; } } if (_ss_client_listen_socket && FD_ISSET(_ss_client_listen_socket, &readfds)) { //printf(\"ss_suspend: thread %s rpc_client_accept socket %d\\n\", ss_tid_to_string(thread_id).c_str(), _ss_client_listen_socket); status = rpc_client_accept(_ss_client_listen_socket); if (status == RPC_SHUTDOWN) { return status; } } /* check server channels */ if (_ss_server_acceptions) { for (unsigned i = 0; i < _ss_server_acceptions->size(); i++) { /* rpc channel */ int sock = (*_ss_server_acceptions)[i]->recv_sock; if (!sock) continue; //printf(\"rpc index %d, socket %d, hostname \\'%s\\', progname \\'%s\\'\\n\", i, sock, _suspend_struct[idx].server_acception[i].host_name, _suspend_struct[idx].server_acception[i].prog_name); if (recv_tcp_check(sock) || FD_ISSET(sock, &readfds)) { //printf(\"ss_suspend: msg %d\\n\", msg); if (msg == MSG_BM) { status = ss_socket_check(sock); } else { //printf(\"ss_suspend: rpc_server_receive_rpc() call!\\n\"); status = rpc_server_receive_rpc(i, (*_ss_server_acceptions)[i]); //printf(\"ss_suspend: rpc_server_receive_rpc() status %d\\n\", status); } (*_ss_server_acceptions)[i]->last_activity = ss_millitime(); if (status == SS_ABORT || status == SS_EXIT || status == RPC_SHUTDOWN) { return status; } return_status = SS_SERVER_RECV; } /* event channel */ sock = (*_ss_server_acceptions)[i]->event_sock; if (!sock) continue; if (FD_ISSET(sock, &readfds)) { if (msg != 0) { status = ss_socket_check(sock); } else { //printf(\"ss_suspend: rpc_server_receive_event() call!\\n\"); status = rpc_server_receive_event(i, (*_ss_server_acceptions)[i], BM_NO_WAIT); //printf(\"ss_suspend: rpc_server_receive_event() status %d\\n\", status); } (*_ss_server_acceptions)[i]->last_activity = ss_millitime(); if (status == SS_ABORT || status == SS_EXIT || status == RPC_SHUTDOWN) { return status; } return_status = SS_SERVER_RECV; } } } /* check for messages from the mserver */ if (_ss_client_connection) { int sock = _ss_client_connection->recv_sock; if (FD_ISSET(sock, &readfds)) { status = rpc_client_dispatch(sock); if (status == SS_ABORT) { cm_msg(MINFO, \"ss_suspend\", \"RPC connection to mserver at \\'%s\\' was broken\", _ss_client_connection->host_name.c_str()); /* close client connection if link broken */ closesocket(_ss_client_connection->send_sock); closesocket(_ss_client_connection->recv_sock); closesocket(_ss_client_connection->event_sock); _ss_client_connection->send_sock = 0; _ss_client_connection->recv_sock = 0; _ss_client_connection->event_sock = 0; _ss_client_connection->clear(); /* exit program after broken connection to MIDAS server */ return SS_ABORT; } return_status = SS_CLIENT_RECV; } } /* check ODB IPC socket */ if (_ss_suspend_odb && _ss_suspend_odb->ipc_recv_socket && FD_ISSET(_ss_suspend_odb->ipc_recv_socket, &readfds)) { status = ss_suspend_process_ipc(millisec, msg, _ss_suspend_odb->ipc_recv_socket); if (status) { return status; } } /* check per-thread IPC socket */ if (psuspend && psuspend->ipc_recv_socket && FD_ISSET(psuspend->ipc_recv_socket, &readfds)) { status = ss_suspend_process_ipc(millisec, msg, psuspend->ipc_recv_socket); if (status) { return status; } } } while (millisec < 0); return return_status; } /*------------------------------------------------------------------*/ INT ss_suspend(INT millisec, INT msg) /********************************************************************\\ Routine: ss_suspend Purpose: Suspend the calling thread for a specified time. If timeout (in millisec.) is negative, the thead is suspended indefinitely. It can only be resumed from another thread or process which calls ss_resume or by some data which arrives on the client or server sockets. If msg equals to one of MSG_BM, MSG_ODB, the function return whenever such a message is received. This is needed to break recursive calls to the event handler and db_watch() handler: Avoided recursion via ss_suspend(MSG_BM): ss_suspend(0) -> -> MSG_BM message arrives in the UDP socket -> ss_suspend_process_ipc() -> cm_dispatch_ipc() -> bm_push_event() -> bm_push_buffer() -> bm_read_buffer() -> bm_wait_for_more_events() -> ss_suspend(MSG_BM) <- event buffer code calls ss_suspend() with MSG_BM set -> MSG_BM arrives arrives in the UDP socket -> ss_suspend_process_ipc(MSG_BM) -> the newly arrived MSG_BM message is discarded, recursive call to cm_dispatch_ipc(), bm_push_buffer() & co avoided Incorrect recursion via the event handler where user called ss_suspend() without MSG_BM: analyzer -> -> cm_yield() in the main loop -> ss_suspend(0) -> MSG_BM message arrives in the UDP socket -> ss_suspend_process_ipc(0) -> cm_dispatch_ipc() -> bm_push_event() -> bm_push_buffer() -> bm_read_buffer() -> bm_dispatch_event() -> user event handler -> user event handler ROOT graphics main loop needs to sleep -> ss_suspend(0) <--- should be ss_suspend(MSG_BM)!!! -> MSG_BM message arrives in the UDP socket -> ss_suspend_process_ipc(0) <- should be ss_suspend_process_ipc(MSG_BM)!!! -> cm_dispatch_ipc() <- without MSG_BM, calling cm_dispatch_ipc() again -> bm_push_event() -> bm_push_buffer() -> bm_read_buffer() -> bm_dispatch_event() -> user event handler <---- called recursively, very bad! Input: INT millisec Timeout in milliseconds INT msg Return from ss_suspend when msg (MSG_BM, MSG_ODB) is received. Output: none Function value: SS_SUCCESS Requested message was received SS_TIMEOUT Timeout expired SS_SERVER_RECV Server channel got data SS_CLIENT_RECV Client channel got data SS_ABORT (RPC_ABORT) Connection lost SS_EXIT Connection closed \\********************************************************************/ { INT status, return_status; midas_thread_t thread_id = ss_gettid(); SUSPEND_STRUCT* psuspend = ss_suspend_get_struct(thread_id); //printf(\"ss_suspend: thread %s\\n\", ss_tid_to_string(thread_id).c_str()); return_status = SS_TIMEOUT; do { fd_set readfds; FD_ZERO(&readfds); if (ss_match_thread(_ss_listen_thread, thread_id)) { /* check listen sockets */ if (_ss_server_listen_socket) { FD_SET(_ss_server_listen_socket, &readfds); //printf(\"ss_suspend: thread %s listen ss_server socket %d\\n\", ss_tid_to_string(thread_id).c_str(), _ss_server_listen_socket); } if (_ss_client_listen_socket) { FD_SET(_ss_client_listen_socket, &readfds); //printf(\"ss_suspend: thread %s listen ss_client socket %d\\n\", ss_tid_to_string(thread_id).c_str(), _ss_client_listen_socket); } } /* check server channels */ if (ss_match_thread(_ss_server_thread, thread_id) && _ss_server_acceptions) { //printf(\"ss_suspend: thread %s server acceptions %d\\n\", ss_tid_to_string(thread_id).c_str(), _ss_server_num_acceptions); for (unsigned i = 0; i < _ss_server_acceptions->size(); i++) { /* RPC channel */ int sock = (*_ss_server_acceptions)[i]->recv_sock; if (!sock) continue; ///* only watch the event tcp connection belonging to this thread */ //if (_suspend_struct[idx].server_acception[i].tid != ss_gettid()) // continue; /* watch server socket if no data in cache */ if (recv_tcp_check(sock) == 0) FD_SET(sock, &readfds); /* set timeout to zero if data in cache (-> just quick check IPC) and not called from inside bm_send_event (-> wait for IPC) */ else if (msg == 0) millisec = 0; if (msg == 0 && msg != MSG_BM) { /* event channel */ sock = (*_ss_server_acceptions)[i]->event_sock; if (!sock) continue; /* check for buffered event */ status = rpc_server_receive_event(0, NULL, BM_NO_WAIT); if (status == BM_ASYNC_RETURN) { /* event buffer is full and rpc_server_receive_event() is holding on * to an event it cannot get rid of. Do not read more events from * the event socket, they have nowhere to go. K.O. */ } else if (status == RPC_SUCCESS) { FD_SET(sock, &readfds); } } } } /* watch for messages from the mserver */ if (ss_match_thread(_ss_client_thread, thread_id)) { if (_ss_client_connection) { FD_SET(_ss_client_connection->recv_sock, &readfds); } } /* watch for UDP messages in the IPC socket: buffer and odb notifications */ if (ss_match_thread(_ss_odb_thread, thread_id)) { if (_ss_suspend_odb && _ss_suspend_odb->ipc_recv_socket) FD_SET(_ss_suspend_odb->ipc_recv_socket, &readfds); } if (psuspend->ipc_recv_socket) FD_SET(psuspend->ipc_recv_socket, &readfds); struct timeval timeout; timeout.tv_sec = millisec / 1000; timeout.tv_usec = (millisec % 1000) * 1000; do { //printf(\"select millisec %d, tv_sec %d, tv_usec %d\\n\", millisec, (int)timeout.tv_sec, (int)timeout.tv_usec); if (millisec < 0) status = select(FD_SETSIZE, &readfds, NULL, NULL, NULL); /* blocking */ else status = select(FD_SETSIZE, &readfds, NULL, NULL, &timeout); /* if an alarm signal was cought, restart select with reduced timeout */ if (status == -1 && timeout.tv_sec >= WATCHDOG_INTERVAL / 1000) timeout.tv_sec -= WATCHDOG_INTERVAL / 1000; } while (status == -1); /* dont return if an alarm signal was cought */ /* check listener sockets */ if (_ss_server_listen_socket && FD_ISSET(_ss_server_listen_socket, &readfds)) { //printf(\"ss_suspend: thread %s rpc_server_accept socket %d\\n\", ss_tid_to_string(thread_id).c_str(), _ss_server_listen_socket); status = rpc_server_accept(_ss_server_listen_socket); if (status == RPC_SHUTDOWN) { return status; } } if (_ss_client_listen_socket && FD_ISSET(_ss_client_listen_socket, &readfds)) { //printf(\"ss_suspend: thread %s rpc_client_accept socket %d\\n\", ss_tid_to_string(thread_id).c_str(), _ss_client_listen_socket); status = rpc_client_accept(_ss_client_listen_socket); if (status == RPC_SHUTDOWN) { return status; } } /* check server channels */ if (_ss_server_acceptions) { for (unsigned i = 0; i < _ss_server_acceptions->size(); i++) { /* rpc channel */ int sock = (*_ss_server_acceptions)[i]->recv_sock; if (!sock) continue; //printf(\"rpc index %d, socket %d, hostname \\'%s\\', progname \\'%s\\'\\n\", i, sock, _suspend_struct[idx].server_acception[i].host_name, _suspend_struct[idx].server_acception[i].prog_name); if (recv_tcp_check(sock) || FD_ISSET(sock, &readfds)) { //printf(\"ss_suspend: msg %d\\n\", msg); if (msg == MSG_BM) { status = ss_socket_check(sock); } else { //printf(\"ss_suspend: rpc_server_receive_rpc() call!\\n\"); status = rpc_server_receive_rpc(i, (*_ss_server_acceptions)[i]); //printf(\"ss_suspend: rpc_server_receive_rpc() status %d\\n\", status); } (*_ss_server_acceptions)[i]->last_activity = ss_millitime(); if (status == SS_ABORT || status == SS_EXIT || status == RPC_SHUTDOWN) { return status; } return_status = SS_SERVER_RECV; } /* event channel */ sock = (*_ss_server_acceptions)[i]->event_sock; if (!sock) continue; if (FD_ISSET(sock, &readfds)) { if (msg != 0) { status = ss_socket_check(sock); } else { //printf(\"ss_suspend: rpc_server_receive_event() call!\\n\"); status = rpc_server_receive_event(i, (*_ss_server_acceptions)[i], BM_NO_WAIT); //printf(\"ss_suspend: rpc_server_receive_event() status %d\\n\", status); } (*_ss_server_acceptions)[i]->last_activity = ss_millitime(); if (status == SS_ABORT || status == SS_EXIT || status == RPC_SHUTDOWN) { return status; } return_status = SS_SERVER_RECV; } } } /* check for messages from the mserver */ if (_ss_client_connection) { int sock = _ss_client_connection->recv_sock; if (FD_ISSET(sock, &readfds)) { status = rpc_client_dispatch(sock); if (status == SS_ABORT) { cm_msg(MINFO, \"ss_suspend\", \"RPC connection to mserver at \\'%s\\' was broken\", _ss_client_connection->host_name.c_str()); /* close client connection if link broken */ closesocket(_ss_client_connection->send_sock); closesocket(_ss_client_connection->recv_sock); closesocket(_ss_client_connection->event_sock); _ss_client_connection->send_sock = 0; _ss_client_connection->recv_sock = 0; _ss_client_connection->event_sock = 0; _ss_client_connection->clear(); /* exit program after broken connection to MIDAS server */ return SS_ABORT; } return_status = SS_CLIENT_RECV; } } /* check ODB IPC socket */ if (_ss_suspend_odb && _ss_suspend_odb->ipc_recv_socket && FD_ISSET(_ss_suspend_odb->ipc_recv_socket, &readfds)) { status = ss_suspend_process_ipc(millisec, msg, _ss_suspend_odb->ipc_recv_socket); if (status) { return status; } } /* check per-thread IPC socket */ if (psuspend && psuspend->ipc_recv_socket && FD_ISSET(psuspend->ipc_recv_socket, &readfds)) { status = ss_suspend_process_ipc(millisec, msg, psuspend->ipc_recv_socket); if (status) { return status; } } } while (millisec < 0); return return_status; } which is called in lots of places, but in our case it comes from cm_yield INT cm_yield(INT millisec) { INT status; INT bMore; //static DWORD last_yield = 0; //static DWORD last_yield_time = 0; //DWORD start_yield = ss_millitime(); /* check for ctrl-c */ if (_ctrlc_pressed) return RPC_SHUTDOWN; /* flush the cm_msg buffer */ cm_msg_flush_buffer(); if (!rpc_is_remote()) { /* flush the ODB to its binary file */ /* for remote clients, ODB is flushed by the mserver */ HNDLE hDB; cm_get_experiment_database(&hDB, NULL); db_flush_database(hDB); } /* check for available events */ if (rpc_is_remote()) { //printf(\"cm_yield() calling bm_poll_event()\\n\"); status = bm_poll_event(); if (status == SS_ABORT) { return status; } if (status == BM_SUCCESS) { /* one or more events received by bm_poll_event() */ status = ss_suspend(0, 0); } else { status = ss_suspend(millisec, 0); } return status; } status = cm_periodic_tasks(); if (status != CM_SUCCESS) return status; //DWORD start_check = ss_millitime(); bMore = bm_check_buffers(); //DWORD end_check = ss_millitime(); //printf(\"cm_yield: timeout %4d, yield period %4d, last yield time %4d, bm_check_buffers() elapsed %4d, returned %d\\n\", millisec, start_yield - last_yield, last_yield_time, end_check - start_check, bMore); //fflush(stdout); if (bMore == BM_CORRUPTED) { status = SS_ABORT; } else if (bMore) { /* if events available, quickly check other IPC channels */ status = ss_suspend(0, 0); } else { status = ss_suspend(millisec, 0); } /* flush the cm_msg buffer */ cm_msg_flush_buffer(); //DWORD end_yield = ss_millitime(); //last_yield_time = end_yield - start_yield; //last_yield = start_yield; return status; } INT cm_yield(INT millisec) { INT status; INT bMore; //static DWORD last_yield = 0; //static DWORD last_yield_time = 0; //DWORD start_yield = ss_millitime(); /* check for ctrl-c */ if (_ctrlc_pressed) return RPC_SHUTDOWN; /* flush the cm_msg buffer */ cm_msg_flush_buffer(); if (!rpc_is_remote()) { /* flush the ODB to its binary file */ /* for remote clients, ODB is flushed by the mserver */ HNDLE hDB; cm_get_experiment_database(&hDB, NULL); db_flush_database(hDB); } /* check for available events */ if (rpc_is_remote()) { //printf(\"cm_yield() calling bm_poll_event()\\n\"); status = bm_poll_event(); if (status == SS_ABORT) { return status; } if (status == BM_SUCCESS) { /* one or more events received by bm_poll_event() */ status = ss_suspend(0, 0); } else { status = ss_suspend(millisec, 0); } return status; } status = cm_periodic_tasks(); if (status != CM_SUCCESS) return status; //DWORD start_check = ss_millitime(); bMore = bm_check_buffers(); //DWORD end_check = ss_millitime(); //printf(\"cm_yield: timeout %4d, yield period %4d, last yield time %4d, bm_check_buffers() elapsed %4d, returned %d\\n\", millisec, start_yield - last_yield, last_yield_time, end_check - start_check, bMore); //fflush(stdout); if (bMore == BM_CORRUPTED) { status = SS_ABORT; } else if (bMore) { /* if events available, quickly check other IPC channels */ status = ss_suspend(0, 0); } else { status = ss_suspend(millisec, 0); } /* flush the cm_msg buffer */ cm_msg_flush_buffer(); //DWORD end_yield = ss_millitime(); //last_yield_time = end_yield - start_yield; //last_yield = start_yield; return status; } 29/07/2025 00:57 It seems changing status = cm_yield(1); status = cm_yield( 1 ) ; to be lower fixes this issue 29/07/2025 01:15 After some tests it appears shortening the yield timeout was the solution. I think midas uses this to say \"okay, this program is going to chill for this many milliseconds so other programs can catch up.\" But it was hard to tell exactly from reading the code what this parameter does.",
    "textLength": 5325
  },
  {
    "kind": "work-log",
    "title": "12_05_2024 - 18_05_2024.html",
    "fileName": "12_05_2024 - 18_05_2024.html",
    "url": "resources/work_logs/12_05_2024 - 18_05_2024.html",
    "createdDate": "2024-05-12",
    "text": "12/05/2024 - 18/05/2024 12/05/2024 - 18/05/2024 12/05/2024 23:14 To incorporate the ethernet splitter to support the multiple crate system once we set it up, I simply plugged in the 1gbE connection into the ethernet splitter, then ran another wire from the ethernet splitter to the MCH. I was still able to ping the MCH with no edits to the network scripts below: /etc/sysconfig/network-script/ifcfg-enp5s0 (1GbE) # # Connect to MCH # TYPE=Ethernet BOOTPROTO=static IPADDR=192.168.1.1 NETMASK=255.255.255.128 IPV4_FAILURE_FATAL=no IPV6INIT=no IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_PEERDNS=yes IPV6_PEERROUTES=yes IPV6_FAILURE_FATAL=no NAME=enp5s0 DEVICE=enp5s0 ONBOOT=yes # # Connect to MCH # TYPE =Ethernet BOOTPROTO =static IPADDR = 192.168 . 1.1 NETMASK = 255.255 . 255.128 IPV4_FAILURE_FATAL = no IPV6INIT = no IPV6_AUTOCONF = yes IPV6_DEFROUTE = yes IPV6_PEERDNS = yes IPV6_PEERROUTES = yes IPV6_FAILURE_FATAL = no NAME =enp5s0 DEVICE =enp5s0 ONBOOT = yes However, we need to support a second crate that will be on the 192.186.{crate #}.xxx network, so I changed the netmask to accept any value from the 3rd octet of the IP address: /etc/sysconfig/network-script/ifcfg-enp5s0 (1GbE) # # Connect to MCH # TYPE=Ethernet BOOTPROTO=static IPADDR=192.168.1.1 NETMASK=255.255.255.128 IPV4_FAILURE_FATAL=no IPV6INIT=no IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_PEERDNS=yes IPV6_PEERROUTES=yes IPV6_FAILURE_FATAL=no NAME=enp5s0 DEVICE=enp5s0 ONBOOT=yes # # Connect to MCH # TYPE =Ethernet BOOTPROTO =static IPADDR = 192.168 . 1.1 NETMASK = 255.255 . 255.128 IPV4_FAILURE_FATAL = no IPV6INIT = no IPV6_AUTOCONF = yes IPV6_DEFROUTE = yes IPV6_PEERDNS = yes IPV6_PEERROUTES = yes IPV6_FAILURE_FATAL = no NAME =enp5s0 DEVICE =enp5s0 ONBOOT = yes 13/05/2024 00:26 Poll event seems to lock the gpu thread to poll if data is available. INT poll_event(INT source __attribute__((unused)), INT count, BOOL test) { // fake calibration if (test) { for (int i = 0; i < count; i++) { usleep(1); } return 0; } INT retval = 0; BOOL data_avail = FALSE; // true if data is available for readout // Check GPU buffer pthread_mutex_lock( &mutex_GPU_general ); if (GPUfillnumber > Midasfillnumber) { data_avail = TRUE; } if (GPUfillnumber < Midasfillnumber && GPUfillnumber!=0) // this is for wrapping over the largest unsigned long, which is not very probable if the run is short { unsigned long buffer_filled = 0xffffffffffffffff - (Midasfillnumber - GPUfillnumber) +1 ; if (buffer_filled < 0xffffffffffffffff / 2) { data_avail = TRUE; } } pthread_mutex_unlock( &mutex_GPU_general ); // if (run_state == STATE_RUNNING) { if (data_avail) { retval = 1; } // } return retval; } // poll_event INT poll_event( INT source __attribute__((unused)), INT count , BOOL test) { // fake calibration if (test) { for ( int i = 0 ; i < count ; i++) { usleep( 1 ); } return 0 ; } INT retval = 0 ; BOOL data_avail = FALSE ; // true if data is available for readout // Check GPU buffer pthread_mutex_lock( &mutex_GPU_general ); if (GPUfillnumber > Midasfillnumber) { data_avail = TRUE ; } if (GPUfillnumber < Midasfillnumber && GPUfillnumber!= 0 ) // this is for wrapping over the largest unsigned long, which is not very probable if the run is short { unsigned long buffer_filled = 0 xffffffffffffffff - (Midasfillnumber - GPUfillnumber) + 1 ; if (buffer_filled < 0 xffffffffffffffff / 2 ) { data_avail = TRUE ; } } pthread_mutex_unlock( &mutex_GPU_general ); // if (run_state == STATE_RUNNING) { if (data_avail) { retval = 1 ; } // } return retval; } // poll_event Though, this shouldn't be problematic because this check is short and isn't done until it can obtain the lock anyways. 13/05/2024 00:59 I've tracked down where all the timestamps are made: TCP proc unlocked, tcp_thread.cxx:624 // get time of start of read / unpack AMC13 event status = gettimeofday( &tstart, NULL); header[1] = tstart.tv_sec; // fill header time info in header header[2] = tstart.tv_usec; // fill header time info in header // get time of start of read / unpack AMC13 event status = gettimeofday( &tstart, NU LL); header[1] = tstart.tv_sec; // fill header time info in header header[2] = tstart.tv_usec; // fill header time info in header got TCP header word, tcp_thread.cxx:1041 // record time got header word gettimeofday( &theader, NULL); header[3] = theader.tv_sec; // fill header time info in header header[4] = theader.tv_usec; // fill header time info in header // record time got header word gettimeofday( &theader, NU LL); header[3] = theader.tv_sec; // fill header time info in header header[4] = theader.tv_usec; // fill header time info in header got TCP header word 2, tcp_thread.cxx:670 // get time done read / unpack of AMC13 event status = gettimeofday( &tdata, NULL); header[5] = tdata.tv_sec; // fill data time info in header header[6] = tdata.tv_usec; // fill data time info in header // get time done read / unpack of AMC13 event status = gettimeofday( &tdata, NU LL); header[5] = tdata.tv_sec; // fill data time info in header header[6] = tdata.tv_usec; // fill data time info in header GPU proc unlocked, gpu_thread.cpp:557 gettimeofday( &tstart, NULL); gettimeof day ( &tstart , NULL ); about 40 lines later... //Add the GPU processing start time stamp GPU_Data_Buffer[GPUbufferindex].gpu_data_header[7] = tstart.tv_sec; GPU_Data_Buffer[GPUbufferindex].gpu_data_header[8] = tstart.tv_usec; //Add the GPU processing start time stamp GPU_Data_Buffer[GPUbufferindex].gpu_data_header[ 7 ] = tstart.tv_sec ; GPU_Data_Buffer[GPUbufferindex].gpu_data_header[ 8 ] = tstart.tv_usec ; GPU copy done, gpu_thread.cpp:701 // get GPU copy time for GPU thread gettimeofday( &tcopy, NULL); dbprintf(\"%s(%d): duration of start to copy, fdt = %e us \\n\", __func__, __LINE__, toddiff( &tstart, &tcopy) ); trigger_info.time_gputhread_copytogpu_done_s = tcopy.tv_sec; trigger_info.time_gputhread_copytogpu_done_us = tcopy.tv_usec; GPU_Data_Buffer[GPUbufferindex].gpu_data_header[9] = tcopy.tv_sec; // fill copy to GPU time info in header GPU_Data_Buffer[GPUbufferindex].gpu_data_header[10] = tcopy.tv_usec; // fill copy to GPU time info in header // get GPU copy time for GPU thread gettimeofday( &tcopy, NU LL); dbprintf( \"%s(%d): duration of start to copy, fdt = %e us \\n\" , __func__, __LINE__, toddiff( &tstart, &tcopy) ); trigger_info.time_gputhread_copytogpu_done_s = tcopy.tv_sec; trigger_info.time_gputhread_copytogpu_done_us = tcopy.tv_usec; GPU_Data_Buffer[GPUbufferindex].gpu_data_header[9] = tcopy.tv_sec; // fill copy to GPU time info in header GPU_Data_Buffer[GPUbufferindex].gpu_data_header[10] = tcopy.tv_usec; // fill copy to GPU time info in header GPU proc done, gpu_thread.cpp:765 // get GPU run time for GPU thread gettimeofday( &tprocess, NULL); dbprintf(\"%s(%d): duration of copy to process, fdt = %e us \\n\", __func__, __LINE__, toddiff( &tprocess, &tcopy) ); trigger_info.time_gputhread_finished_s = tprocess.tv_sec; trigger_info.time_gputhread_finished_us = tprocess.tv_usec; GPU_Data_Buffer[GPUbufferindex].gpu_data_header[11] = tprocess.tv_sec; GPU_Data_Buffer[GPUbufferindex].gpu_data_header[12] = tprocess.tv_usec; // get GPU run time for GPU thread gettimeofday( &tprocess, NULL) ; dbprintf( \"%s(%d): duration of copy to process, fdt = %e us \\n\" , __func__, __LINE__, toddiff( &tprocess, &tcopy) ) ; trigger_info.time_gputhread_finished_s = tprocess.tv_sec ; trigger_info.time_gputhread_finished_us = tprocess.tv_usec ; GPU_Dat a_Buffer [GPUbufferindex].gpu_dat a_header [ 11 ] = tprocess.tv_sec ; GPU_Dat a_Buffer [GPUbufferindex].gpu_dat a_header [ 12 ] = tprocess.tv_usec ; MFE proc unlocked, frontend.cpp:2714 status = gettimeofday( &t_lock_data, NULL); trigger_info.time_slave_lock_dataready_s = t_lock_data.tv_sec; trigger_info.time_slave_lock_dataready_us = t_lock_data.tv_usec; // store timing information and current TCPfillnumber, GPUfillnumber in header databank GPUDATA->gpu_data_header[13] = t_lock_data.tv_sec; GPUDATA->gpu_data_header[14] = t_lock_data.tv_usec; status = gettimeofday( &t_lock_data, NULL ); trigger_info.time_slave_lock_dataready_s = t_lock_data.tv_sec; trigger_info.time_slave_lock_dataready_us = t_lock_data.tv_usec; // store timing information and current TCPfillnumber, GPUfillnumber in header databank GPUDATA->gpu_data_header[ 13 ] = t_lock_data.tv_sec; GPUDATA->gpu_data_header[ 14 ] = t_lock_data.tv_usec; MFE banks made, frontend.cpp:3288 status = gettimeofday( &t_got_data, NULL); trigger_info.time_slave_got_data_s = t_got_data.tv_sec; trigger_info.time_slave_got_data_us = t_got_data.tv_usec; // make more header / timing data // array elements 17, 18 reserced for compression timing data GPUDATA->gpu_data_header[15] = t_got_data.tv_sec; GPUDATA->gpu_data_header[16] = t_got_data.tv_usec; status = gettimeofday( &t_got_data, NU LL); trigger_info.time_slave_got_data_s = t_got_data.tv_sec; trigger_info.time_slave_got_data_us = t_got_data.tv_usec; // make more header / timing data // array elements 17, 18 reserced for compression timing data GPUDATA->gpu_data_header[15] = t_got_data.tv_sec; GPUDATA->gpu_data_header[16] = t_got_data.tv_usec; lossless compression, frontend.cpp:3463 status = gettimeofday( &t_done_compression, NULL); perf_data[17] = t_done_compression.tv_sec; perf_data[18] = t_done_compression.tv_usec; status = gettimeof day ( &t_done_compression , NULL ); perf_data[17] = t_done_compression.tv_sec; perf_data[18] = t_done_compression.tv_usec; 13/05/2024 01:03 What happens in between each time step? got TCP header word - TCP proc unlocked Lock TCP thread, call part of read and unpack pthread_mutex_lock( &mutex_TCP_buf[bufIndex] ); // function reads / unpacks the AMC13 block structure gettimeofday( &tbeginread, NULL); databytes = readAndUnpack( bufIndex ); pthread_mutex_lock( &mutex_TCP_buf [bufIndex] ); // function reads / unpacks the AMC13 block structure gettimeof day ( &tbeginread , NULL ); databytes = readAndUnpack( bufIndex ); Declare local read and unpack variables, read first word: int readAndUnpack(int bufIndex){ //#ifdef DEBUG unsigned int EventIndex; // AMC13 reported event number unsigned int OverallSize; // event size in AMC13 header //#endif int iAMC, nAMC; // AMC13 reported number of AMC modules //#ifdef DEBUG int local_headerbytes = TCPheadersize; //#endif int block_status = 0; int retval = ReadXBytes( clientsockfd, sizeof(uint64_t), (void*)( header ),block_status ); // printf(\"Read Header: %d vs %d\",retval, sizeof(uint64_t)); // get overall CDF header word if (retval < int(sizeof(uint64_t))) { if ( retval < 0 ) { cm_msg(MERROR, __FILE__, \"Cannot read header from socket\"); return -1; }else if (retval == 0) { if (block_status == 1 ) { return 0; }else{ cm_msg(MERROR, __FILE__, \"Cannot read header from socket\"); return -1; } }else{ cm_msg(MERROR, __FILE__, \"Cannot read header from socket\"); return -1; } } // get event number from header bank //#ifdef DEBUG EventIndex = getEventIndex( be64toh( *header ) ); //#endif // pointer location to AMC13 unpacking info in amc13info data array offsetamc13info = amc13info; // write CDF header word in the amc13info array *offsetamc13info = *header; dbprintf(\"%s(%d): read header, header size [bytes] %d, header[0] 0x%016lX, BODdelimiter 0x%016lX, BODmask 0x%016lx Event number %i\\n\", __func__, __LINE__, local_headerbytes, *offsetamc13info, BODdelimiter, BODmask, EventIndex ); offsetamc13info++; // record time got header word gettimeofday( &theader, NULL); header[3] = theader.tv_sec; // fill header time info in header header[4] = theader.tv_usec; // fill header time info in header int readAndUnpack(int bufIndex){ //#ifdef DEBUG unsigned int EventIndex; // AMC13 reported event number unsigned int OverallSize; // event size in AMC13 header //#endif int iAMC, nAMC; // AMC13 reported number of AMC modules //#ifdef DEBUG int local_headerbytes = TCPheadersize; //#endif int block_status = 0; int retval = ReadXBytes( clientsockfd, sizeof(uint64_t), (void*)( header ),block_status ); // printf(\"Read Header: %d vs %d\",retval, sizeof(uint64_t)); // get overall CDF header word if (retval < int(sizeof(uint64_t))) { if ( retval < 0 ) { cm_msg(MERROR, __FILE__, \"Cannot read header from socket\"); return -1; }else if (retval == 0) { if (block_status == 1 ) { return 0; }else{ cm_msg(MERROR, __FILE__, \"Cannot read header from socket\"); return -1; } }else{ cm_msg(MERROR, __FILE__, \"Cannot read header from socket\"); return -1; } } // get event number from header bank //#ifdef DEBUG EventIndex = getEventIndex( be64toh( *header ) ); //#endif // pointer location to AMC13 unpacking info in amc13info data array offsetamc13info = amc13info; // write CDF header word in the amc13info array *offsetamc13info = *header; dbprintf(\"%s(%d): read header, header size [bytes] %d, header[0] 0x%016lX, BODdelimiter 0x%016lX, BODmask 0x%016lx Event number %i\\n\", __func__, __LINE__, local_headerbytes, *offsetamc13info, BODdelimiter, BODmask, EventIndex ); offsetamc13info++; // record time got header word gettimeofday( &theader, NULL); header[3] = theader.tv_sec; // fill header time info in header header[4] = theader.tv_usec; // fill header time info in header got TCP header word 2 - got TCP header word The rest of read and unpack happens: dbprintf(\"%s(%d): duration from AVAIL lock to fill header bank, buffer[%d], fill %d, duration %e us \\n\", __func__, __LINE__, bufIndex, TCPfillnumber, toddiff( &theader, &tstart) ); // byte / block counters for AMC modules x AMC blocks readoout structure int blockdatabytes = 0; // individual AMC module bytes per AMC13 block int totaldatabytes = 0; // running total of all AMC modules data bytes int blockcount = 0; // AMC13 block counters // data offsets for unpacking data buffer structure of AMCs x blocks unsigned int dataoffset = 0, datablockoffset[12], dataAMCoffset[12]; memset( datablockoffset, 0, sizeof(datablockoffset) ); // block offset of particular AMC modules data memset( dataAMCoffset, 0, sizeof(dataAMCoffset) ); // overall offset of particular AMC modules data bool moredata = 1; // more data is true of more blocks are available while ( moredata ){ // loops over AMC data blocks // read single 64-bit AMC13 block header word //Try reading 1 times before giving up int read_fail = 0; while (read_fail<1) { retval = ReadXBytes( clientsockfd, sizeof(uint64_t), (void*)( offsetamc13info ) ,block_status); if (retval>0) { break; } usleep(100000); read_fail++; } if (read_fail>=1) { cm_msg(MERROR, __FILE__, \"Error when reading from socket, fd %d. Read %d bytes vs %d, for %d times\", clientsockfd,retval,sizeof(uint64_t),read_fail); cm_msg(MERROR,__FILE__, \"read header, header size [bytes] %d, header[0] 0x%016lX, BODdelimiter 0x%016lX, BODmask 0x%016lx Event number %i\",local_headerbytes, *offsetamc13info, BODdelimiter, BODmask, EventIndex); } if ( retval < int(sizeof(uint64_t)) ) { cm_msg(MERROR, __FILE__, \"Error when reading from socket, fd %d. Read %d bytes vs %d\", clientsockfd,retval,sizeof(uint64_t)); cm_msg(MERROR,__FILE__, \"read header, header size [bytes] %d, header[0] 0x%016lX, BODdelimiter 0x%016lX, BODmask 0x%016lx Event number %i\",local_headerbytes, *offsetamc13info, BODdelimiter, BODmask, EventIndex); return -1; } // get the number of enabled AMCs nAMC = getAMCNum( be64toh( *offsetamc13info ) ); offsetamc13info++; dbprintf(\"%s(%d): reading AMC general header word 0x%016lX, nAMC decoded %i\\n\", __func__, __LINE__, *offsetamc13info, getAMCNum( be64toh( *offsetamc13info ) ) ); // WARN if mismatch between ODB and AMC13 headers / trailers for number of active modules for first block if ( ( blockcount == 0 ) && ( nAMC != NRiderModuleEnabled ) ) { cm_msg(MERROR, __FILE__, \"WARNING! mismatch between ODB (%i) and AMC13 headers (%i) for number of AMC modules\", NRiderModuleEnabled, nAMC); dbprintf(\"%s(%d): WARNING! mis-match between ODB (%i) and AMC13 headers (%i) for number of AMC modules\\n\", __func__, __LINE__, NRiderModuleEnabled, nAMC); } // read 64-bit AMC module header words - one per AMC retval = ReadXBytes( clientsockfd, nAMC*sizeof(uint64_t), (void*)( offsetamc13info) ,block_status); if ( retval < int(nAMC*sizeof(uint64_t)) ) { cm_msg(MERROR, __FILE__, \"Error when reading from socket, fd %d. Read %d bytes vs %d\", clientsockfd,retval,nAMC*sizeof(uint64_t)); return -1; } // WARN if mismatch between ODB and AMC13 headers / trailers for AMC slot number for (iAMC = 0; iAMC < nAMC; iAMC++){ if ( !amc13_rider_odb[amc_header_info[iAMC].AMCSlotNum-1].board.rider_enabled ) { //cm_msg(MERROR, __FILE__, \"WARNING! AMC slot %i not enabled in ODB\", amc_header_info[iAMC].AMCSlotNum); dbprintf(\"%s(%d): WARNING! amc_header_info[iAMC].AMCSlot %i\\n\", __func__, __LINE__, amc_header_info[iAMC].AMCSlotNum); } } // decode AMC header words - get continuation bits, event / block size, AMC slot number // set moredata = 1 if more blocks are following this block moredata = 0; for (iAMC = 0; iAMC < nAMC; iAMC++){ if ( decodeAMCHeader( iAMC, be64toh( *( offsetamc13info ) ) ) != 0 ) { printf(\"decodeAMCHeader() failed!\"); } offsetamc13info++; if (amc_header_info[iAMC].AMCMoreBit) moredata = 1; dbprintf(\"%s(%d): AMC index %d, AMC Slot number %d, AMCMoreBit %d, more data %d, AMCEventSize 0x%08x\\n\", __func__, __LINE__, iAMC, amc_header_info[iAMC].AMCSlotNum, amc_header_info[iAMC].AMCMoreBit, moredata, amc_header_info[iAMC].AMCEventSize ); } // calculate AMC data offsets dataAMCoffset[amc_header_info[iAMC].AMCSlotNum-1] from total event sizes in S=0 word AMC header word // (i.e. for either M=1,S=0 with continuation blocks or M=0,S=0 with only one block) // This calculation is performed once per fill / event and hanfles different total data sizes, // i.e. amc_header_info[iAMC].AMCEventSize, from different amcmodules if ( !amc_header_info[0].AMCSegBit ) { int AMCoffsetbytes = 0; for (iAMC = 0; iAMC < nAMC; iAMC++){ dataAMCoffset[amc_header_info[iAMC].AMCSlotNum-1] = AMCoffsetbytes / sizeof(uint64_t); dbprintf(\"%s(%d): blockcount %d, AMC index %d, calculated AMC total data offset 0x%08x\\n\", __func__, __LINE__, blockcount, iAMC, dataAMCoffset[amc_header_info[iAMC].AMCSlotNum-1]); AMCoffsetbytes += sizeof(uint64_t)*amc_header_info[iAMC].AMCEventSize; } } // read AMC data block for (iAMC = 0; iAMC < nAMC; iAMC++){ // calculate the data bytes - blockdatabytes - to read for each AMC module with index iAMC // bits determine if first block, intermediate block, last block or single block if ( amc_header_info[iAMC].AMCMoreBit && (!amc_header_info[iAMC].AMCSegBit) ) { blockdatabytes = 32768; dbprintf(\"M=1,S=0 first block in segment, set size to 0x%08x bytes (odb 0x%08x)\\n\", blockdatabytes, amc13_amc13_odb.amc_block_size); } if ( amc_header_info[iAMC].AMCMoreBit && amc_header_info[iAMC].AMCSegBit ) { dbprintf(\"M=1,S=1 intermediate block in segment, set size from amc header word\\n\"); blockdatabytes = sizeof(uint64_t)*amc_header_info[iAMC].AMCEventSize; } if ( (!amc_header_info[iAMC].AMCMoreBit) && amc_header_info[iAMC].AMCSegBit ) { dbprintf(\"M=0,S=1 last block in segment, set size from amc header word\\n\"); blockdatabytes = sizeof(uint64_t)*amc_header_info[iAMC].AMCEventSize; } if ( (!amc_header_info[iAMC].AMCMoreBit) && (!amc_header_info[iAMC].AMCSegBit) ) { dbprintf(\"M=0,S=0 only block in segment, set size from amc header word\\n\"); blockdatabytes = sizeof(uint64_t)*amc_header_info[iAMC].AMCEventSize; } // calculated the location to put the data from block structure in AMC13 event dataoffset = dataAMCoffset[amc_header_info[iAMC].AMCSlotNum-1] + datablockoffset[amc_header_info[iAMC].AMCSlotNum-1]; dbprintf(\"%s(%d): blockcount %d, iAMC %d, calculated AMC+Block data offset 0x%08x block data bytes 0x%08x data bytes total 0x%08x\\n\", __func__, __LINE__, blockcount, iAMC, dataoffset, blockdatabytes, totaldatabytes); // read the data block for each AMC module in array tcp_buf_gl[bufIndex] retval = ReadXBytes( clientsockfd, blockdatabytes, (void*)( tcp_buf_gl[bufIndex] + dataoffset ) ,block_status); if ( retval < blockdatabytes) { cm_msg(MERROR, __FILE__, \"Error when reading from socket, fd %d. Read %d bytes vs %d\", clientsockfd,retval,blockdatabytes); return -1; } dbprintf(\"%s(%d): done reading AMC block %i bytes %i, dataoffset %d, (tcp_buf_gl[bufIndex] + dataoffset ) %p, data[0] 0x%16lx data[1] 0x%16lx\\n\", __func__, __LINE__, blockcount, blockdatabytes, dataoffset, ( tcp_buf_gl[bufIndex] + dataoffset ), *( tcp_buf_gl[bufIndex] + dataoffset ), *( tcp_buf_gl[bufIndex] + dataoffset + 1 ) ); //dataoffset += blockdatabytes/sizeof(uint64_t); // redundant so removed? datablockoffset[amc_header_info[iAMC].AMCSlotNum-1] += blockdatabytes/sizeof(uint64_t); // datablockoffset[i] is individual payload readout from ith AMC module totaldatabytes += blockdatabytes; // totaldatabytes is total payload readout from all AMC modules dbprintf(\"%s(%d): end of read loop for amc %i\\n\",__func__, __LINE__,iAMC); } // read single 64-bit AMC13 block trailer word retval = ReadXBytes( clientsockfd, sizeof(uint64_t), (void*)( offsetamc13info ) ,block_status); if ( retval < int(sizeof(uint64_t))) { cm_msg(MERROR, __FILE__, \"Error when reading from socket, fd %d. Read %d bytes vs %d\", clientsockfd,retval,sizeof(uint64_t)); return -1; } dbprintf(\"%s(%d): done reading AMC block %i, trailer word *tmp 0x%08lx\\n\", __func__, __LINE__, blockcount, *offsetamc13info); offsetamc13info++; blockcount++; } dbprintf(\"%s(%d): finished data read / unpack, databytes total 0x%08x block count %i\\n\", __func__, __LINE__, totaldatabytes, blockcount); // get CDF trailer word retval = ReadXBytes( clientsockfd, tailbytes, (void*)(tail) ,block_status); if ( retval < int(tailbytes)) { cm_msg(MERROR, __FILE__, \"Error when reading from socket, fd %d. Read %d bytes vs %d\", clientsockfd,retval,tailbytes); return -1; } #ifdef DEBUG OverallSize = getOverallSize( be64toh(tail[0]) ); #endif dbprintf(\"%s(%d): read trailer, trailer size [bytes] %d, tail[0] 0x%016lX, EODdelimiter 0x%016lX, EODmask 0x%016lX, Overall Size %i\\n\", __func__, __LINE__, tailbytes, be64toh(tail[0]), EODdelimiter, EODmask, OverallSize); #if 0 // turn on/off CPU-based byte-reordering in 8-byte AMC13 words // re-order data from network / big-endian to little-endian struct timeval tbeforeReorderBytes, tafterReorderBytes; gettimeofday( &tbeforeReorderBytes, NULL); int iReorderBytes, nReorderBytes = totaldatabytes / sizeof(uint64_t); for (iReorderBytes = 0; iReorderBytes < nReorderBytes; iReorderBytes++){ tcp_buf_gl[bufIndex][iReorderBytes] = be64toh( tcp_buf_gl[bufIndex][iReorderBytes] ); } gettimeofday( &tafterReorderBytes, NULL); dbprintf(\"%s(%d): duration of byte re-ordering, buffer[%d], fill %d, duration %e us \\n\", __func__, __LINE__, bufIndex, TCPfillnumber, toddiff( &tafterReorderBytes, &tbeforeReorderBytes) ); #endif return totaldatabytes; } dbprintf(\"%s(%d): duration from AVAIL lock to fill header bank, buffer[%d], fill %d, duration %e us \\n\", __func__, __LINE__, bufIndex, TCPfillnumber, toddiff( &theader, &tstart) ); // byte / block counters for AMC modules x AMC blocks readoout structure int blockdatabytes = 0; // individual AMC module bytes per AMC13 block int totaldatabytes = 0; // running total of all AMC modules data bytes int blockcount = 0; // AMC13 block counters // data offsets for unpacking data buffer structure of AMCs x blocks unsigned int dataoffset = 0, datablockoffset[12], dataAMCoffset[12]; memset( datablockoffset, 0, sizeof(datablockoffset) ); // block offset of particular AMC modules data memset( dataAMCoffset, 0, sizeof(dataAMCoffset) ); // overall offset of particular AMC modules data bool moredata = 1; // more data is true of more blocks are available while ( moredata ){ // loops over AMC data blocks // read single 64-bit AMC13 block header word //Try reading 1 times before giving up int read_fail = 0; while (read_fail<1) { retval = ReadXBytes( clientsockfd, sizeof(uint64_t), (void*)( offsetamc13info ) ,block_status); if (retval>0) { break; } usleep(100000); read_fail++; } if (read_fail>=1) { cm_msg(MERROR, __FILE__, \"Error when reading from socket, fd %d. Read %d bytes vs %d, for %d times\", clientsockfd,retval,sizeof(uint64_t),read_fail); cm_msg(MERROR,__FILE__, \"read header, header size [bytes] %d, header[0] 0x%016lX, BODdelimiter 0x%016lX, BODmask 0x%016lx Event number %i\",local_headerbytes, *offsetamc13info, BODdelimiter, BODmask, EventIndex); } if ( retval < int(sizeof(uint64_t)) ) { cm_msg(MERROR, __FILE__, \"Error when reading from socket, fd %d. Read %d bytes vs %d\", clientsockfd,retval,sizeof(uint64_t)); cm_msg(MERROR,__FILE__, \"read header, header size [bytes] %d, header[0] 0x%016lX, BODdelimiter 0x%016lX, BODmask 0x%016lx Event number %i\",local_headerbytes, *offsetamc13info, BODdelimiter, BODmask, EventIndex); return -1; } // get the number of enabled AMCs nAMC = getAMCNum( be64toh( *offsetamc13info ) ); offsetamc13info++; dbprintf(\"%s(%d): reading AMC general header word 0x%016lX, nAMC decoded %i\\n\", __func__, __LINE__, *offsetamc13info, getAMCNum( be64toh( *offsetamc13info ) ) ); // WARN if mismatch between ODB and AMC13 headers / trailers for number of active modules for first block if ( ( blockcount == 0 ) && ( nAMC != NRiderModuleEnabled ) ) { cm_msg(MERROR, __FILE__, \"WARNING! mismatch between ODB (%i) and AMC13 headers (%i) for number of AMC modules\", NRiderModuleEnabled, nAMC); dbprintf(\"%s(%d): WARNING! mis-match between ODB (%i) and AMC13 headers (%i) for number of AMC modules\\n\", __func__, __LINE__, NRiderModuleEnabled, nAMC); } // read 64-bit AMC module header words - one per AMC retval = ReadXBytes( clientsockfd, nAMC*sizeof(uint64_t), (void*)( offsetamc13info) ,block_status); if ( retval < int(nAMC*sizeof(uint64_t)) ) { cm_msg(MERROR, __FILE__, \"Error when reading from socket, fd %d. Read %d bytes vs %d\", clientsockfd,retval,nAMC*sizeof(uint64_t)); return -1; } // WARN if mismatch between ODB and AMC13 headers / trailers for AMC slot number for (iAMC = 0; iAMC < nAMC; iAMC++){ if ( !amc13_rider_odb[amc_header_info[iAMC].AMCSlotNum-1].board.rider_enabled ) { //cm_msg(MERROR, __FILE__, \"WARNING! AMC slot %i not enabled in ODB\", amc_header_info[iAMC].AMCSlotNum); dbprintf(\"%s(%d): WARNING! amc_header_info[iAMC].AMCSlot %i\\n\", __func__, __LINE__, amc_header_info[iAMC].AMCSlotNum); } } // decode AMC header words - get continuation bits, event / block size, AMC slot number // set moredata = 1 if more blocks are following this block moredata = 0; for (iAMC = 0; iAMC < nAMC; iAMC++){ if ( decodeAMCHeader( iAMC, be64toh( *( offsetamc13info ) ) ) != 0 ) { printf(\"decodeAMCHeader() failed!\"); } offsetamc13info++; if (amc_header_info[iAMC].AMCMoreBit) moredata = 1; dbprintf(\"%s(%d): AMC index %d, AMC Slot number %d, AMCMoreBit %d, more data %d, AMCEventSize 0x%08x\\n\", __func__, __LINE__, iAMC, amc_header_info[iAMC].AMCSlotNum, amc_header_info[iAMC].AMCMoreBit, moredata, amc_header_info[iAMC].AMCEventSize ); } // calculate AMC data offsets dataAMCoffset[amc_header_info[iAMC].AMCSlotNum-1] from total event sizes in S=0 word AMC header word // (i.e. for either M=1,S=0 with continuation blocks or M=0,S=0 with only one block) // This calculation is performed once per fill / event and hanfles different total data sizes, // i.e. amc_header_info[iAMC].AMCEventSize, from different amcmodules if ( !amc_header_info[0].AMCSegBit ) { int AMCoffsetbytes = 0; for (iAMC = 0; iAMC < nAMC; iAMC++){ dataAMCoffset[amc_header_info[iAMC].AMCSlotNum-1] = AMCoffsetbytes / sizeof(uint64_t); dbprintf(\"%s(%d): blockcount %d, AMC index %d, calculated AMC total data offset 0x%08x\\n\", __func__, __LINE__, blockcount, iAMC, dataAMCoffset[amc_header_info[iAMC].AMCSlotNum-1]); AMCoffsetbytes += sizeof(uint64_t)*amc_header_info[iAMC].AMCEventSize; } } // read AMC data block for (iAMC = 0; iAMC < nAMC; iAMC++){ // calculate the data bytes - blockdatabytes - to read for each AMC module with index iAMC // bits determine if first block, intermediate block, last block or single block if ( amc_header_info[iAMC].AMCMoreBit && (!amc_header_info[iAMC].AMCSegBit) ) { blockdatabytes = 32768; dbprintf(\"M=1,S=0 first block in segment, set size to 0x%08x bytes (odb 0x%08x)\\n\", blockdatabytes, amc13_amc13_odb.amc_block_size); } if ( amc_header_info[iAMC].AMCMoreBit && amc_header_info[iAMC].AMCSegBit ) { dbprintf(\"M=1,S=1 intermediate block in segment, set size from amc header word\\n\"); blockdatabytes = sizeof(uint64_t)*amc_header_info[iAMC].AMCEventSize; } if ( (!amc_header_info[iAMC].AMCMoreBit) && amc_header_info[iAMC].AMCSegBit ) { dbprintf(\"M=0,S=1 last block in segment, set size from amc header word\\n\"); blockdatabytes = sizeof(uint64_t)*amc_header_info[iAMC].AMCEventSize; } if ( (!amc_header_info[iAMC].AMCMoreBit) && (!amc_header_info[iAMC].AMCSegBit) ) { dbprintf(\"M=0,S=0 only block in segment, set size from amc header word\\n\"); blockdatabytes = sizeof(uint64_t)*amc_header_info[iAMC].AMCEventSize; } // calculated the location to put the data from block structure in AMC13 event dataoffset = dataAMCoffset[amc_header_info[iAMC].AMCSlotNum-1] + datablockoffset[amc_header_info[iAMC].AMCSlotNum-1]; dbprintf(\"%s(%d): blockcount %d, iAMC %d, calculated AMC+Block data offset 0x%08x block data bytes 0x%08x data bytes total 0x%08x\\n\", __func__, __LINE__, blockcount, iAMC, dataoffset, blockdatabytes, totaldatabytes); // read the data block for each AMC module in array tcp_buf_gl[bufIndex] retval = ReadXBytes( clientsockfd, blockdatabytes, (void*)( tcp_buf_gl[bufIndex] + dataoffset ) ,block_status); if ( retval < blockdatabytes) { cm_msg(MERROR, __FILE__, \"Error when reading from socket, fd %d. Read %d bytes vs %d\", clientsockfd,retval,blockdatabytes); return -1; } dbprintf(\"%s(%d): done reading AMC block %i bytes %i, dataoffset %d, (tcp_buf_gl[bufIndex] + dataoffset ) %p, data[0] 0x%16lx data[1] 0x%16lx\\n\", __func__, __LINE__, blockcount, blockdatabytes, dataoffset, ( tcp_buf_gl[bufIndex] + dataoffset ), *( tcp_buf_gl[bufIndex] + dataoffset ), *( tcp_buf_gl[bufIndex] + dataoffset + 1 ) ); //dataoffset += blockdatabytes/sizeof(uint64_t); // redundant so removed? datablockoffset[amc_header_info[iAMC].AMCSlotNum-1] += blockdatabytes/sizeof(uint64_t); // datablockoffset[i] is individual payload readout from ith AMC module totaldatabytes += blockdatabytes; // totaldatabytes is total payload readout from all AMC modules dbprintf(\"%s(%d): end of read loop for amc %i\\n\",__func__, __LINE__,iAMC); } // read single 64-bit AMC13 block trailer word retval = ReadXBytes( clientsockfd, sizeof(uint64_t), (void*)( offsetamc13info ) ,block_status); if ( retval < int(sizeof(uint64_t))) { cm_msg(MERROR, __FILE__, \"Error when reading from socket, fd %d. Read %d bytes vs %d\", clientsockfd,retval,sizeof(uint64_t)); return -1; } dbprintf(\"%s(%d): done reading AMC block %i, trailer word *tmp 0x%08lx\\n\", __func__, __LINE__, blockcount, *offsetamc13info); offsetamc13info++; blockcount++; } dbprintf(\"%s(%d): finished data read / unpack, databytes total 0x%08x block count %i\\n\", __func__, __LINE__, totaldatabytes, blockcount); // get CDF trailer word retval = ReadXBytes( clientsockfd, tailbytes, (void*)(tail) ,block_status); if ( retval < int(tailbytes)) { cm_msg(MERROR, __FILE__, \"Error when reading from socket, fd %d. Read %d bytes vs %d\", clientsockfd,retval,tailbytes); return -1; } #ifdef DEBUG OverallSize = getOverallSize( be64toh(tail[0]) ); #endif dbprintf(\"%s(%d): read trailer, trailer size [bytes] %d, tail[0] 0x%016lX, EODdelimiter 0x%016lX, EODmask 0x%016lX, Overall Size %i\\n\", __func__, __LINE__, tailbytes, be64toh(tail[0]), EODdelimiter, EODmask, OverallSize); #if 0 // turn on/off CPU-based byte-reordering in 8-byte AMC13 words // re-order data from network / big-endian to little-endian struct timeval tbeforeReorderBytes, tafterReorderBytes; gettimeofday( &tbeforeReorderBytes, NULL); int iReorderBytes, nReorderBytes = totaldatabytes / sizeof(uint64_t); for (iReorderBytes = 0; iReorderBytes < nReorderBytes; iReorderBytes++){ tcp_buf_gl[bufIndex][iReorderBytes] = be64toh( tcp_buf_gl[bufIndex][iReorderBytes] ); } gettimeofday( &tafterReorderBytes, NULL); dbprintf(\"%s(%d): duration of byte re-ordering, buffer[%d], fill %d, duration %e us \\n\", __func__, __LINE__, bufIndex, TCPfillnumber, toddiff( &tafterReorderBytes, &tbeforeReorderBytes) ); #endif return totaldatabytes; } Some checks are made in the main thread: gettimeofday( &tfinishread, NULL); //Test print of the fill number //printf(\"AMC13 Fill number = %d ; TCP Fill number = %d \\n\",getEventIndex( be64toh( header[0] ) ),int(TCPfillnumber)); //Check if there are data readout correctly if (databytes == 0) { //skip this iteration if there are no data available pthread_mutex_unlock( &mutex_TCP_buf[bufIndex] ); continue; } if (databytes < 0) { //terminate the while loop if there is an read error read_error = true; pthread_mutex_unlock( &mutex_TCP_buf[bufIndex] ); cm_msg(MERROR, __FILE__,\"tcp_thread: break the tcp thread loop becuase of a reading error %d\", databytes); break; } if ( toddiff( &tfinishread, &tbeginread) > 100000.) { printf(\"WARNING tcpip stall, readAndUnpack > 100ms!\"); printf(\"%s(%d): duration of readAndUnpack, read %d bytes, time = %e us \\n\", __func__, __LINE__, databytes , toddiff( &tfinishread, &tbeginread) ); } amc13infobytes = (uint64_t)offsetamc13info - (uint64_t)amc13info; trigger_info.time_tcp_finish_header_read_s = header[3]; trigger_info.time_tcp_finish_header_read_us = header[4]; // get time done read / unpack of AMC13 event status = gettimeofday( &tdata, NULL); header[5] = tdata.tv_sec; // fill data time info in header header[6] = tdata.tv_usec; // fill data time info in header gettimeofday( &tfinishread, NULL); //Test print of the fill number //printf(\"AMC13 Fill number = %d ; TCP Fill number = %d \\n\",getEventIndex( be64toh( header[0] ) ),int(TCPfillnumber)); //Check if there are data readout correctly if (databytes == 0) { //skip this iteration if there are no data available pthread_mutex_unlock( &mutex_TCP_buf[bufIndex] ); continue; } if (databytes < 0) { //terminate the while loop if there is an read error read_error = true; pthread_mutex_unlock( &mutex_TCP_buf[bufIndex] ); cm_msg(MERROR, __FILE__,\"tcp_thread: break the tcp thread loop becuase of a reading error %d\", databytes); break; } if ( toddiff( &tfinishread, &tbeginread) > 100000.) { printf(\"WARNING tcpip stall, readAndUnpack > 100ms!\"); printf(\"%s(%d): duration of readAndUnpack, read %d bytes, time = %e us \\n\", __func__, __LINE__, databytes , toddiff( &tfinishread, &tbeginread) ); } amc13infobytes = (uint64_t)offsetamc13info - (uint64_t)amc13info; trigger_info.time_tcp_finish_header_read_s = header[3]; trigger_info.time_tcp_finish_header_read_us = header[4]; // get time done read / unpack of AMC13 event status = gettimeofday( &tdata, NULL); header[5] = tdata.tv_sec; // fill data time info in header header[6] = tdata.tv_usec; // fill data time info in header GPU Proc Unlocked - got TCP Header Word 2 Some checks are made to see if data is recieved, variables initialized: //Check TCPfillnumber and makesure TCPfillnumber is greater unsigned long TCPfillnumber_local; unsigned long GPUfillnumber_local; //bor function can change the global fill number unsigned long Midasfillnumber_local; int local_thread_active = 0; int local_thread_read = 0; pthread_mutex_lock( &mutex_TCP_general ); TCPfillnumber_local = TCPfillnumber; pthread_mutex_unlock( &mutex_TCP_general ); pthread_mutex_lock( &mutex_GPU_general ); GPUfillnumber_local = GPUfillnumber; local_thread_active = gpu_thread_active; local_thread_read = gpu_thread_read; pthread_mutex_unlock( &mutex_GPU_general ); pthread_mutex_lock(&mutex_midas); Midasfillnumber_local = Midasfillnumber; pthread_mutex_unlock(&mutex_midas); if (!local_thread_active) { break; } if (!local_thread_read) { usleep(100); continue; } if (GPUfillnumber_local == TCPfillnumber_local || TCPfillnumber_local == 0) { dbprintf(\"%s(%d): No new events in the TCP buffer \\n\", __func__, __LINE__ ); usleep(100); continue; } unsigned long tcp_buffer_filled = 0; if (TCPfillnumber_local > GPUfillnumber_local) { tcp_buffer_filled = TCPfillnumber_local - GPUfillnumber_local; }else{ tcp_buffer_filled = 0xffffffffffffffff - (GPUfillnumber_local - TCPfillnumber_local) +1 ; } dbprintf(\"%s(%d): tcp_ring_buffer_size %d \\n\", __func__, __LINE__, tcp_buffer_filled ); dbprintf(\"%s(%d): tcp fill %d gpu fill %d \\n\", __func__, __LINE__, TCPfillnumber_local , GPUfillnumber_local ); float BufLoad = tcp_buffer_filled * 1.0 / TCP_BUF_MAX_FILLS; float BufLoadThreshold = 0.9; if (BufLoad > BufLoadThreshold && !BufFullAlarmTriggered) { BufFullAlarmTriggered = true; char AlarmMsg[500]; sprintf(AlarmMsg,\"DAQ | AMC13%03d TCP Ring buffer close to full (%f%%)\",frontend_index,BufLoad*100); int ret_code = al_trigger_alarm(\"Frontend TCP Buffer Error\", AlarmMsg, \"Warning\", \"Frontend TCP Buffer Error\", AT_INTERNAL); if (ret_code != AL_SUCCESS) { cm_msg(MERROR, __FILE__, \"Failure Raising Alarm: Error %d, Alarm \\\"%s\\\"\", ret_code, \"Frontend TCP Buffer Error\" ); } } if (BufLoad < BufLoadThreshold && BufFullAlarmTriggered) { BufFullAlarmTriggered = false; char AlarmMsg[500]; sprintf(AlarmMsg,\"DAQ | AMC13%03d TCP Ring buffer returns normal (%f%%)\",frontend_index,BufLoad*100); int ret_code = al_trigger_alarm(\"Frontend TCP Buffer Recovery\", AlarmMsg, \"Recovery\", \"Frontend TCP Buffer Recovery\", AT_INTERNAL); if (ret_code != AL_SUCCESS) { cm_msg(MERROR, __FILE__, \"Failure Raising Alarm: Error %d, Alarm \\\"%s\\\"\", ret_code, \"Frontend TCP Buffer Recovery\" ); } } unsigned long gpu_buffer_filled = 0; if (GPUfillnumber_local > Midasfillnumber_local) { gpu_buffer_filled = GPUfillnumber_local - Midasfillnumber_local; }else{ gpu_buffer_filled = 0xffffffffffffffff - (Midasfillnumber_local - GPUfillnumber_local) +1 ; } dbprintf(\"%s(%d): gpu_ring_buffer_size %d \\n\", __func__, __LINE__, gpu_buffer_filled ); dbprintf(\"%s(%d): gpu fill %d midas fill %d \\n\", __func__, __LINE__, GPUfillnumber_local , Midasfillnumber_local ); float GPUBufLoad = gpu_buffer_filled * 1.0 / GPU_BUFFER_SIZE; float GPUBufLoadThreshold = 0.9; if (GPUBufLoad > GPUBufLoadThreshold && !GPUBufFullAlarmTriggered) { GPUBufFullAlarmTriggered = true; char AlarmMsg[500]; sprintf(AlarmMsg,\"DAQ | AMC13%03d GPU Ring buffer close to full (%f%%)\",frontend_index,GPUBufLoad*100); int ret_code = al_trigger_alarm(\"Frontend GPU Buffer Error\", AlarmMsg, \"Warning\", \"Frontend GPU Buffer Error\", AT_INTERNAL); if (ret_code != AL_SUCCESS) { cm_msg(MERROR, __FILE__, \"Failure Raising Alarm: Error %d, Alarm \\\"%s\\\"\", ret_code, \"Frontend GPU Buffer Error\" ); } } if (GPUBufLoad < GPUBufLoadThreshold && GPUBufFullAlarmTriggered) { GPUBufFullAlarmTriggered = false; char AlarmMsg[500]; sprintf(AlarmMsg,\"DAQ | AMC13%03d GPU Ring buffer returns normal (%f%%)\",frontend_index,GPUBufLoad*100); int ret_code = al_trigger_alarm(\"Frontend GPU Buffer Recovery\", AlarmMsg, \"Recovery\", \"Frontend GPU Buffer Recovery\", AT_INTERNAL); if (ret_code != AL_SUCCESS) { cm_msg(MERROR, __FILE__, \"Failure Raising Alarm: Error %d, Alarm \\\"%s\\\"\", ret_code, \"Frontend GPU Buffer Recovery\" ); } } //Do not proceed if the GPU buffer is full if ( (gpu_buffer_filled >= GPU_BUFFER_SIZE - 1) || (tcp_buffer_filled >= TCP_BUF_MAX_FILLS - 1) ) { fc7help->setThrottleTriggers( encoder_fc7, frontend_index, 1); triggersThrottled = true; cm_msg(MINFO, __FILE__, \"Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers\"); continue; } else if ( triggersThrottled ) { fc7help->setThrottleTriggers( encoder_fc7, frontend_index, 0); triggersThrottled = false; cm_msg(MINFO, __FILE__, \"Trigger throttling removed\"); } // calculate TCP ring buffer index from GPU fill number TCPbufferindex = GPUfillnumber_local%TCP_BUF_MAX_FILLS; dbprintf(\"%s(%d): start new fill %d, buffer %d\\n\", __func__, __LINE__, GPUfillnumber_local, TCPbufferindex ); // calculate the GPU ring buffer index GPUbufferindex = GPUfillnumber_local % GPU_BUFFER_SIZE; //Lock GPU buffer unit pthread_mutex_lock( &mutex_GPU_buf[GPUbufferindex] ); dbprintf(\"%s(%d): got lock to write to GPU buffers %d, \\n\", __func__, __LINE__, GPUbufferindex ); // get start time for GPU thread processing gettimeofday( &tstart, NULL); trigger_info.time_gputhread_started_s = tstart.tv_sec; trigger_info.time_gputhread_started_us = tstart.tv_usec; //These has to be done after the memory copy //TODO: Check DATA //GPU_Data_Buffer[GPUbufferindex].gpu_data_header[7] = tstart.tv_sec; //GPU_Data_Buffer[GPUbufferindex].gpu_data_header[8] = tstart.tv_usec; // use lock to access the tcp_thread buffers - tcp_buf_gl[i], tcp_buf_header_gl[i], tcp_buf_tail_gl[i] pthread_mutex_lock( &mutex_TCP_buf[TCPbufferindex] ); dbprintf(\"%s(%d): got lock to read from TCP output buffers, *tcp_buf_header_gl[%d] = 0x%08x\\n\", __func__, __LINE__, TCPbufferindex, be32toh ( *tcp_buf_header_gl[TCPbufferindex] ) ); // get AMC13 event index from data header ( ugly fix for 64-bit AMC words ) #ifdef DEBUG AMC13fillcounter = ( be32toh ( *tcp_buf_header_gl[TCPbufferindex] ) & 0x00FFFFFF ); #endif #ifdef USE_GPU #ifdef TIME_MEASURE_DEF cudaEvent_t start, stop; float elapsedTime; cudaEventCreate(&start); cudaEventCreate(&stop); cudaEventRecord(start, 0); #endif // USE_GPU #endif // TIME_MEASURE_DEF dbprintf(\"%s(%d): got lock to write to GPU output buffers, fill %d\\n\", __func__, __LINE__, GPUfillnumber_local); // set GPU_thread data sizes from TCP_thread data sizes and ODB parameters GPU_Data_Buffer[GPUbufferindex].gpu_data_header_amc13_size = TCPtotalamc13infosize[TCPbufferindex]; // AMC13 headers / trailers GPU_Data_Buffer[GPUbufferindex].gpu_data_header_size = TCPtotalheadersize[TCPbufferindex]; // timing / performance data GPU_Data_Buffer[GPUbufferindex].gpu_data_tail_size = TCPtotaltailsize[TCPbufferindex]; // CDF 64-bit trailer word GPU_Data_Buffer[GPUbufferindex].gpu_data_raw_size = TCPtotaldatasize[TCPbufferindex]; // raw, unpacked AMC payload // copy header, trailer amc13info for every fill memcpy( GPU_Data_Buffer[GPUbufferindex].gpu_data_header, tcp_buf_header_gl[TCPbufferindex], GPU_Data_Buffer[GPUbufferindex].gpu_data_header_size ); //Add the GPU processing start time stamp GPU_Data_Buffer[GPUbufferindex].gpu_data_header[7] = tstart.tv_sec; GPU_Data_Buffer[GPUbufferindex].gpu_data_header[8] = tstart.tv_usec; //Check TCPfillnumber and makesure TCPfillnumber is greater unsigned long TCPfillnumber_local; unsigned long GPUfillnumber_local; //bor function can change the global fill number unsigned long Midasfillnumber_local; int local_thread_active = 0; int local_thread_read = 0; pthread_mutex_lock( &mutex_TCP_general ); TCPfillnumber_local = TCPfillnumber; pthread_mutex_unlock( &mutex_TCP_general ); pthread_mutex_lock( &mutex_GPU_general ); GPUfillnumber_local = GPUfillnumber; local_thread_active = gpu_thread_active; local_thread_read = gpu_thread_read; pthread_mutex_unlock( &mutex_GPU_general ); pthread_mutex_lock(&mutex_midas); Midasfillnumber_local = Midasfillnumber; pthread_mutex_unlock(&mutex_midas); if (!local_thread_active) { break; } if (!local_thread_read) { usleep(100); continue; } if (GPUfillnumber_local == TCPfillnumber_local || TCPfillnumber_local == 0) { dbprintf(\"%s(%d): No new events in the TCP buffer \\n\", __func__, __LINE__ ); usleep(100); continue; } unsigned long tcp_buffer_filled = 0; if (TCPfillnumber_local > GPUfillnumber_local) { tcp_buffer_filled = TCPfillnumber_local - GPUfillnumber_local; }else{ tcp_buffer_filled = 0xffffffffffffffff - (GPUfillnumber_local - TCPfillnumber_local) +1 ; } dbprintf(\"%s(%d): tcp_ring_buffer_size %d \\n\", __func__, __LINE__, tcp_buffer_filled ); dbprintf(\"%s(%d): tcp fill %d gpu fill %d \\n\", __func__, __LINE__, TCPfillnumber_local , GPUfillnumber_local ); float BufLoad = tcp_buffer_filled * 1.0 / TCP_BUF_MAX_FILLS; float BufLoadThreshold = 0.9; if (BufLoad > BufLoadThreshold && !BufFullAlarmTriggered) { BufFullAlarmTriggered = true; char AlarmMsg[500]; sprintf(AlarmMsg,\"DAQ | AMC13%03d TCP Ring buffer close to full (%f%%)\",frontend_index,BufLoad*100); int ret_code = al_trigger_alarm(\"Frontend TCP Buffer Error\", AlarmMsg, \"Warning\", \"Frontend TCP Buffer Error\", AT_INTERNAL); if (ret_code != AL_SUCCESS) { cm_msg(MERROR, __FILE__, \"Failure Raising Alarm: Error %d, Alarm \\\"%s\\\"\", ret_code, \"Frontend TCP Buffer Error\" ); } } if (BufLoad < BufLoadThreshold && BufFullAlarmTriggered) { BufFullAlarmTriggered = false; char AlarmMsg[500]; sprintf(AlarmMsg,\"DAQ | AMC13%03d TCP Ring buffer returns normal (%f%%)\",frontend_index,BufLoad*100); int ret_code = al_trigger_alarm(\"Frontend TCP Buffer Recovery\", AlarmMsg, \"Recovery\", \"Frontend TCP Buffer Recovery\", AT_INTERNAL); if (ret_code != AL_SUCCESS) { cm_msg(MERROR, __FILE__, \"Failure Raising Alarm: Error %d, Alarm \\\"%s\\\"\", ret_code, \"Frontend TCP Buffer Recovery\" ); } } unsigned long gpu_buffer_filled = 0; if (GPUfillnumber_local > Midasfillnumber_local) { gpu_buffer_filled = GPUfillnumber_local - Midasfillnumber_local; }else{ gpu_buffer_filled = 0xffffffffffffffff - (Midasfillnumber_local - GPUfillnumber_local) +1 ; } dbprintf(\"%s(%d): gpu_ring_buffer_size %d \\n\", __func__, __LINE__, gpu_buffer_filled ); dbprintf(\"%s(%d): gpu fill %d midas fill %d \\n\", __func__, __LINE__, GPUfillnumber_local , Midasfillnumber_local ); float GPUBufLoad = gpu_buffer_filled * 1.0 / GPU_BUFFER_SIZE; float GPUBufLoadThreshold = 0.9; if (GPUBufLoad > GPUBufLoadThreshold && !GPUBufFullAlarmTriggered) { GPUBufFullAlarmTriggered = true; char AlarmMsg[500]; sprintf(AlarmMsg,\"DAQ | AMC13%03d GPU Ring buffer close to full (%f%%)\",frontend_index,GPUBufLoad*100); int ret_code = al_trigger_alarm(\"Frontend GPU Buffer Error\", AlarmMsg, \"Warning\", \"Frontend GPU Buffer Error\", AT_INTERNAL); if (ret_code != AL_SUCCESS) { cm_msg(MERROR, __FILE__, \"Failure Raising Alarm: Error %d, Alarm \\\"%s\\\"\", ret_code, \"Frontend GPU Buffer Error\" ); } } if (GPUBufLoad < GPUBufLoadThreshold && GPUBufFullAlarmTriggered) { GPUBufFullAlarmTriggered = false; char AlarmMsg[500]; sprintf(AlarmMsg,\"DAQ | AMC13%03d GPU Ring buffer returns normal (%f%%)\",frontend_index,GPUBufLoad*100); int ret_code = al_trigger_alarm(\"Frontend GPU Buffer Recovery\", AlarmMsg, \"Recovery\", \"Frontend GPU Buffer Recovery\", AT_INTERNAL); if (ret_code != AL_SUCCESS) { cm_msg(MERROR, __FILE__, \"Failure Raising Alarm: Error %d, Alarm \\\"%s\\\"\", ret_code, \"Frontend GPU Buffer Recovery\" ); } } //Do not proceed if the GPU buffer is full if ( (gpu_buffer_filled >= GPU_BUFFER_SIZE - 1) || (tcp_buffer_filled >= TCP_BUF_MAX_FILLS - 1) ) { fc7help->setThrottleTriggers( encoder_fc7, frontend_index, 1); triggersThrottled = true; cm_msg(MINFO, __FILE__, \"Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers\"); continue; } else if ( triggersThrottled ) { fc7help->setThrottleTriggers( encoder_fc7, frontend_index, 0); triggersThrottled = false; cm_msg(MINFO, __FILE__, \"Trigger throttling removed\"); } // calculate TCP ring buffer index from GPU fill number TCPbufferindex = GPUfillnumber_local%TCP_BUF_MAX_FILLS; dbprintf(\"%s(%d): start new fill %d, buffer %d\\n\", __func__, __LINE__, GPUfillnumber_local, TCPbufferindex ); // calculate the GPU ring buffer index GPUbufferindex = GPUfillnumber_local % GPU_BUFFER_SIZE; //Lock GPU buffer unit pthread_mutex_lock( &mutex_GPU_buf[GPUbufferindex] ); dbprintf(\"%s(%d): got lock to write to GPU buffers %d, \\n\", __func__, __LINE__, GPUbufferindex ); // get start time for GPU thread processing gettimeofday( &tstart, NULL); trigger_info.time_gputhread_started_s = tstart.tv_sec; trigger_info.time_gputhread_started_us = tstart.tv_usec; //These has to be done after the memory copy //TODO: Check DATA //GPU_Data_Buffer[GPUbufferindex].gpu_data_header[7] = tstart.tv_sec; //GPU_Data_Buffer[GPUbufferindex].gpu_data_header[8] = tstart.tv_usec; // use lock to access the tcp_thread buffers - tcp_buf_gl[i], tcp_buf_header_gl[i], tcp_buf_tail_gl[i] pthread_mutex_lock( &mutex_TCP_buf[TCPbufferindex] ); dbprintf(\"%s(%d): got lock to read from TCP output buffers, *tcp_buf_header_gl[%d] = 0x%08x\\n\", __func__, __LINE__, TCPbufferindex, be32toh ( *tcp_buf_header_gl[TCPbufferindex] ) ); // get AMC13 event index from data header ( ugly fix for 64-bit AMC words ) #ifdef DEBUG AMC13fillcounter = ( be32toh ( *tcp_buf_header_gl[TCPbufferindex] ) & 0x00FFFFFF ); #endif #ifdef USE_GPU #ifdef TIME_MEASURE_DEF cudaEvent_t start, stop; float elapsedTime; cudaEventCreate(&start); cudaEventCreate(&stop); cudaEventRecord(start, 0); #endif // USE_GPU #endif // TIME_MEASURE_DEF dbprintf(\"%s(%d): got lock to write to GPU output buffers, fill %d\\n\", __func__, __LINE__, GPUfillnumber_local); // set GPU_thread data sizes from TCP_thread data sizes and ODB parameters GPU_Data_Buffer[GPUbufferindex].gpu_data_header_amc13_size = TCPtotalamc13infosize[TCPbufferindex]; // AMC13 headers / trailers GPU_Data_Buffer[GPUbufferindex].gpu_data_header_size = TCPtotalheadersize[TCPbufferindex]; // timing / performance data GPU_Data_Buffer[GPUbufferindex].gpu_data_tail_size = TCPtotaltailsize[TCPbufferindex]; // CDF 64-bit trailer word GPU_Data_Buffer[GPUbufferindex].gpu_data_raw_size = TCPtotaldatasize[TCPbufferindex]; // raw, unpacked AMC payload // copy header, trailer amc13info for every fill memcpy( GPU_Data_Buffer[GPUbufferindex].gpu_data_header, tcp_buf_header_gl[TCPbufferindex], GPU_Data_Buffer[GPUbufferindex].gpu_data_header_size ); //Add the GPU processing start time stamp GPU_Data_Buffer[GPUbufferindex].gpu_data_header[7] = tstart.tv_sec; GPU_Data_Buffer[GPUbufferindex].gpu_data_header[8] = tstart.tv_usec; 4. GPU Copy Done - GPU Proc Unlocked 1. Some cuda memcopies and such: dbprintf(\"%s(%d): copied header databank [size=0x%08x], header[0] 0x%08x, readout fill number %d, GPU fill number %d\\n\", __func__, __LINE__, GPU_Data_Buffer[GPUbufferindex].gpu_data_header_size, be32toh(GPU_Data_Buffer[GPUbufferindex].gpu_data_header[0]), AMC13fillcounter, GPUfillnumber_local ); memcpy( GPU_Data_Buffer[GPUbufferindex].gpu_data_tail, tcp_buf_tail_gl[TCPbufferindex], TCPtotaltailsize[TCPbufferindex] ); dbprintf(\"%s(%d): copied tail databank [size=0x%08x], tail[0] 0x%08x, readout fill number %d, GPU fill number %d\\n\", __func__, __LINE__, GPU_Data_Buffer[GPUbufferindex].gpu_data_tail_size, be32toh(GPU_Data_Buffer[GPUbufferindex].gpu_data_tail[0]), AMC13fillcounter, GPUfillnumber_local ); memcpy( GPU_Data_Buffer[GPUbufferindex].gpu_data_header_amc13, tcp_buf_amc13_gl[TCPbufferindex], TCPtotalamc13infosize[TCPbufferindex] ); dbprintf(\"%s(%d): copied amc13 databank [size=0x%08x], amc13[0] 0x%08x, readout fill number %d, GPU fill number %d\\n\", __func__, __LINE__, GPU_Data_Buffer[GPUbufferindex].gpu_data_header_amc13_size, be32toh(GPU_Data_Buffer[GPUbufferindex].gpu_data_header_amc13[0]), AMC13fillcounter, GPUfillnumber_local ); // extract / copy rider header / trailer data from raw payload to rider header / trailer array (call arguments mirror memcpy) gettimeofday( &tbeforeextract, NULL); GPU_Data_Buffer[GPUbufferindex].gpu_data_header_rider_size = extractRiderHeader( GPU_Data_Buffer[GPUbufferindex].gpu_data_header_rider, tcp_buf_gl[TCPbufferindex], GPU_Data_Buffer[GPUbufferindex].gpu_data_raw_size ); dbprintf(\"%s(%d): copied rider databank[%d], rider[first] 0x%16lx, rider[last] 0x%16lx, readout fill number %d, GPU fill number %d\\n\", __func__, __LINE__, GPU_Data_Buffer[GPUbufferindex].gpu_data_header_rider_size, *(GPU_Data_Buffer[GPUbufferindex].gpu_data_header_rider), *(GPU_Data_Buffer[GPUbufferindex].gpu_data_header_rider+(GPU_Data_Buffer[GPUbufferindex].gpu_data_header_rider_size/sizeof(uint64_t))-1), AMC13fillcounter, GPUfillnumber_local ); gettimeofday( &tafterextract, NULL); dbprintf(\"%s(%d): duration of extract and copy of rider headers, fdt = %e us \\n\", __func__, __LINE__, toddiff( &tafterextract, &tbeforeextract) ); // extract the FillType etc from rider header / trailers words int indexModHeaderWord2 = 1; // using module header word u_int64_t ModHeader2 = be64toh ( GPU_Data_Buffer[GPUbufferindex].gpu_data_header_rider[indexModHeaderWord2] ); u_int64_t ModUserBitMask = ModUserBitField << ModUserBitOffset; int UserField = ( ( ModHeader2 & ModUserBitMask ) >> ModUserBitOffset ); // from Rider User Manual, June 17 2015 int ModFillType = UserField & 0x7; dbprintf(\"%s(%d): 64-bit Mod header word 0x%016lx after be64toh 0x%016lx and ModFillType 0x%04x\\n\", __func__, __LINE__, GPU_Data_Buffer[GPUbufferindex].gpu_data_header_rider[indexModHeaderWord2], ModHeader2, ModFillType); /* // 8/14/2017, TG, skip the identification of the fill length from the channel headers. This won't work // for async WFD5s with muon/laser fills and sync WFD5s with async fills.. The calculated variables // ChanFillType and WfrmFillType were only used to verify the fill type extracted from the module header int indexChanHeaderWord2 = 3; // using channel header word u_int64_t ChanHeader2 = be64toh ( gpu_data_header_rider[indexChanHeaderWord2] ); u_int64_t ChanFTBitMask = ChanFTBitField << ChanFTBitOffset; int ChanFillType = ( ( ChanHeader2 & ChanFTBitMask ) >> ChanFTBitOffset ); // from Rider User Manual, June 17 2015 dbprintf(\"%s(%d): 64-bit Chan header word 0x%016lx after be64toh 0x%016lx and chan fill type 0x%04x\\n\", __func__, __LINE__, gpu_data_header_rider[indexChanHeaderWord2], ChanHeader2, ChanFillType); int indexWfrmHeaderWord1 = 4; // using waveform header word u_int64_t WfrmHeader1 = be64toh ( gpu_data_header_rider[indexWfrmHeaderWord1] ); u_int64_t WfrmFTBitMask = WfrmFTBitField << WfrmFTBitOffset; int WfrmFillType = ( ( WfrmHeader1 & WfrmFTBitMask ) >> WfrmFTBitOffset ); // from Rider User Manual, June 17 2015 dbprintf(\"%s(%d): 64-bit Wfrm header word 0x%016lx after be64toh 0x%016lx and wfrm fill type 0x%04x\\n\", __func__, __LINE__, gpu_data_header_rider[indexWfrmHeaderWord1], WfrmHeader1, WfrmFillType); */ bool process_laser = false; for(int ii=0;ii<4;ii++){ if(tq_parameters_odb[ii].fill_type==2) process_laser=true; } // copy raw data for pre-scaled muon fills or always of laser/pededstal type fill //if ( ModFillType>1 || ( amc13_settings_odb.store_raw && !((AMC13fillcounter-1)%amc13_settings_odb.prescale_raw) ) ) //printf(\"ModFillType = %i, amc13_settings_odb.store_raw = %i, GPUmuonfillnumber = %i\\n\",ModFillType, amc13_settings_odb.store_raw, GPUmuonfillnumber); //printf(\"store_raw = %i, GPUmuonfillnumber = %i, amc13_settings_odb.prescale_raw = %i, check = %i\\n\",amc13_settings_odb.store_raw,GPUmuonfillnumber,amc13_settings_odb.prescale_raw,!GPUmuonfillnumber%amc13_settings_odb.prescale_raw ); if ( frontend_index==local_encoder_crate || ModFillType>2 || (ModFillType==2 && !process_laser) || ( amc13_settings_odb.store_raw && !GPUmuonfillnumber%amc13_settings_odb.prescale_raw ) ) { memcpy( GPU_Data_Buffer[GPUbufferindex].gpu_data_raw, tcp_buf_gl[TCPbufferindex], GPU_Data_Buffer[GPUbufferindex].gpu_data_raw_size ); dbprintf(\"%s(%d): copied raw databank [size=0x%08x], raw[0] 0x%04x, raw[1] 0x%04x, raw[2] 0x%04x, raw[3] 0x%04x, readout fill number %d, GPU fill number %d, , GPU muon fill number %d\\n\", __func__, __LINE__, GPU_Data_Buffer[GPUbufferindex].gpu_data_raw_size, *GPU_Data_Buffer[GPUbufferindex].gpu_data_raw, *(GPU_Data_Buffer[GPUbufferindex].gpu_data_raw+1), *(GPU_Data_Buffer[GPUbufferindex].gpu_data_raw+2), *(GPU_Data_Buffer[GPUbufferindex].gpu_data_raw+3), AMC13fillcounter, GPUfillnumber_local, GPUmuonfillnumber ); } #ifdef USE_GPU // for muon type fill and any TQ processing switched on copy data to GPU if ( (ModFillType==1 || (ModFillType==2 && process_laser)) && Any_processing_on ) { if ( GPU_IBUF_SIZE < GPU_Data_Buffer[GPUbufferindex].gpu_data_raw_size ) { printf(\"%s(%d): fill is too large (%d bytes) for GPU buffer (%d bytes) \\n\", __func__, __LINE__, GPU_Data_Buffer[GPUbufferindex].gpu_data_raw_size, GPU_IBUF_SIZE ); GPU_Data_Buffer[GPUbufferindex].gpu_data_raw_size = 1; } dbprintf(\"%s(%d): *** GPU input data[0], data[0]: %li %li total size %d\\n\", __func__, __LINE__, *(tcp_buf_gl[TCPbufferindex]), *(tcp_buf_gl[TCPbufferindex]), GPU_Data_Buffer[GPUbufferindex].gpu_data_raw_size); // copy raw AMC payload data to GPU cudaCopyStatus = cudaMemcpy( gpu_idata, tcp_buf_gl[TCPbufferindex], GPU_Data_Buffer[GPUbufferindex].gpu_data_raw_size, cudaMemcpyHostToDevice); if ( cudaCopyStatus != cudaSuccess ) { printf(\"cudaMemcpy of input data FAIL, status: %d error: %s bytes: %d\\n\", cudaCopyStatus, cudaGetErrorString(cudaCopyStatus), GPU_Data_Buffer[GPUbufferindex].gpu_data_raw_size); if ( cudaCopyStatus == cudaErrorInvalidValue ) printf(\"cudaErrorInvalidValue !\\n\"); if ( cudaCopyStatus == cudaErrorInvalidDevicePointer ) printf(\"cudaErrorInvalidDevicePointer!\\n\"); } #ifdef TIME_MEASURE_DEF cudaEventRecord(stop, 0); cudaEventSynchronize(stop); cudaEventElapsedTime(&elapsedTime, start, stop); dbprintf(\"%s(%d): copied data from CPU (pntr %p) to GPU (pntr %p), size %d, time %f ms\\n\", __func__, __LINE__, tcp_buf_gl[TCPbufferindex], gpu_idata, GPU_Data_Buffer[GPUbufferindex].gpu_data_raw_size, elapsedTime); cudaEventDestroy(start); cudaEventDestroy(stop); #endif // TIME_MEASURE_DEF } // end cuda copy from host to device (if Any_processing_on is true) // get GPU copy time for GPU thread gettimeofday( &tcopy, NULL); dbprintf(\"%s(%d): duration of start to copy, fdt = %e us \\n\", __func__, __LINE__, toddiff( &tstart, &tcopy) ); trigger_info.time_gputhread_copytogpu_done_s = tcopy.tv_sec; trigger_info.time_gputhread_copytogpu_done_us = tcopy.tv_usec; dbprintf(\"%s(%d): copied header databank [size=0x%08x], header[0] 0x%08x, readout fill number %d, GPU fill number %d\\n\", __func__, __LINE__, GPU_Data_Buffer[GPUbufferindex].gpu_data_header_size, be32toh(GPU_Data_Buffer[GPUbufferindex].gpu_data_header[0]), AMC13fillcounter, GPUfillnumber_local ); memcpy( GPU_Data_Buffer[GPUbufferindex].gpu_data_tail, tcp_buf_tail_gl[TCPbufferindex], TCPtotaltailsize[TCPbufferindex] ); dbprintf(\"%s(%d): copied tail databank [size=0x%08x], tail[0] 0x%08x, readout fill number %d, GPU fill number %d\\n\", __func__, __LINE__, GPU_Data_Buffer[GPUbufferindex].gpu_data_tail_size, be32toh(GPU_Data_Buffer[GPUbufferindex].gpu_data_tail[0]), AMC13fillcounter, GPUfillnumber_local ); memcpy( GPU_Data_Buffer[GPUbufferindex].gpu_data_header_amc13, tcp_buf_amc13_gl[TCPbufferindex], TCPtotalamc13infosize[TCPbufferindex] ); dbprintf(\"%s(%d): copied amc13 databank [size=0x%08x], amc13[0] 0x%08x, readout fill number %d, GPU fill number %d\\n\", __func__, __LINE__, GPU_Data_Buffer[GPUbufferindex].gpu_data_header_amc13_size, be32toh(GPU_Data_Buffer[GPUbufferindex].gpu_data_header_amc13[0]), AMC13fillcounter, GPUfillnumber_local ); // extract / copy rider header / trailer data from raw payload to rider header / trailer array (call arguments mirror memcpy) gettimeofday( &tbeforeextract, NULL); GPU_Data_Buffer[GPUbufferindex].gpu_data_header_rider_size = extractRiderHeader( GPU_Data_Buffer[GPUbufferindex].gpu_data_header_rider, tcp_buf_gl[TCPbufferindex], GPU_Data_Buffer[GPUbufferindex].gpu_data_raw_size ); dbprintf(\"%s(%d): copied rider databank[%d], rider[first] 0x%16lx, rider[last] 0x%16lx, readout fill number %d, GPU fill number %d\\n\", __func__, __LINE__, GPU_Data_Buffer[GPUbufferindex].gpu_data_header_rider_size, *(GPU_Data_Buffer[GPUbufferindex].gpu_data_header_rider), *(GPU_Data_Buffer[GPUbufferindex].gpu_data_header_rider+(GPU_Data_Buffer[GPUbufferindex].gpu_data_header_rider_size/sizeof(uint64_t))-1), AMC13fillcounter, GPUfillnumber_local ); gettimeofday( &tafterextract, NULL); dbprintf(\"%s(%d): duration of extract and copy of rider headers, fdt = %e us \\n\", __func__, __LINE__, toddiff( &tafterextract, &tbeforeextract) ); // extract the FillType etc from rider header / trailers words int indexModHeaderWord2 = 1; // using module header word u_int64_t ModHeader2 = be64toh ( GPU_Data_Buffer[GPUbufferindex].gpu_data_header_rider[indexModHeaderWord2] ); u_int64_t ModUserBitMask = ModUserBitField << ModUserBitOffset; int UserField = ( ( ModHeader2 & ModUserBitMask ) >> ModUserBitOffset ); // from Rider User Manual, June 17 2015 int ModFillType = UserField & 0x7; dbprintf(\"%s(%d): 64-bit Mod header word 0x%016lx after be64toh 0x%016lx and ModFillType 0x%04x\\n\", __func__, __LINE__, GPU_Data_Buffer[GPUbufferindex].gpu_data_header_rider[indexModHeaderWord2], ModHeader2, ModFillType); /* // 8/14/2017, TG, skip the identification of the fill length from the channel headers. This won't work // for async WFD5s with muon/laser fills and sync WFD5s with async fills.. The calculated variables // ChanFillType and WfrmFillType were only used to verify the fill type extracted from the module header int indexChanHeaderWord2 = 3; // using channel header word u_int64_t ChanHeader2 = be64toh ( gpu_data_header_rider[indexChanHeaderWord2] ); u_int64_t ChanFTBitMask = ChanFTBitField << ChanFTBitOffset; int ChanFillType = ( ( ChanHeader2 & ChanFTBitMask ) >> ChanFTBitOffset ); // from Rider User Manual, June 17 2015 dbprintf(\"%s(%d): 64-bit Chan header word 0x%016lx after be64toh 0x%016lx and chan fill type 0x%04x\\n\", __func__, __LINE__, gpu_data_header_rider[indexChanHeaderWord2], ChanHeader2, ChanFillType); int indexWfrmHeaderWord1 = 4; // using waveform header word u_int64_t WfrmHeader1 = be64toh ( gpu_data_header_rider[indexWfrmHeaderWord1] ); u_int64_t WfrmFTBitMask = WfrmFTBitField << WfrmFTBitOffset; int WfrmFillType = ( ( WfrmHeader1 & WfrmFTBitMask ) >> WfrmFTBitOffset ); // from Rider User Manual, June 17 2015 dbprintf(\"%s(%d): 64-bit Wfrm header word 0x%016lx after be64toh 0x%016lx and wfrm fill type 0x%04x\\n\", __func__, __LINE__, gpu_data_header_rider[indexWfrmHeaderWord1], WfrmHeader1, WfrmFillType); */ bool process_laser = false; for(int ii=0;ii<4;ii++){ if(tq_parameters_odb[ii].fill_type==2) process_laser=true; } // copy raw data for pre-scaled muon fills or always of laser/pededstal type fill //if ( ModFillType>1 || ( amc13_settings_odb.store_raw && !((AMC13fillcounter-1)%amc13_settings_odb.prescale_raw) ) ) //printf(\"ModFillType = %i, amc13_settings_odb.store_raw = %i, GPUmuonfillnumber = %i\\n\",ModFillType, amc13_settings_odb.store_raw, GPUmuonfillnumber); //printf(\"store_raw = %i, GPUmuonfillnumber = %i, amc13_settings_odb.prescale_raw = %i, check = %i\\n\",amc13_settings_odb.store_raw,GPUmuonfillnumber,amc13_settings_odb.prescale_raw,!GPUmuonfillnumber%amc13_settings_odb.prescale_raw ); if ( frontend_index==local_encoder_crate || ModFillType>2 || (ModFillType==2 && !process_laser) || ( amc13_settings_odb.store_raw && !GPUmuonfillnumber%amc13_settings_odb.prescale_raw ) ) { memcpy( GPU_Data_Buffer[GPUbufferindex].gpu_data_raw, tcp_buf_gl[TCPbufferindex], GPU_Data_Buffer[GPUbufferindex].gpu_data_raw_size ); dbprintf(\"%s(%d): copied raw databank [size=0x%08x], raw[0] 0x%04x, raw[1] 0x%04x, raw[2] 0x%04x, raw[3] 0x%04x, readout fill number %d, GPU fill number %d, , GPU muon fill number %d\\n\", __func__, __LINE__, GPU_Data_Buffer[GPUbufferindex].gpu_data_raw_size, *GPU_Data_Buffer[GPUbufferindex].gpu_data_raw, *(GPU_Data_Buffer[GPUbufferindex].gpu_data_raw+1), *(GPU_Data_Buffer[GPUbufferindex].gpu_data_raw+2), *(GPU_Data_Buffer[GPUbufferindex].gpu_data_raw+3), AMC13fillcounter, GPUfillnumber_local, GPUmuonfillnumber ); } #ifdef USE_GPU // for muon type fill and any TQ processing switched on copy data to GPU if ( (ModFillType==1 || (ModFillType==2 && process_laser)) && Any_processing_on ) { if ( GPU_IBUF_SIZE < GPU_Data_Buffer[GPUbufferindex].gpu_data_raw_size ) { printf(\"%s(%d): fill is too large (%d bytes) for GPU buffer (%d bytes) \\n\", __func__, __LINE__, GPU_Data_Buffer[GPUbufferindex].gpu_data_raw_size, GPU_IBUF_SIZE ); GPU_Data_Buffer[GPUbufferindex].gpu_data_raw_size = 1; } dbprintf(\"%s(%d): *** GPU input data[0], data[0]: %li %li total size %d\\n\", __func__, __LINE__, *(tcp_buf_gl[TCPbufferindex]), *(tcp_buf_gl[TCPbufferindex]), GPU_Data_Buffer[GPUbufferindex].gpu_data_raw_size); // copy raw AMC payload data to GPU cudaCopyStatus = cudaMemcpy( gpu_idata, tcp_buf_gl[TCPbufferindex], GPU_Data_Buffer[GPUbufferindex].gpu_data_raw_size, cudaMemcpyHostToDevice); if ( cudaCopyStatus != cudaSuccess ) { printf(\"cudaMemcpy of input data FAIL, status: %d error: %s bytes: %d\\n\", cudaCopyStatus, cudaGetErrorString(cudaCopyStatus), GPU_Data_Buffer[GPUbufferindex].gpu_data_raw_size); if ( cudaCopyStatus == cudaErrorInvalidValue ) printf(\"cudaErrorInvalidValue !\\n\"); if ( cudaCopyStatus == cudaErrorInvalidDevicePointer ) printf(\"cudaErrorInvalidDevicePointer!\\n\"); } #ifdef TIME_MEASURE_DEF cudaEventRecord(stop, 0); cudaEventSynchronize(stop); cudaEventElapsedTime(&elapsedTime, start, stop); dbprintf(\"%s(%d): copied data from CPU (pntr %p) to GPU (pntr %p), size %d, time %f ms\\n\", __func__, __LINE__, tcp_buf_gl[TCPbufferindex], gpu_idata, GPU_Data_Buffer[GPUbufferindex].gpu_data_raw_size, elapsedTime); cudaEventDestroy(start); cudaEventDestroy(stop); #endif // TIME_MEASURE_DEF } // end cuda copy from host to device (if Any_processing_on is true) // get GPU copy time for GPU thread gettimeofday( &tcopy, NULL); dbprintf(\"%s(%d): duration of start to copy, fdt = %e us \\n\", __func__, __LINE__, toddiff( &tstart, &tcopy) ); trigger_info.time_gputhread_copytogpu_done_s = tcopy.tv_sec; trigger_info.time_gputhread_copytogpu_done_us = tcopy.tv_usec; GPU Proc Done - GPU Copy Done Cuda memcopy #endif // USE_GPU // unlocked the access to TCP buffer now all data is copied to GPU buffers pthread_mutex_unlock( &mutex_TCP_buf[TCPbufferindex]); dbprintf(\"%s(%d): unlocking ring buffer , buffer %d, fill %d\\n\", __func__, __LINE__, TCPbufferindex, GPUfillnumber_local); #ifdef USE_GPU // for muon type fill and TQ processing switched on launch processing on GPU if ( ModFillType==1 || ModFillType==2) { for (int itq = 0; itq < TQMETHOD_MAX; itq++){ if ( tq_parameters_odb[itq].TQ_on || tq_parameters_odb[itq].store_hist ) { if(tq_parameters_odb[itq].fill_type != ModFillType) continue; cuda_g2_run_kernel( gpu_idata, gpu_odata, GPU_Data_Buffer[GPUbufferindex].gpu_data_proc[itq], itq , GPUbufferindex); // see kernel.cu for gpu proceesing functions // note that copy from device to host of processed data gpu_data_proc and setting of data size gpu_data_proc_size is done // in function cuda_g2_run_kernel() whereas the copying and zeroing of histogram data on pre-scaled fills is done here. //if ( tq_parameters_odb[itq].store_hist && !((AMC13fillcounter-1)%tq_parameters_odb[itq].flush_hist) ) if ( tq_parameters_odb[itq].store_hist && ((GPUmuonfillnumber+1)%tq_parameters_odb[itq].flush_hist)==0 ) { // copy histogram data cudaCopyStatus = cudaMemcpy( GPU_Data_Buffer[GPUbufferindex].gpu_data_his[itq], gpu_odata+GPU_Data_Buffer[GPUbufferindex].gpu_data_his_offset[itq], GPU_Data_Buffer[GPUbufferindex].gpu_data_his_size[itq], cudaMemcpyDeviceToHost); if (cudaCopyStatus != cudaSuccess ) { printf(\"cudaMemcpy of output data FAIL, status: %d error: %s bytes: %d\\n\", cudaCopyStatus, cudaGetErrorString(cudaCopyStatus), GPU_Data_Buffer[GPUbufferindex].gpu_data_his_size[itq]); if ( cudaCopyStatus == cudaErrorInvalidValue ) printf(\"cudaErrorInvalidValue !\\n\"); if ( cudaCopyStatus == cudaErrorInvalidDevicePointer ) printf(\"cudaErrorInvalidDevicePointer!\\n\"); } dbprintf(\"%s(%d): TQ=%i, gpu_odata %p, copying / zeroing hist databank [ size=%d, offset=%d], hist[0] 0x%08x, hist[N/8] 0x%08x, hist[N/4] 0x%08x, readout fill number %d, GPU fill number %d, GPU muon fill number %d\\n\", __func__, __LINE__, itq, (gpu_odata+GPU_Data_Buffer[GPUbufferindex].gpu_data_his_offset[itq]), GPU_Data_Buffer[GPUbufferindex].gpu_data_his_size[itq], GPU_Data_Buffer[GPUbufferindex].gpu_data_his_offset[itq], *(GPU_Data_Buffer[GPUbufferindex].gpu_data_his[itq]), *(GPU_Data_Buffer[GPUbufferindex].gpu_data_his[itq]+GPU_Data_Buffer[GPUbufferindex].gpu_data_his_size[itq]/8+1), *(GPU_Data_Buffer[GPUbufferindex].gpu_data_his[itq]+GPU_Data_Buffer[GPUbufferindex].gpu_data_his_size[itq]/4+1), AMC13fillcounter, GPUfillnumber_local, GPUmuonfillnumber ); // zero histogram data cudaCopyStatus = cudaMemset( gpu_odata+GPU_Data_Buffer[GPUbufferindex].gpu_data_his_offset[itq], 0, GPU_Data_Buffer[GPUbufferindex].gpu_data_his_size[itq]); // size unuts are bytes if (cudaCopyStatus != cudaSuccess ) { printf(\"cudaMemset of histo data FAIL, status: %d error: %s bytes: %d\\n\", cudaCopyStatus, cudaGetErrorString(cudaCopyStatus), GPU_Data_Buffer[GPUbufferindex].gpu_data_his_size[itq]); if ( cudaCopyStatus == cudaErrorInvalidValue ) printf(\"cudaErrorInvalidValue !\\n\"); if ( cudaCopyStatus == cudaErrorInvalidDevicePointer ) printf(\"cudaErrorInvalidDevicePointer!\\n\"); } } // end flush and zero of histogram data } // if TQ processing or histogram processing is switched on } // loop over index itq of TQ methods } // if muon fill #endif // USE_GPU // unlocked the access to TCP buffer now all data is copied to GPU buffers pthread_mutex_unlock( &mutex_TCP_buf[TCPbufferindex]); dbprintf(\"%s(%d): unlocking ring buffer , buffer %d, fill %d\\n\", __func__, __LINE__, TCPbufferindex, GPUfillnumber_local); #ifdef USE_GPU // for muon type fill and TQ processing switched on launch processing on GPU if ( ModFillType==1 || ModFillType==2) { for (int itq = 0; itq < TQMETHOD_MAX; itq++){ if ( tq_parameters_odb[itq].TQ_on || tq_parameters_odb[itq].store_hist ) { if(tq_parameters_odb[itq].fill_type != ModFillType) continue; cuda_g2_run_kernel( gpu_idata, gpu_odata, GPU_Data_Buffer[GPUbufferindex].gpu_data_proc[itq], itq , GPUbufferindex); // see kernel.cu for gpu proceesing functions // note that copy from device to host of processed data gpu_data_proc and setting of data size gpu_data_proc_size is done // in function cuda_g2_run_kernel() whereas the copying and zeroing of histogram data on pre-scaled fills is done here. //if ( tq_parameters_odb[itq].store_hist && !((AMC13fillcounter-1)%tq_parameters_odb[itq].flush_hist) ) if ( tq_parameters_odb[itq].store_hist && ((GPUmuonfillnumber+1)%tq_parameters_odb[itq].flush_hist)==0 ) { // copy histogram data cudaCopyStatus = cudaMemcpy( GPU_Data_Buffer[GPUbufferindex].gpu_data_his[itq], gpu_odata+GPU_Data_Buffer[GPUbufferindex].gpu_data_his_offset[itq], GPU_Data_Buffer[GPUbufferindex].gpu_data_his_size[itq], cudaMemcpyDeviceToHost); if (cudaCopyStatus != cudaSuccess ) { printf(\"cudaMemcpy of output data FAIL, status: %d error: %s bytes: %d\\n\", cudaCopyStatus, cudaGetErrorString(cudaCopyStatus), GPU_Data_Buffer[GPUbufferindex].gpu_data_his_size[itq]); if ( cudaCopyStatus == cudaErrorInvalidValue ) printf(\"cudaErrorInvalidValue !\\n\"); if ( cudaCopyStatus == cudaErrorInvalidDevicePointer ) printf(\"cudaErrorInvalidDevicePointer!\\n\"); } dbprintf(\"%s(%d): TQ=%i, gpu_odata %p, copying / zeroing hist databank [ size=%d, offset=%d], hist[0] 0x%08x, hist[N/8] 0x%08x, hist[N/4] 0x%08x, readout fill number %d, GPU fill number %d, GPU muon fill number %d\\n\", __func__, __LINE__, itq, (gpu_odata+GPU_Data_Buffer[GPUbufferindex].gpu_data_his_offset[itq]), GPU_Data_Buffer[GPUbufferindex].gpu_data_his_size[itq], GPU_Data_Buffer[GPUbufferindex].gpu_data_his_offset[itq], *(GPU_Data_Buffer[GPUbufferindex].gpu_data_his[itq]), *(GPU_Data_Buffer[GPUbufferindex].gpu_data_his[itq]+GPU_Data_Buffer[GPUbufferindex].gpu_data_his_size[itq]/8+1), *(GPU_Data_Buffer[GPUbufferindex].gpu_data_his[itq]+GPU_Data_Buffer[GPUbufferindex].gpu_data_his_size[itq]/4+1), AMC13fillcounter, GPUfillnumber_local, GPUmuonfillnumber ); // zero histogram data cudaCopyStatus = cudaMemset( gpu_odata+GPU_Data_Buffer[GPUbufferindex].gpu_data_his_offset[itq], 0, GPU_Data_Buffer[GPUbufferindex].gpu_data_his_size[itq]); // size unuts are bytes if (cudaCopyStatus != cudaSuccess ) { printf(\"cudaMemset of histo data FAIL, status: %d error: %s bytes: %d\\n\", cudaCopyStatus, cudaGetErrorString(cudaCopyStatus), GPU_Data_Buffer[GPUbufferindex].gpu_data_his_size[itq]); if ( cudaCopyStatus == cudaErrorInvalidValue ) printf(\"cudaErrorInvalidValue !\\n\"); if ( cudaCopyStatus == cudaErrorInvalidDevicePointer ) printf(\"cudaErrorInvalidDevicePointer!\\n\"); } } // end flush and zero of histogram data } // if TQ processing or histogram processing is switched on } // loop over index itq of TQ methods } // if muon fill MFE proc unlocked - GPU Proc done Near beginning of read trigger event INT read_trigger_event(char *pevent, INT off __attribute__((unused))) { int status __attribute__((unused)); float *fdata; BYTE *bdata; short *pdata; DWORD *hdata; char bk_name[8]; int frontend_index = get_frontend_index(); // temporary array for performance data to allowing unlocking gpu thread before data compression int perf_data_size = 0; uint64_t *perf_data; perf_data = (uint64_t*) malloc( gpu_data_header_size_max ); dbprintf(\"Begin read_trigger_event!\\n\"); //Obtain the address of the data struct in the GPU buffer int GPUbufferindex = Midasfillnumber % GPU_BUFFER_SIZE; GPU_Data_t* GPUDATA = &(GPU_Data_Buffer[GPUbufferindex]); //Lock the buffer access pthread_mutex_lock( &mutex_GPU_buf[GPUbufferindex] ); // get AMC13 fill number unsigned int AMC13fillcounter = ( be32toh ( GPUDATA->gpu_data_header[0] ) & 0x00FFFFFF ); // get GPU muon fill number that's stored by gpu_thread (used for flushing the CQ, CR banks) unsigned int GPUmuonfillcounter = GPUDATA->gpu_data_header[21]; dbprintf(\"GPUmuonfillcounter %i\\n\", GPUmuonfillcounter); // get data ready time struct timeval t_lock_data, t_got_data; status = gettimeofday( &t_lock_data, NULL); trigger_info.time_slave_lock_dataready_s = t_lock_data.tv_sec; trigger_info.time_slave_lock_dataready_us = t_lock_data.tv_usec; INT read_trigger_event(char *pevent, INT off __attribute__((unused))) { int status __attribute__((unused)); float *fdata; BYTE *bdata; short *pdata; DWORD *hdata; char bk_name[8]; int frontend_index = get_frontend_index(); // temporary array for performance data to allowing unlocking gpu thread before data compression int perf_data_size = 0; uint64_t *perf_data; perf_data = (uint64_t*) malloc( gpu_data_header_size_max ); dbprintf(\"Begin read_trigger_event!\\n\"); //Obtain the address of the data struct in the GPU buffer int GPUbufferindex = Midasfillnumber % GPU_BUFFER_SIZE; GPU_Data_t* GPUDATA = &(GPU_Data_Buffer[GPUbufferindex]); //Lock the buffer access pthread_mutex_lock( &mutex_GPU_buf[GPUbufferindex] ); // get AMC13 fill number unsigned int AMC13fillcounter = ( be32toh ( GPUDATA->gpu_data_header[0] ) & 0x00FFFFFF ); // get GPU muon fill number that's stored by gpu_thread (used for flushing the CQ, CR banks) unsigned int GPUmuonfillcounter = GPUDATA->gpu_data_header[21]; dbprintf(\"GPUmuonfillcounter %i\\n\", GPUmuonfillcounter); // get data ready time struct timeval t_lock_data, t_got_data; status = gettimeofday( &t_lock_data, NULL); trigger_info.time_slave_lock_dataready_s = t_lock_data.tv_sec; trigger_info.time_slave_lock_dataready_us = t_lock_data.tv_usec; MFE Banks Made - MFE Proc Unlocked Bunch of bank construction (too many lines) lossless compression - MFE Banks Made lossless data compression, then deletes other banks if compression is on //This is for run3 and before /* GPUDATA->gpu_data_header[19] = TCPfillnumber; GPUDATA->gpu_data_header[20] = GPUfillnumber; GPUDATA->gpu_data_header[21] = GPUmuonfillcounter; // the muon fill counter as set for fill in gpu_thread */ //In Run 4 nothing has to be done here //TODO Check Data! // fix size of header / timing data perf_data_size = 22*sizeof(GPUDATA->gpu_data_header[0]); // perf_data, perf_data_size are copies of GPUDATA->gpu_data_header, GPUDATA->gpu_data_header_size in order to release gpu lock before data compression memcpy( perf_data, GPUDATA->gpu_data_header, perf_data_size); // unlocking gpu thread access to GPU output buffer (commented out because causing problems) pthread_mutex_unlock( &mutex_GPU_buf[GPUbufferindex] ); // for rider's make losslessly-compressed processed databank dbprintf(\"%s(%d): lossless data compression %i\\n\", __func__, __LINE__, amc13_settings_odb.lossless_compression); if ( amc13_settings_odb.lossless_compression ){ BANK_HEADER *bank_header = (BANK_HEADER *) pevent; dbprintf(\"%s(%d): fill FZ data bank, data size %lu\\n\",__func__, __LINE__, bank_header->data_size+sizeof(BANK_HEADER)); if ( fe_compress_z(pevent, // char pointer to location of output (char*)bank_header, // char pointer to location of input bank_header->data_size+sizeof(BANK_HEADER), // data size + header size max_event_size-(bank_header->data_size+sizeof(BANK_HEADER)+sizeof(EVENT_HEADER)), // available space 0) != FE_SUCCESS ){ // compression failed. store raw dats printf(\"%s(%d): fill FZ data bank - compression failed\\n\",__func__, __LINE__); } // if losslessly compressing the midas banks then delete the uncompressed banks #ifdef USE_GPU for (int itq = 0; itq < TQMETHOD_MAX; itq++){ if ( tq_parameters_odb[itq].TQ_on && Fill_type==1 ) { sprintf(bk_name,\"%sS%03i\", tq_parameters_odb[itq].TQ_bankprefix, frontend_index); bk_delete(pevent,bk_name); dbprintf(\"%s(%d): deleted bank %s\\n\", __func__, __LINE__, bk_name); sprintf(bk_name,\"%sP%03i\", tq_parameters_odb[itq].TQ_bankprefix, frontend_index); bk_delete(pevent,bk_name); dbprintf(\"%s(%d): deleted bank %s\\n\", __func__, __LINE__, bk_name); sprintf(bk_name,\"%sT%03i\", tq_parameters_odb[itq].TQ_bankprefix, frontend_index); bk_delete(pevent,bk_name); dbprintf(\"%s(%d): deleted bank %s\\n\", __func__, __LINE__, bk_name); } // end delete CQ, CP, CT banks //if ( tq_parameters_odb[itq].store_hist && Fill_type==1 && !( (AMC13fillcounter-1-tq_parameters_odb[itq].flush_offset_hist) % tq_parameters_odb[itq].flush_hist ) ) // flush offset is disabled for run4, and making sure that fill0 is not flushed. if ( tq_parameters_odb[itq].store_hist && Fill_type==1 && ( (GPUmuonfillcounter+1) % tq_parameters_odb[itq].flush_hist ) == 0) { sprintf(bk_name,\"%sQ%03i\", tq_parameters_odb[itq].TQ_bankprefix, frontend_index); bk_delete(pevent,bk_name); dbprintf(\"%s(%d): deleted bank %s\\n\", __func__, __LINE__, bk_name); } // end delete CH bank if ( tq_parameters_odb[itq].fit_islands>0 && Fill_type==1 ){ sprintf(bk_name,\"%sF%03i\", tq_parameters_odb[itq].TQ_bankprefix, frontend_index); bk_delete(pevent,bk_name); dbprintf(\"%s(%d): deleted bank %s\\n\", __func__, __LINE__, bk_name); } // end delete CF bank } // end loop over TQ methods sprintf(bk_name,\"CA000\"); bk_delete(pevent,bk_name); dbprintf(\"%s(%d): deleted bank %s\\n\", __func__, __LINE__, bk_name); sprintf(bk_name,\"CR000\"); bk_delete(pevent,bk_name); dbprintf(\"%s(%d): deleted bank %s\\n\", __func__, __LINE__, bk_name); sprintf(bk_name,\"CZ000\"); bk_delete(pevent,bk_name); dbprintf(\"%s(%d): deleted bank %s\\n\", __func__, __LINE__, bk_name); #endif // USE_GPU if (Fill_type>1 || ( amc13_settings_odb.store_raw && !( ( GPUmuonfillcounter - amc13_settings_odb.prescale_offset_raw ) % amc13_settings_odb.prescale_raw ) && AMC13fillcounter>=amc13_settings_odb.prescale_offset_raw)) { if (Fill_type == 0x1) { sprintf(bk_name,\"CR%03i\",frontend_index); // muon fill type } else if(Fill_type == 0x2) { sprintf(bk_name,\"LR%03i\",frontend_index); // laser fill type } else if(Fill_type == 0x3) { sprintf(bk_name,\"PR%03i\",frontend_index); // pedestal fill type } else if(Fill_type == 0x4) { sprintf(bk_name,\"AR%03i\",frontend_index); // async fill type } bk_delete(pevent,bk_name); dbprintf(\"%s(%d): deleted bank %s\\n\", __func__, __LINE__, bk_name); } // end delete CR bank, etc // delete CA / LA / PA banks if (Fill_type == 0x1) { sprintf(bk_name,\"CA%03i\",frontend_index); // muon fill type } else if(Fill_type == 0x2) { sprintf(bk_name,\"LA%03i\",frontend_index); // laser fill type } else if(Fill_type == 0x3) { sprintf(bk_name,\"PA%03i\",frontend_index); // pedestal fill type } else if(Fill_type == 0x4) { sprintf(bk_name,\"AA%03i\",frontend_index); // async fill type } bk_delete(pevent,bk_name); dbprintf(\"%s(%d): deleted bank %s\\n\", __func__, __LINE__, bk_name); // delete CB bank (there's no filling of \"CB\" bank equivalent for laser, ped, async fills if (Fill_type == 0x1) { sprintf(bk_name,\"CB%03i\",frontend_index); // muon fill type bk_delete(pevent,bk_name); dbprintf(\"%s(%d): deleted bank %s\\n\", __func__, __LINE__, bk_name); } // delete CC / LC / PC / AC banks if (Fill_type == 0x1) { sprintf(bk_name,\"CC%03i\",frontend_index); // muon fill type } else if(Fill_type == 0x2) { sprintf(bk_name,\"LC%03i\",frontend_index); // laser fill type } else if(Fill_type == 0x3) { sprintf(bk_name,\"PC%03i\",frontend_index); // pedestal fill type } else if(Fill_type == 0x4) { sprintf(bk_name,\"AC%03i\",frontend_index); // async fill type } bk_delete(pevent,bk_name); dbprintf(\"%s(%d): deleted bank %s\\n\", __func__, __LINE__, bk_name); // delete CZ / LZ / PZ / AZ banks if (Fill_type == 0x1) { sprintf(bk_name,\"CZ%03i\",frontend_index); // muon fill type } else if(Fill_type == 0x2) { sprintf(bk_name,\"LZ%03i\",frontend_index); // laser fill type } else if(Fill_type == 0x3) { sprintf(bk_name,\"PZ%03i\",frontend_index); // pedestal fill type } else if(Fill_type == 0x4) { sprintf(bk_name,\"AZ%03i\",frontend_index); // async fill type } bk_delete(pevent,bk_name); dbprintf(\"%s(%d): deleted bank %s\\n\", __func__, __LINE__, bk_name); } // end lossless compression //This is for run3 and before /* GPUDATA->gpu_data_header[19] = TCPfillnumber; GPUDATA->gpu_data_header[20] = GPUfillnumber; GPUDATA->gpu_data_header[21] = GPUmuonfillcounter; // the muon fill counter as set for fill in gpu_thread */ //In Run 4 nothing has to be done here //TODO Check Data! // fix size of header / timing data perf_data_size = 22*sizeof(GPUDATA->gpu_data_header[0]); // perf_data, perf_data_size are copies of GPUDATA->gpu_data_header, GPUDATA->gpu_data_header_size in order to release gpu lock before data compression memcpy( perf_data, GPUDATA->gpu_data_header, perf_data_size); // unlocking gpu thread access to GPU output buffer (commented out because causing problems) pthread_mutex_unlock( &mutex_GPU_buf[GPUbufferindex] ); // for rider's make losslessly-compressed processed databank dbprintf(\"%s(%d): lossless data compression %i\\n\", __func__, __LINE__, amc13_settings_odb.lossless_compression); if ( amc13_settings_odb.lossless_compression ){ BANK_HEADER *bank_header = (BANK_HEADER *) pevent; dbprintf(\"%s(%d): fill FZ data bank, data size %lu\\n\",__func__, __LINE__, bank_header->data_size+sizeof(BANK_HEADER)); if ( fe_compress_z(pevent, // char pointer to location of output (char*)bank_header, // char pointer to location of input bank_header->data_size+sizeof(BANK_HEADER), // data size + header size max_event_size-(bank_header->data_size+sizeof(BANK_HEADER)+sizeof(EVENT_HEADER)), // available space 0) != FE_SUCCESS ){ // compression failed. store raw dats printf(\"%s(%d): fill FZ data bank - compression failed\\n\",__func__, __LINE__); } // if losslessly compressing the midas banks then delete the uncompressed banks #ifdef USE_GPU for (int itq = 0; itq < TQMETHOD_MAX; itq++){ if ( tq_parameters_odb[itq].TQ_on && Fill_type==1 ) { sprintf(bk_name,\"%sS%03i\", tq_parameters_odb[itq].TQ_bankprefix, frontend_index); bk_delete(pevent,bk_name); dbprintf(\"%s(%d): deleted bank %s\\n\", __func__, __LINE__, bk_name); sprintf(bk_name,\"%sP%03i\", tq_parameters_odb[itq].TQ_bankprefix, frontend_index); bk_delete(pevent,bk_name); dbprintf(\"%s(%d): deleted bank %s\\n\", __func__, __LINE__, bk_name); sprintf(bk_name,\"%sT%03i\", tq_parameters_odb[itq].TQ_bankprefix, frontend_index); bk_delete(pevent,bk_name); dbprintf(\"%s(%d): deleted bank %s\\n\", __func__, __LINE__, bk_name); } // end delete CQ, CP, CT banks //if ( tq_parameters_odb[itq].store_hist && Fill_type==1 && !( (AMC13fillcounter-1-tq_parameters_odb[itq].flush_offset_hist) % tq_parameters_odb[itq].flush_hist ) ) // flush offset is disabled for run4, and making sure that fill0 is not flushed. if ( tq_parameters_odb[itq].store_hist && Fill_type==1 && ( (GPUmuonfillcounter+1) % tq_parameters_odb[itq].flush_hist ) == 0) { sprintf(bk_name,\"%sQ%03i\", tq_parameters_odb[itq].TQ_bankprefix, frontend_index); bk_delete(pevent,bk_name); dbprintf(\"%s(%d): deleted bank %s\\n\", __func__, __LINE__, bk_name); } // end delete CH bank if ( tq_parameters_odb[itq].fit_islands>0 && Fill_type==1 ){ sprintf(bk_name,\"%sF%03i\", tq_parameters_odb[itq].TQ_bankprefix, frontend_index); bk_delete(pevent,bk_name); dbprintf(\"%s(%d): deleted bank %s\\n\", __func__, __LINE__, bk_name); } // end delete CF bank } // end loop over TQ methods sprintf(bk_name,\"CA000\"); bk_delete(pevent,bk_name); dbprintf(\"%s(%d): deleted bank %s\\n\", __func__, __LINE__, bk_name); sprintf(bk_name,\"CR000\"); bk_delete(pevent,bk_name); dbprintf(\"%s(%d): deleted bank %s\\n\", __func__, __LINE__, bk_name); sprintf(bk_name,\"CZ000\"); bk_delete(pevent,bk_name); dbprintf(\"%s(%d): deleted bank %s\\n\", __func__, __LINE__, bk_name); #endif // USE_GPU if (Fill_type>1 || ( amc13_settings_odb.store_raw && !( ( GPUmuonfillcounter - amc13_settings_odb.prescale_offset_raw ) % amc13_settings_odb.prescale_raw ) && AMC13fillcounter>=amc13_settings_odb.prescale_offset_raw)) { if (Fill_type == 0x1) { sprintf(bk_name,\"CR%03i\",frontend_index); // muon fill type } else if(Fill_type == 0x2) { sprintf(bk_name,\"LR%03i\",frontend_index); // laser fill type } else if(Fill_type == 0x3) { sprintf(bk_name,\"PR%03i\",frontend_index); // pedestal fill type } else if(Fill_type == 0x4) { sprintf(bk_name,\"AR%03i\",frontend_index); // async fill type } bk_delete(pevent,bk_name); dbprintf(\"%s(%d): deleted bank %s\\n\", __func__, __LINE__, bk_name); } // end delete CR bank, etc // delete CA / LA / PA banks if (Fill_type == 0x1) { sprintf(bk_name,\"CA%03i\",frontend_index); // muon fill type } else if(Fill_type == 0x2) { sprintf(bk_name,\"LA%03i\",frontend_index); // laser fill type } else if(Fill_type == 0x3) { sprintf(bk_name,\"PA%03i\",frontend_index); // pedestal fill type } else if(Fill_type == 0x4) { sprintf(bk_name,\"AA%03i\",frontend_index); // async fill type } bk_delete(pevent,bk_name); dbprintf(\"%s(%d): deleted bank %s\\n\", __func__, __LINE__, bk_name); // delete CB bank (there's no filling of \"CB\" bank equivalent for laser, ped, async fills if (Fill_type == 0x1) { sprintf(bk_name,\"CB%03i\",frontend_index); // muon fill type bk_delete(pevent,bk_name); dbprintf(\"%s(%d): deleted bank %s\\n\", __func__, __LINE__, bk_name); } // delete CC / LC / PC / AC banks if (Fill_type == 0x1) { sprintf(bk_name,\"CC%03i\",frontend_index); // muon fill type } else if(Fill_type == 0x2) { sprintf(bk_name,\"LC%03i\",frontend_index); // laser fill type } else if(Fill_type == 0x3) { sprintf(bk_name,\"PC%03i\",frontend_index); // pedestal fill type } else if(Fill_type == 0x4) { sprintf(bk_name,\"AC%03i\",frontend_index); // async fill type } bk_delete(pevent,bk_name); dbprintf(\"%s(%d): deleted bank %s\\n\", __func__, __LINE__, bk_name); // delete CZ / LZ / PZ / AZ banks if (Fill_type == 0x1) { sprintf(bk_name,\"CZ%03i\",frontend_index); // muon fill type } else if(Fill_type == 0x2) { sprintf(bk_name,\"LZ%03i\",frontend_index); // laser fill type } else if(Fill_type == 0x3) { sprintf(bk_name,\"PZ%03i\",frontend_index); // pedestal fill type } else if(Fill_type == 0x4) { sprintf(bk_name,\"AZ%03i\",frontend_index); // async fill type } bk_delete(pevent,bk_name); dbprintf(\"%s(%d): deleted bank %s\\n\", __func__, __LINE__, bk_name); } // end lossless compression 14/05/2024 12:19 Scanning the 192.168.xxx.xxx subet with nmap 192.168.0.0/16 shows me the VadaTech MCH is here(?): 192.168.20.14 <-- Network Research 192.168.20.230 <-- Network Research 192.168.60.15 <-- VadaTech 192.168.60.17 <-- VadaTech 192.168.60.18 <-- VadaTech 192.168.60.19 <-- VadaTech 192.168.20.14 <-- Network Research 192.168.20.230 <-- Network Research 192.168.60.15 <-- VadaTech 192.168.60.17 <-- VadaTech 192.168.60.18 <-- VadaTech 192.168.60.19 <-- VadaTech For some reason I can't scroll up in the terminal, so I'm a little upset by that, but this is all I can see. Apparently CentOS7 clears the terminal buffer after some time. In any event, pinging any of the VadaTech modules hangs. The destination is reachable from the 'be' computer's perspective, but there is no response from the modules. I can, however, ping T1 and T2 located at 192.168.20.13 and 192.168.20.14 . 14/05/2024 13:11 For our temporary setup using WiFi, the 'be' computer can be connected to by ssh tunneling. See intructions below: Remotely connect to newest desktop Port forward connections for midas, crate monitor, data monitor: ssh -L 8080:localhost:8080 -L 8000:localhost:8000 -L 7000:localhost:7000 pioneer@10.47.95.44 ssh -L 8080 :localhost: 8080 -L 8000 :localhost: 8000 -L 7000 :localhost: 7000 pioneer@ 10.47.95.44 Remotely connect to 'be' Port forward connections for midas, crate monitor, data monitor: ssh -L 8080:localhost:8080 -L 8000:localhost:8000 -L 7000:localhost:7000 root@10.0.0.3 ssh -L 8080 :localhost: 8080 -L 8000 :localhost: 8000 -L 7000 :localhost: 7000 root@ 10.0.0.3 Passwords for both are mu->egamma 14/05/2024 13:19 I tested swapping out the MCHs (put N.A.T. MCH in our second crate). I was able to ping the N.A.T. with ping 192.168.1.41 [root@localhost ~]# ping 192.168.1.41 PING 192.168.1.41 (192.168.1.41) 56(84) bytes of data. 64 bytes from 192.168.1.41: icmp_seq=1 ttl=255 time=0.313 ms 64 bytes from 192.168.1.41: icmp_seq=2 ttl=255 time=0.355 ms [root@localhost ~]# ping 192.168.1.41 PING 192.168.1.41 (192.168.1.41) 56(84) bytes of data. 64 bytes from 192.168.1.41: icmp_seq =1 ttl =255 time =0.313 ms 64 bytes from 192.168.1.41: icmp_seq =2 ttl =255 time =0.355 ms 14/05/2024 13:37 Here are the untrucated results of nmap 192.168.0.0/16 : [root@localhost output_files]# cat nmap_output2.txt Starting Nmap 6.40 ( http://nmap.org ) at 2024-05-14 12:49 EDT Nmap scan report for 192.168.1.1 Host is up (0.00011s latency). All 1000 scanned ports on 192.168.1.1 are filtered MAC Address: 00:60:55:00:01:DF (Cornell University) Nmap scan report for 192.168.4.3 Host is up (-0.034s latency). All 1000 scanned ports on 192.168.4.3 are filtered MAC Address: 00:60:55:00:01:BC (Cornell University) Nmap scan report for 192.168.1.100 Host is up (0.000031s latency). Not shown: 997 closed ports PORT STATE SERVICE 22/tcp open ssh 111/tcp open rpcbind 2049/tcp open nfs Nmap scan report for 192.168.20.13 Host is up (-0.10s latency). All 1000 scanned ports on 192.168.20.13 are filtered MAC Address: 08:00:30:F3:04:33 (Network Research) Nmap scan report for 192.168.20.14 Host is up (0.00011s latency). All 1000 scanned ports on 192.168.20.14 are filtered MAC Address: 08:00:30:F3:04:73 (Network Research) Nmap scan report for 192.168.40.230 Host is up (0.0015s latency). All 1000 scanned ports on 192.168.40.230 are filtered MAC Address: 00:13:3A:0A:21:72 (VadaTech) Nmap scan report for 192.168.60.15 Host is up (0.00092s latency). All 1000 scanned ports on 192.168.60.15 are filtered MAC Address: 00:13:3A:0A:14:B9 (VadaTech) Nmap scan report for 192.168.60.17 Host is up (0.0012s latency). All 1000 scanned ports on 192.168.60.17 are filtered MAC Address: 00:13:3A:0A:14:B9 (VadaTech) Nmap scan report for 192.168.60.18 Host is up (0.0012s latency). All 1000 scanned ports on 192.168.60.18 are filtered MAC Address: 00:13:3A:0A:14:B9 (VadaTech) Nmap scan report for 192.168.60.19 Host is up (0.0011s latency). All 1000 scanned ports on 192.168.60.19 are filtered MAC Address: 00:13:3A:0A:14:B9 (VadaTech) Nmap scan report for 192.168.122.1 Host is up (0.000031s latency). Not shown: 996 closed ports PORT STATE SERVICE 22/tcp open ssh 53/tcp open domain 111/tcp open rpcbind 2049/tcp open nfs Nmap done: 47872 IP addresses (11 hosts up) scanned in 1743.13 seconds [root@localhost output_files]# [root@localhost output_files]# cat nmap_output2.txt Starting Nmap 6.40 ( http://nmap.org ) at 2024-05-14 12:49 EDT Nmap scan report for 192.168.1.1 Host is up (0.00011s latency). All 1000 scanned ports on 192.168.1.1 are filtered MAC Address: 00:60:55:00:01:DF (Cornell University) Nmap scan report for 192.168.4.3 Host is up (-0.034s latency). All 1000 scanned ports on 192.168.4.3 are filtered MAC Address: 00:60:55:00:01:BC (Cornell University) Nmap scan report for 192.168.1.100 Host is up (0.000031s latency). Not shown: 997 closed ports PORT STATE SERVICE 22/tcp open ssh 111/tcp open rpcbind 2049/tcp open nfs Nmap scan report for 192.168.20.13 Host is up (-0.10s latency). All 1000 scanned ports on 192.168.20.13 are filtered MAC Address: 08:00:30:F3:04:33 (Network Research) Nmap scan report for 192.168.20.14 Host is up (0.00011s latency). All 1000 scanned ports on 192.168.20.14 are filtered MAC Address: 08:00:30:F3:04:73 (Network Research) Nmap scan report for 192.168.40.230 Host is up (0.0015s latency). All 1000 scanned ports on 192.168.40.230 are filtered MAC Address: 00:13:3A:0A:21:72 (VadaTech) Nmap scan report for 192.168.60.15 Host is up (0.00092s latency). All 1000 scanned ports on 192.168.60.15 are filtered MAC Address: 00:13:3A:0A:14:B9 (VadaTech) Nmap scan report for 192.168.60.17 Host is up (0.0012s latency). All 1000 scanned ports on 192.168.60.17 are filtered MAC Address: 00:13:3A:0A:14:B9 (VadaTech) Nmap scan report for 192.168.60.18 Host is up (0.0012s latency). All 1000 scanned ports on 192.168.60.18 are filtered MAC Address: 00:13:3A:0A:14:B9 (VadaTech) Nmap scan report for 192.168.60.19 Host is up (0.0011s latency). All 1000 scanned ports on 192.168.60.19 are filtered MAC Address: 00:13:3A:0A:14:B9 (VadaTech) Nmap scan report for 192.168.122.1 Host is up (0.000031s latency). Not shown: 996 closed ports PORT STATE SERVICE 22/tcp open ssh 53/tcp open domain 111/tcp open rpcbind 2049/tcp open nfs Nmap done: 47872 IP addresses (11 hosts up) scanned in 1743.13 seconds [root@localhost output_files]# 14/05/2024 15:16 I tried to connect to Vadatech MCH webpage on the newest desktop with it connected to 'be' which is connected to the VadaTech MCH: ssh -L 8081:192.168.40.230:80 root@10.0.0.3 ssh -L 8081 : 192.168.40.230:80 root@ 10.0.0.3 Then going to localhost:8081 should bring up the webpage, but it just hangs. It's unclear to me what the port 80 does at the end of the -L flag parameter (though this worked for the N.A.T. MCH). I then tried to remove 'be' as the middle man. I reconfigured the network settings on the newest desktop so it is on the 192.168.xxx.xxx network and directly connected it to the MCH GbE0 port. I was able to ping T1, T2, and the 2 WFD5s in the crate, so the connection \"worked.\" But I have all the same problems as before (can't see webpage by going to http://192.168.40.230/ , can't ping MCH, etc.) 14/05/2024 16:49 I was able to get into the MCH by setting the computer's IP to 192.168.60.xxx. # # Connect to MCH # TYPE=Ethernet BOOTPROTO=static IPADDR=192.168.60.100 NETMASK=255.255.0.0 IPV4_FAILURE_FATAL=no IPV6INIT=no IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_PEERDNS=yes IPV6_PEERROUTES=yes IPV6_FAILURE_FATAL=no NAME=enp5s0 DEVICE=enp5s0 ONBOOT=yes # # Connect to MCH # TYPE =Ethernet BOOTPROTO =static IPADDR = 192.168 . 60.100 NETMASK = 255.255 . 0.0 IPV4_FAILURE_FATAL = no IPV6INIT = no IPV6_AUTOCONF = yes IPV6_DEFROUTE = yes IPV6_PEERDNS = yes IPV6_PEERROUTES = yes IPV6_FAILURE_FATAL = no NAME =enp5s0 DEVICE =enp5s0 ONBOOT = yes It turns out our MCH was configured to ignore traffic outside of the 255.255.254.0 = 192.168.60.xxx subnet, as you can see when doing vim /etc/rc.d/rc.conf # net interface 0 export SYSCFG_IFACE0=n export INTERFACE0=\"eth0\" export IPADDR0=\"0.0.0.0\" export NETMASK0=\"0.0.0.0\" export BROADCAST0=\"0.0.0.0\" export GATEWAY0=\"0.0.0.0\" export NAMESERVER0=\"0.0.0.0\" # net interface 1 export SYSCFG_IFACE1=y export INTERFACE1=\"eth1\" export IPADDR1=\"192.168.60.15\" export NETMASK1=\"255.255.254.0\" export BROADCAST1=\"192.168.61.255\" export GATEWAY1=\"192.168.60.121\" export NAMESERVER1=\"0.0.0.0\" # net interface 0 export SYSCFG_IFACE0 =n export INTERFACE0 = \"eth0\" export IPADDR0 = \"0.0.0.0\" export NETMASK0 = \"0.0.0.0\" export BROADCAST0 = \"0.0.0.0\" export GATEWAY0 = \"0.0.0.0\" export NAMESERVER0 = \"0.0.0.0\" # net interface 1 export SYSCFG_IFACE1 =y export INTERFACE1 = \"eth1\" export IPADDR1 = \"192.168.60.15\" export NETMASK1 = \"255.255.254.0\" export BROADCAST1 = \"192.168.61.255\" export GATEWAY1 = \"192.168.60.121\" export NAMESERVER1 = \"0.0.0.0\" To edit files, you have to run: mount -o remount,rw / mount -o remount,rw / Also, for some reason to use vim on the MCH you have to run: :set nocompatible : set nocompatible first. 14/05/2024 16:55 I was able to edit the MCH to change it's crate number to \"2\" by following the steps in this pdf. mch_network_configuration.pdf 14/05/2024 17:36 Before I solved the problem with the 10GbE link by putting the 10GbE AMC port on a different subnet (192.168.1.150). However, this will no longer work with two crates. In short, it's against subnetting rules to have a subnet like 192.168.{1 or 2}.{1 to 128} or anything similar. Basically, you can't have control over the 3rd and 4th octet simulatenously. As a result, I need to find a way to get the 10GbE link on a different subnet (i.e 192.168.50.xxx, or something like that). I failed to do this before, and I'm unsure why it didn't work. I didn't test too thoroughly 27/03/2024 20:38 I am trying to change the IP to 192.168.10.1 Pick an action (h for menu): wv 0x1c1c 0xc0a80a01 Writing to T1: 00001c1c: c0a80a01 Pick an action (h for menu): rv 0x1c1c Reading T1: 00001c1c: c0a80a01 since 192 = c0 168 = a8 10 = 0a 1 = 01 I then changed enp1s0f1 to be on the 192.168.10.xxx subnet with IP 192.168.1.2. It didn't really seem to work: [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# ping 192.168.10.1 PING 192.168.10.1 (192.168.10.1) 56(84) bytes of data. ^C --- 192.168.10.1 ping statistics --- 2 packets transmitted, 0 received, 100% packet loss, time 999ms [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# ifdown enp5s0 Device 'enp5s0' successfully disconnected. [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# ping 192.168.10.1 PING 192.168.10.1 (192.168.10.1) 56(84) bytes of data. ^C --- 192.168.10.1 ping statistics --- 1 packets transmitted, 0 received, 100% packet loss, time 0ms [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# I can successfully change the IP to something else on the 192.168.1.xxx subnet though 15/05/2024 12:18 I don't know what I was doing wrong last time. I got the 10GbE links to work rather trivially this time. First I change the network settings scripts for the 10GbE ports on 'be'. I set them to be on the networks 192.168.50.xxx and 192.168.51.xxx. enp1s0f1 is connected to crate 1, and enp1s0f0 is connected to crate 2, so we have to set the 10GbE port addresses to be on the respective network. /etc/sysconfig/network-scripts/ifcfg-enp1s0f0: # # Connect to AMC # TYPE=Ethernet BOOTPROTO=static IPADDR=192.168.51.100 NETMASK=255.255.255.0 IPV4_FAILURE_FATAL=no IPV6INIT=no IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_PEERDNS=yes IPV6_PEERROUTES=yes IPV6_FAILURE_FATAL=no NAME=enp1s0f0 DEVICE=enp1s0f0 ONBOOT=yes AUTOCONNECT_PRIORITY=-999 MTU=9000 # # Connect to AMC # TYPE =Ethernet BOOTPROTO =static IPADDR = 192.168 . 51.100 NETMASK = 255.255 . 255.0 IPV4_FAILURE_FATAL = no IPV6INIT = no IPV6_AUTOCONF = yes IPV6_DEFROUTE = yes IPV6_PEERDNS = yes IPV6_PEERROUTES = yes IPV6_FAILURE_FATAL = no NAME =enp1s0f0 DEVICE =enp1s0f0 ONBOOT = yes AUTOCONNECT_PRIORITY =- 999 MTU = 9000 /etc/sysconfig/network-scripts/ifcfg-enp1s0f1: # # Connect to AMC # HWADDR=b4:b5:2f:a4:e7:fc TYPE=Ethernet PROXY_METHOD=none BROWSER_ONLY=no BOOTPROTO=none IPADDR=192.168.50.100 NETMASK=255.255.255.0 DEFROUTE=yes IPV4_FAILURE_FATAL=no IPV6INIT=yes IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_FAILURE_FATAL=no IPV6_ADDR_GEN_MODE=stable-privacy UUID=f1d52da3-687b-3215-a2c0-60c11d0fd3bf ONBOOT=yes AUTOCONNECT_PRIORITY=-999 MTU=9000 DEVICE=enp1s0f1 NAME=enp1s0f1 # # Connect to AMC # HWADDR =b4:b5: 2 f:a4:e7:fc TYPE =Ethernet PROXY_METHOD =none BROWSER_ONLY = no BOOTPROTO =none IPADDR = 192.168 . 50.100 NETMASK = 255.255 . 255.0 DEFROUTE = yes IPV4_FAILURE_FATAL = no IPV6INIT = yes IPV6_AUTOCONF = yes IPV6_DEFROUTE = yes IPV6_FAILURE_FATAL = no IPV6_ADDR_GEN_MODE =stable-privacy UUID =f1d52da3- 687 b- 3215 -a2c0- 60 c11d0fd3bf ONBOOT = yes AUTOCONNECT_PRIORITY =- 999 MTU = 9000 DEVICE =enp1s0f1 NAME =enp1s0f1 For crate 1: Follow these steps Set T1 and T2 IPs again Ensure the correct IP and network base in systemVars.py, should look like this: #File to specify what the default varaibles addresses are used in your system #Default IP address for commercial MCH module # our NAT MCH address DEFAULT_HOST_IP=\"192.168.1.41\" # our Vadatech MCH address #DEFAULT_HOST_IP=\"192.168.2.15\" #Default AMC13 slot number DEFAULT_AMC13_SLOT=13 #Location of 'config_tools'. This should never need to be changed DEFAULT_CONFIG_DIR=\"./config_tools\" #Network base for your uTCA crate's AMC modules NETWORK_BASE=\"192.168.1\" #NETWORK_BASE=\"192.168.2\" #File to specify what the default varaibles addresses are used in your system #Default IP address for commercial MCH module # our NAT MCH address DEFAULT_HOST_IP = \"192.168.1.41\" # our Vadatech MCH address #DEFAULT_HOST_IP=\"192.168.2.15\" #Default AMC13 slot number DEFAULT_AMC13_SLOT = 13 #Location of 'config_tools'. This should never need to be changed DEFAULT_CONFIG_DIR = \"./config_tools\" #Network base for your uTCA crate's AMC modules NETWORK_BASE = \"192.168.1\" #NETWORK_BASE=\"192.168.2\" Now set the IPs: cd /home/installation_testing/packages/experiment/lxedaq/amc13/amc13_v1_2_18/dev_tools/amc13Config ./applyConfig.py -i 192.168.1.13 The -i flag defines the T1 and T2 IP. T1 will be the argument of -i and T2 will be that argument +1 in the octet of the IP. cd /home/installation_testing/packages/experiment/lxedaq/amc13/amc13_v1_2_18/dev_tools/amc13Config ./applyConfig. py -i 192.168 . 1.13 The -i flag defines the T1 and T2 IP. T1 will be the argument of -i and T2 will be that argument + 1 in the octet of the IP. Test pinging T1 and T2: ping 192.168.1.13 ping 192.168.1.14 ping 192.168.1.13 ping 192.168.1.14 Configure 10GbE link cd /home/installation_testing/packages/experiment/lxedaq/amc13/amc13StandaloneMAN_2014-05-12 bin/AMC13Tool -i 192.168.1.13 cd /home/installation_testing/packages/experiment/lxedaq/amc13/amc13StandaloneMAN_2014- 05 - 12 bin /AMC13Tool -i 192.168.1.13 Within AMC13Tool: Enable DAQ Link: Pick an action (h for menu): i 0-11 d Enabling AMC inputs from list: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11 Link status: 0fff0fff Enable DAQ Link 'CONTROL1': 813f0003 Pick an action (h for menu) : i 0-11 d Enabling AMC inputs from list : 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11 Link status : 0fff0fff Enable DAQ Link 'CONTROL1' : 813f0003 Note: This has parameters: i <ena_list> (d) (f) enable AMCs from input list. Enable (d)AQlink, (f)ake data, (t) (l) use local (T)TC signal, enable (L)ocal triggers, (r) (b) TTC(r)x, monBuf (b)ackpressure i <ena_list> (d) (f) enable AMCs from input list. Enable (d)AQlink, (f)ake data, (t) (l) use local (T)TC signal, enable (L)ocal triggers, (r) (b) TTC (r)x, monBuf (b)ackpressure I'm not sure which one to use. Enable SFP+ Ports: Pick an action (h for menu): wv 0x3 0x1fff Writing to T1: 00000003: 00001fff Pick an action (h for menu): wv 0 x3 0 x1fff Writing to T1: 00000003 : 00001 fff Change SFP+ port IP address to 192.168.50.1: Pick an action (h for menu): wv 0x1c1c 0xC0A83201 Writing to T1: 00001c1c: c0a83201 Pick an action (h for menu): wv 0x1c1c 0xC0A83201 Writing to T 1 : 00001 c 1 c : c 0 a 83201 Now cycle the 10GbE port on 'be': ifdown enp1s0f1 ifup enp1s0f1 ifdown enp1s0f1 ifup enp1s0f1 Try pinging ping 192.168.50.1 ping 192.168.50.1 Also ensure you can still ping the MCHs: ping 192.168.1.41 ping 192.168.2.15 ping 192.168.1.41 ping 192.168.2.15 (sometimes enp1s0f1 will start stealing traffic from enp5s0. To fix this ifdown enp5s0, ifdown enp1s0f1, ifup enp5s0, ifup enp1s0f1 in that order and retry pinging). For crate 2: Follow these steps Set T1 and T2 IPs Ensure the correct IP and network base in systemVars.py, should look like this: #File to specify what the default varaibles addresses are used in your system #Default IP address for commercial MCH module # our NAT MCH address #DEFAULT_HOST_IP=\"192.168.1.41\" # our Vadatech MCH address DEFAULT_HOST_IP=\"192.168.2.15\" #Default AMC13 slot number DEFAULT_AMC13_SLOT=13 #Location of 'config_tools'. This should never need to be changed DEFAULT_CONFIG_DIR=\"./config_tools\" #Network base for your uTCA crate's AMC modules #NETWORK_BASE=\"192.168.1\" NETWORK_BASE=\"192.168.2\" #File to specify what the default varaibles addresses are used in your system #Default IP address for commercial MCH module # our NAT MCH address #DEFAULT_HOST_IP=\"192.168.1.41\" # our Vadatech MCH address DEFAULT_HOST_IP = \"192.168.2.15\" #Default AMC13 slot number DEFAULT_AMC13_SLOT = 13 #Location of 'config_tools'. This should never need to be changed DEFAULT_CONFIG_DIR = \"./config_tools\" #Network base for your uTCA crate's AMC modules #NETWORK_BASE=\"192.168.1\" NETWORK_BASE = \"192.168.2\" Now set the IPs: cd /home/installation_testing/packages/experiment/lxedaq/amc13/amc13_v1_2_18/dev_tools/amc13Config ./applyConfig.py -i 192.168.2.13 The -i flag defines the T1 and T2 IP. T1 will be the argument of -i and T2 will be that argument +1 in the octet of the IP. cd /home/installation_testing/packages/experiment/lxedaq/amc13/amc13_v1_2_18/dev_tools/amc13Config ./applyConfig. py -i 192.168 . 2.13 The -i flag defines the T1 and T2 IP. T1 will be the argument of -i and T2 will be that argument + 1 in the octet of the IP. Test pinging T1 and T2: ping 192.168.2.13 ping 192.168.2.14 ping 192.168.2.13 ping 192.168.2.14 Configure 10GbE link cd /home/installation_testing/packages/experiment/lxedaq/amc13/amc13StandaloneMAN_2014-05-12 bin/AMC13Tool -i 192.168.2.13 cd /home/installation_testing/packages/experiment/lxedaq/amc13/amc13StandaloneMAN_2014- 05 - 12 bin /AMC13Tool -i 192.168.2.13 Within AMC13Tool: Enable DAQ Link: Pick an action (h for menu): i 0-11 d Enabling AMC inputs from list: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11 Link status: 0fff0fff Enable DAQ Link 'CONTROL1': 813f0003 Pick an action (h for menu) : i 0-11 d Enabling AMC inputs from list : 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11 Link status : 0fff0fff Enable DAQ Link 'CONTROL1' : 813f0003 Note: This has parameters: i <ena_list> (d) (f) enable AMCs from input list. Enable (d)AQlink, (f)ake data, (t) (l) use local (T)TC signal, enable (L)ocal triggers, (r) (b) TTC(r)x, monBuf (b)ackpressure i <ena_list> (d) (f) enable AMCs from input list. Enable (d)AQlink, (f)ake data, (t) (l) use local (T)TC signal, enable (L)ocal triggers, (r) (b) TTC (r)x, monBuf (b)ackpressure I'm not sure which one to use. Enable SFP+ Ports: Pick an action (h for menu): wv 0x3 0x1fff Writing to T1: 00000003: 00001fff Pick an action (h for menu): wv 0 x3 0 x1fff Writing to T1: 00000003 : 00001 fff Change SFP+ port IP address to 192.168.51.1: Pick an action (h for menu): wv 0x1c1c 0xC0A83301 Writing to T1: 00001c1c: c0a83301 Pick an action (h for menu): wv 0x1c1c 0xC0A83301 Writing to T 1 : 00001 c 1 c : c 0 a 83301 Now cycle the 10GbE port on 'be': ifdown enp1s0f0 ifup enp1s0f0 ifdown enp1s0f0 ifup enp1s0f0 Try pinging ping 192.168.51.1 ping 192.168.51.1 Also ensure you can still ping the MCH(s): ping 192.168.1.41 ping 192.168.2.15 ping 192.168.1.41 ping 192.168.2.15 (sometimes enp1s0f1 will start stealing traffic from enp5s0. To fix this ifdown enp5s0, ifdown enp1s0f1, ifup enp5s0, ifup enp1s0f1 in that order and retry pinging).",
    "textLength": 13945
  },
  {
    "kind": "work-log",
    "title": "11_05_2025 - 17_05_2025.html",
    "fileName": "11_05_2025 - 17_05_2025.html",
    "url": "resources/work_logs/11_05_2025 - 17_05_2025.html",
    "createdDate": "2025-05-11",
    "text": "11/05/2025 - 17/05/2025 11/05/2025 - 17/05/2025 12/05/2025 17:25 Using a new algorithm for vertex creation that looks for specific vertex types and scores them, I was able to \"improve\" the results of the pattern finder. The caveat is this method is heavily biased; i.e. it only looks for vertices you tell it to look for, so it can't handle anything \"unknown\". \\boldsymbol{\\pi^+ \\rightarrow \\mu^+ + \\nu_\\mu \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 \u03bc + + \u03bd \u03bc \u2192 e + + \u03bd e \\boldsymbol{\\pi^+ \\rightarrow \\mu^+ + \\nu_\\mu \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 \u03bc + + \u03bd \u03bc \u200b \u2192 e + + \u03bd e \u200b : I've broken the plots down into \"stages\" to get a better idea of where things go wrong. It looks to me like things are going wrong at the tracklet stage, i.e. particles are missing at the tracklet stage so there's no way they can be correct by the pattern stage. I.e. the incorrect parts are not due to errors in the pattern finding. The further drive home this point, here are the results when I replace the reco file with the truth file; i.e. the tracklet reconstructions are truth now instead: The only incorrect events we see are those without a coded vertex type. I.e. here are all the vertex types the code is looking for: # vertex_types.py from algorithms.vertex.vertex_types.vertex_type import VertexType from algorithms.vertex.vertex_types.scoring.distance_scorer import DistanceScorer class PionMuonVertex(VertexType): def __init__(self): super().__init__( id=\"pi+_to_mu+\", input_particles={211}, # pi+ output_particles={-13}, # mu+ scorer=DistanceScorer() ) class PionPositronVertex(VertexType): def __init__(self): super().__init__( id=\"pi+_to_e+\", input_particles={211}, # pi+ output_particles={-11}, # e+ scorer=DistanceScorer() ) class MuonPositronVertex(VertexType): def __init__(self): super().__init__( id=\"mu+_to_e+\", input_particles={-13}, # mu+ output_particles={-11}, # e+ scorer=DistanceScorer() ) # vertex_types.py from algorithms.vertex.vertex_types.vertex_type import VertexType from algorithms.vertex.vertex_types.scoring.distance_scorer import DistanceScorer class PionMuonVertex ( VertexType ): def __init__ ( self ): super ().__init__( id = \"pi+_to_mu+\" , input_particles={ 211 }, # pi+ output_particles={- 13 }, # mu+ scorer=DistanceScorer() ) class PionPositronVertex ( VertexType ): def __init__ ( self ): super ().__init__( id = \"pi+_to_e+\" , input_particles={ 211 }, # pi+ output_particles={- 11 }, # e+ scorer=DistanceScorer() ) class MuonPositronVertex ( VertexType ): def __init__ ( self ): super ().__init__( id = \"mu+_to_e+\" , input_particles={- 13 }, # mu+ output_particles={- 11 }, # e+ scorer=DistanceScorer() ) 12/05/2025 17:32 Here are all the same plots but for \\boldsymbol{\\pi^+ \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 e + + \u03bd e \\boldsymbol{\\pi^+ \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 e + + \u03bd e \u200b : With reco tracklets: Here we have an additional problem. If we are just given an positron tracklet, then there is no vertex we defined that starts with a positron. So no pattern is created. This can be fixed by adding a vertex that starts with a positron. With truth tracklets: Again, we see we perform perfectly for vertex types we've actually programmed in. 12/05/2025 17:46 Some remaining puzzles if we choose to go this route: What additional vertex types to program in How to tune the \"scoring\" system so it outputs the correct results Event mixing has the issue where tracklets could be incorrectly attached to other tracklets. The details of this are left ot be figured out by the scoring system.",
    "textLength": 531
  },
  {
    "kind": "work-log",
    "title": "16_03_2025 - 22_03_2025.html",
    "fileName": "16_03_2025 - 22_03_2025.html",
    "url": "resources/work_logs/16_03_2025 - 22_03_2025.html",
    "createdDate": "2025-03-16",
    "text": "16/03/2025 - 22/03/2025 16/03/2025 - 22/03/2025 20/03/2025 14:30 Performance of pattern finding (reminder): Sean and I met to discuss the problems with the pattern finder. Our current idea is that there are two main failing points: Tracklets line fitting being skewed causing improper distance calculation Example: Truth: Reconstruction: Potential Solution: In general, we need a better fitter. How to go about that (and at what stage) is unclear. One option is to only do linear fits near the stop and start of tracks (preventing \"pull\" from scattering). Another option is to have a more robust fitter that considers scattering like seen above. Particles (like Bhabas) being created far from tracklet endpoints Example Truth: Reconstruction Potential Solution: First, it's unclear whether or not these electrons will be accurately resolved by the tracklet finder (or if they even need to be). Assuming these electron tracklets are accurately resolved, we instead need to project tracklet starts onto some finite space (ex. line segment). That way, the distance calculation will be based on how close the new tracklets start is to an existing tracklet as a whole , not just the endpoints of another tracklet. If this is more computationally expensive, it can be done as a \"second pass\", i.e. the original method of just comparing endpoint distances can be done first. 20/03/2025 14:41 Some discussion points for Jessie: How much info from tracklet finding (all hits vs some fit) If we have a fit, how much information are we getting from that? (maybe for Patrick) how much computatation resources can we spare? I.e. how fast does this need to be.",
    "textLength": 281
  },
  {
    "kind": "work-log",
    "title": "23_02_2025 - 01_03_2025.html",
    "fileName": "23_02_2025 - 01_03_2025.html",
    "url": "resources/work_logs/23_02_2025 - 01_03_2025.html",
    "createdDate": "2025-02-23",
    "text": "23/02/2025 - 01/03/2025 23/02/2025 - 01/03/2025 27/02/2025 00:07 Some example data rates for the collector if I turn off the \"checks\" for data integrity. This seems to be okay, the data is very consistent Rolling Average (148): +---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+ | Avg Data Rate (MB/s) | Avg Parse Time (ms) | Avg Event Time (ms) | Avg UDP Time (ms) | Avg Data Processed (KB) | Avg Total Time (ms) | +---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+ | 163.64 | 1.97 | 2.37 | 0.27 | 615.85 | 4.73 | +---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+ Rolling Average (148): +---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+ | Avg Data Rate (MB/s) | Avg Parse Time (ms) | Avg Event Time (ms) | Avg UDP Time (ms) | Avg Data Processed (KB) | Avg Total Time (ms) | +---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+ | 163.64 | 1.97 | 2.37 | 0.27 | 615.85 | 4.73 | +---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+ And here is if I have the integrity checks on. Doesn't seem to make much a difference. Rolling Average (155): +---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+ | Avg Data Rate (MB/s) | Avg Parse Time (ms) | Avg Event Time (ms) | Avg UDP Time (ms) | Avg Data Processed (KB) | Avg Total Time (ms) | +---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+ | 154.68 | 2.26 | 2.35 | 0.27 | 617.55 | 5.01 | +---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+ Rolling Average (155): +---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+ | Avg Data Rate (MB/s) | Avg Parse Time (ms) | Avg Event Time (ms) | Avg UDP Time (ms) | Avg Data Processed (KB) | Avg Total Time (ms) | +---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+ | 154.68 | 2.26 | 2.35 | 0.27 | 617.55 | 5.01 | +---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+ The difference is in the parsing stage. The UDP stage is pretty \"bad\" as it uses a lot of unessary copies. However, it wouldn't speed times up any reasonable amount to rewrite the code there. I was able to achieve a ~33% speed up in parse time (parse time 3ms --> 2ms, for this case at least). This was achieved mostly by removing a large unncessary memory copy. I was appending the leftovers from the last UDP packet to the to the whole byte stream which required copying the whole byte stream. You really only need to do this for the first nalu packet (74 bytes). 27/02/2025 03:00 I took a larger sample with 32 channels and and 4 windows. As expected performance goes up with event size (more data processed by the event builder for a similar amount of work). Rolling Average (698): +---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+ | Avg Data Rate (MB/s) | Avg Parse Time (ms) | Avg Event Time (ms) | Avg UDP Time (ms) | Avg Data Processed (KB) | Avg Total Time (ms) | +---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+ | 198.34 | 4.09 | 3.17 | 0.57 | 1309.74 | 7.91 | +---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+ Event Timings (698): +---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+ | Data Rate (MB/s) | Parse Time (ms) | Event Time (ms) | UDP Time (ms) | Data Processed (KB) | Total Time (ms) | +---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+ | 124.41 | 4.32 | 5.06 | 0.63 | 1295.00 | 10.17 | +---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+ Rolling Average (698): +---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+ | Avg Data Rate (MB/s) | Avg Parse Time (ms) | Avg Event Time (ms) | Avg UDP Time (ms) | Avg Data Processed (KB) | Avg Total Time (ms) | +---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+ | 198.34 | 4.09 | 3.17 | 0.57 | 1309.74 | 7.91 | +---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+ Event Timings (698): +---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+ | Data Rate (MB/s) | Parse Time (ms) | Event Time (ms) | UDP Time (ms) | Data Processed (KB) | Total Time (ms) | +---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+ | 124.41 | 4.32 | 5.06 | 0.63 | 1295.00 | 10.17 | +---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+ 27/02/2025 03:20 1 second wait between processing: Rolling Average (30): +---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+ | Avg Data Rate (MB/s) | Avg Parse Time (ms) | Avg Event Time (ms) | Avg UDP Time (ms) | Avg Data Processed (KB) | Avg Total Time (ms) | +---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+ | 370.16 | 16.74 | 25.47 | 6.52 | 12715.87 | 50.09 | +---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+ Event Timings (30): +---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+ | Data Rate (MB/s) | Parse Time (ms) | Event Time (ms) | UDP Time (ms) | Data Processed (KB) | Total Time (ms) | +---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+ | 366.30 | 18.28 | 8.75 | 6.17 | 12518.00 | 33.37 | +---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+ Rolling Average (30): +---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+ | Avg Data Rate (MB/s) | Avg Parse Time (ms) | Avg Event Time (ms) | Avg UDP Time (ms) | Avg Data Processed (KB) | Avg Total Time (ms) | +---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+ | 370.16 | 16.74 | 25.47 | 6.52 | 12715.87 | 50.09 | +---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+ Event Timings (30): +---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+ | Data Rate (MB/s) | Parse Time (ms) | Event Time (ms) | UDP Time (ms) | Data Processed (KB) | Total Time (ms) | +---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+ | 366.30 | 18.28 | 8.75 | 6.17 | 12518.00 | 33.37 | +---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+ no wait between processing Rolling Average (40441): +---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+ | Avg Data Rate (MB/s) | Avg Parse Time (ms) | Avg Event Time (ms) | Avg UDP Time (ms) | Avg Data Processed (KB) | Avg Total Time (ms) | +---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+ | 277.79 | 0.00 | 0.00 | 0.00 | 1.56 | 0.01 | +---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+ Event Timings (40441): +---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+ | Data Rate (MB/s) | Parse Time (ms) | Event Time (ms) | UDP Time (ms) | Data Processed (KB) | Total Time (ms) | +---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+ | 326.94 | 0.00 | 0.00 | 0.00 | 1.00 | 0.00 | +---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+ Rolling Average (40441): +---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+ | Avg Data Rate (MB/s) | Avg Parse Time (ms) | Avg Event Time (ms) | Avg UDP Time (ms) | Avg Data Processed (KB) | Avg Total Time (ms) | +---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+ | 277.79 | 0.00 | 0.00 | 0.00 | 1.56 | 0.01 | +---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+ Event Timings (40441): +---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+ | Data Rate (MB/s) | Parse Time (ms) | Event Time (ms) | UDP Time (ms) | Data Processed (KB) | Total Time (ms) | +---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+ | 326.94 | 0.00 | 0.00 | 0.00 | 1.00 | 0.00 | +---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+ It's interesting that it seems the performance seems to go down, then back up for processed chunk size.",
    "textLength": 842
  },
  {
    "kind": "work-log",
    "title": "28_12_2025 - 03_01_2026.html",
    "fileName": "28_12_2025 - 03_01_2026.html",
    "url": "resources/work_logs/28_12_2025 - 03_01_2026.html",
    "createdDate": "2025-12-28",
    "text": "28/12/2025 - 03/01/2026 28/12/2025 - 03/01/2026 03/01/2026 05:10 Stereo encoding (two-view handling) What it does Split hits by view (0 = X plane, 1 = Y plane); embed each view separately; then fuse. Pool per view \u2192 emb_view0 , emb_view1 ; if a view is missing, zero-pad that slot and add presence masks. Fused feature shape example: [emb_view0, emb_view1, mask0, mask1] ( mask0 / mask1 are 1 if that view had hits, else 0). Why it helps Keeps the two projections separate; reduces view-mixing noise. Robust when one view is absent/sparse (fixed shape with masks). Treats view id as discrete routing, not a continuous \u201cview 0.5\u201d scalar. Why it\u2019s learnable Trainable per-view hit embeddings and view embeddings. Trainable fusion MLP/head learns how much to trust each view, how to scale/shape per-view features, and how to behave when a view is weak or missing. At a glance Piece Role Learns Per-view embed Encode hits within each view Hit scales/patterns per view View embedding Small vector added per view id Bias for view X vs view Y Masks 1/0 flags for presence of each view N/A (passed through) Fusion MLP/head Combine [emb_view0, emb_view1, mask0, mask1] How to weight/use each view 03/01/2026 05:40 Pipeline chain (upstream \u2192 builder/mixer \u2192 downstream) At a glance Stage Model Input Output Learns Upstream GroupClassifier Hit graph Data(x, edge_index, edge_attr) with x=[coord,z,energy,view] , edge_attr=[dx,dz,dE,same_view] group_probs (and optional group_emb ) tensor/checkpoint Per-view hit embeds, view embeds, fusion, class head Upstream EndpointRegressor Hit graph Data(x, edge_index, edge_attr) with x=[coord,z,energy,view] , edge_attr=[dx,dz,dE,same_view] endpoint_quantiles per view (+ optional group_score / group_energy ) Per-view embeds, view embeds, fusion, quantile heads Mid (opt.) EventMixer Unmixed per-event hit graphs ( Data with upstream preds attached) Mixed per-event hit graphs ( MixedEventData , same hit schema) None (data augmentation) Mid EventBuilder Hit graphs ( Data or MixedEventData ) + upstream preds ( group_probs , endpoint_quantiles , group_energy ) + view masks Group graph GroupData (pooled per-view + masks) and affinities MLPs to pool/fuse per-view; group/global embeddings Downstream PionStopRegressor GroupData from builder with pion_stop / pred_pion_stop ; globals include per-view pools/masks pion_stop_pred tensor/checkpoint Group embeds, message passing, regression head Downstream PositronAngleModel GroupData with pion_stop / pred_pion_stop ; globals include per-view pools/masks angle_pred tensor (e.g., [sin\u03b8 cos\u03c6, sin\u03b8 sin\u03c6, cos\u03b8] ) Group embeds, message passing, regression head Data / view conventions Node features (hits): [coord, z, energy, view] ; edges: [dx, dz, dE, same_view] . View handling: split by view (0 = X, 1 = Y), embed per view, zero-pad missing view, include presence masks ( mask0 , mask1 ). Globals u : pooled per-view energy/embeddings + masks so downstream heads know view composition. Pooled = reduce a set of hit features into a fixed-size summary (e.g., mean/max over hits for a given view) so downstream layers get a consistent shape. Flow Upstream GroupClassifier runs on raw hit graphs to produce group_probs . EndpointRegressor runs on the same hits to produce per-view endpoint quantiles (and optional group score/energy). Mixer (optional) EventMixer can mix events after upstream predictions are attached (operates on unmixed events with group_probs / pred_endpoints already present) to create composite graphs. Builder EventBuilder uses upstream outputs + hits (mixed or unmixed) to build a group-level graph with globals u (per-view pooled features + masks) and affinities. Downstream PionStopRegressor consumes the built/mixed group graph (with masks/globals) to predict pion stop. PositronAngleModel consumes the same graph (expects pion_stop / pred_pion_stop ) to predict the 3-D angle vector. Definitions / notes Stereo (two-view) handling: The detector has two projections (view 0 = X plane, view 1 = Y plane). Models split hits by view, embed each view separately, pad missing views, and fuse with masks. \u201cStereo\u201d refers to handling both projections jointly but explicitly. Quantiles (endpoint regressor): Instead of a single endpoint value, the model outputs multiple quantile estimates (e.g., low/median/high) for endpoints per view, giving an uncertainty-aware range. Globals u : Graph-level feature vector that typically contains pooled per-view energies/embeddings and the presence masks. Masks ( mask0 , mask1 ): Binary flags (1/0) indicating whether view 0 or view 1 had hits; used alongside zero-padded per-view embeddings so downstream can ignore missing views. Pion stop regression: Predicting a continuous target tied to where the pion stops (position/score), optimized with regression losses (MSE/L1), not a discrete class label. Affinities: Learned edge weights on the group-level graph (nodes = groups/segments). They quantify how likely two groups belong to the same physical object or should be connected in the reconstructed event. The builder derives them from pooled per-view features and upstream outputs (group_probs, endpoints, energies).",
    "textLength": 788
  },
  {
    "kind": "work-log",
    "title": "27_04_2025 - 03_05_2025.html",
    "fileName": "27_04_2025 - 03_05_2025.html",
    "url": "resources/work_logs/27_04_2025 - 03_05_2025.html",
    "createdDate": "2025-04-27",
    "text": "27/04/2025 - 03/05/2025 27/04/2025 - 03/05/2025 30/04/2025 22:21 def _get_scalar_values(self, pause: float = 0.1): \"\"\"Reimplementation to perform some extra setup.\"\"\" rc = get_readout_controller(self.board) rc.set_readout_channels(self.channels) tc = self.board.trigger tc.tsel = { \"0_15\": True, \"16_31\": True, } tc.references = { \"0_15\": self.references, \"16_31\": self.references, } return self._get_scalar_values_vertical(pause) def _get_scalar_values ( self, pause: float = 0.1 ): \"\"\"Reimplementation to perform some extra setup.\"\"\" rc = get_readout_controller( self .board) rc.set_readout_channels( self .channels) tc = self .board.trigger tc.tsel = { \"0_15\" : True , \"16_31\" : True , } tc.references = { \"0_15\" : self .references, \"16_31\" : self .references, } return self ._get_scalar_values_vertical(pause) It appears this above function is how the threshold scan in naludaq/tools/threshold_scan/hdsoc_thresholdscan.py sets the reference values.",
    "textLength": 123
  },
  {
    "kind": "work-log",
    "title": "15_12_2024 - 21_12_2024.html",
    "fileName": "15_12_2024 - 21_12_2024.html",
    "url": "resources/work_logs/15_12_2024 - 21_12_2024.html",
    "createdDate": "2024-12-15",
    "text": "15/12/2024 - 21/12/2024 15/12/2024 - 21/12/2024 18/12/2024 20:32 I'm testing how changing the external trigger rate affects the data rate for the nalu system. I still don't know how to construct events from the UDP packets, so the true event rate is unknown with these tests. Also keep in mind I'm not bothering to adjust the fine rate tuning knob on the gate generator. Gate Generator Knob Setting (Hz) Oscilloscope Measured Rate (Hz) MIDAS Data Rate (MB/s) Screenshot Link 1 <10 0.25 Link 10 18 2.7 Link 100 191 14.1 Link 1000 1850 21 Link 10000 17855 17.6 Link 100000 172700 17.7 Link It seems the highest achievable rate is about 21 MB/s. But it is indeed responding to the external trigger in some way. 19/12/2024 01:25 I took some data using the NaluScope with varying gate generator (external trigger) rate: Gate Generator Knob Setting (Hz) Oscilloscope Measured Rate (Hz) 1 <10 10 18 100 191 1000 1850 10000 17855 100000 172700 The goal being to see how external trigger rate affects the rate of events digitized. 19/12/2024 01:33 Here is the structure of an event read in from an aquisition: {'window_labels': [[], [], [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []], 'evt_window_labels': [[], [], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []], 'data': [array([], dtype=float64), array([], dtype=float64), array([2053, 2108, 2102, 2078, 2073, 2092, 2099, 2090, 2058, 2074, 2076, 2095, 2094, 2078, 2028, 2069, 2106, 2088, 2072, 2025, 2009, 2082, 2078, 2067, 2068, 2058, 2028, 2054, 2024, 2075, 2074, 2080, 2056, 2046, 2071, 2076, 2054, 2044, 2078, 2085, 2002, 2032, 2040, 2035, 2033, 2046, 2050, 2025, 2033, 2078, 2071, 2040, 2005, 2026, 2044, 2040, 2003, 2040, 2046, 2032, 2055, 2076, 2054, 2025, 2040, 2069, 2082, 2088, 2048, 2046, 2052, 1984, 1664, 1573, 1573, 1620, 1572, 1558, 1529, 1518, 1534, 1541, 1538, 1480, 1491, 1516, 1520, 1477, 1529, 1519, 1459, 1488, 1486, 1500, 1517, 1516, 1590, 1516, 1566, 1554, 1518, 1517, 1528, 1516, 1455, 1446, 1486, 1466, 1488, 1468, 1467, 1452, 1486, 1467, 1510, 1526, 1463, 1492, 1487, 1451, 1491, 1506, 1468, 1491, 1496, 1516, 1493, 1481, 1487, 1493, 1492, 1490, 1470, 1469, 1484, 1502, 1495, 1488, 1457, 1504, 1520, 1489, 1516, 1492, 1535, 1568, 1509, 1503, 1488, 1536, 1540, 1516, 1490, 1517, 1502, 1515, 1501, 1540, 1544, 1539, 1547, 1522, 1524, 1541, 1566, 1540, 1538, 1542, 1524, 1542, 1536, 1568, 1506, 1518, 1554, 1528, 1548, 1536, 1559, 1550, 1510, 1542, 1505, 1510, 1517, 1526, 1555, 1568, 1556, 1552, 1506, 1536, 1537, 1558, 1576, 1540, 1483, 1497, 1503, 1542, 1525, 1515, 1531, 1528, 1491, 1526, 1540, 1523, 1542, 1568, 1554, 1530, 1522, 1550, 1550, 1527, 1516, 1524, 1498, 1518, 1534, 1525, 1532, 1541, 1570, 1528, 1549, 1561, 1542, 1544, 1559, 1569, 1510, 1527, 1542, 1568, 1557, 1528, 1542, 1556, 1565, 1563, 1584, 1602, 1507, 1566, 1550, 1518, 1550, 1546, 1547, 1567, 1560, 1593, 1564, 1574, 1614, 1618, 1644, 1616, 1607, 1638, 1634, 1598, 1616, 1599, 1616, 1619, 1594, 1605, 1612, 1596, 1628, 1619, 1608, 1640, 1592, 1626, 1645, 1579, 1606, 1643, 1606, 1617, 1592, 1619, 1635, 1619, 1624, 1544, 1658, 1673, 1646, 1669, 1650, 1640, 1593, 1612, 1630, 1637, 1644, 1606, 1628, 1620, 1646, 1629, 1635, 1646, 1641, 1644, 1657, 1598, 1622, 1622, 1620, 1620, 1608, 1640, 1629, 1619, 1614, 1619, 1670, 1632, 1596, 1598, 1626, 1610, 1638, 1604, 1644, 1622, 1625, 1622, 1618, 1615, 1644, 1662, 1617, 1645, 1618, 1611, 1618, 1607, 1613, 1617, 1619, 1612, 1609, 1623, 1624, 1646, 1607, 1597, 1640, 1667, 1648, 1647, 1630, 1644, 1606, 1606, 1620, 1624, 1616, 1597, 1646, 1615, 1661, 1650, 1647, 1640, 1602, 1603, 1595, 1586, 1644, 1621, 1630, 1616, 1584, 1632, 1624, 1608, 1662, 1641, 1656, 1645, 1593, 1593, 1567, 1608, 1632, 1594, 1643, 1667, 1645, 1624, 1616, 1632, 1646, 1660, 1628, 1640, 1593, 1618, 1645, 1594, 1628, 1631, 1593, 1615, 1594, 1614, 1646, 1656, 1648, 1620, 1656, 1656, 1666, 1670, 1664, 1694, 1616, 1626, 1614, 1660, 1618, 1617, 1659, 1606, 1660, 1622, 1662, 1654, 1566, 1614, 1634, 1596, 1630, 1619, 1646, 1595, 1608, 1656, 1645, 1605, 1644, 1621, 1673, 1635, 1618, 1621, 1616, 1645, 1606, 1622, 1618, 1608, 1579, 1618, 1619, 1616, 1672, 1640, 1645, 1623, 1590, 1635, 1623, 1616, 1631, 1632, 1618, 1610, 1585, 1620, 1621, 1604, 1749, 1622, 1632, 1656, 1627, 1623, 1618, 1645, 1595, 1614, 1622, 1667, 1606, 1620, 1648, 1619, 1669, 1614, 1640, 1655, 1616, 1638, 1602, 1642, 1625, 1618, 1667, 1621, 1618, 1646, 1624, 1646], dtype=uint16), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64)], 'timing': [[], [], [10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []], 'time': [array([], dtype=float64), array([], dtype=float64), array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511]), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64)], 'created_at': 0, 'pkg_num': 0, 'event_num': 0, 'name': None} {'window_labels': [[], [], [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []], 'evt_window_labels': [[], [], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []], 'data': [array([], dtype=float64), array([], dtype=float64), array([2053, 2108, 2102, 2078, 2073, 2092, 2099, 2090, 2058, 2074, 2076, 2095, 2094, 2078, 2028, 2069, 2106, 2088, 2072, 2025, 2009, 2082, 2078, 2067, 2068, 2058, 2028, 2054, 2024, 2075, 2074, 2080, 2056, 2046, 2071, 2076, 2054, 2044, 2078, 2085, 2002, 2032, 2040, 2035, 2033, 2046, 2050, 2025, 2033, 2078, 2071, 2040, 2005, 2026, 2044, 2040, 2003, 2040, 2046, 2032, 2055, 2076, 2054, 2025, 2040, 2069, 2082, 2088, 2048, 2046, 2052, 1984, 1664, 1573, 1573, 1620, 1572, 1558, 1529, 1518, 1534, 1541, 1538, 1480, 1491, 1516, 1520, 1477, 1529, 1519, 1459, 1488, 1486, 1500, 1517, 1516, 1590, 1516, 1566, 1554, 1518, 1517, 1528, 1516, 1455, 1446, 1486, 1466, 1488, 1468, 1467, 1452, 1486, 1467, 1510, 1526, 1463, 1492, 1487, 1451, 1491, 1506, 1468, 1491, 1496, 1516, 1493, 1481, 1487, 1493, 1492, 1490, 1470, 1469, 1484, 1502, 1495, 1488, 1457, 1504, 1520, 1489, 1516, 1492, 1535, 1568, 1509, 1503, 1488, 1536, 1540, 1516, 1490, 1517, 1502, 1515, 1501, 1540, 1544, 1539, 1547, 1522, 1524, 1541, 1566, 1540, 1538, 1542, 1524, 1542, 1536, 1568, 1506, 1518, 1554, 1528, 1548, 1536, 1559, 1550, 1510, 1542, 1505, 1510, 1517, 1526, 1555, 1568, 1556, 1552, 1506, 1536, 1537, 1558, 1576, 1540, 1483, 1497, 1503, 1542, 1525, 1515, 1531, 1528, 1491, 1526, 1540, 1523, 1542, 1568, 1554, 1530, 1522, 1550, 1550, 1527, 1516, 1524, 1498, 1518, 1534, 1525, 1532, 1541, 1570, 1528, 1549, 1561, 1542, 1544, 1559, 1569, 1510, 1527, 1542, 1568, 1557, 1528, 1542, 1556, 1565, 1563, 1584, 1602, 1507, 1566, 1550, 1518, 1550, 1546, 1547, 1567, 1560, 1593, 1564, 1574, 1614, 1618, 1644, 1616, 1607, 1638, 1634, 1598, 1616, 1599, 1616, 1619, 1594, 1605, 1612, 1596, 1628, 1619, 1608, 1640, 1592, 1626, 1645, 1579, 1606, 1643, 1606, 1617, 1592, 1619, 1635, 1619, 1624, 1544, 1658, 1673, 1646, 1669, 1650, 1640, 1593, 1612, 1630, 1637, 1644, 1606, 1628, 1620, 1646, 1629, 1635, 1646, 1641, 1644, 1657, 1598, 1622, 1622, 1620, 1620, 1608, 1640, 1629, 1619, 1614, 1619, 1670, 1632, 1596, 1598, 1626, 1610, 1638, 1604, 1644, 1622, 1625, 1622, 1618, 1615, 1644, 1662, 1617, 1645, 1618, 1611, 1618, 1607, 1613, 1617, 1619, 1612, 1609, 1623, 1624, 1646, 1607, 1597, 1640, 1667, 1648, 1647, 1630, 1644, 1606, 1606, 1620, 1624, 1616, 1597, 1646, 1615, 1661, 1650, 1647, 1640, 1602, 1603, 1595, 1586, 1644, 1621, 1630, 1616, 1584, 1632, 1624, 1608, 1662, 1641, 1656, 1645, 1593, 1593, 1567, 1608, 1632, 1594, 1643, 1667, 1645, 1624, 1616, 1632, 1646, 1660, 1628, 1640, 1593, 1618, 1645, 1594, 1628, 1631, 1593, 1615, 1594, 1614, 1646, 1656, 1648, 1620, 1656, 1656, 1666, 1670, 1664, 1694, 1616, 1626, 1614, 1660, 1618, 1617, 1659, 1606, 1660, 1622, 1662, 1654, 1566, 1614, 1634, 1596, 1630, 1619, 1646, 1595, 1608, 1656, 1645, 1605, 1644, 1621, 1673, 1635, 1618, 1621, 1616, 1645, 1606, 1622, 1618, 1608, 1579, 1618, 1619, 1616, 1672, 1640, 1645, 1623, 1590, 1635, 1623, 1616, 1631, 1632, 1618, 1610, 1585, 1620, 1621, 1604, 1749, 1622, 1632, 1656, 1627, 1623, 1618, 1645, 1595, 1614, 1622, 1667, 1606, 1620, 1648, 1619, 1669, 1614, 1640, 1655, 1616, 1638, 1602, 1642, 1625, 1618, 1667, 1621, 1618, 1646, 1624, 1646], dtype=uint16), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64)], 'timing': [[], [], [10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []], 'time': [array([], dtype=float64), array([], dtype=float64), array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511]), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64)], 'created_at': 0, 'pkg_num': 0, 'event_num': 0, 'name': None} It appears that the section 'timing': [[], [], [10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []] 'timing ': [[], [], [ 10488814 , 10488814 , 10488814 , 10488814 , 10488814 , 10488814 , 10488814 , 10488814 , 10488814 , 10488814 , 10488814 , 10488814 , 10488814 , 10488814 , 10488814 , 10488814 ], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []] has some of timestamps. I'm guessing they're the current clock cycle stored in some register. There's an array for each channel. I don't know why each channel has 16 copies of the timestamp; I checked that these 16 numbers are always equal to each other in any event. I modified this notebook: https://github.com/NaluScientific/naluexamples/blob/main/examples/opening_acquisitions.ipynb To have this code loop through events and create a histogram of the differences between timestamps in import matplotlib.pyplot as plt import numpy as np from naludaq.backend import DiskAcquisition # Path to the acquisition data ACQ_PATH = r\"/home/pioneer/nalu_stuff/first_project/2024-12-18 21-08-39.934460\" # Initialize a list to store timestamps for each channel channel_timestamps = [] max_timestamp_value = 16777216 # Assumed power of 2 (2^24) # DiskAcquisition is recommended to be used as a context manager for safety with DiskAcquisition(ACQ_PATH) as acq: print(\"Board model:\", acq.params[\"model\"]) print(\"Number of events:\", len(acq)) print(\"Pedestals stored:\", acq.pedestals is not None) # Loop through all events and collect the first timing entry from non-empty channels for EVENT_INDEX in range(len(acq)): EVENT = acq[EVENT_INDEX] if EVENT.get(\"data\", None) is None: print(f\"Event {EVENT_INDEX} is corrupted!\") else: # Get the timing data for the event timing = EVENT.get(\"timing\", []) # Iterate through each channel's timing data for channel_idx, channel_timing in enumerate(timing): if channel_timing: # Only consider non-empty timing data first_timestamp = channel_timing[0] # Check if all values in the timing array are the same if len(set(channel_timing)) > 1: print(f\"Warning: Channel {channel_idx} has inconsistent timing values!\") # Store the first timestamp for this channel channel_timestamps.append(first_timestamp) # Compute the differential time between successive events if len(channel_timestamps) > 1: diff_times = np.diff(channel_timestamps) # Computes the difference between successive timestamps # Filter out negative values from diff_times diff_times = diff_times[diff_times >= 0] #Printing np.set_printoptions(threshold=np.inf) print(channel_timestamps) print(diff_times) # Plotting the differential times as a histogram plt.hist(diff_times, bins=50, edgecolor='black') plt.xlabel(\"Time Difference\") plt.ylabel(\"Frequency\") plt.title(\"Time Between Events (~1 Hz external trigger)\") plt.show() else: print(\"Not enough timestamps to calculate differentials!\") import matplotlib.pyplot as plt import numpy as np from naludaq.backend import DiskAcquisition # Path to the acquisition data ACQ_PATH = r\"/home/pioneer/nalu_stuff/first_project/2024-12-18 21-08-39.934460\" # Initialize a list to store timestamps for each channel channel_timestamps = [] max_timestamp_value = 16777216 # Assumed power of 2 (2^24) # DiskAcquisition is recommended to be used as a context manager for safety with DiskAcquisition(ACQ_PATH) as acq: print(\"Board model:\", acq.params[\"model\"]) print(\"Number of events:\", len(acq)) print(\"Pedestals stored:\", acq.pedestals is not None) # Loop through all events and collect the first timing entry from non-empty channels for EVENT_INDEX in range(len(acq)): EVENT = acq[EVENT_INDEX] if EVENT.get(\"data\", None) is None: print(f\"Event {EVENT_INDEX} is corrupted!\") else: # Get the timing data for the event timing = EVENT.get(\"timing\", []) # Iterate through each channel's timing data for channel_idx, channel_timing in enumerate(timing): if channel_timing: # Only consider non-empty timing data first_timestamp = channel_timing[0] # Check if all values in the timing array are the same if len(set(channel_timing)) > 1: print(f\"Warning: Channel {channel_idx} has inconsistent timing values!\") # Store the first timestamp for this channel channel_timestamps.append(first_timestamp) # Compute the differential time between successive events if len(channel_timestamps) > 1: diff_times = np.diff(channel_timestamps) # Computes the difference between successive timestamps # Filter out negative values from diff_times diff_times = diff_times[diff_times >= 0] #Printing np.set_printoptions(threshold=np.inf) print(channel_timestamps) print(diff_times) # Plotting the differential times as a histogram plt.hist(diff_times, bins=50, edgecolor='black') plt.xlabel(\"Time Difference\") plt.ylabel(\"Frequency\") plt.title(\"Time Between Events (~1 Hz external trigger)\") plt.show() else: print(\"Not enough timestamps to calculate differentials!\") 19/12/2024 01:39 There seems to be a maximum to the timing value (I'm guessing it's 2^24 -1), after this the values seem to loop back around. Subsequently, I just ignored negative values when plotting the diff histograms below. [16543325, 16546825, 16550325, 16553825, 16557325, 16560826, 16564326, 16567826, 16571326, 16574826, 16578326, 16581826, 16585326, 16588826, 16592326, 16595827, 16599327, 16602827, 16606327, 16609827, 16613327, 16616827, 16620327, 16623827, 16627328, 16630827, 16634328, 16637828, 16641328, 16644827, 16648328, 16651828, 16655328, 16658828, 16662328, 16665828, 16669328, 16672828, 16676328, 16679828, 16683328, 16686829, 16690329, 16693829, 16697329, 16700829, 16704329, 16707829, 16711329, 16714829, 16718329, 16721830, 16725330, 16728830, 16732330, 16735830, 16739330, 16742830, 16746330, 16749830, 16753331, 16756831, 16760331, 16763831, 16767331, 16770831, 16774331, 615, 4115, [ 16543325 , 16546825 , 16550325 , 16553825 , 16557325 , 16560826 , 16564326 , 16567826 , 16571326 , 16574826 , 16578326 , 16581826 , 16585326 , 16588826 , 16592326 , 16595827 , 16599327 , 16602827 , 16606327 , 16609827 , 16613327 , 16616827 , 16620327 , 16623827 , 16627328 , 16630827 , 16634328 , 16637828 , 16641328 , 16644827 , 16648328 , 16651828 , 16655328 , 16658828 , 16662328 , 16665828 , 16669328 , 16672828 , 16676328 , 16679828 , 16683328 , 16686829 , 16690329 , 16693829 , 16697329 , 16700829 , 16704329 , 16707829 , 16711329 , 16714829 , 16718329 , 16721830 , 16725330 , 16728830 , 16732330 , 16735830 , 16739330 , 16742830 , 16746330 , 16749830 , 16753331 , 16756831 , 16760331 , 16763831 , 16767331 , 16770831 , 16774331 , 615 , 4115 , 19/12/2024 01:39 Here are the plots: I only took a few seconds of data for each rate; So each aquistion is somewhere between 3 and 10 seconds of data taking. 19/12/2024 01:45 I'm not understanding the timing differences. They do appear to get smaller the higher the rate (though the ~1 Hz to ~100 Hz region all have about the same time differences). However, they don't scale correctly. I would expect the time difference between 1850Hz and 17855Hz to scale by about a factor of 10, but it's more like a factor of 5. Furthermore the jump from 17855Hz to 172700 Hz should scale by a factor of 10, but don't. Mayb there's some maximum rate the board can handle for external trigger which is bottlenecking things at higher rates. 21/12/2024 20:52 I did some \"fine control\" on the gate generator to change the rate. I did a sort of \"binary search\" to maximize the data rate based on the trigger rate. We know the optimal event rate is around 2kHz, so my start is at about 1kHz. The way I did this way I just left a midas run going while I adjusted the trigger rate with the \"fine control\", reading the trigger rate off the oscilliscope. 21/12/2024 21:22 The \"binary search\" results confused me: Window size 62, all channels enabled: Gate Generator Knob Setting (Hz) Oscilloscope Measured Rate (Hz) MIDAS Data Rate (MB/s) Screenshot Link 1 <10 0.25 Screenshot 10 18 2.7 Screenshot 100 191 14.1 Screenshot 1000 1850 21 Screenshot 10000 17855 17.6 Screenshot 100000 172700 17.7 Screenshot 1000 1002 20.1 Screenshot 1000 2980 19.6 Screenshot 1000 2000 20.7 Screenshot 1000 1502 19.6 Screenshot 1000 1748 20.7 Screenshot 1000 1850 20.5 Screenshot 100 497 18.1 Screenshot 100 798 17.1 Screenshot So I am taking a more systematic approach next. 21/12/2024 21:52 I realized I never was really explicitly setting the channels for these tests, so I went and used the method: if self.channels: get_readout_controller(self.board).set_readout_channels(self.channels) if self . channels: get_readout_controller( self .board).set_readout_channels( self .channels) to set it and verified with: print(get_readout_controller(self.board).get_readout_channels()) print( get_readout_controller ( self .board).get_readout_channels()) If we specify no channels, the print statement prints all channels are enabled for readout (which makes sense given out data rates). I.e. all previous tests were with 32 channels, but I was already operating under that assumption. 21/12/2024 22:48 I've \"consolidated\" my data into 3 tables with corresponding plots Window size 32, all channels enabled: Gate Generator Knob Setting (Hz) Target Trigger Rate (Hz) Oscilloscope Measured Rate (Hz) MIDAS Data Rate (MB/s) Screenshot Link 1 - <10 0.25 Link 10 - 18 2.7 Link 100 100 101 14.7 Link 100 250 249 14.2 Link 100 500 497 18.1 Link 100 750 798 17.1 Link 1000 1000 1002 20.1 Link 1000 1250 1246 20.2 Link 1000 1500 1502 19.6 Link 1000 1750 1748 20.7 Link 1000 2000 2000 20.7 Link 1000 2500 2501 18.8 Link 1000 2750 2745 19.9 Link 1000 3000 2980 19.6 Link 10000 - 17855 17.6 Link 100000 - 172700 17.7 Link Window size 1, all channels enabled Gate Generator Knob Setting (Hz) Target Trigger Rate (Hz) Oscilloscope Measured Rate (Hz) MIDAS Data Rate (MB/s) Screenshot Link 1 1 1 0.24 Link 100 100 101 0.24 Link 1000 1000 973 2.29 Link 10000 10000 9416 22.1 Link 10000 20000 20375 47.9 Link 10000 22500 22390 52.7 Link 10000 23750 23770 54.2 Link 10000 25000 25024 54.7 Link 10000 30000 30337 54.7 Link 100000 100000 92289 54.7 Link Window size 1, 1 channel enabled: Gate Generator Knob Setting (Hz) Target Trigger Rate (Hz) Oscilloscope Measured Rate (Hz) MIDAS Data Rate (MB/s) Screenshot Link 100 100 108 0.01 Link 1000 1000 1041 0.07 Link 10000 10000 10077 0.74 Link 100000 100000 98657 7.26 Link 100000 200000 200000 13.1 Link 100000 500000 499530 14.8 Link 100000 625000 623000 15.2 Link 100000 700000 689000 16.8 Link 100000 750000 752600 18.1 Link 100000 875000 872400 15.9 Link 1000000 1000000 891670 16.3 Link",
    "textLength": 4363
  },
  {
    "kind": "work-log",
    "title": "04_08_2024 - 10_08_2024.html",
    "fileName": "04_08_2024 - 10_08_2024.html",
    "url": "resources/work_logs/04_08_2024 - 10_08_2024.html",
    "createdDate": "2024-08-04",
    "text": "04/08/2024 - 10/08/2024 04/08/2024 - 10/08/2024 06/08/2024 15:19 Followed these steps to mount the SSD to a XFS (high performance) file system: 1. Create Mount sudo mkfs.xfs /dev/nvme0n1 sudo mkdir /data/ssd sudo mount /dev/nvme0n1 /data/ssd sudo mkfs.xfs /dev/nvme0n1 sudo mkdir /data/ssd sudo mount /dev/nvme0n1 /data/ssd 2. Verify Mount df -h df -h **3. Update /ect/fstab for persistent mount on boot ** i) Get UUID: sudo blkid /dev/nvme0n1 sudo blkid /dev/ nvme0 n1 ii) Note output, for example: /dev/nvme0n1: UUID=\"002e991c-d707-4e80-adb3-709087f45151\" TYPE=\"xfs\" /dev/ nvme0 n1 : UUID= \"002e991c-d707-4e80-adb3-709087f45151\" TYPE= \"xfs\" iii) Add line to /ect/fstab sudo nano /etc/fstab UUID=002e991c-d707-4e80-adb3-709087f45151 /data/ssd xfs defaults 0 0 sudo nano /etc/fstab UUID = 002 e991c-d707- 4 e80-adb3- 709087 f45151 /data/ssd xfs defaults 0 0 To save and exit, Ctrl+X then Y then Enter . 07/08/2024 16:20 Notes: Every test is done with one crate enabled, logging BUF001 \"AMC13 Lagged behind?\" just means I visually percieved the event rate suffer with the logger on \"Percieved Data Rate\" is just the rate I saw updating on the midas webpage \"SSD\" just means I wrote to /data/ssd/midas_data_files where I have an SSD mounted \"HDD\" just means I wrote to /home/installation_testing/online where I have an HDD mounted (?) Indicates the value jumped around a lot ~ Indicates the data rate jumped around a bit, but this was a percieved average Waveform Length Internal Trigger Period (\u03bcs) Drive Type Perceived Data Rate (MB/s) Expected Data Rate (MB/s) AMC13 Lagged behind? 4800 110 SSD ~280(?) ~450 Yes 2400 110 SSD ~200(?) ~220 Yes 1600 110 SSD ~150 ~150 No 1600 110 HDD ~150 ~150 No 9000 500 SSD ~180 ~180 No 9000 500 HDD ~180 ~180 No 12000 500 SSD ~240 ~240 No 12000 500 HDD ~240 ~240 Yes (barely) 15000 500 SSD ~240 ~300 Yes 15000 500 HDD ~240 ~300 Yes",
    "textLength": 348
  },
  {
    "kind": "work-log",
    "title": "11_08_2024 - 17_08_2024.html",
    "fileName": "11_08_2024 - 17_08_2024.html",
    "url": "resources/work_logs/11_08_2024 - 17_08_2024.html",
    "createdDate": "2024-08-11",
    "text": "11/08/2024 - 17/08/2024 11/08/2024 - 17/08/2024 13/08/2024 23:29 Tried making a new midas install on the SSD and linking it to dependencies already on the HDD. The idea was to somehow remove any knowledge of the HDD from midas. It didn't seem to work, supporting the theory that the bottlneck lies in mlogger instead. 5kHz with waveform size 4800 5kHz with waveform size 7200: The conclusion is will still max at around 240 MB/s",
    "textLength": 85
  },
  {
    "kind": "work-log",
    "title": "07_04_2024 - 13_04_2024.html",
    "fileName": "07_04_2024 - 13_04_2024.html",
    "url": "resources/work_logs/07_04_2024 - 13_04_2024.html",
    "createdDate": "2024-04-07",
    "text": "07/04/2024 - 13/04/2024 07/04/2024 - 13/04/2024 07/04/2024 - 13/04/2024 10/04/2024 14:41 When starting the frontends, I noticed there was an ipmi communication failure for slot 1. So I disabled slot 1 in the ODB and was able to start the frontends. Then I was able to start a run for ~20 minutes: 14:38:06.738 2024/04/10 [mhttpd,INFO] Run #65 stopped 14:38:00.523 2024/04/10 [MasterGM2,INFO] End of Run: DC7 Triggers Received 101970 Count triggers 101970 14:37:48.015 2024/04/10 [MasterGM2,TALK] Alarm: CCC Run Aborted 14:36:48.445 2024/04/10 [MasterGM2,TALK] Alarm: CCC Run Aborted 14:19:18.733 2024/04/10 [mhttpd,INFO] Run #65 started 14:38:06.738 2024/04/10 [mhttpd, INFO ] Run #65 stopped 14:38:00.523 2024/04/10 [MasterGM2, INFO ] End of Run: DC7 Triggers Received 101970 Count triggers 101970 14:37:48.015 2024/04/10 [MasterGM2,TALK] Alarm: CCC Run Aborted 14:36:48.445 2024/04/10 [MasterGM2,TALK] Alarm: CCC Run Aborted 14:19:18.733 2024/04/10 [mhttpd, INFO ] Run #65 started I also noticed: tcp_client_eor(505): end-of-run TCP fill number 101970 --> entering setMasterRegister to write node CBUF.ACQUIRE ... --> entering setMasterRegister to write node CBUF.ACQUIRE ReadXBytes(919): socket file descriptor 48, request 8 bytes, read 0 bytes, tries 1000 10-04-24 14:38:04.625942 [7efec77fe700] ERROR - Timeout (1000 milliseconds) occurred for UDP receive from target with URI: ipbusudp-2.0://192.168.1.4:50001 Caught Exception setMasterRegister(799): uHAL Exception: Timeout (1000 milliseconds) occurred for UDP receive from target with URI: ipbusudp-2.0://192.168.1.4:50001 10-04-24 14:38:06.626302 [7efec77fe700] ERROR - Timeout (1000 milliseconds) occurred for UDP receive from target with URI: ipbusudp-2.0://192.168.1.4:50001 Caught Exception setMasterRegister(799): uHAL Exception: Timeout (1000 milliseconds) occurred for UDP receive from target with URI: ipbusudp-2.0://192.168.1.4:50001 <-- leaving getMasterRegister after failure ... <-- leaving getMasterRegister after success tcp_client_eor( 505 ): end - of -run TCP fill number 101970 --> entering setMasterRegister to write node CBUF.ACQUIRE ... --> entering setMasterRegister to write node CBUF.ACQUIRE ReadXBytes( 919 ): socket file descriptor 48 , request 8 bytes , read 0 bytes , tries 1000 10 -04 -24 14 : 38 : 04.625942 [ 7 efec77fe700] ERROR - Timeout ( 1000 milliseconds ) occurred for UDP receive from target with URI: ipbusudp -2.0 :// 192.168 .1 .4 : 50001 Caught Exception setMasterRegister( 799 ): uHAL Exception: Timeout ( 1000 milliseconds ) occurred for UDP receive from target with URI: ipbusudp -2.0 :// 192.168 .1 .4 : 50001 10 -04 -24 14 : 38 : 06.626302 [ 7 efec77fe700] ERROR - Timeout ( 1000 milliseconds ) occurred for UDP receive from target with URI: ipbusudp -2.0 :// 192.168 .1 .4 : 50001 Caught Exception setMasterRegister( 799 ): uHAL Exception: Timeout ( 1000 milliseconds ) occurred for UDP receive from target with URI: ipbusudp -2.0 :// 192.168 .1 .4 : 50001 < -- leaving getMasterRegister after failure ... < -- leaving getMasterRegister after success After this, I was unable to ping 192.168.1.4 or read its status with python3 read_status.py 1 4 . This indicates to me the WFD5 shut off for some reason (overheating?)",
    "textLength": 542
  },
  {
    "kind": "work-log",
    "title": "20_04_2025 - 26_04_2025.html",
    "fileName": "20_04_2025 - 26_04_2025.html",
    "url": "resources/work_logs/20_04_2025 - 26_04_2025.html",
    "createdDate": "2025-04-20",
    "text": "20/04/2025 - 26/04/2025 20/04/2025 - 26/04/2025 21/04/2025 16:45 I set the vertex finding algorithm to create vertices from the front plane information with parameters (sigma = 0.5 ,n_iters = 25) to investigate why increasing the number of iterations was causing worse performance. In short, I still don't know, but here are some plots: Basically the algorithm creates k vertices, it tests the range [1, num_endpoints] and does n_iters iterations and picks the one the one that minimizes the BIC score. I.e. it will still test every k even if the \"minimizing\" k is smaller than num_endpoints. So most the time, the algorithm converges very quickly. But for some cases the convergence does not happen quickly. It may be that there is some very high order (insiginificant adjustment) that sometimes gets made at later iterations, but it's unclear from these plots. 21/04/2025 16:50 I wanted to get a deeper view of how the fit performance affected the pattern finding. Note for all the below plots, we are just fitting the (x,z) or \"front\" plane. That may be made obvious in the second plot. We define \"failed\" fits as just ones that did not have at least 2 unique z coordiantes to fit to. Unsurprisingly, the fewer failed fits there are, the better we do. I also checked how the performance goes with number of muon hits. Also unsurprisingly, the more muon hits we see in the (x,z) plane, the better performance we have building patterns out of that (x,z) data. 21/04/2025 16:53 I wanted to try a new vertex seeding algorithm to see how it affects performance. I tried some bad ones (not shown) at first and saw a big drop in performance (~90% --> ~80% validation success rate for \\boldsymbol{\\pi^+ \\rightarrow \\mu^+ + \\nu_\\mu \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 \u03bc + + \u03bd \u03bc \u2192 e + + \u03bd e \\boldsymbol{\\pi^+ \\rightarrow \\mu^+ + \\nu_\\mu \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 \u03bc + + \u03bd \u03bc \u200b \u2192 e + + \u03bd e \u200b ). My \"new\" algorithm basically does a round of clustering at first to determine vertex guesses. It just groups endpoints by distance, ensuring that two endpoints from the same tracklet are not grouped and assigns cluster centers based on that distance. The benefit to this is no random guess is made, the DBSCAN algorithm makes no such random guess in it's clustering. Any additional vertices requested (k are requested by the constrained_k_means algorithm) are just added randomly as before. \\boldsymbol{\\pi^+ \\rightarrow \\mu^+ + \\nu_\\mu \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 \u03bc + + \u03bd \u03bc \u2192 e + + \u03bd e \\boldsymbol{\\pi^+ \\rightarrow \\mu^+ + \\nu_\\mu \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 \u03bc + + \u03bd \u03bc \u200b \u2192 e + + \u03bd e \u200b : \\boldsymbol{\\pi^+ \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 e + + \u03bd e \\boldsymbol{\\pi^+ \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 e + + \u03bd e \u200b : We see a performance increase in identifying \"expected\" events, but a drop-off for \"unexpected\" events like those with electrons. 22/04/2025 01:15 I pulled Jessie's tracklet finding algorithm and ran the simulation with this macro: # print macro commands on screen /control/verbose 0 ################################################################### # geometry must be specified before /run/initialize # /geometry/source default_lyso.gdml # Configure magnetic fields # /magfield/scalingfactor 1 # End of geometry configuration # ################################################################### ################################################################### # Configuration of the physics to be used # /Physics/SelectList QGSP_BERT_EM4 #/Physics/SelectList CEX /process/had/verbose 0 /process/em/verbose 0 # Add optical physics. #/Physics/AddOptics #/process/optical/verbose 1 #/process/optical/processActivation Cerenkov false #/process/optical/processActivation Scintillation false #/process/optical/processActivation OpAbsorption true #/process/optical/processActivation OpRayleigh true #/process/optical/processActivation OpMieHG true #/process/optical/processActivation OpBoundary true #/process/optical/processActivation OpWLS true #/process/optical/processActivation OpWLS2 true # #/process/optical/scintillation/verbose 1 #/process/optical/scintillation/setByParticleType false #/process/optical/scintillation/setTrackInfo true #/process/optical/scintillation/setFiniteRiseTime false #/process/optical/scintillation/setStackPhotons true #/process/optical/scintillation/setTrackSecondariesFirst true # Decay mode selection #/decay/all /decay/pimunu #/decay/rad_muon #/decay/pienu #/decay/pienug #/decay/rad_michel #/decay/rad_michel_rad_muon #/decay/pibeta # Cap muon/pion lifetime to enhance probability of decay in flight # /decay/mulifetimecap 50 ps # /decay/pilifetimecap 100 ps # /decay/pistartatcreation false # Increase Pion Charge Exchange Cross Section by Factor #/Physics/scalePionCEX 1 # End of physics configuration # ################################################################### ################################################################### # Configuration of the output to be written # # path to output file. \"#RUN#\" will be replaced by the run ID /output/FileName ./pimunu_run#RUN# # Switching on/off branches in the output TTree /output/SaveInit true #/output/SaveTrack true /output/SaveDecay true /output/SaveAtar true /output/SaveTracker true /output/SaveCalo true /output/SaveSipm true /output/SaveUpstream true #/output/SaveGhost true #/output/SaveGhostCalo true #/output/SaveSplitoff true # End of output configuration # ################################################################### #================================================================== # Initialise the run /run/initialize # check physics processes and particles. # Beware, output is somewhat messy in multithreaded mode #/process/list #/particle/list #/geometry/list # Configure pion beam /gen/select beam # Select beam phasespace definition # Options: pre-built, flexible /gen/beam pre-built # Beam contaminations (0 - 1.00) /gen/beam/muons 0 /gen/beam/positrons 0 # Beam parameters # General beam parameters #/gen/beam/momentum 65 MeV #/gen/beam/momsigma 1.4 MeV #/gen/beam/xmean 0 mm #/gen/beam/ymean 0 mm #/gen/beam/zpos -1000 mm # Select gaussian beam and set mode # Options are (gaus, shape) for shape #/gen/beam/shape cyl # Cylindrical beam parameters #/gen/beam/cyl/rmax 10 mm # Gaussian beam parameters #/gen/beam/gaus/rmax 25 cm #/gen/beam/gaus/mode sinit_emittance #/gen/beam/gaus/zoff 0 mm #/gen/beam/gaus/xinitsigma 91 mm #/gen/beam/gaus/yinitsigma 54 mm #/gen/beam/gaus/xemittance 0.62 mm #/gen/beam/gaus/yemittance 0.23 mm #/gen/beam/gaus/xwaistsigma 6.8 mm #/gen/beam/gaus/ywaistsigma 4.3 mm #/gen/beam/gaus/xprimesigma 0.09 #/gen/beam/gaus/yprimesigma 0.05 #/gen/select signal #/gen/signal/momentum 70 MeV #/gen/signal/momsigma 1 MeV #/gen/signal/thetaMin 60 deg #/gen/signal/thetaMax 120 deg #/gen/signal/phiMin 0 deg #/gen/signal/phiMax 360 deg #/gen/signal/sigmaX 2 mm #/gen/signal/sigmaY 2 mm #/gen/signal/sigmaZ 2 mm # configure the generic particle source #/gps/particle pi+ #/gps/energy 0.0 MeV #/gps/pos/type Volume #/gps/pos/shape Para #/gps/pos/centre 0 0 0 mm #/gps/pos/halfx 10 mm #/gps/pos/halfy 10 mm #/gps/pos/halfz 3 mm # ================================================================= # visualize geometry and events for debugging #/vis/open HepRepFile #/vis/drawVolume #/vis/scene/add/trajectories # +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ # Start the run /run/beamOn 100000 # print macro commands on screen /control/verbose 0 ################################################################### # geometry must be specified before /run/initialize # /geometry/source default_lyso.gdml # Configure magnetic fields # /magfield/scalingfactor 1 # End of geometry configuration # ################################################################### ################################################################### # Configuration of the physics to be used # /Physics/SelectList QGSP_BERT_EM4 #/Physics/SelectList CEX /process/had/verbose 0 /process/em/verbose 0 # Add optical physics. #/Physics/AddOptics #/process/optical/verbose 1 #/process/optical/processActivation Cerenkov false #/process/optical/processActivation Scintillation false #/process/optical/processActivation OpAbsorption true #/process/optical/processActivation OpRayleigh true #/process/optical/processActivation OpMieHG true #/process/optical/processActivation OpBoundary true #/process/optical/processActivation OpWLS true #/process/optical/processActivation OpWLS2 true # #/process/optical/scintillation/verbose 1 #/process/optical/scintillation/setByParticleType false #/process/optical/scintillation/setTrackInfo true #/process/optical/scintillation/setFiniteRiseTime false #/process/optical/scintillation/setStackPhotons true #/process/optical/scintillation/setTrackSecondariesFirst true # Decay mode selection #/decay/all /decay/pimunu #/decay/rad_muon #/decay/pienu #/decay/pienug #/decay/rad_michel #/decay/rad_michel_rad_muon #/decay/pibeta # Cap muon/pion lifetime to enhance probability of decay in flight # /decay/mulifetimecap 50 ps # /decay/pilifetimecap 100 ps # /decay/pistartatcreation false # Increase Pion Charge Exchange Cross Section by Factor #/Physics/scalePionCEX 1 # End of physics configuration # ################################################################### ################################################################### # Configuration of the output to be written # # path to output file. \"#RUN#\" will be replaced by the run ID /output/FileName ./pimunu_run#RUN# # Switching on/off branches in the output TTree /output/SaveInit true #/output/SaveTrack true /output/SaveDecay true /output/SaveAtar true /output/SaveTracker true /output/SaveCalo true /output/SaveSipm true /output/SaveUpstream true #/output/SaveGhost true #/output/SaveGhostCalo true #/output/SaveSplitoff true # End of output configuration # ################################################################### #================================================================== # Initialise the run /run/initialize # check physics processes and particles. # Beware, output is somewhat messy in multithreaded mode #/process/list #/particle/list #/geometry/list # Configure pion beam /gen/select beam # Select beam phasespace definition # Options: pre-built, flexible /gen/beam pre-built # Beam contaminations (0 - 1.00) /gen/beam/muons 0 /gen/beam/positrons 0 # Beam parameters # General beam parameters #/gen/beam/momentum 65 MeV #/gen/beam/momsigma 1.4 MeV #/gen/beam/xmean 0 mm #/gen/beam/ymean 0 mm #/gen/beam/zpos -1000 mm # Select gaussian beam and set mode # Options are (gaus, shape) for shape #/gen/beam/shape cyl # Cylindrical beam parameters #/gen/beam/cyl/rmax 10 mm # Gaussian beam parameters #/gen/beam/gaus/rmax 25 cm #/gen/beam/gaus/mode sinit_emittance #/gen/beam/gaus/zoff 0 mm #/gen/beam/gaus/xinitsigma 91 mm #/gen/beam/gaus/yinitsigma 54 mm #/gen/beam/gaus/xemittance 0.62 mm #/gen/beam/gaus/yemittance 0.23 mm #/gen/beam/gaus/xwaistsigma 6.8 mm #/gen/beam/gaus/ywaistsigma 4.3 mm #/gen/beam/gaus/xprimesigma 0.09 #/gen/beam/gaus/yprimesigma 0.05 #/gen/select signal #/gen/signal/momentum 70 MeV #/gen/signal/momsigma 1 MeV #/gen/signal/thetaMin 60 deg #/gen/signal/thetaMax 120 deg #/gen/signal/phiMin 0 deg #/gen/signal/phiMax 360 deg #/gen/signal/sigmaX 2 mm #/gen/signal/sigmaY 2 mm #/gen/signal/sigmaZ 2 mm # configure the generic particle source #/gps/particle pi+ #/gps/energy 0.0 MeV #/gps/pos/type Volume #/gps/pos/shape Para #/gps/pos/centre 0 0 0 mm #/gps/pos/halfx 10 mm #/gps/pos/halfy 10 mm #/gps/pos/halfz 3 mm # ================================================================= # visualize geometry and events for debugging #/vis/open HepRepFile #/vis/drawVolume #/vis/scene/add/trajectories # +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ # Start the run /run/beamOn 100000 As shown below, it appears there are fewer events with lots of \"extra\" particles. Maybe this is just chance, maybe I've somehow repressed them with these new settings. 22/04/2025 01:05 Some results using Jessie's endpoints; However, this is just using the x-z information and random tracklet seeding (also some endpoints can be NaN for \\boldsymbol{\\pi^+ \\rightarrow \\mu^+ + \\nu_\\mu \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 \u03bc + + \u03bd \u03bc \u2192 e + + \u03bd e \\boldsymbol{\\pi^+ \\rightarrow \\mu^+ + \\nu_\\mu \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 \u03bc + + \u03bd \u03bc \u200b \u2192 e + + \u03bd e \u200b decays : Instead using 3D information: (I still have the \"worst of both worlds\" theory here, where you're now twice as likely to have an endpoint have a messed up coordinate, causing issues) Now if we use front information and a non-random seeding: And 3D information with non-random seeding 22/04/2025 01:08 Here's the same plots for \\boldsymbol{\\pi^+ \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 e + + \u03bd e \\boldsymbol{\\pi^+ \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 e + + \u03bd e \u200b . Again, the first set is just (x,z) information and random tracklet seeding: If we instead use a 3D information (also some endpoints can be NaN): Now if we use 3D information a non-random seeding (remapped NaN --> (0,0,0) as well): 22/04/2025 14:45 For reference, here are the reuslts using the same dataset, but the old endpoint finding algorithm (only using front planes, \\boldsymbol{\\pi^+ \\rightarrow \\mu^+ + \\nu_\\mu \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 \u03bc + + \u03bd \u03bc \u2192 e + + \u03bd e \\boldsymbol{\\pi^+ \\rightarrow \\mu^+ + \\nu_\\mu \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 \u03bc + + \u03bd \u03bc \u200b \u2192 e + + \u03bd e \u200b So we see \\frac{98.65}{92.57} \\approx 1.07 \\implies 98.65 92.57 \u2248 1.07 \u27f9 \\frac{98.65}{92.57} \\approx 1.07 \\implies 92.57 98.65 \u200b \u2248 1.07 \u27f9 7% increase in performance. What's not shown is that these new endpoints also solve the \"missing tracklet problems\" I described earlier (you can sort of see this affect by looking that the pattern correct is now never true while validation is false). This indicates the problem was with my endpoint assigning (probably because I had to assign some endpoints to \"None\" and the vertex finder didn't like that). 23/04/2025 15:07 All of the above data was taken with respect to the truth pattern finder running on the reconstructed tracklets This makes the pattern finding performance look as if it is better than it truly is. It also makes the the reconstructed pattern particle compoisition look the same as the true particle composition, because the pattern finder only has access to the reco tracklets knowledge of particle compositon. Instead if we comapre to truth pattern finding running on truth tracklets, we get different results: \\boldsymbol{\\pi^+ \\rightarrow \\mu^+ + \\nu_\\mu \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 \u03bc + + \u03bd \u03bc \u2192 e + + \u03bd e \\boldsymbol{\\pi^+ \\rightarrow \\mu^+ + \\nu_\\mu \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 \u03bc + + \u03bd \u03bc \u200b \u2192 e + + \u03bd e \u200b (x,z) information, random seeding, Jessie's Tracklets: (x,z) information, random seeding, fitting truth Tracklets: In a way, this differentiates how the pattern finding algorithm and tracklet finding algoirthm affect performance. In any event, you still see performance gains using Jessie's Tracklet finding, which is good. 23/04/2025 15:36 Here's the same plots for \\boldsymbol{\\pi^+ \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 e + + \u03bd e \\boldsymbol{\\pi^+ \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 e + + \u03bd e \u200b . (x,z) information, random seeding, Jessie's Tracklets: (x,z) information, random seeding, fitting truth Tracklets: 23/04/2025 17:18 It seems some endpoints just don't have enough information to form at all (from inspection, I don't see cases where where have an (x,z) coordinate but not (y,z) coordiante) \u26a0\ufe0f Invalid endpoint detected: [ nan nan -inf] [array([ 4.98903478, -6.37736092, 0.24183216])] \u26a0\ufe0f Invalid endpoint at ([ nan nan -inf]) for vertex 0. \u26a0\ufe0f Non-finite values detected in the input endpoints and cluster centers: k: 1 End Points: [[ 5.02008748 -6.20570401 -0.15888712] [ 4.69999994 -6.91760125 3.42886032] [ nan nan -inf] [ 4.69999993 -6.86386318 3.41874448]] Cluster Centers: [[ 4.80669578 -6.66238948 2.22957256] [ 4.80669578 -6.66238948 2.22957256] [ 4.80669578 -6.66238948 2.22957256] [ 4.80669578 -6.66238948 2.22957256]] \u26a0\ufe0f Non-finite values detected in a vector pair! Cluster Centers: [ 4.80669578 -6.66238948 2.22957256] End Points: [ nan nan -inf] Valid mask: [False False False] Filtered vec1: [] Filtered vec2: [] \u26a0\ufe0f Invalid endpoint detected: [ nan nan -inf] [array([ 4.98903478 , - 6.37736092 , 0.24183216 ])] \u26a0\ufe0f Invalid endpoint at ([ nan nan -inf]) for vertex 0 . \u26a0\ufe0f Non-finite values detected in the input endpoints and cluster centers: k: 1 End Points: [[ 5.02008748 - 6.20570401 - 0.15888712 ] [ 4.69999994 - 6.91760125 3.42886032 ] [ nan nan -inf] [ 4.69999993 - 6.86386318 3.41874448 ]] Cluster Centers: [[ 4.80669578 - 6.66238948 2.22957256 ] [ 4.80669578 - 6.66238948 2.22957256 ] [ 4.80669578 - 6.66238948 2.22957256 ] [ 4.80669578 - 6.66238948 2.22957256 ]] \u26a0\ufe0f Non-finite values detected in a vector pair! Cluster Centers: [ 4.80669578 - 6.66238948 2.22957256 ] End Points: [ nan nan -inf] Valid mask: [False False False] Filtered vec1: [] Filtered vec2: [] I added some code to \"ignore\" these endpoints when creating clusters, but it doesn't seem to imrpove anything. I.e. the code as it was before was already ignoring these endpoints because they produced an infinite BIC. Performance for \\boldsymbol{\\pi^+ \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 e + + \u03bd e \\boldsymbol{\\pi^+ \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 e + + \u03bd e \u200b with endpoint filtering. Using Jessie's Tracklets, Both planes of information, random seeding: Performance for \\boldsymbol{\\pi^+ \\rightarrow \\mu^+ + \\nu_\\mu \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 \u03bc + + \u03bd \u03bc \u2192 e + + \u03bd e \\boldsymbol{\\pi^+ \\rightarrow \\mu^+ + \\nu_\\mu \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 \u03bc + + \u03bd \u03bc \u200b \u2192 e + + \u03bd e \u200b with endpoint filtering. Using Jessie's Tracklets, Both planes of information, random seeding: Currently erroring out because some points get deleted and then later attempted to access",
    "textLength": 2590
  },
  {
    "kind": "work-log",
    "title": "25_02_2024 - 02_03_2024.html",
    "fileName": "25_02_2024 - 02_03_2024.html",
    "url": "resources/work_logs/25_02_2024 - 02_03_2024.html",
    "createdDate": "2024-02-25",
    "text": "25/02/2024 - 02/03/2024 25/02/2024 - 02/03/2024 26/02/2024 06:51 I was able to get the readstatus.py script to \"work\": [root@dhcp-10-163-105-238 software]# python3 read_status.py 1 11 Crate 01, Slot 11 Traceback (most recent call last): File \"read_status.py\", line 55, in <module> wfd.dispatch() uhal._core.UdpTimeout: Timeout (1000 milliseconds) occurred for UDP receive from target with URI: ipbusudp-2.0://192.168.1.11:50001 [root @dhcp -10 -163 -105 -238 software]# python3 read_status.py 1 11 Crate 01 , Slot 11 Traceback (most recent call last ): File \"read_status.py\", line 55 , in < module > wfd.dispatch() uhal._core.UdpTimeout: Timeout ( 1000 milliseconds) occurred for UDP receive from target with URI: ipbusudp -2.0 : / / 192.168 .1 .11 : 50001 I also tried the \"working\" IP: [root@dhcp-10-163-105-238 software]# python3 read_status.py 1 41 Crate 01, Slot 41 Traceback (most recent call last): File \"read_status.py\", line 55, in <module> wfd.dispatch() uhal._core.UdpTimeout: Timeout (1000 milliseconds) occurred for UDP receive from target with URI: ipbusudp-2.0://192.168.1.41:50001 [root@dhcp-10-163-105-238 software]# [root@dhcp -10 -163 -105 -238 software]# python3 read_status.py 1 41 Crate 01, Slot 41 Traceback (most recent call last): File \"read_status.py\", line 55, in <module> wfd.dispatch() uhal._core.UdpTimeout: Timeout (1000 milliseconds) occurred for UDP receive from target with URI: ipbusudp -2 .0://192.168.1.41:50001 [root@dhcp -10 -163 -105 -238 software]# Unsurprisingly we have a communicatation problem right now. What I did to get the wfdConfig scripts installed: This is built upon my environment installed by my installer ( https://github.com/PIONEER-Experiment/gm2daq-installer ) cd /home/installation_testing/packages/experiment/gm2daq/environment_setup (replace with the correct path to environment_setup) ./detect_environment.sh (populations environment_variables.txt with locations of dependencies, you only need to do this once) cd ../../.. (returns to packages directory, but the software can be installed anywhere) git clone git@github.com:PIONEER-Experiment/wfdConfig.git export ADDRESS_TABLES=/home/installation_testing/packages/wfdConfig/software/address_tables/ (replace this with correct path to address_tables directory) python3 read_status.py 1 11 26/02/2024 07:14 I checked the BIOS on the 'be' computer and was unable to find any setting that corresponded to IPMI communcation. 26/02/2024 07:41 I noticed the version of our Nat-MCH is rather old from the sticker left on the back Here is a guide that is closer to the correct version (but still not the correct version!): https://www.slac.stanford.edu/grp/ssrl/spear/epics/vme/NAT_MCH-UsersManual_V122.pdf 26/02/2024 07:55 I'm able to use ipmitool to communicate with the MCH to retrieve some basic information: [root@dhcp-10-163-105-238 software]# ipmitool -H 192.168.1.41 -P \"\" fru print FRU Device Description : Builtin FRU Device (ID 0) Invalid FRU size 0 FRU Device Description : ICL-CERN FC7 (ID 13) Unsupported device FRU Device Description : VT VT095 (ID 41) Unsupported device FRU Device Description : VT VT095 (ID 40) Unsupported device FRU Device Description : CU WFD5 (ID 15) Unsupported device FRU Device Description : BU AMC13 (ID 30) Unsupported device FRU Device Description : NAT-MCH-MCMC (ID 3) Unsupported device FRU Device Description : VT UTC010 (ID 50) Unsupported device FRU Device Description : NMCH-ShM Device not present (Destination unavailable) [root@dhcp- 10 - 163 - 105 - 238 software]# ipmitool -H 192.168 . 1.41 -P \"\" fru print FRU Device Description : Builtin FRU Device (ID 0 ) Invalid FRU size 0 FRU Device Description : ICL -CERN FC7 (ID 13 ) Unsupported device FRU Device Description : VT VT095 (ID 41 ) Unsupported device FRU Device Description : VT VT095 (ID 40 ) Unsupported device FRU Device Description : CU WFD5 (ID 15 ) Unsupported device FRU Device Description : BU AMC13 (ID 30 ) Unsupported device FRU Device Description : NAT -MCH-MCMC (ID 3 ) Unsupported device FRU Device Description : VT UTC010 (ID 50 ) Unsupported device FRU Device Description : NMCH -ShM Device not present (Destination unavailable) This is nothing more than what we got from telnet , but it's proof that there is nothing \"blocking\" ipmitool from functioning. 26/02/2024 08:17 This first command: [root@dhcp-10-163-105-238 lxedaq]# ipmitool -H 192.168.1.41 -P \"\" -T 0x82 -b 1 -t 0x82 raw 0x32 0x34 1 11 0 4 Unable to send RAW command (channel=0x1 netfn=0x32 lun=0x0 cmd=0x34) [root@dhcp-10-163-105-238 lxedaq]# ipmitool -H 192.168.1.41 -P \"\" -T 0x82 -b 1 -t 0x82 raw 0x32 0x34 1 11 0 4 Unable to send RAW command ( channel =0x1 netfn =0x32 lun =0x0 cmd =0x34) reaches an error almost immediately (order of ms) This second command [root@dhcp-10-163-105-238 lxedaq]# ipmitool -H 192.168.1.41 -P \"\" -T 0x82 -b 7 -t 0x82 raw 0x32 0x34 1 11 0 4 Unable to send RAW command (channel=0x7 netfn=0x32 lun=0x0 cmd=0x34) [root@dhcp-10-163-105-238 lxedaq]# ipmitool -H 192.168.1.41 -P \"\" -T 0x82 -b 7 -t 0x82 raw 0x32 0x34 1 11 0 4 Unable to send RAW command ( channel =0x7 netfn =0x32 lun =0x0 cmd =0x34) Takes longer to reach the same errors (~1 second). This makes me think this command is reaching some sort of timeout This -b parameter is the transit channel, which I guess makes sense that we need to pick the right one. The same thing happens if you independently vary the -T parameter. I think these two parameters are specify the \"out\" route in the MCH, so when you get that correct it has some timeout while it waits for a response. The -t parameter is like the destination, while everything after raw are commands/command parameters. 26/02/2024 09:20 Copying commands from the MCH manual gives this error: [root@dhcp-10-163-105-238 amc13Config]# ipmitool \u2013H 192.168.1.41 \u2013P \"\" \u2013T 0x82 \u2013B 0 \u2013t 0xc2 \u2013b 7 hpm upgrade Could not open device at /dev/ipmi0 or /dev/ipmi/0 or /dev/ipmidev/0: No such file or directory [root @dhcp - 10 - 163 - 105 - 238 amc13Config]# ipmitool \u2013 H 192.168 . 1.41 \u2013 P \"\" \u2013 T 0x82 \u2013 B 0 \u2013t 0xc2 \u2013b 7 hpm upgrade Could not open device at /dev/ ipmi0 or /dev/ ipmi /0 or / dev /ipmidev/ 0 : No such file or directory This is a very stupid error that's hidden to the user. In short, the hyphens are different ASCII characters. ipmitool gets confused by the copy pasted version, but not the typed version. Example: [root@dhcp-10-163-105-238 amc13Config]# ipmitool \u2013H 192.168.1.41 \u2013P \"\" \u2013T 0x82 -b 7 \u2013t 0x82 hpm upgstatus Could not open device at /dev/ipmi0 or /dev/ipmi/0 or /dev/ipmidev/0: No such file or directory [root@dhcp-10-163-105-238 amc13Config]# ipmitool -H 192.168.1.41 -P \"\" -T 0x82 -b 7 -t 0x82 hpm upgstatus PICMG HPM.1 Upgrade Agent 1.0.9: ^C [root @dhcp - 10 - 163 - 105 - 238 amc13Config]# ipmitool \u2013 H 192.168 . 1.41 \u2013 P \"\" \u2013 T 0x82 - b 7 \u2013t 0x82 hpm upgstatus Could not open device at /dev/ ipmi0 or /dev/ ipmi /0 or / dev /ipmidev/ 0 : No such file or directory [root @dhcp - 10 - 163 - 105 - 238 amc13Config]# ipmitool - H 192.168 . 1.41 - P \"\" - T 0x82 - b 7 - t 0x82 hpm upgstatus PICMG HPM . 1 Upgrade Agent 1.0 . 9 : ^ C 26/02/2024 09:37 There's an example command in the manual ( https://www.slac.stanford.edu/grp/ssrl/spear/epics/vme/NAT_MCH-UsersManual_V122.pdf ) to upgrade the firmware. Interestingly, I get different errors depending on which module I try it on. First I tried the power module 1 [root@dhcp-10-163-105-238 amc13Config]# ipmitool -I lan -H 192.168.1.41 -A none -T 0x82 -B 0 -t 0xc2 -b 7 hpm upgrade f w.hpm PICMG HPM.1 Upgrade Agent 1.0.9: Error getting device ID. Verify whether the Target board is present [root@dhcp-10-163-105-238 amc13Config]# [root@dhcp -10 -163 -105 -238 amc13Config]# ipmitool -I lan -H 192.168.1.41 -A none -T 0x82 -B 0 -t 0xc2 -b 7 hpm upgrade f w.hpm PICMG HPM.1 Upgrade Agent 1.0.9: Error getting device ID. Verify whether the Target board is present [root@dhcp -10 -163 -105 -238 amc13Config]# for sanity, I tried power module 2 as well, though I can visually see our power module is plugged into the 'PM1' slot [root@dhcp-10-163-105-238 amc13Config]# ipmitool -I lan -H 192.168.1.41 -A none -T 0x82 -B 0 -t 0xc4 -b 7 hpm upgrade f w.hpm PICMG HPM.1 Upgrade Agent 1.0.9: Error getting device ID. Verify whether the Target board is present [root@dhcp -10 -163 -105 -238 amc13Config]# ipmitool -I lan -H 192.168.1.41 -A none -T 0x82 -B 0 -t 0xc4 -b 7 hpm upgrade f w.hpm PICMG HPM.1 Upgrade Agent 1.0.9: Error getting device ID. Verify whether the Target board is present I also tried these commands to see if there was any variance in error messages depending on what parameters I use: [root@dhcp-10-163-105-238 amc13Config]# ipmitool -H 192.168.1.41 -P \"\" -T 0x82 -b 7 -t 0xc2 hpm upgstatus PICMG HPM.1 Upgrade Agent 1.0.9: Error getting upgrade status. Failed to get response. [root@dhcp -10 -163 -105 -238 amc13Config]# ipmitool -H 192.168.1.41 -P \"\" -T 0x82 -b 7 -t 0xc2 hpm upgstatus PICMG HPM.1 Upgrade Agent 1.0.9: Error getting upgrade status. Failed to get response. [root@dhcp-10-163-105-238 amc13Config]# ipmitool -I lan -H 192.168.1.41 -A none -T 0x82 -b 7 -t 0xc2 hpm upgstatus PICMG HPM.1 Upgrade Agent 1.0.9: Error getting upgrade status. Failed to get response. [root@dhcp -10 -163 -105 -238 amc13Config]# ipmitool -I lan -H 192.168.1.41 -A none -T 0x82 -b 7 -t 0xc2 hpm upgstatus PICMG HPM.1 Upgrade Agent 1.0.9: Error getting upgrade status. Failed to get response. [root@dhcp-10-163-105-238 amc13Config]# ipmitool -H 192.168.1.41 -P \"\" -T 0x82 -b 7 -t 0xc2 hpm upgrade fw.hpm PICMG HPM.1 Upgrade Agent 1.0.9: Error getting device ID. Verify whether the Target board is present [root@dhcp -10 -163 -105 -238 amc13Config]# ipmitool -H 192.168.1.41 -P \"\" -T 0x82 -b 7 -t 0xc2 hpm upgrade fw.hpm PICMG HPM.1 Upgrade Agent 1.0.9: Error getting device ID. Verify whether the Target board is present This leads me to believe there is no effective difference between using the -P flag vs the -I and -A flags. 26/02/2024 09:55 With the USB to microUSB plugged into the MCH, I get this error spam [root@dhcp-10-163-105-238 amc13Config]# telnet 192.168.1.41 Trying 192.168.1.41... Connected to 192.168.1.41. Escape character is '^]'. Welcome to NAT-MCH nat> WARNING: usb: TX buffer(8) pending, dtdt=0x00088080, EPSR=0x000a0004, EPCR1=0x00880000 WARNING: usb: TX buffer(8) pending, dtdt=0x00088080, EPSR=0x000a0004, EPCR1=0x00880000 WARNING: usb: TX buffer(8) pending, dtdt=0x00088080, EPSR=0x000a0004, EPCR1=0x00880000 WARNING: usb: TX buffer(8) pending, dtdt=0x00088080, EPSR=0x000a0004, EPCR1=0x00880000 WARNING: usb: TX buffer(8) pending, dtdt=0x00088080, EPSR=0x000a0004, EPCR1=0x00880000 [root@dhcp-10-163-105-238 amc13Config]# telnet 192.168.1.41 Trying 192.168.1.41... Connected to 192.168.1.41. Escape character is '^]' . Welcome to NAT-MCH nat> WARNING: usb: TX buffer(8) pending, dtdt=0x00088080, EPSR=0x000a0004, EPCR1=0x00880000 WARNING: usb: TX buffer(8) pending, dtdt=0x00088080, EPSR=0x000a0004, EPCR1=0x00880000 WARNING: usb: TX buffer(8) pending, dtdt=0x00088080, EPSR=0x000a0004, EPCR1=0x00880000 WARNING: usb: TX buffer(8) pending, dtdt=0x00088080, EPSR=0x000a0004, EPCR1=0x00880000 WARNING: usb: TX buffer(8) pending, dtdt=0x00088080, EPSR=0x000a0004, EPCR1=0x00880000 unplugging the USB and power cycling the crate seemed to fix the issue. 26/02/2024 10:09 To view the MCH webserver on a computer with a GUI you can just ssh port forward the webpage server: ssh -L 8080:192.168.1.41:80 root@10.163.105.238 ssh -L 8080 : 192.168.1.41:80 root@ 10.163.105.238 This maps the MCH webserver to your computer's localhost:8080, so then just enter localhost:8080 into your webrowser to see the webpage. Credentials are Username: root Password: nat 26/02/2024 11:39 NatView software description link: https://nateurope.com/product/natview-mtca-management/ Free version download link (requires account): https://nateurope.com/dl.php?file=2592 I'm skeptical this will help us because the description just says \"On request NATview can scan a selectable range of IP addresses and will display those assigned to a NAT-MCH\" which to me seems functionally the same as my brute force IP checker. It would also require a computer with a GUI (it's probably possible but very nontrivial to forward the GUI output of a java application). 27/02/2024 16:16 The output in terminal and inside telnet 192.168.1.41 when trying to run the readIPs.py -s 13 script: [root@dhcp-10-163-105-238 amc13Config]# ./readIPs.py -s 13 Reading IP addresses of board in slot 13 from host 192.168.1.41 T2 IP Bytes: ipmitool -H 192.168.1.41 -U '' -P '' -T 0x82 -b 7 -t 0xa4 raw 0x32 0x34 0 11 0 4 Unable to send RAW command (channel=0x7 netfn=0x32 lun=0x0 cmd=0x34) [] [] T1 IP Bytes: ipmitool -H 192.168.1.41 -U '' -P '' -T 0x82 -b 7 -t 0xa4 raw 0x32 0x34 1 11 0 4 Unable to send RAW command (channel=0x7 netfn=0x32 lun=0x0 cmd=0x34) [] [] [root@dhcp-10-163-105-238 amc13Config]# ./readIPs.py -s 13 Reading IP addresses of board in slot 13 from host 192.168.1.41 T2 IP Bytes: ipmitool -H 192.168.1.41 -U '' -P '' -T 0x82 -b 7 -t 0xa4 raw 0x32 0x34 0 11 0 4 Unable to send RAW command ( channel =0x7 netfn =0x32 lun =0x0 cmd =0x34) [] [] T1 IP Bytes: ipmitool -H 192.168.1.41 -U '' -P '' -T 0x82 -b 7 -t 0xa4 raw 0x32 0x34 1 11 0 4 Unable to send RAW command ( channel =0x7 netfn =0x32 lun =0x0 cmd =0x34) [] [] SESSION(0): activated session 0x00000005 R(30,16,1)R(30,16,2)ipmi_SendFru(30): timeout - no response for REQ: 0x10->0xa4, Seq=9 GET_ADDRESS_INFO_REQ R(30,16,1)R(30,16,2)WARN - SMQ(0x81->0x20->0x82:0): SEND_MESSAGE_REQ - timeout remove WARN - SMQ(0x10->0x82->0xa4:1): GET_ADDRESS_INFO_REQ - timeout remove ipmi_SendFru(30): timeout - no response for REQ: 0x10->0xa4, Seq=9 GET_ADDRESS_INFO_REQ R(30,16,1)WARN - SMQ(0x10->0x82->0xa4:3): GET_ADDRESS_INFO_REQ - timeout remove R(30,16,2)ipmi_SendFru(30): timeout - no response for REQ: 0x10->0xa4, Seq=9 GET_ADDRESS_INFO_REQ WARN - SMQ(0x81->0x20->0x82:4): SEND_MESSAGE_REQ - timeout remove WARN - SMQ(0x10->0x82->0xa4:5): GET_ADDRESS_INFO_REQ - timeout remove ERR - SMQ(0x82->0x10): SEND_MESSAGE_RSP - unexpected response ERR - SEND_MSG_RSP(0x82->0x10): no outstanding message R(30,16,1)WARN - SMQ(0x10->0x82->0xa4:1): GET_ADDRESS_INFO_REQ - timeout remove ERR - SMQ(0x82->0x10): SEND_MESSAGE_RSP - unexpected response ERR - SEND_MSG_RSP(0x82->0x10): no outstanding message WARN - SMQ(0x81->0x20->0x82:2): SEND_MESSAGE_REQ - timeout remove WARN - SMQ(0x10->0x82->0xa4:6): NETFN_CONTR1_REQ - timeout remove ERR - SMQ(0x82->0x10): SEND_MESSAGE_RSP - unexpected response ERR - SEND_MSG_RSP(0x82->0x10): no outstanding message R(30,16,2)ipmi_SendFru(30): timeout - no response for REQ: 0x10->0xa4, Seq=9 GET_ADDRESS_INFO_REQ R(30,16,1)R(30,16,2)WARN - FMQ(0x20->0x82->0xa8): GET_FAN_LEVEL_REQ - timeout remove idx 0 WARN - FMQ(0x20->0x82->0xaa): GET_FAN_LEVEL_REQ - timeout remove idx 1 ipmi_SendFru(30): timeout - no response for REQ: 0x10->0xa4, Seq=10 NETFN_CONTR1_REQ ERR - FMQ(0xa8->0x82): GET_FAN_LEVEL_RSP - unexpected response ERR - FMSG_RSP(0xa8->0x82): no outstanding message ERR - FMQ(0xaa->0x82): GET_FAN_LEVEL_RSP - unexpected response ERR - FMSG_RSP(0xaa->0x82): no outstanding message WARN - SMQ(0x81->0x20->0x82:0): SEND_MESSAGE_REQ - timeout remove WARN - SMQ(0x10->0x82->0xa4:1): NETFN_CONTR1_REQ - timeout remove WARN - SESSION(0): discarded 1 pending messages SESSION(0): closing session 0x00000005 SESSION(0): activated session 0x00000005 R(30,16,1)R(30,16,2)WARN - SMQ(0x10->0x82->0xa4:3): NETFN_CONTR1_REQ - timeout remove ERR - SESSION: cannot get SEND_MESSAGE_REQ from queue ERR - RMCP: could not find nat0 session for msg ERR - CSIF: xfer failed - SHM(20)->SMS(81) IPMI msg seq 0x20 SEND_MESSAGE_RSP ERR - LSHM(0): failed - SHM(20)->SMS(81) IPMI msg seq 0x20 SEND_MESSAGE_RSP ipmi_SendFru(30): timeout - no response for REQ: 0x10->0xa4, Seq=10 NETFN_CONTR1_REQ R(30,16,1)WARN - SMQ(0x10->0x82->0xa4:5): NETFN_CONTR1_REQ - timeout remove ERR - SMQ(0x82->0x10): SEND_MESSAGE_RSP - unexpected response ERR - SEND_MSG_RSP(0x82->0x10): no outstanding message WARN - FMQ(0x20->0x82->0xa8): GET_FAN_LEVEL_REQ - timeout remove idx 2 WARN - FMQ(0x20->0x82->0xaa): GET_FAN_LEVEL_REQ - timeout remove idx 3 R(30,16,2)WARN - SMQ(0x81->0x20->0x82:0): SEND_MESSAGE_REQ - timeout remove WARN - SMQ(0x10->0x82->0xa4:1): GET_ADDRESS_INFO_REQ - timeout remove ipmi_SendFru(30): timeout - no response for REQ: 0x10->0xa4, Seq=10 NETFN_CONTR1_REQ ERR - FMQ(0xa8->0x82): GET_FAN_LEVEL_RSP - unexpected response ERR - FMSG_RSP(0xa8->0x82): no outstanding message ERR - FMQ(0xaa->0x82): GET_FAN_LEVEL_RSP - unexpected response ERR - FMSG_RSP(0xaa->0x82): no outstanding message R(30,16,1)WARN - SMQ(0x10->0x82->0xa4:3): GET_ADDRESS_INFO_REQ - timeout remove R(30,16,2)ipmi_SendFru(30): timeout - no response for REQ: 0x10->0xa4, Seq=10 NETFN_CONTR1_REQ WARN - SMQ(0x81->0x20->0x82:4): SEND_MESSAGE_REQ - timeout remove WARN - SMQ(0x10->0x82->0xa4:5): GET_ADDRESS_INFO_REQ - timeout remove ERR - SMQ(0x82->0x10): SEND_MESSAGE_RSP - unexpected response ERR - SEND_MSG_RSP(0x82->0x10): no outstanding message WARN - FMQ(0x20->0x82->0xa8): GET_FAN_LEVEL_REQ - timeout remove idx 0 WARN - FMQ(0x20->0x82->0xaa): GET_FAN_LEVEL_REQ - timeout remove idx 1 R(30,16,1)WARN - SMQ(0x10->0x82->0xa4:1): GET_ADDRESS_INFO_REQ - timeout remove ERR - SMQ(0x82->0x10): SEND_MESSAGE_RSP - unexpected response ERR - SEND_MSG_RSP(0x82->0x10): no outstanding message WARN - SMQ(0x81->0x20->0x82:2): SEND_MESSAGE_REQ - timeout remove WARN - SMQ(0x10->0x82->0xa4:6): NETFN_CONTR1_REQ - timeout remove ERR - SMQ(0x82->0x10): SEND_MESSAGE_RSP - unexpected response ERR - SEND_MSG_RSP(0x82->0x10): no outstanding message R(30,16,2)ipmi_SendFru(30): timeout - no response for REQ: 0x10->0xa4, Seq=9 GET_ADDRESS_INFO_REQ R(30,16,1)R(30,16,2)WARN - FMQ(0x20->0x82->0xa8): GET_FAN_LEVEL_REQ - timeout remove idx 2 WARN - FMQ(0x20->0x82->0xaa): GET_FAN_LEVEL_REQ - timeout remove idx 3 ipmi_SendFru(30): timeout - no response for REQ: 0x10->0xa4, Seq=9 GET_ADDRESS_INFO_REQ ERR - FMQ(0xa8->0x82): GET_FAN_LEVEL_RSP - unexpected response ERR - FMSG_RSP(0xa8->0x82): no outstanding message ERR - FMQ(0xaa->0x82): GET_FAN_LEVEL_RSP - unexpected response ERR - FMSG_RSP(0xaa->0x82): no outstanding message WARN - SMQ(0x81->0x20->0x82:0): SEND_MESSAGE_REQ - timeout remove WARN - SMQ(0x10->0x82->0xa4:1): NETFN_CONTR1_REQ - timeout remove WARN - SESSION(0): discarded 1 pending messages SESSION(0): closing session 0x00000005 R(30,16,1)R(30,16,2)WARN - SMQ(0x10->0x82->0xa4:3): NETFN_CONTR1_REQ - timeout remove ERR - SESSION: cannot get SEND_MESSAGE_REQ from queue ERR - RMCP: could not find nat0 session for msg ERR - CSIF: xfer failed - SHM(20)->SMS(81) IPMI msg seq 0x31 SEND_MESSAGE_RSP ERR - LSHM(0): failed - SHM(20)->SMS(81) IPMI msg seq 0x31 SEND_MESSAGE_RSP ipmi_SendFru(30): timeout - no response for REQ: 0x10->0xa4, Seq=9 GET_ADDRESS_INFO_REQ R(30,16,1)WARN - SMQ(0x10->0x82->0xa4:5): NETFN_CONTR1_REQ - timeout remove ERR - SMQ(0x82->0x10): SEND_MESSAGE_RSP - unexpected response ERR - SEND_MSG_RSP(0x82->0x10): no outstanding message WARN - FMQ(0x20->0x82->0xa8): GET_FAN_LEVEL_REQ - timeout remove idx 0 WARN - FMQ(0x20->0x82->0xaa): GET_FAN_LEVEL_REQ - timeout remove idx 1 R(30,16,2)ipmi_SendFru(30): timeout - no response for REQ: 0x10->0xa4, Seq=9 GET_ADDRESS_INFO_REQ R(30,16,1)R(30,16,2)ipmi_SendFru(30): timeout - no response for REQ: 0x10->0xa4, Seq=10 NETFN_CONTR1_REQ ERR - FMQ(0xa8->0x82): GET_FAN_LEVEL_RSP - unexpected response ERR - FMSG_RSP(0xa8->0x82): no outstanding message ERR - FMQ(0xaa->0x82): GET_FAN_LEVEL_RSP - unexpected response ERR - FMSG_RSP(0xaa->0x82): no outstanding message WARN - FMQ(0x20->0x82->0xa8): GET_FAN_LEVEL_REQ - timeout remove idx 2 WARN - FMQ(0x20->0x82->0xaa): GET_FAN_LEVEL_REQ - timeout remove idx 3 R(30,16,1)R(30,16,2)ipmi_SendFru(30): timeout - no response for REQ: 0x10->0xa4, Seq=10 NETFN_CONTR1_REQ R(30,16,1)R(30,16,2)WARN - FMQ(0x20->0x82->0xa8): GET_FAN_LEVEL_REQ - timeout remove idx 0 WARN - FMQ(0x20->0x82->0xaa): GET_FAN_LEVEL_REQ - timeout remove idx 1 ipmi_SendFru(30): timeout - no response for REQ: 0x10->0xa4, Seq=10 NETFN_CONTR1_REQ ERR - FMQ(0xa8->0x82): GET_FAN_LEVEL_RSP - unexpected response ERR - FMSG_RSP(0xa8->0x82): no outstanding message ERR - FMQ(0xaa->0x82): GET_FAN_LEVEL_RSP - unexpected response ERR - FMSG_RSP(0xaa->0x82): no outstanding message R(30,16,1)R(30,16,2)ipmi_SendFru(30): timeout - no response for REQ: 0x10->0xa4, Seq=10 NETFN_CONTR1_REQ ERR - FMQ(0xa8->0x82): GET_FAN_LEVEL_RSP - unexpected response ERR - FMSG_RSP(0xa8->0x82): no outstanding message ERR - FMQ(0xaa->0x82): GET_FAN_LEVEL_RSP - unexpected response ERR - FMSG_RSP(0xaa->0x82): no outstanding message ERR - FMQ(0xa8->0x82): GET_FAN_LEVEL_RSP - unexpected response ERR - FMSG_RSP(0xa8->0x82): no outstanding message ERR - FMQ(0xaa->0x82): GET_FAN_LEVEL_RSP - unexpected response ERR - FMSG_RSP(0xaa->0x82): no outstanding message SESSION(0): activated session 0x00000005 R(30,16,1)R(30,16,2)ipmi_SendFru(30): timeout - no response for REQ: 0x10->0xa4, Seq=9 GET_ADDRESS_INFO_REQ R(30,16,1)R(30,16,2)WARN - SMQ(0x81->0x20->0x82:0): SEND_MESSAGE_REQ - timeout remove WARN - SMQ(0x10->0x82->0xa4:1): GET_ADDRESS_INFO_REQ - timeout remove ipmi_SendFru(30): timeout - no response for REQ: 0x10->0xa4, Seq=9 GET_ADDRESS_INFO_REQ R(30,16,1)WARN - SMQ(0x10->0x82->0xa4:3): GET_ADDRESS_INFO_REQ - timeout remove R(30,16,2)ipmi_SendFru(30): timeout - no response for REQ: 0x10->0xa4, Seq=9 GET_ADDRESS_INFO_REQ WARN - SMQ(0x81->0x20->0x82:4): SEND_MESSAGE_REQ - timeout remove WARN - SMQ(0x10->0x82->0xa4:5): GET_ADDRESS_INFO_REQ - timeout remove ERR - SMQ(0x82->0x10): SEND_MESSAGE_RSP - unexpected response ERR - SEND_MSG_RSP(0x82->0x10): no outstanding message R(30,16,1)WARN - SMQ(0x10->0x82->0xa4:1): GET_ADDRESS_INFO_REQ - timeout remove ERR - SMQ(0x82->0x10): SEND_MESSAGE_RSP - unexpected response ERR - SEND_MSG_RSP(0x82->0x10): no outstanding message WARN - SMQ(0x81->0x20->0x82:2): SEND_MESSAGE_REQ - timeout remove WARN - SMQ(0x10->0x82->0xa4:6): NETFN_CONTR1_REQ - timeout remove ERR - SMQ(0x82->0x10): SEND_MESSAGE_RSP - unexpected response ERR - SEND_MSG_RSP(0x82->0x10): no outstanding message R(30,16,2)ipmi_SendFru(30): timeout - no response for REQ: 0x10->0xa4, Seq=9 GET_ADDRESS_INFO_REQ R(30,16,1)R(30,16,2)WARN - FMQ(0x20->0x82->0xa8): GET_FAN_LEVEL_REQ - timeout remove idx 0 WARN - FMQ(0x20->0x82->0xaa): GET_FAN_LEVEL_REQ - timeout remove idx 1 ipmi_SendFru(30): timeout - no response for REQ: 0x10->0xa4, Seq=10 NETFN_CONTR1_REQ ERR - FMQ(0xa8->0x82): GET_FAN_LEVEL_RSP - unexpected response ERR - FMSG_RSP(0xa8->0x82): no outstanding message ERR - FMQ(0xaa->0x82): GET_FAN_LEVEL_RSP - unexpected response ERR - FMSG_RSP(0xaa->0x82): no outstanding message WARN - SMQ(0x81->0x20->0x82:0): SEND_MESSAGE_REQ - timeout remove WARN - SMQ(0x10->0x82->0xa4:1): NETFN_CONTR1_REQ - timeout remove WARN - SESSION(0): discarded 1 pending messages SESSION(0): closing session 0x00000005 SESSION(0): activated session 0x00000005 R(30,16,1)R(30,16,2)WARN - SMQ(0x10->0x82->0xa4:3): NETFN_CONTR1_REQ - timeout remove ERR - SESSION: cannot get SEND_MESSAGE_REQ from queue ERR - RMCP: could not find nat0 session for msg ERR - CSIF: xfer failed - SHM(20)->SMS(81) IPMI msg seq 0x20 SEND_MESSAGE_RSP ERR - LSHM(0): failed - SHM(20)->SMS(81) IPMI msg seq 0x20 SEND_MESSAGE_RSP ipmi_SendFru(30): timeout - no response for REQ: 0x10->0xa4, Seq=10 NETFN_CONTR1_REQ R(30,16,1)WARN - SMQ(0x10->0x82->0xa4:5): NETFN_CONTR1_REQ - timeout remove ERR - SMQ(0x82->0x10): SEND_MESSAGE_RSP - unexpected response ERR - SEND_MSG_RSP(0x82->0x10): no outstanding message WARN - FMQ(0x20->0x82->0xa8): GET_FAN_LEVEL_REQ - timeout remove idx 2 WARN - FMQ(0x20->0x82->0xaa): GET_FAN_LEVEL_REQ - timeout remove idx 3 R(30,16,2)WARN - SMQ(0x81->0x20->0x82:0): SEND_MESSAGE_REQ - timeout remove WARN - SMQ(0x10->0x82->0xa4:1): GET_ADDRESS_INFO_REQ - timeout remove ipmi_SendFru(30): timeout - no response for REQ: 0x10->0xa4, Seq=10 NETFN_CONTR1_REQ ERR - FMQ(0xa8->0x82): GET_FAN_LEVEL_RSP - unexpected response ERR - FMSG_RSP(0xa8->0x82): no outstanding message ERR - FMQ(0xaa->0x82): GET_FAN_LEVEL_RSP - unexpected response ERR - FMSG_RSP(0xaa->0x82): no outstanding message R(30,16,1)WARN - SMQ(0x10->0x82->0xa4:3): GET_ADDRESS_INFO_REQ - timeout remove R(30,16,2)ipmi_SendFru(30): timeout - no response for REQ: 0x10->0xa4, Seq=10 NETFN_CONTR1_REQ WARN - SMQ(0x81->0x20->0x82:4): SEND_MESSAGE_REQ - timeout remove WARN - SMQ(0x10->0x82->0xa4:5): GET_ADDRESS_INFO_REQ - timeout remove ERR - SMQ(0x82->0x10): SEND_MESSAGE_RSP - unexpected response ERR - SEND_MSG_RSP(0x82->0x10): no outstanding message WARN - FMQ(0x20->0x82->0xa8): GET_FAN_LEVEL_REQ - timeout remove idx 0 WARN - FMQ(0x20->0x82->0xaa): GET_FAN_LEVEL_REQ - timeout remove idx 1 R(30,16,1)WARN - SMQ(0x10->0x82->0xa4:1): GET_ADDRESS_INFO_REQ - timeout remove ERR - SMQ(0x82->0x10): SEND_MESSAGE_RSP - unexpected response ERR - SEND_MSG_RSP(0x82->0x10): no outstanding message WARN - SMQ(0x81->0x20->0x82:2): SEND_MESSAGE_REQ - timeout remove WARN - SMQ(0x10->0x82->0xa4:6): NETFN_CONTR1_REQ - timeout remove ERR - SMQ(0x82->0x10): SEND_MESSAGE_RSP - unexpected response ERR - SEND_MSG_RSP(0x82->0x10): no outstanding message R(30,16,2)ipmi_SendFru(30): timeout - no response for REQ: 0x10->0xa4, Seq=9 GET_ADDRESS_INFO_REQ R(30,16,1)R(30,16,2)WARN - FMQ(0x20->0x82->0xa8): GET_FAN_LEVEL_REQ - timeout remove idx 2 WARN - FMQ(0x20->0x82->0xaa): GET_FAN_LEVEL_REQ - timeout remove idx 3 ipmi_SendFru(30): timeout - no response for REQ: 0x10->0xa4, Seq=9 GET_ADDRESS_INFO_REQ ERR - FMQ(0xa8->0x82): GET_FAN_LEVEL_RSP - unexpected response ERR - FMSG_RSP(0xa8->0x82): no outstanding message ERR - FMQ(0xaa->0x82): GET_FAN_LEVEL_RSP - unexpected response ERR - FMSG_RSP(0xaa->0x82): no outstanding message WARN - SMQ(0x81->0x20->0x82:0): SEND_MESSAGE_REQ - timeout remove WARN - SMQ(0x10->0x82->0xa4:1): NETFN_CONTR1_REQ - timeout remove WARN - SESSION(0): discarded 1 pending messages SESSION(0): closing session 0x00000005 R(30,16,1)R(30,16,2)WARN - SMQ(0x10->0x82->0xa4:3): NETFN_CONTR1_REQ - timeout remove ERR - SESSION: cannot get SEND_MESSAGE_REQ from queue ERR - RMCP: could not find nat0 session for msg ERR - CSIF: xfer failed - SHM(20)->SMS(81) IPMI msg seq 0x31 SEND_MESSAGE_RSP ERR - LSHM(0): failed - SHM(20)->SMS(81) IPMI msg seq 0x31 SEND_MESSAGE_RSP ipmi_SendFru(30): timeout - no response for REQ: 0x10->0xa4, Seq=9 GET_ADDRESS_INFO_REQ R(30,16,1)WARN - SMQ(0x10->0x82->0xa4:5): NETFN_CONTR1_REQ - timeout remove ERR - SMQ(0x82->0x10): SEND_MESSAGE_RSP - unexpected response ERR - SEND_MSG_RSP(0x82->0x10): no outstanding message WARN - FMQ(0x20->0x82->0xa8): GET_FAN_LEVEL_REQ - timeout remove idx 0 WARN - FMQ(0x20->0x82->0xaa): GET_FAN_LEVEL_REQ - timeout remove idx 1 R(30,16,2)ipmi_SendFru(30): timeout - no response for REQ: 0x10->0xa4, Seq=9 GET_ADDRESS_INFO_REQ R(30,16,1)R(30,16,2)ipmi_SendFru(30): timeout - no response for REQ: 0x10->0xa4, Seq=10 NETFN_CONTR1_REQ ERR - FMQ(0xa8->0x82): GET_FAN_LEVEL_RSP - unexpected response ERR - FMSG_RSP(0xa8->0x82): no outstanding message ERR - FMQ(0xaa->0x82): GET_FAN_LEVEL_RSP - unexpected response ERR - FMSG_RSP(0xaa->0x82): no outstanding message WARN - FMQ(0x20->0x82->0xa8): GET_FAN_LEVEL_REQ - timeout remove idx 2 WARN - FMQ(0x20->0x82->0xaa): GET_FAN_LEVEL_REQ - timeout remove idx 3 R(30,16,1)R(30,16,2)ipmi_SendFru(30): timeout - no response for REQ: 0x10->0xa4, Seq=10 NETFN_CONTR1_REQ R(30,16,1)R(30,16,2)WARN - FMQ(0x20->0x82->0xa8): GET_FAN_LEVEL_REQ - timeout remove idx 0 WARN - FMQ(0x20->0x82->0xaa): GET_FAN_LEVEL_REQ - timeout remove idx 1 ipmi_SendFru(30): timeout - no response for REQ: 0x10->0xa4, Seq=10 NETFN_CONTR1_REQ ERR - FMQ(0xa8->0x82): GET_FAN_LEVEL_RSP - unexpected response ERR - FMSG_RSP(0xa8->0x82): no outstanding message ERR - FMQ(0xaa->0x82): GET_FAN_LEVEL_RSP - unexpected response ERR - FMSG_RSP(0xaa->0x82): no outstanding message R(30,16,1)R(30,16,2)ipmi_SendFru(30): timeout - no response for REQ: 0x10->0xa4, Seq=10 NETFN_CONTR1_REQ ERR - FMQ(0xa8->0x82): GET_FAN_LEVEL_RSP - unexpected response ERR - FMSG_RSP(0xa8->0x82): no outstanding message ERR - FMQ(0xaa->0x82): GET_FAN_LEVEL_RSP - unexpected response ERR - FMSG_RSP(0xaa->0x82): no outstanding message ERR - FMQ(0xa8->0x82): GET_FAN_LEVEL_RSP - unexpected response ERR - FMSG_RSP(0xa8->0x82): no outstanding message ERR - FMQ(0xaa->0x82): GET_FAN_LEVEL_RSP - unexpected response ERR - FMSG_RSP(0xaa->0x82): no outstanding message A lot of timeouts. In contrast, this is what happens when I intentionall pick a wrong target address for the carrier: [root@dhcp-10-163-105-238 amc13Config]# ipmitool -H 192.168.1.41 -P \"\" -T 0x84 -b 7 -t 0xa4 raw 0x32 0x34 0 11 0 4 Unable to send RAW command (channel=0x7 netfn=0x32 lun=0x0 cmd=0x34) [root@dhcp-10-163-105-238 amc13Config]# ipmitool -H 192.168.1.41 -P \"\" -T 0x84 -b 7 -t 0xa4 raw 0x32 0x34 0 11 0 4 Unable to send RAW command ( channel =0x7 netfn =0x32 lun =0x0 cmd =0x34) SESSION(0): activated session 0x00000005 WARN - CMU(0): invalid i2c dst - input SHM(10)->CM(84) BRIDGED IPMI msg seq 0x09 SEND_MESSAGE_REQ WARN - CMU(0): invalid i2c dst - input SHM(10)->CM(84) BRIDGED IPMI msg seq 0x09 SEND_MESSAGE_REQ WARN - CMU(0): invalid i2c dst - input SHM(10)->CM(84) BRIDGED IPMI msg seq 0x09 SEND_MESSAGE_REQ WARN - CMU(0): invalid i2c dst - input SHM(10)->CM(84) BRIDGED IPMI msg seq 0x09 SEND_MESSAGE_REQ WARN - CMU(0): invalid i2c dst - input SHM(10)->CM(84) BRIDGED IPMI msg seq 0x0a SEND_MESSAGE_REQ WARN - CMU(0): invalid i2c dst - input SHM(10)->CM(84) BRIDGED IPMI msg seq 0x0a SEND_MESSAGE_REQ WARN - CMU(0): invalid i2c dst - input SHM(10)->CM(84) BRIDGED IPMI msg seq 0x0a SEND_MESSAGE_REQ WARN - CMU(0): invalid i2c dst - input SHM(10)->CM(84) BRIDGED IPMI msg seq 0x0a SEND_MESSAGE_REQ SESSION(0): closing session 0x00000005 SESSION( 0 ): activated session 0x00000005 WARN - CMU ( 0 ) : invalid i2c dst - input SHM ( 10 ) -> CM( 84 ) BRIDGED IPMI msg seq 0x09 SEND_MESSAGE_REQ WARN - CMU ( 0 ) : invalid i2c dst - input SHM ( 10 ) -> CM( 84 ) BRIDGED IPMI msg seq 0x09 SEND_MESSAGE_REQ WARN - CMU ( 0 ) : invalid i2c dst - input SHM ( 10 ) -> CM( 84 ) BRIDGED IPMI msg seq 0x09 SEND_MESSAGE_REQ WARN - CMU ( 0 ) : invalid i2c dst - input SHM ( 10 ) -> CM( 84 ) BRIDGED IPMI msg seq 0x09 SEND_MESSAGE_REQ WARN - CMU ( 0 ) : invalid i2c dst - input SHM ( 10 ) -> CM( 84 ) BRIDGED IPMI msg seq 0x0a SEND_MESSAGE_REQ WARN - CMU ( 0 ) : invalid i2c dst - input SHM ( 10 ) -> CM( 84 ) BRIDGED IPMI msg seq 0x0a SEND_MESSAGE_REQ WARN - CMU ( 0 ) : invalid i2c dst - input SHM ( 10 ) -> CM( 84 ) BRIDGED IPMI msg seq 0x0a SEND_MESSAGE_REQ WARN - CMU ( 0 ) : invalid i2c dst - input SHM ( 10 ) -> CM( 84 ) BRIDGED IPMI msg seq 0x0a SEND_MESSAGE_REQ SESSION( 0 ): closing session 0x00000005 If I turn on IPMI debug on, I can see the request being transferred, but nothing recieved. Command: [root@dhcp-10-163-105-238 amc13Config]# ipmitool -H 192.168.1.41 -P \"\" -T 0x82 -b 7 -t 0xa4 raw 0x32 0x34 0 11 0 4 Unable to send RAW command (channel=0x7 netfn=0x32 lun=0x0 cmd=0x34) [root@dhcp-10-163-105-238 amc13Config]# ipmitool -H 192.168.1.41 -P \"\" -T 0x82 -b 7 -t 0xa4 raw 0x32 0x34 0 11 0 4 Unable to send RAW command ( channel =0x7 netfn =0x32 lun =0x0 cmd =0x34) telnet output: TX CM->MMC: *** GET_ADDRESS_INFO_REQ *** src: rqAddr 0x10 LUN 2 dest: rsAddr 0xa4 LUN 0 rqSeq: 0x09 CRC1: 0xac (ok) CRC2: 0xc9 (ok) message data (len 1): 00 TX CM->MMC: *** GET_ADDRESS_INFO_REQ *** src : rqAddr 0 x10 LUN 2 dest: rsAddr 0 xa4 LUN 0 rqSeq: 0 x09 CRC1 : 0 xac (ok) CRC2: 0 xc9 (ok) message data (len 1 ): 00 What's curious to me is it looks like the message data is not what we're trying to send. If I reboot the module and telnet in, this are all the messages I can see as it boots up: [root@dhcp-10-163-105-238 ~]# telnet 192.168.1.41 Trying 192.168.1.41... Connected to 192.168.1.41. Escape character is '^]'. Welcome to NAT-MCH nat> .. PM(50): State change M1->M2 PM(50): State change M2->M3 PM(50): State change M3->M4 (global status 0x06 ok - Primary) PM(50): FRU active, state M4 PM(50): changed to NORMAL mode LSHM(0): CM sensor 68 LUN 0 <unknown> hotswap M1->M2 LSHM(0): FRU 50 sensor 37 LUN 0 'PM HOT SWAP' hotswap M2->M3 LSHM(0): FRU 50 sensor 37 LUN 0 'PM HOT SWAP' hotswap M3->M4 PM1(50): PM module at ic2=0xc2 chosen as the primary PM ! mcmc(3): M0->M1 mcmc(3): reading 512 bytes of fru data Base AVR version is 1.2 ...........PM1(50): determining type of Module in MCH 2 slot - AMC CU1(40): started management task for i2c=0xa8 CU1(40): State change M0->M1 CU2(41): started management task for i2c=0xaa CU2(41): State change M0->M1 . mcmc(3): M1->M2 mcmc(3): M2->M3 PM1: payload already ON for FRU 3 WARN - LSHM(0): ignore version change sensor LSHM(0): CM sensor 108 LUN 0 <unknown> hotswap M1->M2 LSHM(0): FRU 3 sensor 114 LUN 0 'HotSwap' hotswap M2->M3 CU1(40): reading 1024 bytes of fru data CU2(41): reading 1024 bytes of fru data mcmc(3): M3->M4 mcmc(3): M4 (MCH FRU active) AMC26(30): M0->M1 AMC9(13): M0->M1 AMC11(15): M0->M1 LSHM(0): FRU 3 sensor 114 LUN 0 'HotSwap' hotswap M3->M4 PM1 Event(50): new power state=0x5b for channel 1 PM1 Event(50): new power state=0x1b for channel 2 PM1 Event(50): new power state=0x1b for channel 3 PM1 Event(50): new power state=0x1b for channel 4 PM1 Event(50): new power state=0x1b for channel 13 PM1 Event(50): new power state=0x1b for channel 15 LSHM(0): FRU 50 sensor 34 LUN 0 'FET TEMP' temperature 'upper non-recoverable go high' LSHM(0): FRU 50 sensor 34 LUN 0 'FET TEMP' temperature 'upper critical go high' LSHM(0): FRU 50 sensor 34 LUN 0 'FET TEMP' temperature 'upper non-critical go high' LSHM(0): FRU 50 sensor 33 LUN 0 'BRICK 1 TEMP' temperature 'upper non-recoverable go high' LSHM(0): FRU 50 sensor 33 LUN 0 'BRICK 1 TEMP' temperature 'upper critical go high' LSHM(0): FRU 50 sensor 33 LUN 0 'BRICK 1 TEMP' temperature 'upper non-critical go high' AMC26(30): reading 152 bytes of fru data AMC11(15): reading 232 bytes of fru data AMC9(13): reading 512 bytes of fru data ..LSHM(0): FRU 50 sensor 32 LUN 0 'BRICK 2 TEMP' temperature 'upper non-recoverable go high' LSHM(0): FRU 50 sensor 32 LUN 0 'BRICK 2 TEMP' temperature 'upper critical go high' LSHM(0): FRU 50 sensor 32 LUN 0 'BRICK 2 TEMP' temperature 'upper non-critical go high' LSHM(0): FRU 50 sensor 31 LUN 0 'UTC010 tIN' temperature 'upper non-recoverable go high' LSHM(0): FRU 50 sensor 31 LUN 0 'UTC010 tIN' temperature 'upper critical go high' LSHM(0): FRU 50 sensor 31 LUN 0 'UTC010 tIN' temperature 'upper non-critical go high' LSHM(0): FRU 50 sensor 30 LUN 0 'UTC010 tOUT' temperature 'upper non-recoverable go high' LSHM(0): FRU 50 sensor 30 LUN 0 'UTC010 tOUT' temperature 'upper critical go high' LSHM(0): FRU 50 sensor 30 LUN 0 'UTC010 tOUT' temperature 'upper non-critical go high' LSHM(0): FRU 50 sensor 29 LUN 0 'UTC010 Brick T1' temperature 'upper critical go high' LSHM(0): FRU 50 sensor 29 LUN 0 'UTC010 Brick T1' temperature 'upper non-critical go high' LSHM(0): FRU 50 sensor 28 LUN 0 'UTC010 Brick T2' temperature 'upper critical go high' LSHM(0): FRU 50 sensor 28 LUN 0 'UTC010 Brick T2' temperature 'upper non-critical go high' LSHM(0): FRU 50 sensor 27 LUN 0 'UTC010 Brick T3' temperature 'upper critical go high' LSHM(0): FRU 50 sensor 27 LUN 0 'UTC010 Brick T3' temperature 'upper non-critical go high' LSHM(0): FRU 50 sensor 26 LUN 0 'UTC010 Brick T4' temperature 'upper critical go high' LSHM(0): FRU 50 sensor 26 LUN 0 'UTC010 Brick T4' temperature 'upper non-critical go high' ...R(40,13,1)...bp_getCurrent(13): no Current Descriptor found for channel ! bp_getCurrent(15): no Current Descriptor found for channel ! ......... AMC11(15): Handle=0x01 - closed AMC11(15): M1->M2 .....LSHM(0): CM sensor 118 LUN 0 <unknown> hotswap M1->M2 ............... .AMC26(30): Handle=0x01 - closed AMC26(30): M1->M2 ......LSHM(0): CM sensor 129 LUN 0 <unknown> hotswap M1->M2 ....... AMC9(13): Handle=0x01 - closed AMC9(13): M1->M2 LSHM(0): CM sensor 138 LUN 0 <unknown> hotswap M1->M2 R(41,13,1)CU1(40): Cooling Unit needs 5.0 Amps power CU2(41): Cooling Unit needs 5.0 Amps power CU1(40): Cooling unit has 20 sensors, reading ... CU2(41): Cooling unit has 17 sensors, reading ... ...................................... CU2(41): State change M1->M2 CU2(41): State change M2->M3 PM1: payload already ON for FRU 41 ... LSHM(0): CM sensor 169 LUN 0 <unknown> hotswap M1->M2 LSHM(0): FRU 41 sensor 208 LUN 0 'CU HOT SWAP' hotswap M2->M3 CU1(40): State change M1->M2 CU1(40): State change M2->M3 PM1: payload already ON for FRU 40 Activation: modules are ready Activation: all modules ready, Allowance Period (30 sec) stopped - continue with module startup ! CU2(41): State change M3->M4 CU2(41): FRU active (state M4) CU2(41) fan speed properties: minimum speed level: 0x05 maximum speed level: 0x3f normal operating level: 0x20 fan tray properties: 0x00 LSHM(0): FRU 40 sensor 189 LUN 0 'CU HOT SWAP' hotswap M1->M2 LSHM(0): CU2 FRU 41 added LSHM(0): FRU 40 sensor 189 LUN 0 'CU HOT SWAP' hotswap M2->M3 LSHM(0): FRU 41 sensor 208 LUN 0 'CU HOT SWAP' hotswap M3->M4 LSHM(0): CU2 properties min 5 max 63 norm 32 LSHM(0): CU2 now operational at level 22 (29%) AMC26(30): M2->M3 PM1: payload already ON for FRU 30 CU1(40): State change M3->M4 CU1(40): FRU active (state M4) CU1(40) fan speed properties: minimum speed level: 0x05 maximum speed level: 0x3f normal operating level: 0x20 fan tray properties: 0x00 LSHM(0): FRU 30 sensor 136 LUN 0 'Hotswap' hotswap M2->M3 LSHM(0): CU1 FRU 40 added LSHM(0): FRU 40 sensor 189 LUN 0 'CU HOT SWAP' hotswap M3->M4 LSHM(0): CU1 properties min 5 max 63 norm 32 LSHM(0): CU1 now operational at level 22 (29%) AMC26(30): M3->M4 AMC26(30): State M4 (FRU active) LSHM(0): FRU 30 sensor 136 LUN 0 'Hotswap' hotswap M3->M4 AMC9(13): M2->M3 PM1: payload already ON for FRU 13 LSHM(0): FRU 13 sensor 167 LUN 0 'FC7 HS' hotswap M2->M3 AMC11(15): M2->M3 PM1: payload already ON for FRU 15 AMC9(13): M3->M4 AMC9(13): State M4 (FRU active) LSHM(0): FRU 15 sensor 127 LUN 0 'Hotswap' hotswap M2->M3 LSHM(0): FRU 13 sensor 167 LUN 0 'FC7 HS' hotswap M3->M4 AMC11(15): M3->M4 AMC11(15): State M4 (FRU active) LSHM(0): FRU 15 sensor 127 LUN 0 'Hotswap' hotswap M3->M4 [root@dhcp-10-163-105-238 ~]# telnet 192.168.1.41 Trying 192.168.1.41... Connected to 192.168.1.41. Escape character is '^]'. Welcome to NAT-MCH nat> .. PM(50): State change M1->M2 PM(50): State change M2->M3 PM(50): State change M3->M4 (global status 0x06 ok - Primary) PM(50): FRU active, state M4 PM(50): changed to NORMAL mode LSHM(0): CM sensor 68 LUN 0 <unknown> hotswap M1->M2 LSHM(0): FRU 50 sensor 37 LUN 0 'PM HOT SWAP' hotswap M2->M3 LSHM(0): FRU 50 sensor 37 LUN 0 'PM HOT SWAP' hotswap M3->M4 PM1(50): PM module at ic2=0xc2 chosen as the primary PM ! mcmc(3): M0->M1 mcmc(3): reading 512 bytes of fru data Base AVR version is 1.2 ...........PM1(50): determining type of Module in MCH 2 slot - AMC CU1(40): started management task for i2c=0xa8 CU1(40): State change M0->M1 CU2(41): started management task for i2c=0xaa CU2(41): State change M0->M1 . mcmc(3): M1->M2 mcmc(3): M2->M3 PM1: payload already ON for FRU 3 WARN - LSHM(0): ignore version change sensor LSHM(0): CM sensor 108 LUN 0 <unknown> hotswap M1->M2 LSHM(0): FRU 3 sensor 114 LUN 0 'HotSwap' hotswap M2->M3 CU1(40): reading 1024 bytes of fru data CU2(41): reading 1024 bytes of fru data mcmc(3): M3->M4 mcmc(3): M4 (MCH FRU active) AMC26(30): M0->M1 AMC9(13): M0->M1 AMC11(15): M0->M1 LSHM(0): FRU 3 sensor 114 LUN 0 'HotSwap' hotswap M3->M4 PM1 Event(50): new power state=0x5b for channel 1 PM1 Event(50): new power state=0x1b for channel 2 PM1 Event(50): new power state=0x1b for channel 3 PM1 Event(50): new power state=0x1b for channel 4 PM1 Event(50): new power state=0x1b for channel 13 PM1 Event(50): new power state=0x1b for channel 15 LSHM(0): FRU 50 sensor 34 LUN 0 'FET TEMP' temperature 'upper non-recoverable go high' LSHM(0): FRU 50 sensor 34 LUN 0 'FET TEMP' temperature 'upper critical go high' LSHM(0): FRU 50 sensor 34 LUN 0 'FET TEMP' temperature 'upper non-critical go high' LSHM(0): FRU 50 sensor 33 LUN 0 'BRICK 1 TEMP' temperature 'upper non-recoverable go high' LSHM(0): FRU 50 sensor 33 LUN 0 'BRICK 1 TEMP' temperature 'upper critical go high' LSHM(0): FRU 50 sensor 33 LUN 0 'BRICK 1 TEMP' temperature 'upper non-critical go high' AMC26(30): reading 152 bytes of fru data AMC11(15): reading 232 bytes of fru data AMC9(13): reading 512 bytes of fru data ..LSHM(0): FRU 50 sensor 32 LUN 0 'BRICK 2 TEMP' temperature 'upper non-recoverable go high' LSHM(0): FRU 50 sensor 32 LUN 0 'BRICK 2 TEMP' temperature 'upper critical go high' LSHM(0): FRU 50 sensor 32 LUN 0 'BRICK 2 TEMP' temperature 'upper non-critical go high' LSHM(0): FRU 50 sensor 31 LUN 0 'UTC010 tIN' temperature 'upper non-recoverable go high' LSHM(0): FRU 50 sensor 31 LUN 0 'UTC010 tIN' temperature 'upper critical go high' LSHM(0): FRU 50 sensor 31 LUN 0 'UTC010 tIN' temperature 'upper non-critical go high' LSHM(0): FRU 50 sensor 30 LUN 0 'UTC010 tOUT' temperature 'upper non-recoverable go high' LSHM(0): FRU 50 sensor 30 LUN 0 'UTC010 tOUT' temperature 'upper critical go high' LSHM(0): FRU 50 sensor 30 LUN 0 'UTC010 tOUT' temperature 'upper non-critical go high' LSHM(0): FRU 50 sensor 29 LUN 0 'UTC010 Brick T1' temperature 'upper critical go high' LSHM(0): FRU 50 sensor 29 LUN 0 'UTC010 Brick T1' temperature 'upper non-critical go high' LSHM(0): FRU 50 sensor 28 LUN 0 'UTC010 Brick T2' temperature 'upper critical go high' LSHM(0): FRU 50 sensor 28 LUN 0 'UTC010 Brick T2' temperature 'upper non-critical go high' LSHM(0): FRU 50 sensor 27 LUN 0 'UTC010 Brick T3' temperature 'upper critical go high' LSHM(0): FRU 50 sensor 27 LUN 0 'UTC010 Brick T3' temperature 'upper non-critical go high' LSHM(0): FRU 50 sensor 26 LUN 0 'UTC010 Brick T4' temperature 'upper critical go high' LSHM(0): FRU 50 sensor 26 LUN 0 'UTC010 Brick T4' temperature 'upper non-critical go high' ...R(40,13,1)...bp_getCurrent(13): no Current Descriptor found for channel ! bp_getCurrent(15): no Current Descriptor found for channel ! ......... AMC11(15): Handle=0x01 - closed AMC11(15): M1->M2 .....LSHM(0): CM sensor 118 LUN 0 <unknown> hotswap M1->M2 ............... .AMC26(30): Handle=0x01 - closed AMC26(30): M1->M2 ......LSHM(0): CM sensor 129 LUN 0 <unknown> hotswap M1->M2 ....... AMC9(13): Handle=0x01 - closed AMC9(13): M1->M2 LSHM(0): CM sensor 138 LUN 0 <unknown> hotswap M1->M2 R(41,13,1)CU1(40): Cooling Unit needs 5.0 Amps power CU2(41): Cooling Unit needs 5.0 Amps power CU1(40): Cooling unit has 20 sensors, reading ... CU2(41): Cooling unit has 17 sensors, reading ... ...................................... CU2(41): State change M1->M2 CU2(41): State change M2->M3 PM1: payload already ON for FRU 41 ... LSHM(0): CM sensor 169 LUN 0 <unknown> hotswap M1->M2 LSHM(0): FRU 41 sensor 208 LUN 0 'CU HOT SWAP' hotswap M2->M3 CU1(40): State change M1->M2 CU1(40): State change M2->M3 PM1: payload already ON for FRU 40 Activation: modules are ready Activation: all modules ready, Allowance Period (30 sec) stopped - continue with module startup ! CU2(41): State change M3->M4 CU2(41): FRU active (state M4) CU2(41) fan speed properties: minimum speed level: 0x05 maximum speed level: 0x3f normal operating level: 0x20 fan tray properties: 0x00 LSHM(0): FRU 40 sensor 189 LUN 0 'CU HOT SWAP' hotswap M1->M2 LSHM(0): CU2 FRU 41 added LSHM(0): FRU 40 sensor 189 LUN 0 'CU HOT SWAP' hotswap M2->M3 LSHM(0): FRU 41 sensor 208 LUN 0 'CU HOT SWAP' hotswap M3->M4 LSHM(0): CU2 properties min 5 max 63 norm 32 LSHM(0): CU2 now operational at level 22 (29%) AMC26(30): M2->M3 PM1: payload already ON for FRU 30 CU1(40): State change M3->M4 CU1(40): FRU active (state M4) CU1(40) fan speed properties: minimum speed level: 0x05 maximum speed level: 0x3f normal operating level: 0x20 fan tray properties: 0x00 LSHM(0): FRU 30 sensor 136 LUN 0 'Hotswap' hotswap M2->M3 LSHM(0): CU1 FRU 40 added LSHM(0): FRU 40 sensor 189 LUN 0 'CU HOT SWAP' hotswap M3->M4 LSHM(0): CU1 properties min 5 max 63 norm 32 LSHM(0): CU1 now operational at level 22 (29%) AMC26(30): M3->M4 AMC26(30): State M4 (FRU active) LSHM(0): FRU 30 sensor 136 LUN 0 'Hotswap' hotswap M3->M4 AMC9(13): M2->M3 PM1: payload already ON for FRU 13 LSHM(0): FRU 13 sensor 167 LUN 0 'FC7 HS' hotswap M2->M3 AMC11(15): M2->M3 PM1: payload already ON for FRU 15 AMC9(13): M3->M4 AMC9(13): State M4 (FRU active) LSHM(0): FRU 15 sensor 127 LUN 0 'Hotswap' hotswap M2->M3 LSHM(0): FRU 13 sensor 167 LUN 0 'FC7 HS' hotswap M3->M4 AMC11(15): M3->M4 AMC11(15): State M4 (FRU active) LSHM(0): FRU 15 sensor 127 LUN 0 'Hotswap' hotswap M3->M4 29/02/2024 09:37 I just noticed that the command [root@dhcp-10-163-105-238 amc13Config]# ipmitool -H 192.168.1.41 -P \"\" -T 0x82 -b 7 -t 0xa4 raw 0x32 0x34 0 11 0 4 Unable to send RAW command (channel=0x7 netfn=0x32 lun=0x0 cmd=0x34) [root@dhcp-10-163-105-238 amc13Config]# ipmitool -H 192.168.1.41 -P \"\" -T 0x82 -b 7 -t 0xa4 raw 0x32 0x34 0 11 0 4 Unable to send RAW command ( channel =0x7 netfn =0x32 lun =0x0 cmd =0x34) telnet output: TX CM->MMC: *** GET_ADDRESS_INFO_REQ *** src: rqAddr 0x10 LUN 2 dest: rsAddr 0xa4 LUN 0 rqSeq: 0x09 CRC1: 0xac (ok) CRC2: 0xc9 (ok) message data (len 1): 00 TX CM->MMC: *** GET_ADDRESS_INFO_REQ *** src : rqAddr 0 x10 LUN 2 dest: rsAddr 0 xa4 LUN 0 rqSeq: 0 x09 CRC1 : 0 xac (ok) CRC2: 0 xc9 (ok) message data (len 1 ): 00 also has: TX CM->MMC: *** NETFN_CONTR1_REQ *** src: rqAddr 0x10 LUN 2 dest: rsAddr 0xa4 LUN 0 rqSeq: 0x0a CRC1: 0x94 (ok) CRC2: 0x83 (ok) message data (len 4): 00 0b 00 04 TX CM->MMC: *** NETFN_CONTR1_REQ *** src : rqAddr 0 x10 LUN 2 dest: rsAddr 0 xa4 LUN 0 rqSeq: 0 x0a CRC1 : 0 x94 (ok) CRC2: 0 x83 (ok) message data (len 4 ): 00 0 b 00 04 The message data here corresponds to the command parameters: 0 11 0 4 In hex I think the \"real\" error is that the amc13 is not responding: ipmi_SendFru(30): timeout - no response for REQ: 0x10->0xa4, Seq=10 NETFN_CONTR1_REQ ipmi_SendFru ( 30 ): timeout - no response for REQ: 0 x10-> 0 xa4, Seq= 10 NETFN_CONTR1_REQ 29/02/2024 12:08 From /.../wfdConfig/software/read_addresses.py I editted the script to print out the IPMI command used. IT looked liek this: [root@dhcp-10-163-105-238 software]# python3 read_addresses.py 1 1 Crate Slot S/N IP Address MAC Address ipmitool -I lan -H 192.168.1.15 -U shelf -P shelf -B 0x0 -T 0x82 -b 7 -t 0x72 raw 0x32 0x53 ipmitool -I lan -H 192.168.1.15 -U shelf -P shelf -B 0x0 -T 0x82 -b 7 -t 0x72 raw 0x32 0x52 [root@dhcp-10-163-105-238 software] # python3 read_addresses .py 1 1 Crate Slot S/N IP Address MAC Address ipmitool - I lan -H 192.168 . 1.15 -U shelf - P shelf - B 0 x0 -T 0 x82 - b 7 -t 0 x72 raw 0 x32 0 x53 ipmitool - I lan -H 192.168 . 1.15 -U shelf - P shelf - B 0 x0 -T 0 x82 - b 7 -t 0 x72 raw 0 x32 0 x52 I changed the fields for username, password, IP, and the target address -t to reflect our setup: ipmitool -I lan -H 192.168.1.41 -P \"\" -B 0x0 -T 0x82 -b 7 -t 0x86 raw 0x32 0x53 I get all the same issues as when trying to communicate with the AMC [root@dhcp-10-163-105-238 software]# ipmitool -I lan -H 192.168.1.41 -P \"\" -B 0x0 -T 0x82 -b 7 -t 0x86 raw 0x32 0x53 Unable to send RAW command (channel=0x7 netfn=0x32 lun=0x0 cmd=0x53) [root@dhcp-10-163-105-238 software]# ipmitool -I lan -H 192.168.1.41 -P \"\" -B 0x0 -T 0x82 -b 7 -t 0x86 raw 0x32 0x53 Unable to send RAW command ( channel =0x7 netfn =0x32 lun =0x0 cmd =0x53) TX CM->MMC: *** GET_ADDRESS_INFO_REQ *** src: rqAddr 0x10 LUN 2 dest: rsAddr 0x86 LUN 0 rqSeq: 0x09 CRC1: 0xca (ok) CRC2: 0xc9 (ok) message data (len 1): 00 TX CM->MMC: *** GET_ADDRESS_INFO_REQ *** src : rqAddr 0 x10 LUN 2 dest: rsAddr 0 x86 LUN 0 rqSeq: 0 x09 CRC1 : 0 xca (ok) CRC2: 0 xc9 (ok) message data (len 1 ): 00 TX CM->MMC: *** NETFN_CONTR1_REQ *** src: rqAddr 0x10 LUN 2 dest: rsAddr 0x86 LUN 0 rqSeq: 0x0a CRC1: 0xb2 (ok) CRC2: 0x73 (ok) no message data TX CM->MMC: *** NETFN_CONTR1_REQ *** src : rqAddr 0 x10 LUN 2 dest: rsAddr 0 x86 LUN 0 rqSeq: 0 x0a CRC1 : 0 xb2 (ok) CRC2: 0 x73 (ok) no message data ipmi_SendFru(15): timeout - no response for REQ: 0x10->0x86, Seq=9 GET_ADDRESS_INFO_REQ ipmi_SendFru ( 15 ): timeout - no response for REQ: 0 x10-> 0 x86, Seq= 9 GET_ADDRESS_INFO_REQ 29/02/2024 12:21 ChatGPT's explanation of all the debug information: TX CM->MMC: This indicates that the message is being transmitted from the Command Manager to the Management Controller. NETFN_CONTR1_REQ: This is the type of IPMI message being sent. It's a request related to some control function (contr1). NETFN stands for Network Function, which specifies the type of operation being requested. src: This section provides information about the source of the message. rqAddr 0x10: This is the request address, indicating the source address of the message. In this case, it's 0x10. LUN 2: This indicates the Logical Unit Number associated with the source of the message. LUN values specify the logical unit within a device that the message is intended for. dest: This section provides information about the destination of the message. rsAddr 0x86: This is the response address, indicating the destination address of the message. In this case, it's 0x86. LUN 0: This indicates the Logical Unit Number associated with the destination of the message. rqSeq: This is the request sequence number, indicating the sequence number associated with the request. In this case, it's 0x0a. CRC1 and CRC2: These are cyclic redundancy check values used to ensure the integrity of the message data during transmission. CRC1 and CRC2 are computed checksums that are compared against expected values to verify that the message hasn't been corrupted. no message data: This indicates that there is no message data included with this particular message. It's just a control request without additional payload data.",
    "textLength": 8664
  },
  {
    "kind": "work-log",
    "title": "02_02_2025 - 08_02_2025.html",
    "fileName": "02_02_2025 - 08_02_2025.html",
    "url": "resources/work_logs/02_02_2025 - 08_02_2025.html",
    "createdDate": "2025-02-02",
    "text": "02/02/2025 - 08/02/2025 02/02/2025 - 08/02/2025 03/02/2025 15:33 Meeting with Marcus 01/31/2025 UDP Packet format: Each channel sends it's own \"event fragment\" with it's own timestamp Need to listen for event fragments with some collector logic before parsing into a full event Supposedly once an event is \"collected,\" the parser in the naludaq package should work (though Marcus mentioned it will be slow) Rate Limitations: The board has a parallel bus limited to 31.5MHz, samples are 12 bits long so the amount of real data we can get out is ~50MB/s (maybe header/trailer caused a bump so we could see 55MB/s) There is some firmware issue for event creation at higher rates that causes a performance drop when the system is overwhelmed (~20kHz or 100000 packages(?)) Sampling rate: To move from 1Gsps to ~1.6Gsps is \"tricky\" according to marcus, but can be done on the HDSoCv1. He made it sound like it will be less of an issue on newer versions Using the Threshold Scanner: The threshold scanner \"tool\" in the naludaq package should just \"work\" Marcus mentioned the trigger values are very stable But we will need to compute them anytime we adjust the internal trigger in any way at the very least. Documentation: Marcus mentioned he'd send an updated naludaq documentation, ~ v0.30 03/02/2025 15:34 Here is the table image transcribed 12-bit data format, RAW readout from ASIC 2nd 1 Byte1 [15..8] 1st 1 Byte1 [7..0] 0xE0 channel number [7..0] 0xE[15..12] & trigger arrival time 1 [11..8] trigger arrival time 1 [7..0] 0xE[15..12] & trigger arrival time 2 [11..8] trigger arrival time 2 [7..0] 0xE[15..12] & logical position [11..8] logical position [7..6] & physical position [5..0] sample 1 data [15..8] sample 1 data [7..4] & sample 2 data [3..0] sample 2 data [15..8] sample 3 data [7..0] sample 3 data [15..12] & sample 4 data [11..8] sample 4 data [7..0] ... ... sample 31 data [15..12] & sample 32 data [11..8] sample 32 data [7..0] 0x0A 0x5A CRC packet footer ... ... 0xE0 channel number [7..0] 0xE[15..12] & trigger arrival time 1 [11..8] trigger arrival time 1 [7..0] 0xE[15..12] & trigger arrival time 2 [11..8] trigger arrival time 2 [7..0] 0xE[15..12] & logical position [11..8] logical position [7..6] & physical position [5..0] sample 1 data [15..8] sample 1 data [7..4] & sample 2 data [3..0] sample 2 data [15..8] sample 3 data [7..0] sample 3 data [15..12] & sample 4 data [11..8] sample 4 data [7..0] ... ... sample 31 data [15..12] & sample 32 data [11..8] sample 32 data [7..0] 0x0A 0x5A CRC packet footer 16-bit \"expanded\" data, used in NaluDAQ 2nd 1 Byte1 [15..8] 1st 1 Byte1 [7..0] 0xE0 channel number [7..0] 0x0[15..12] & trigger arrival time 1 [11..8] trigger arrival time 1 [7..0] 0x0[15..12] & trigger arrival time 2 [11..8] trigger arrival time 2 [7..0] 0x0[15..12] & logical position [11..8] logical position [7..6] & physical position [5..0] sample 1 data [11..8] sample1 data [7..0] sample 2 data [11..8] sample2 data [7..0] ... ... sample 32 data [11..8] sample 32 data [7..0] 0x0A 0x5A 0xFE 0xCA ... ... 0xE0 channel number [7..0] 0x0[15..12] & trigger arrival time 1 [11..8] trigger arrival time 1 [7..0] 0x0[15..12] & trigger arrival time 2 [11..8] trigger arrival time 2 [7..0] 0x0[15..12] & logical position [11..8] logical position [7..6] & physical position [5..0] sample 1 data [11..8] sample1 data [7..0] sample 2 data [11..8] sample2 data [7..0] ... ... sample 32 data [11..8] sample 32 data [7..0] 0x0A 0x5A 0xFE 0xCA 03/02/2025 15:47 I was able to get a conda environment to have root and some machine learning libraries at the same time. It took a few attempts because there's some nuance. First off, the ML libraries are a few versions of python behind, so I had to use python 3.10 (as oppose to 3.12). Second, I had to use the correct keywords when building the environment: conda create --name root_env -c conda-forge -c root python=3.10 cudatoolkit=11.8 numpy matplotlib scikit-learn pytorch=2.1 torchvision tensorflow jupyter conda create --name root_env -c conda-forge -c root python= 3 . 10 cudatoolkit= 11 . 8 numpy matplotlib scikit-learn pytorch= 2 . 1 torchvision tensorflow jupyter ROOT seemed to not want to install, so I tried it again conda install -c conda-forge root conda install -c conda-forge root and it seemed to install on the second pass. This notably doesn't include torch audio, if that's needed. Afterwards you can test some of the installations: python -c \"import torch; print(torch.cuda.is_available())\" python -c \"import tensorflow as tf; print(tf.__version__)\" python -c \"import sklearn; print(sklearn.__version__)\" python -c \"import ROOT; print(ROOT.__version__) python -c \"import torch; print (torch.cuda.is_available())\" python -c \"import tensorflow as tf; print (tf.__version__)\" python -c \"import sklearn; print (sklearn.__version__)\" python -c \"import ROOT; print (ROOT.__version__) 03/02/2025 16:52 Judging by this plot, I'm pretty sure we're in the 16-bit \"expanded\" data because I see 8 bytes, then data, then a footer byte (0xFA5A). This footer byte does not match the image Marcus sent us but does match the input parameters to the HDSoC class: class HDSoCParser(Parser): def __init__(self, params): super().__init__(params) self._stop_word = params.get(\"stop_word\", b\"\\xfa\\x5a\") if isinstance(self._stop_word, str): self._stop_word = bytes.fromhex(self._stop_word) self._chan_mask = params.get(\"chanmask\", 0x3F) self._chan_shift = params.get(\"chanshift\", 0) self._abs_wind_mask = params.get(\"abs_wind_mask\", 0x3F) self._evt_wind_mask = params.get(\"evt_wind_mask\", 0x3F) self._evt_wind_shift = params.get(\"evt_wind_shift\", 6) self._headers = params.get(\"headers\", 4) self._timing_mask = params.get(\"timing_mask\", 0xFFF) self._timing_shift = params.get(\"timing_mask\", 12) self._packet_size = 72 class HDSoCParser ( Parser ): def __init__ ( self, params ): super ().__init__(params) self ._stop_word = params.get( \"stop_word\" , b\"\\xfa\\x5a\" ) if isinstance ( self ._stop_word, str ): self ._stop_word = bytes .fromhex( self ._stop_word) self ._chan_mask = params.get( \"chanmask\" , 0x3F ) self ._chan_shift = params.get( \"chanshift\" , 0 ) self ._abs_wind_mask = params.get( \"abs_wind_mask\" , 0x3F ) self ._evt_wind_mask = params.get( \"evt_wind_mask\" , 0x3F ) self ._evt_wind_shift = params.get( \"evt_wind_shift\" , 6 ) self ._headers = params.get( \"headers\" , 4 ) self ._timing_mask = params.get( \"timing_mask\" , 0xFFF ) self ._timing_shift = params.get( \"timing_mask\" , 12 ) self ._packet_size = 72 03/02/2025 18:40 I had to fill in some blanks, but I think I was able to correctly reconstruct the channel, time, and samples of a 1040 byte UDP package (not really sure what logical and physical position are): {'Channel': 0, 'Trigger Time': 16031077, 'Logical Position': 0, 'Physical Position': 29, 'Samples': [1496, 1511, 1503, 1515, 1474, 1489, 1492, 1470, 1488, 1490, 1486, 1467, 1464, 1466, 1480, 1494, 1464, 1506, 1497, 1485, 1489, 1489, 1496, 1516, 1508, 1444, 1482, 1464, 1494, 1486, 1489, 1559], 'Footer': (250, 90)} {'Channel': 0, 'Trigger Time': 16032109, 'Logical Position': 0, 'Physical Position': 7, 'Samples': [1489, 1498, 1504, 1514, 1488, 1497, 1490, 1488, 1492, 1508, 1468, 1490, 1491, 1471, 1480, 1461, 1467, 1496, 1512, 1498, 1468, 1461, 1505, 1500, 1492, 1487, 1520, 1494, 1504, 1495, 1494, 1518], 'Footer': (250, 90)} {'Channel': 0, 'Trigger Time': 16033142, 'Logical Position': 0, 'Physical Position': 48, 'Samples': [1509, 1455, 1442, 1519, 1528, 1481, 1515, 1494, 1506, 1497, 1480, 1494, 1464, 1477, 1489, 1483, 1509, 1511, 1491, 1484, 1494, 1488, 1441, 1468, 1472, 1494, 1474, 1466, 1467, 1486, 1527, 1493], 'Footer': (250, 90)} {'Channel': 0, 'Trigger Time': 16034175, 'Logical Position': 0, 'Physical Position': 27, 'Samples': [1478, 1506, 1492, 1520, 1458, 1495, 1467, 1469, 1476, 1504, 1512, 1486, 1468, 1494, 1518, 1504, 1491, 1523, 1516, 1494, 1502, 1461, 1452, 1443, 1491, 1520, 1512, 1495, 1488, 1500, 1473, 1522], 'Footer': (250, 90)} {'Channel': 0, 'Trigger Time': 16035207, 'Logical Position': 0, 'Physical Position': 5, 'Samples': [1503, 1490, 1445, 1512, 1491, 1491, 1496, 1496, 1443, 1505, 1514, 1502, 1483, 1442, 1496, 1490, 1490, 1494, 1502, 1512, 1503, 1488, 1508, 1491, 1490, 1499, 1485, 1454, 1458, 1474, 1486, 1511], 'Footer': (250, 90)} {'Channel': 0, 'Trigger Time': 16037273, 'Logical Position': 0, 'Physical Position': 25, 'Samples': [1479, 1518, 1501, 1525, 1494, 1484, 1494, 1457, 1505, 1492, 1507, 1500, 1467, 1486, 1506, 1513, 1501, 1490, 1494, 1488, 1465, 1477, 1468, 1496, 1493, 1520, 1515, 1486, 1478, 1510, 1488, 1541], 'Footer': (250, 90)} {'Channel': 0, 'Trigger Time': 16038305, 'Logical Position': 0, 'Physical Position': 3, 'Samples': [1468, 1467, 1507, 1541, 1503, 1508, 1516, 1477, 1492, 1470, 1524, 1512, 1504, 1496, 1499, 1517, 1465, 1505, 1499, 1471, 1480, 1495, 1496, 1517, 1498, 1518, 1464, 1466, 1503, 1492, 1493, 1544], 'Footer': (250, 90)} {'Channel': 0, 'Trigger Time': 16039338, 'Logical Position': 0, 'Physical Position': 44, 'Samples': [1531, 1441, 1488, 1482, 1494, 1488, 1506, 1489, 1471, 1486, 1477, 1482, 1470, 1488, 1442, 1463, 1490, 1516, 1500, 1472, 1486, 1514, 1484, 1515, 1487, 1513, 1512, 1494, 1486, 1490, 1513, 1486], 'Footer': (250, 90)} {'Channel': 0, 'Trigger Time': 16040371, 'Logical Position': 0, 'Physical Position': 23, 'Samples': [1510, 1486, 1510, 1522, 1486, 1488, 1493, 1457, 1475, 1492, 1539, 1508, 1491, 1470, 1551, 1518, 1504, 1512, 1492, 1468, 1481, 1490, 1499, 1512, 1500, 1490, 1515, 1499, 1516, 1513, 1468, 1552], 'Footer': (250, 90)} {'Channel': 0, 'Trigger Time': 16042436, 'Logical Position': 0, 'Physical Position': 42, 'Samples': [1538, 1468, 1467, 1492, 1464, 1477, 1459, 1478, 1488, 1486, 1464, 1464, 1475, 1466, 1480, 1479, 1468, 1504, 1492, 1503, 1486, 1484, 1447, 1486, 1478, 1488, 1490, 1487, 1480, 1478, 1488, 1467], 'Footer': (250, 90)} {'Channel': 0, 'Trigger Time': 16043469, 'Logical Position': 0, 'Physical Position': 21, 'Samples': [1502, 1476, 1481, 1517, 1449, 1460, 1465, 1469, 1468, 1502, 1508, 1492, 1464, 1506, 1510, 1495, 1478, 1512, 1504, 1530, 1478, 1477, 1480, 1496, 1473, 1497, 1491, 1487, 1462, 1484, 1462, 1494], 'Footer': (250, 90)} {'Channel': 0, 'Trigger Time': 16044502, 'Logical Position': 0, 'Physical Position': 0, 'Samples': [1500, 1517, 1477, 1494, 1476, 1502, 1489, 1463, 1486, 1464, 1467, 1491, 1481, 1493, 1474, 1480, 1512, 1524, 1483, 1482, 1496, 1494, 1432, 1490, 1488, 1513, 1484, 1511, 1477, 1520, 1510, 1537], 'Footer': (250, 90)} {'Channel': 0, 'Trigger Time': 16045535, 'Logical Position': 0, 'Physical Position': 41, 'Samples': [1483, 1497, 1470, 1494, 1440, 1485, 1488, 1494, 1459, 1458, 1493, 1486, 1496, 1495, 1499, 1510, 1486, 1493, 1507, 1469, 1487, 1478, 1517, 1489, 1498, 1494, 1488, 1508, 1474, 1511, 1470, 1490], 'Footer': (250, 90)} {'Channel': 0, 'Trigger Time': 16031077, 'Logical Position': 0, 'Physical Position': 29, 'Samples': [1496, 1511, 1503, 1515, 1474, 1489, 1492, 1470, 1488, 1490, 1486, 1467, 1464, 1466, 1480, 1494, 1464, 1506, 1497, 1485, 1489, 1489, 1496, 1516, 1508, 1444, 1482, 1464, 1494, 1486, 1489, 1559], 'Footer': (250, 90)} {'Channel': 0, 'Trigger Time': 16032109, 'Logical Position': 0, 'Physical Position': 7, 'Samples': [1489, 1498, 1504, 1514, 1488, 1497, 1490, 1488, 1492, 1508, 1468, 1490, 1491, 1471, 1480, 1461, 1467, 1496, 1512, 1498, 1468, 1461, 1505, 1500, 1492, 1487, 1520, 1494, 1504, 1495, 1494, 1518], 'Footer': (250, 90)} {'Channel': 0, 'Trigger Time': 16033142, 'Logical Position': 0, 'Physical Position': 48, 'Samples': [1509, 1455, 1442, 1519, 1528, 1481, 1515, 1494, 1506, 1497, 1480, 1494, 1464, 1477, 1489, 1483, 1509, 1511, 1491, 1484, 1494, 1488, 1441, 1468, 1472, 1494, 1474, 1466, 1467, 1486, 1527, 1493], 'Footer': (250, 90)} {'Channel': 0, 'Trigger Time': 16034175, 'Logical Position': 0, 'Physical Position': 27, 'Samples': [1478, 1506, 1492, 1520, 1458, 1495, 1467, 1469, 1476, 1504, 1512, 1486, 1468, 1494, 1518, 1504, 1491, 1523, 1516, 1494, 1502, 1461, 1452, 1443, 1491, 1520, 1512, 1495, 1488, 1500, 1473, 1522], 'Footer': (250, 90)} {'Channel': 0, 'Trigger Time': 16035207, 'Logical Position': 0, 'Physical Position': 5, 'Samples': [1503, 1490, 1445, 1512, 1491, 1491, 1496, 1496, 1443, 1505, 1514, 1502, 1483, 1442, 1496, 1490, 1490, 1494, 1502, 1512, 1503, 1488, 1508, 1491, 1490, 1499, 1485, 1454, 1458, 1474, 1486, 1511], 'Footer': (250, 90)} {'Channel': 0, 'Trigger Time': 16037273, 'Logical Position': 0, 'Physical Position': 25, 'Samples': [1479, 1518, 1501, 1525, 1494, 1484, 1494, 1457, 1505, 1492, 1507, 1500, 1467, 1486, 1506, 1513, 1501, 1490, 1494, 1488, 1465, 1477, 1468, 1496, 1493, 1520, 1515, 1486, 1478, 1510, 1488, 1541], 'Footer': (250, 90)} {'Channel': 0, 'Trigger Time': 16038305, 'Logical Position': 0, 'Physical Position': 3, 'Samples': [1468, 1467, 1507, 1541, 1503, 1508, 1516, 1477, 1492, 1470, 1524, 1512, 1504, 1496, 1499, 1517, 1465, 1505, 1499, 1471, 1480, 1495, 1496, 1517, 1498, 1518, 1464, 1466, 1503, 1492, 1493, 1544], 'Footer': (250, 90)} {'Channel': 0, 'Trigger Time': 16039338, 'Logical Position': 0, 'Physical Position': 44, 'Samples': [1531, 1441, 1488, 1482, 1494, 1488, 1506, 1489, 1471, 1486, 1477, 1482, 1470, 1488, 1442, 1463, 1490, 1516, 1500, 1472, 1486, 1514, 1484, 1515, 1487, 1513, 1512, 1494, 1486, 1490, 1513, 1486], 'Footer': (250, 90)} {'Channel': 0, 'Trigger Time': 16040371, 'Logical Position': 0, 'Physical Position': 23, 'Samples': [1510, 1486, 1510, 1522, 1486, 1488, 1493, 1457, 1475, 1492, 1539, 1508, 1491, 1470, 1551, 1518, 1504, 1512, 1492, 1468, 1481, 1490, 1499, 1512, 1500, 1490, 1515, 1499, 1516, 1513, 1468, 1552], 'Footer': (250, 90)} {'Channel': 0, 'Trigger Time': 16042436, 'Logical Position': 0, 'Physical Position': 42, 'Samples': [1538, 1468, 1467, 1492, 1464, 1477, 1459, 1478, 1488, 1486, 1464, 1464, 1475, 1466, 1480, 1479, 1468, 1504, 1492, 1503, 1486, 1484, 1447, 1486, 1478, 1488, 1490, 1487, 1480, 1478, 1488, 1467], 'Footer': (250, 90)} {'Channel': 0, 'Trigger Time': 16043469, 'Logical Position': 0, 'Physical Position': 21, 'Samples': [1502, 1476, 1481, 1517, 1449, 1460, 1465, 1469, 1468, 1502, 1508, 1492, 1464, 1506, 1510, 1495, 1478, 1512, 1504, 1530, 1478, 1477, 1480, 1496, 1473, 1497, 1491, 1487, 1462, 1484, 1462, 1494], 'Footer': (250, 90)} {'Channel': 0, 'Trigger Time': 16044502, 'Logical Position': 0, 'Physical Position': 0, 'Samples': [1500, 1517, 1477, 1494, 1476, 1502, 1489, 1463, 1486, 1464, 1467, 1491, 1481, 1493, 1474, 1480, 1512, 1524, 1483, 1482, 1496, 1494, 1432, 1490, 1488, 1513, 1484, 1511, 1477, 1520, 1510, 1537], 'Footer': (250, 90)} {'Channel': 0, 'Trigger Time': 16045535, 'Logical Position': 0, 'Physical Position': 41, 'Samples': [1483, 1497, 1470, 1494, 1440, 1485, 1488, 1494, 1459, 1458, 1493, 1486, 1496, 1495, 1499, 1510, 1486, 1493, 1507, 1469, 1487, 1478, 1517, 1489, 1498, 1494, 1488, 1508, 1474, 1511, 1470, 1490], 'Footer': (250, 90)} this looks very similar to the data I got from NaluScopes acquistions: {'window_labels': [[], [], [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []], 'evt_window_labels': [[], [], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []], 'data': [array([], dtype=float64), array([], dtype=float64), array([2053, 2108, 2102, 2078, 2073, 2092, 2099, 2090, 2058, 2074, 2076, 2095, 2094, 2078, 2028, 2069, 2106, 2088, 2072, 2025, 2009, 2082, 2078, 2067, 2068, 2058, 2028, 2054, 2024, 2075, 2074, 2080, 2056, 2046, 2071, 2076, 2054, 2044, 2078, 2085, 2002, 2032, 2040, 2035, 2033, 2046, 2050, 2025, 2033, 2078, 2071, 2040, 2005, 2026, 2044, 2040, 2003, 2040, 2046, 2032, 2055, 2076, 2054, 2025, 2040, 2069, 2082, 2088, 2048, 2046, 2052, 1984, 1664, 1573, 1573, 1620, 1572, 1558, 1529, 1518, 1534, 1541, 1538, 1480, 1491, 1516, 1520, 1477, 1529, 1519, 1459, 1488, 1486, 1500, 1517, 1516, 1590, 1516, 1566, 1554, 1518, 1517, 1528, 1516, 1455, 1446, 1486, 1466, 1488, 1468, 1467, 1452, 1486, 1467, 1510, 1526, 1463, 1492, 1487, 1451, 1491, 1506, 1468, 1491, 1496, 1516, 1493, 1481, 1487, 1493, 1492, 1490, 1470, 1469, 1484, 1502, 1495, ... 1627, 1623, 1618, 1645, 1595, 1614, 1622, 1667, 1606, 1620, 1648, 1619, 1669, 1614, 1640, 1655, 1616, 1638, 1602, 1642, 1625, 1618, 1667, 1621, 1618, 1646, 1624, 1646], dtype=uint16), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64)], 'timing': [[], [], [10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []], 'time': [array([], dtype=float64), array([], dtype=float64), array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, ... 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511]), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64)], 'created_at': 0, 'pkg_num': 0, 'event_num': 0, 'name': None} {'window_labels': [[], [], [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []], 'evt_window_labels': [[], [], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []], 'data': [array([], dtype=float64), array([], dtype=float64), array([2053, 2108, 2102, 2078, 2073, 2092, 2099, 2090, 2058, 2074, 2076, 2095, 2094, 2078, 2028, 2069, 2106, 2088, 2072, 2025, 2009, 2082, 2078, 2067, 2068, 2058, 2028, 2054, 2024, 2075, 2074, 2080, 2056, 2046, 2071, 2076, 2054, 2044, 2078, 2085, 2002, 2032, 2040, 2035, 2033, 2046, 2050, 2025, 2033, 2078, 2071, 2040, 2005, 2026, 2044, 2040, 2003, 2040, 2046, 2032, 2055, 2076, 2054, 2025, 2040, 2069, 2082, 2088, 2048, 2046, 2052, 1984, 1664, 1573, 1573, 1620, 1572, 1558, 1529, 1518, 1534, 1541, 1538, 1480, 1491, 1516, 1520, 1477, 1529, 1519, 1459, 1488, 1486, 1500, 1517, 1516, 1590, 1516, 1566, 1554, 1518, 1517, 1528, 1516, 1455, 1446, 1486, 1466, 1488, 1468, 1467, 1452, 1486, 1467, 1510, 1526, 1463, 1492, 1487, 1451, 1491, 1506, 1468, 1491, 1496, 1516, 1493, 1481, 1487, 1493, 1492, 1490, 1470, 1469, 1484, 1502, 1495, ... 1627, 1623, 1618, 1645, 1595, 1614, 1622, 1667, 1606, 1620, 1648, 1619, 1669, 1614, 1640, 1655, 1616, 1638, 1602, 1642, 1625, 1618, 1667, 1621, 1618, 1646, 1624, 1646], dtype=uint16), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64)], 'timing': [[], [], [10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814, 10488814], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []], 'time': [array([], dtype=float64), array([], dtype=float64), array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, ... 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511]), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64), array([], dtype=float64)], 'created_at': 0, 'pkg_num': 0, 'event_num': 0, 'name': None} 04/02/2025 10:06 It looks like python can handle about 7.5 MB/s per thread. The performance is slightly better for smaller \"chunks\" thrown into the algorithm. I.e. if I give the algorithm a a a a times more data it will take a^{1.07} a 1.07 a^{1.07} a 1.07 times longer to handle it (i.e the data rate will slow down). 04/02/2025 10:43 Here is the non log version of the plot, just to help 04/02/2025 11:44 Steps I follow to build the simulation: Clone https://github.com/PIONEER-Experiment/main git clone git@github.com:PIONEER-Experiment/main.git git clone git @github.com:PIONEER-Experiment/main.git Follow the steps in the README.md for building in a docker container, you can find them on the main page. You may need the additional argument to link your ssh id for cloning private repos inside the docker. Check your ~/.ssh for your public key, for example: -v ~/.ssh/id_ed25519:/root/.ssh/id_ed25519 -v ~ /.ssh/i d_ed25519: /root/ .ssh/id_ed25519 In the docker container edit /simulation/checkout-branches.sh to point to the branches you want, then run: git pull --recurse-submodules ./checkout-branches.sh git pull --recurse-submodules ./checkout-branches.sh Then you should be able to build everything with ./setup.sh -aelr . Look at ./setup.sh --help for information on what each flag does 06/02/2025 12:50 Pi -> e + nu pattern recognition performance: Pi -> mu + nu pattern recognition performance: 07/02/2025 09:58 \"Properly\" configured Gaudi option files. all_dir.opts //############################################################## // Job options file //============================================================== AuditorSvc.Auditors = { \"ChronoAuditor\" }; //-------------------------------------------------------------- //-------------------------------------------------------------- // Private Application Configuration options //-------------------------------------------------------------- ApplicationMgr.TopAlg = { \"PIAMainDetRes\" }; // Set output level threshold (2=DEBUG, 3=INFO, 4=WARNING, 5=ERROR, 6=FATAL ) MessageSvc.OutputLevel = 3; //-------------------------------------------------------------- // Event related parameters //-------------------------------------------------------------- ApplicationMgr.EvtMax = -1; ApplicationMgr.EvtSel = \"NONE\"; //-------------------------------------------------------------- // Other Service Options //-------------------------------------------------------------- PIAMainDetRes.ExecuteFastResponse = 1; PIAMainDetRes.ExecuteCaloDigitiser = 0; PIAMainDetRes.OutputFile = \"all_dir.root\"; PIAMainDetRes.OutputMode = 8064; SimReader.Files = {\"/simulation/test/pimunu_run00000*.root 1\"}; FastResponse.RequireTracker = False; FastResponse.RequireCalo = False; //############################################################## // Job options file //============================================================== AuditorSvc.Auditors = { \"ChronoAuditor\" }; //-------------------------------------------------------------- //-------------------------------------------------------------- // Private Application Configuration options //-------------------------------------------------------------- ApplicationMgr.TopAlg = { \"PIAMainDetRes\" }; // Set output level threshold (2=DEBUG, 3=INFO, 4=WARNING, 5=ERROR, 6=FATAL ) MessageSvc.OutputLevel = 3; //-------------------------------------------------------------- // Event related parameters //-------------------------------------------------------------- ApplicationMgr.EvtMax = -1; ApplicationMgr.EvtSel = \"NONE\"; //-------------------------------------------------------------- // Other Service Options //-------------------------------------------------------------- PIAMainDetRes.ExecuteFastResponse = 1; PIAMainDetRes.ExecuteCaloDigitiser = 0; PIAMainDetRes.OutputFile = \"all_dir.root\"; PIAMainDetRes.OutputMode = 8064; SimReader.Files = {\"/simulation/test/pimunu_run00000*.root 1\"}; FastResponse.RequireTracker = False; FastResponse.RequireCalo = False; all_rec.opts: (Without Sean's pattern finding) //############################################################## // Job options file //============================================================== AuditorSvc.Auditors = { \"ChronoAuditor\" }; //-------------------------------------------------------------- //-------------------------------------------------------------- // Private Application Configuration options //-------------------------------------------------------------- ApplicationMgr.TopAlg = { \"PIAMainRec\" }; // Set output level threshold (2=DEBUG, 3=INFO, 4=WARNING, 5=ERROR, 6=FATAL ) MessageSvc.OutputLevel = 3; //-------------------------------------------------------------- // Event related parameters //-------------------------------------------------------------- ApplicationMgr.EvtMax = -1; ApplicationMgr.EvtSel = \"NONE\"; //-------------------------------------------------------------- // Other Service Options //-------------------------------------------------------------- PIAMainRec.InputFile = \"all_dir*.root\"; PIAMainRec.InputTree = \"rec\"; PIAMainRec.InputMode = 8064; PIAMainRec.OutputFile = \"all_rec.root\"; PIAMainRec.OutputMode = 1515392; //PIAMainRec.OutputMode = 0; PIAMainRec.ExecuteTruthTrackletFinder = 1; PIAMainRec.ExecuteTruthPatternFinder = 1; PIAMainRec.ExecutePionStopLocator = 1; PIAMainRec.ExecuteMudifDiscriminant = 1; PIAMainRec.ExecutePatternFinder = 0; PIAMainRec.ExecuteCaloSingleHitFinder = 0; PIAMainRec.ExecuteCaloClusterFinder = 1; PIAMainRec.ExecuteSummaryCollector = 1; PIAMainRec.ExecuteHistogrammer = 1; CaloClusterFinder.SpaceThr = 60; Histogrammer.filename = \"all_hst.root\"; Histogrammer.calib = \"lyso_cal.txt\"; Histogrammer.cuts = { \"time TimeWindow all;-300 -5;5 500\", \"box AtarBox time 8 8 1.2 4.8\", \"fid FidTheta box 120\", \"1p SinglePattern fid\", \"3c TrippleDep 1p 2\", \"edep PromptLateEdep 1p 10.8 4.5\", \"kink AtarKink edep\", \"doca Doca kink 0.2 0.12\", \"init InitStopDEDX doca 6.4\", \"dedz DelayedDEDZ init 1.5\", \"tkr1 HasTracker fid\", \"tkr2 HasTracker dedz\" }; //############################################################## // Job options file //============================================================== AuditorSvc.Auditors = { \"ChronoAuditor\" }; //-------------------------------------------------------------- //-------------------------------------------------------------- // Private Application Configuration options //-------------------------------------------------------------- ApplicationMgr.TopAlg = { \"PIAMainRec\" }; // Set output level threshold (2=DEBUG, 3=INFO, 4=WARNING, 5=ERROR, 6=FATAL ) MessageSvc.OutputLevel = 3; //-------------------------------------------------------------- // Event related parameters //-------------------------------------------------------------- ApplicationMgr.EvtMax = -1; ApplicationMgr.EvtSel = \"NONE\"; //-------------------------------------------------------------- // Other Service Options //-------------------------------------------------------------- PIAMainRec.InputFile = \"all_dir*.root\"; PIAMainRec.InputTree = \"rec\"; PIAMainRec.InputMode = 8064; PIAMainRec.OutputFile = \"all_rec.root\"; PIAMainRec.OutputMode = 1515392; //PIAMainRec.OutputMode = 0; PIAMainRec.ExecuteTruthTrackletFinder = 1; PIAMainRec.ExecuteTruthPatternFinder = 1; PIAMainRec.ExecutePionStopLocator = 1; PIAMainRec.ExecuteMudifDiscriminant = 1; PIAMainRec.ExecutePatternFinder = 0; PIAMainRec.ExecuteCaloSingleHitFinder = 0; PIAMainRec.ExecuteCaloClusterFinder = 1; PIAMainRec.ExecuteSummaryCollector = 1; PIAMainRec.ExecuteHistogrammer = 1; CaloClusterFinder.SpaceThr = 60; Histogrammer.filename = \"all_hst.root\"; Histogrammer.calib = \"lyso_cal.txt\"; Histogrammer.cuts = { \"time TimeWindow all;-300 -5;5 500\", \"box AtarBox time 8 8 1.2 4.8\", \"fid FidTheta box 120\", \"1p SinglePattern fid\", \"3c TrippleDep 1p 2\", \"edep PromptLateEdep 1p 10.8 4.5\", \"kink AtarKink edep\", \"doca Doca kink 0.2 0.12\", \"init InitStopDEDX doca 6.4\", \"dedz DelayedDEDZ init 1.5\", \"tkr1 HasTracker fid\", \"tkr2 HasTracker dedz\" }; all_rec.opts (with Sean's pattern finding) //############################################################## // Job options file //============================================================== AuditorSvc.Auditors = { \"ChronoAuditor\" }; //-------------------------------------------------------------- //-------------------------------------------------------------- // Private Application Configuration options //-------------------------------------------------------------- ApplicationMgr.TopAlg = { \"PIAMainRec\" }; // Set output level threshold (2=DEBUG, 3=INFO, 4=WARNING, 5=ERROR, 6=FATAL ) MessageSvc.OutputLevel = 3; //-------------------------------------------------------------- // Event related parameters //-------------------------------------------------------------- ApplicationMgr.EvtMax = -1; ApplicationMgr.EvtSel = \"NONE\"; //-------------------------------------------------------------- // Other Service Options //-------------------------------------------------------------- PIAMainRec.InputFile = \"all_dir*.root\"; PIAMainRec.InputTree = \"rec\"; PIAMainRec.InputMode = 8064; PIAMainRec.OutputFile = \"all_rec.root\"; PIAMainRec.OutputMode = 1515392; //PIAMainRec.OutputMode = 0; PIAMainRec.ExecuteTruthTrackletFinder = 1; PIAMainRec.ExecuteTruthPatternFinder = 0; PIAMainRec.ExecutePatternFinder = 1; PatternFinder.UseTrackletTimeOrder = true; PatternFinder.DeltaRThreshold = 1.0; PIAMainRec.ExecutePionStopLocator = 1; PIAMainRec.ExecuteMudifDiscriminant = 1; PIAMainRec.ExecuteCaloSingleHitFinder = 0; PIAMainRec.ExecuteCaloClusterFinder = 1; PIAMainRec.ExecuteSummaryCollector = 1; PIAMainRec.ExecuteHistogrammer = 1; CaloClusterFinder.SpaceThr = 60; Histogrammer.filename = \"all_hst.root\"; Histogrammer.calib = \"lyso_cal.txt\"; Histogrammer.cuts = { \"time TimeWindow all;-300 -5;5 500\", \"box AtarBox time 8 8 1.2 4.8\", \"fid FidTheta box 120\", \"1p SinglePattern fid\", \"3c TrippleDep 1p 2\", \"edep PromptLateEdep 1p 10.8 4.5\", \"kink AtarKink edep\", \"doca Doca kink 0.2 0.12\", \"init InitStopDEDX doca 6.4\", \"dedz DelayedDEDZ init 1.5\", \"tkr1 HasTracker fid\", \"tkr2 HasTracker dedz\" }; //############################################################## // Job options file //============================================================== AuditorSvc.Auditors = { \"ChronoAuditor\" }; //-------------------------------------------------------------- //-------------------------------------------------------------- // Private Application Configuration options //-------------------------------------------------------------- ApplicationMgr.TopAlg = { \"PIAMainRec\" }; // Set output level threshold (2=DEBUG, 3=INFO, 4=WARNING, 5=ERROR, 6=FATAL ) MessageSvc.OutputLevel = 3; //-------------------------------------------------------------- // Event related parameters //-------------------------------------------------------------- ApplicationMgr.EvtMax = -1; ApplicationMgr.EvtSel = \"NONE\"; //-------------------------------------------------------------- // Other Service Options //-------------------------------------------------------------- PIAMainRec.InputFile = \"all_dir*.root\"; PIAMainRec.InputTree = \"rec\"; PIAMainRec.InputMode = 8064; PIAMainRec.OutputFile = \"all_rec.root\"; PIAMainRec.OutputMode = 1515392; //PIAMainRec.OutputMode = 0; PIAMainRec.ExecuteTruthTrackletFinder = 1; PIAMainRec.ExecuteTruthPatternFinder = 0; PIAMainRec.ExecutePatternFinder = 1; PatternFinder.UseTrackletTimeOrder = true; PatternFinder.DeltaRThreshold = 1.0; PIAMainRec.ExecutePionStopLocator = 1; PIAMainRec.ExecuteMudifDiscriminant = 1; PIAMainRec.ExecuteCaloSingleHitFinder = 0; PIAMainRec.ExecuteCaloClusterFinder = 1; PIAMainRec.ExecuteSummaryCollector = 1; PIAMainRec.ExecuteHistogrammer = 1; CaloClusterFinder.SpaceThr = 60; Histogrammer.filename = \"all_hst.root\"; Histogrammer.calib = \"lyso_cal.txt\"; Histogrammer.cuts = { \"time TimeWindow all;-300 -5;5 500\", \"box AtarBox time 8 8 1.2 4.8\", \"fid FidTheta box 120\", \"1p SinglePattern fid\", \"3c TrippleDep 1p 2\", \"edep PromptLateEdep 1p 10.8 4.5\", \"kink AtarKink edep\", \"doca Doca kink 0.2 0.12\", \"init InitStopDEDX doca 6.4\", \"dedz DelayedDEDZ init 1.5\", \"tkr1 HasTracker fid\", \"tkr2 HasTracker dedz\" };",
    "textLength": 4635
  },
  {
    "kind": "work-log",
    "title": "21_04_2024 - 27_04_2024.html",
    "fileName": "21_04_2024 - 27_04_2024.html",
    "url": "resources/work_logs/21_04_2024 - 27_04_2024.html",
    "createdDate": "2024-04-21",
    "text": "21/04/2024 - 27/04/2024 21/04/2024 - 27/04/2024 23/04/2024 11:20 Ran at ~1.8kHz for 30 minutes with external trigger. First time I tried I got a CCC run abort immediately. I simply restarted the frontends: 23/04/2024 11:45 Some timing info for the master \"read_trigger_event\": read_trigger_event : Trigger info: trigger number 24571 trigger mask 0 time_s : 1713886819 time_us : -2067971001 time_done_s : 0 time_done_us : 0 Block 1 (Initialization) time: 0 microseconds Block 2 (Creating TRIG bank) time: 0 microseconds Block 3 (Writing GPS timestamp) time: 0 microseconds Block 4 (Printing trigger info) time: 39 microseconds Block 5 (Updating odb monitor) time: 4 microseconds Block 6 (Checking slave fills and triggering alarm) time: 0 microseconds read_trigger_event : Trigger info: trigger number 24572 trigger mask 0 time_s : 1713886819 time_us : -2065393376 time_done_s : 0 time_done_us : 0 Block 1 (Initialization) time: 0 microseconds Block 2 (Creating TRIG bank) time: 0 microseconds Block 3 (Writing GPS timestamp) time: 0 microseconds Block 4 (Printing trigger info) time: 37 microseconds Block 5 (Updating odb monitor) time: 4 microseconds Block 6 (Checking slave fills and triggering alarm) time: 0 microseconds read_trigger_event : Trigger info: trigger number 24571 trigger mask 0 time_s : 1713886819 time_us : - 2067971001 time_done_s : 0 time_done_us : 0 Block 1 (Initialization) time: 0 microseconds Block 2 (Creating TRIG bank) time: 0 microseconds Block 3 (Writing GPS timestamp) time: 0 microseconds Block 4 (Printing trigger info) time: 39 microseconds Block 5 (Updating odb monitor) time: 4 microseconds Block 6 (Checking slave fills and triggering alarm) time: 0 microseconds read_trigger_event : Trigger info: trigger number 24572 trigger mask 0 time_s : 1713886819 time_us : - 2065393376 time_done_s : 0 time_done_us : 0 Block 1 (Initialization) time: 0 microseconds Block 2 (Creating TRIG bank) time: 0 microseconds Block 3 (Writing GPS timestamp) time: 0 microseconds Block 4 (Printing trigger info) time: 37 microseconds Block 5 (Updating odb monitor) time: 4 microseconds Block 6 (Checking slave fills and triggering alarm) time: 0 microseconds And if we turn verbose off, the printing goes to near zero: Block 1 (Initialization) time: 0 microseconds Block 2 (Creating TRIG bank) time: 0 microseconds Block 3 (Writing GPS timestamp) time: 0 microseconds Block 4 (Printing trigger info) time: 0 microseconds Block 5 (Updating odb monitor) time: 3 microseconds Block 6 (Checking slave fills and triggering alarm) time: 0 microseconds Block 1 (Initialization) time: 0 microseconds Block 2 (Creating TRIG bank) time: 0 microseconds Block 3 (Writing GPS timestamp) time: 0 microseconds Block 4 (Printing trigger info) time: 0 microseconds Block 5 (Updating odb monitor) time: 3 microseconds Block 6 (Checking slave fills and triggering alarm) time: 0 microseconds Block 1 (Initialization) time: 0 microseconds Block 2 (Creating TRIG bank) time: 0 microseconds Block 3 (Writing GPS timestamp) time: 0 microseconds Block 4 (Printing trigger info) time: 0 microseconds Block 5 (Updating odb monitor) time: 3 microseconds Block 6 (Checking slave fills and triggering alarm) time: 0 microseconds Block 1 (Initialization) time: 0 microseconds Block 2 (Creating TRIG bank) time: 0 microseconds Block 3 (Writing GPS timestamp) time: 0 microseconds Block 4 (Printing trigger info) time: 0 microseconds Block 5 (Updating odb monitor) time: 3 microseconds Block 6 (Checking slave fills and triggering alarm) time: 0 microseconds However, the rate is limited to at best ~3kHz. 1/3us = 300kHZ, so there's something \"hidden\" going on. Explicitly, these were the timings done: INT read_trigger_event_with_timings(char *pevent, INT off) { // Define variables to store execution times long long totalTime1 = 0; long long totalTime2 = 0; long long totalTime3 = 0; long long totalTime4 = 0; long long totalTime5 = 0; long long totalTime6 = 0; // Block 1: Initialization auto start1 = std::chrono::high_resolution_clock::now(); bk_init32(pevent); auto end1 = std::chrono::high_resolution_clock::now(); totalTime1 = std::chrono::duration_cast<std::chrono::microseconds>(end1 - start1).count(); // Block 2: Creating TRIG bank auto start2 = std::chrono::high_resolution_clock::now(); DWORD *pdata; bk_create(pevent, \"TRIG\", TID_DWORD, (void**)&pdata); // Populate TRIG bank data *pdata++ = trigger_time_info.trigger_nr; *pdata++ = trigger_time_info.trigger_mask; *pdata++ = trigger_time_info.time_s; *pdata++ = trigger_time_info.time_us; *pdata++ = trigger_time_info.time_recv_s; *pdata++ = trigger_time_info.time_recv_us; *pdata++ = trigger_time_info.time_done_s; *pdata++ = trigger_time_info.time_done_us; bk_close(pevent, pdata); auto end2 = std::chrono::high_resolution_clock::now(); totalTime2 = std::chrono::duration_cast<std::chrono::microseconds>(end2 - start2).count(); // Block 3: Writing GPS timestamp auto start3 = std::chrono::high_resolution_clock::now(); if (trigger_source == GPS) { DWORD *pdata; bk_create(pevent, \"GPS0\", TID_DWORD, (void**)&pdata); // Populate GPS0 bank data *pdata++ = gps_evnt_counter; *pdata++ = gps_tstamp_cap.sec; *pdata++ = gps_tstamp_cap.frac; *pdata++ = gps_tstamp_now.sec; *pdata++ = gps_tstamp_now.frac; bk_close(pevent, pdata); } auto end3 = std::chrono::high_resolution_clock::now(); totalTime3 = std::chrono::duration_cast<std::chrono::microseconds>(end3 - start3).count(); // Block 4: Printing trigger info (if verbose) auto start4 = std::chrono::high_resolution_clock::now(); if (master_settings_odb.verbose) { printf(\"read_trigger_event : Trigger info:\\n\"); printf(\" trigger number %i\\n\", trigger_time_info.trigger_nr); printf(\" trigger mask %i\\n\", trigger_time_info.trigger_mask); printf(\" time_s : %i\\n\", trigger_time_info.time_s); printf(\" time_us : %i\\n\", trigger_time_info.time_us); printf(\" time_done_s : %i\\n\", trigger_time_info.time_done_s); printf(\" time_done_us : %i\\n\", trigger_time_info.time_done_us); } auto end4 = std::chrono::high_resolution_clock::now(); totalTime4 = std::chrono::duration_cast<std::chrono::microseconds>(end4 - start4).count(); // Block 5: Updating odb monitor auto start5 = std::chrono::high_resolution_clock::now(); int GPSFill = gps_evnt_counter; db_set_value(hDB, 0, \"/Equipment/MasterGM2/Monitors/GPS Fill Number\", &GPSFill, sizeof(GPSFill), 1, TID_INT); auto end5 = std::chrono::high_resolution_clock::now(); totalTime5 = std::chrono::duration_cast<std::chrono::microseconds>(end5 - start5).count(); // Block 6: Checking slave fills and triggering alarm auto start6 = std::chrono::high_resolution_clock::now(); if (GPSFill % master_settings_odb.fill_number_check_interval == 0) { int count_threshold = 1; int slave_mismatched = check_slave_fills_odb_in_run(GPSFill, master_settings_odb.fill_number_alarm_threshold); if (slave_mismatched >= count_threshold && !FillNumberAlarmTriggered) { FillNumberAlarmTriggered = true; char AlarmMsg[500]; sprintf(AlarmMsg, \"DAQ | MasterGM2 discovered severe fill number mismatch\"); int ret_code = al_trigger_alarm(\"Fill Mismatch Error\", AlarmMsg, \"Alarm\", \"Fill Mismatch Error\", AT_INTERNAL); if (ret_code != AL_SUCCESS) { cm_msg(MERROR, __FILE__, \"Failure Raising Alarm: Error %d, Alarm \\\"%s\\\"\", ret_code, \"Fill Mismatch Error\"); } } } auto end6 = std::chrono::high_resolution_clock::now(); totalTime6 = std::chrono::duration_cast<std::chrono::microseconds>(end6 - start6).count(); // Print out execution times for each block printf(\"Block 1 (Initialization) time: %lld microseconds\\n\", totalTime1); printf(\"Block 2 (Creating TRIG bank) time: %lld microseconds\\n\", totalTime2); printf(\"Block 3 (Writing GPS timestamp) time: %lld microseconds\\n\", totalTime3); printf(\"Block 4 (Printing trigger info) time: %lld microseconds\\n\", totalTime4); printf(\"Block 5 (Updating odb monitor) time: %lld microseconds\\n\", totalTime5); printf(\"Block 6 (Checking slave fills and triggering alarm) time: %lld microseconds\\n\", totalTime6); return bk_size(pevent); } INT read_trigger_event_with_timings(char *pevent, INT off) { // Define variables to store execution times long long totalTime1 = 0; long long totalTime2 = 0; long long totalTime3 = 0; long long totalTime4 = 0; long long totalTime5 = 0; long long totalTime6 = 0; // Block 1: Initialization auto start1 = std::chrono::high_resolution_clock::now(); bk_init32(pevent); auto end1 = std::chrono::high_resolution_clock::now(); totalTime1 = std::chrono::duration_cast<std::chrono::microseconds>(end1 - start1).count(); // Block 2: Creating TRIG bank auto start2 = std::chrono::high_resolution_clock::now(); DWORD *pdata; bk_create(pevent, \"TRIG\", TID_DWORD, (void**)&pdata); // Populate TRIG bank data *pdata++ = trigger_time_info.trigger_nr; *pdata++ = trigger_time_info.trigger_mask; *pdata++ = trigger_time_info.time_s; *pdata++ = trigger_time_info.time_us; *pdata++ = trigger_time_info.time_recv_s; *pdata++ = trigger_time_info.time_recv_us; *pdata++ = trigger_time_info.time_done_s; *pdata++ = trigger_time_info.time_done_us; bk_close(pevent, pdata); auto end2 = std::chrono::high_resolution_clock::now(); totalTime2 = std::chrono::duration_cast<std::chrono::microseconds>(end2 - start2).count(); // Block 3: Writing GPS timestamp auto start3 = std::chrono::high_resolution_clock::now(); if (trigger_source == GPS) { DWORD *pdata; bk_create(pevent, \"GPS0\", TID_DWORD, (void**)&pdata); // Populate GPS0 bank data *pdata++ = gps_evnt_counter; *pdata++ = gps_tstamp_cap.sec; *pdata++ = gps_tstamp_cap.frac; *pdata++ = gps_tstamp_now.sec; *pdata++ = gps_tstamp_now.frac; bk_close(pevent, pdata); } auto end3 = std::chrono::high_resolution_clock::now(); totalTime3 = std::chrono::duration_cast<std::chrono::microseconds>(end3 - start3).count(); // Block 4: Printing trigger info (if verbose) auto start4 = std::chrono::high_resolution_clock::now(); if (master_settings_odb.verbose) { printf(\"read_trigger_event : Trigger info:\\n\"); printf(\" trigger number %i\\n\", trigger_time_info.trigger_nr); printf(\" trigger mask %i\\n\", trigger_time_info.trigger_mask); printf(\" time_s : %i\\n\", trigger_time_info.time_s); printf(\" time_us : %i\\n\", trigger_time_info.time_us); printf(\" time_done_s : %i\\n\", trigger_time_info.time_done_s); printf(\" time_done_us : %i\\n\", trigger_time_info.time_done_us); } auto end4 = std::chrono::high_resolution_clock::now(); totalTime4 = std::chrono::duration_cast<std::chrono::microseconds>(end4 - start4).count(); // Block 5: Updating odb monitor auto start5 = std::chrono::high_resolution_clock::now(); int GPSFill = gps_evnt_counter; db_set_value(hDB, 0, \"/Equipment/MasterGM2/Monitors/GPS Fill Number\", &GPSFill, sizeof(GPSFill), 1, TID_INT); auto end5 = std::chrono::high_resolution_clock::now(); totalTime5 = std::chrono::duration_cast<std::chrono::microseconds>(end5 - start5).count(); // Block 6: Checking slave fills and triggering alarm auto start6 = std::chrono::high_resolution_clock::now(); if (GPSFill % master_settings_odb.fill_number_check_interval == 0) { int count_threshold = 1; int slave_mismatched = check_slave_fills_odb_in_run(GPSFill, master_settings_odb.fill_number_alarm_threshold); if (slave_mismatched >= count_threshold && !FillNumberAlarmTriggered) { FillNumberAlarmTriggered = true; char AlarmMsg[500]; sprintf(AlarmMsg, \"DAQ | MasterGM2 discovered severe fill number mismatch\"); int ret_code = al_trigger_alarm(\"Fill Mismatch Error\", AlarmMsg, \"Alarm\", \"Fill Mismatch Error\", AT_INTERNAL); if (ret_code != AL_SUCCESS) { cm_msg(MERROR, __FILE__, \"Failure Raising Alarm: Error %d, Alarm \\\"%s\\\"\", ret_code, \"Fill Mismatch Error\"); } } } auto end6 = std::chrono::high_resolution_clock::now(); totalTime6 = std::chrono::duration_cast<std::chrono::microseconds>(end6 - start6).count(); // Print out execution times for each block printf(\"Block 1 (Initialization) time: %lld microseconds\\n\", totalTime1); printf(\"Block 2 (Creating TRIG bank) time: %lld microseconds\\n\", totalTime2); printf(\"Block 3 (Writing GPS timestamp) time: %lld microseconds\\n\", totalTime3); printf(\"Block 4 (Printing trigger info) time: %lld microseconds\\n\", totalTime4); printf(\"Block 5 (Updating odb monitor) time: %lld microseconds\\n\", totalTime5); printf(\"Block 6 (Checking slave fills and triggering alarm) time: %lld microseconds\\n\", totalTime6); return bk_size(pevent); } 23/04/2024 11:53 I noticed the \"CCC Run aborted\" alarm is raised at the start of a run if the AMC13001 is started before the master completely finishes initializing. Though, sometimes the \"CCC Run aborted\" alarm is raised even if we wait for the master to completely initialize before starting the AMC13001 frontend. 23/04/2024 11:56 I added this line to the top of the timings: // Print the timestamp when the function starts auto startTimestamp = std::chrono::system_clock::now(); auto startTimestampMs = std::chrono::time_point_cast<std::chrono::milliseconds>(startTimestamp); auto timestamp = std::chrono::duration_cast<std::chrono::milliseconds>(startTimestampMs.time_since_epoch()).count(); std::cout << \"Function started at timestamp: \" << timestamp << \" ms\" << std::endl; // Print the timestamp when the function starts auto startTimestamp = std ::chrono ::system_clock ::now (); auto startTimestampMs = std ::chrono ::time_point_cast <std ::chrono ::milliseconds >(startTimestamp); auto timestamp = std ::chrono ::duration_cast <std ::chrono ::milliseconds >(startTimestampMs.time_since_epoch()).count(); std ::cout << \"Function started at timestamp: \" << timestamp << \" ms\" << std ::endl ; And the output: Function started at timestamp: 1713888335077028 microseconds Block 1 (Initialization) time: 0 microseconds Block 2 (Creating TRIG bank) time: 0 microseconds Block 3 (Writing GPS timestamp) time: 0 microseconds Block 4 (Printing trigger info) time: 0 microseconds Block 5 (Updating odb monitor) time: 3 microseconds Block 6 (Checking slave fills and triggering alarm) time: 0 microseconds Function started at timestamp: 1713888335077389 microseconds Block 1 (Initialization) time: 0 microseconds Block 2 (Creating TRIG bank) time: 0 microseconds Block 3 (Writing GPS timestamp) time: 0 microseconds Block 4 (Printing trigger info) time: 0 microseconds Block 5 (Updating odb monitor) time: 6 microseconds Block 6 (Checking slave fills and triggering alarm) time: 0 microseconds Function started at timestamp: 1713888335077766 microseconds Block 1 (Initialization) time: 0 microseconds Block 2 (Creating TRIG bank) time: 0 microseconds Block 3 (Writing GPS timestamp) time: 0 microseconds Block 4 (Printing trigger info) time: 0 microseconds Block 5 (Updating odb monitor) time: 3 microseconds Block 6 (Checking slave fills and triggering alarm) time: 0 microseconds Function started at timestamp: 1713888335078138 microseconds Block 1 (Initialization) time: 0 microseconds Block 2 (Creating TRIG bank) time: 0 microseconds Block 3 (Writing GPS timestamp) time: 0 microseconds Block 4 (Printing trigger info) time: 0 microseconds Block 5 (Updating odb monitor) time: 3 microseconds Block 6 (Checking slave fills and triggering alarm) time: 0 microseconds Function started at timestamp: 1713888335078500 microseconds Block 1 (Initialization) time: 0 microseconds Block 2 (Creating TRIG bank) time: 0 microseconds Block 3 (Writing GPS timestamp) time: 0 microseconds Block 4 (Printing trigger info) time: 0 microseconds Block 5 (Updating odb monitor) time: 3 microseconds Block 6 (Checking slave fills and triggering alarm) time: 0 microseconds Function started at timestamp: 1713888335078861 microseconds Block 1 (Initialization) time: 0 microseconds Block 2 (Creating TRIG bank) time: 0 microseconds Block 3 (Writing GPS timestamp) time: 0 microseconds Block 4 (Printing trigger info) time: 0 microseconds Function started at timestamp: 1713888335077028 microseconds Block 1 (Initialization) time: 0 microseconds Block 2 (Creating TRIG bank) time: 0 microseconds Block 3 (Writing GPS timestamp) time: 0 microseconds Block 4 (Printing trigger info) time: 0 microseconds Block 5 (Updating odb monitor) time: 3 microseconds Block 6 (Checking slave fills and triggering alarm) time: 0 microseconds Function started at timestamp: 1713888335077389 microseconds Block 1 (Initialization) time: 0 microseconds Block 2 (Creating TRIG bank) time: 0 microseconds Block 3 (Writing GPS timestamp) time: 0 microseconds Block 4 (Printing trigger info) time: 0 microseconds Block 5 (Updating odb monitor) time: 6 microseconds Block 6 (Checking slave fills and triggering alarm) time: 0 microseconds Function started at timestamp: 1713888335077766 microseconds Block 1 (Initialization) time: 0 microseconds Block 2 (Creating TRIG bank) time: 0 microseconds Block 3 (Writing GPS timestamp) time: 0 microseconds Block 4 (Printing trigger info) time: 0 microseconds Block 5 (Updating odb monitor) time: 3 microseconds Block 6 (Checking slave fills and triggering alarm) time: 0 microseconds Function started at timestamp: 1713888335078138 microseconds Block 1 (Initialization) time: 0 microseconds Block 2 (Creating TRIG bank) time: 0 microseconds Block 3 (Writing GPS timestamp) time: 0 microseconds Block 4 (Printing trigger info) time: 0 microseconds Block 5 (Updating odb monitor) time: 3 microseconds Block 6 (Checking slave fills and triggering alarm) time: 0 microseconds Function started at timestamp: 1713888335078500 microseconds Block 1 (Initialization) time: 0 microseconds Block 2 (Creating TRIG bank) time: 0 microseconds Block 3 (Writing GPS timestamp) time: 0 microseconds Block 4 (Printing trigger info) time: 0 microseconds Block 5 (Updating odb monitor) time: 3 microseconds Block 6 (Checking slave fills and triggering alarm) time: 0 microseconds Function started at timestamp: 1713888335078861 microseconds Block 1 (Initialization) time: 0 microseconds Block 2 (Creating TRIG bank) time: 0 microseconds Block 3 (Writing GPS timestamp) time: 0 microseconds Block 4 (Printing trigger info) time: 0 microseconds For some reason then function calls are seperated by ~0.3ms (corresponds to us seeing max rate of 3kHz). However, the function itself isn't causing the lag. 23/04/2024 12:14 I tried to match the way CaloReadoutAMC13 and MasterGM2 frontends trigger, so I commented this line out: //#define USE_INTERRUPT // #define USE_INTERRUPT So that MasterGM2's \"Equipment\" list uses the same equipment type as CaloReadoutAMC13: MasterGM2/frontend.cpp:311 EQUIPMENT equipment[] = { { \"MasterGM2\", /* equipment name */ { // EQUIPMENT_INFO 1, /* event ID */ 0xffff, /* trigger mask */ \"BUF\", /* event buffer */ #ifdef USE_INTERRUPT EQ_INTERRUPT | EQ_EB, /* equipment type */ #else EQ_POLLED | EQ_EB, /* equipment type */ #endif // LAM_SOURCE(0, 0xFFFFFF), /* event source crate 0, all stations */ 0, /* event source */ \"MIDAS\", /* format */ TRUE, /* enabled */ RO_RUNNING , /* read only when running */ //| RO_ODB, /* and update ODB */ 1, /* poll for 1ms */ 0, /* stop run after this event limit */ 0, /* number of sub events */ 0, /* don't log history */ \"\", /* frontend host */ \"\", /* frontend name */ \"\", /* source file */ \"\", /* current status of equipment */ \"\", /* color to be used by mhttpd for status */ FALSE /* hidden */ }, read_trigger_event, /* pointer to readout routine */ }, {\"\"} }; EQUIPMENT equipment[] = { { \"MasterGM2\", /* equipment name */ { // EQUIPMENT_INFO 1, /* event ID */ 0xffff, /* trigger mask */ \"BUF\", /* event buffer */ #ifdef USE_INTERRUPT EQ_INTERRUPT | EQ_EB, /* equipment type */ #else EQ_POLLED | EQ_EB, /* equipment type */ #endif // LAM_SOURCE(0, 0xFFFFFF), /* event source crate 0, all stations */ 0, /* event source */ \"MIDAS\", /* format */ TRUE, /* enabled */ RO_RUNNING , /* read only when running */ //| RO_ODB, /* and update ODB */ 1, /* poll for 1ms */ 0, /* stop run after this event limit */ 0, /* number of sub events */ 0, /* don't log history */ \"\", /* frontend host */ \"\", /* frontend name */ \"\", /* source file */ \"\", /* current status of equipment */ \"\", /* color to be used by mhttpd for status */ FALSE /* hidden */ }, read_trigger_event, /* pointer to readout routine */ }, {\"\"} }; CaloReadoutAMC13/frontend.cpp:401 EQUIPMENT equipment[] = { { \"AMC13%03d\", /* equipment name */ {1, 0xffff, /* event ID, trigger mask */ \"BUF%03d\", /* event buffer */ EQ_POLLED | EQ_EB, /* equipment type */ LAM_SOURCE(0, 0xFFFFFF), /* event source crate 0, all stations */ \"MIDAS\", /* format */ TRUE, /* enabled */ RO_RUNNING , /* read only when running and end of run */ 10, /* poll for 1ms */ 0, /* stop run after this event limit */ 0, /* number of sub events */ 0, /* don't log history */ \"\", \"\", \"\", /* frontend host, frontend name, frontend file name */ \"\", \"\", FALSE}, /* status, status color, hidden */ read_trigger_event, /* readout routine */ }, {\"\"} }; EQUIPMENT equipment[] = { { \"AMC13%03d\" , /* equipment name */ { 1 , 0 xffff, /* event ID, trigger mask */ \"BUF%03d\" , /* event buffer */ EQ_POLLED | EQ_EB, /* equipment type */ LAM_SOURCE( 0 , 0 xFFFFFF), /* event source crate 0, all stations */ \"MIDAS\" , /* format */ TRUE, /* enabled */ RO_RUNNING , /* read only when running and end of run */ 10, /* poll for 1ms */ 0, /* stop run after this event limit */ 0, /* number of sub events */ 0, /* don't log history */ \"\" , \"\" , \"\" , /* frontend host, frontend name, frontend file name */ \"\" , \"\" , FALSE }, /* status, status color, hidden */ read_trigger_event, /* readout routine */ }, { \"\" } } ; This sped the master up a little bit, but it still caps at ~3kHz. 25/04/2024 14:17 Crate errors when high trigger rate: 25/04/2024 14:24 Truncated outpiut of mbggpscap : [root@dhcp-10-163-105-238 ~]# mbggpscap mbggpscap v4.2.24 copyright Meinberg 2001-2023 TCR180PEX 039212025430 (FW 1.21, ASIC 9.00) at port 0xE000, irq 45 Be sure the device has been properly configured to enable capture inputs. On-board FIFO: 583 of 583 entries used. Reading capture events: New capture: CH0: 2024-04-25 18:18:28.8675413 UTC New capture: CH0: 2024-04-25 18:18:28.8678414 UTC << BUF OVR New capture: CH0: 2024-04-25 18:18:28.8684415 UTC New capture: CH0: 2024-04-25 18:18:28.8687416 UTC New capture: CH0: 2024-04-25 18:18:28.8690417 UTC << BUF OVR New capture: CH0: 2024-04-25 18:18:28.8696418 UTC New capture: CH0: 2024-04-25 18:18:28.8705421 UTC New capture: CH0: 2024-04-25 18:18:28.8708421 UTC New capture: CH0: 2024-04-25 18:18:28.8711422 UTC << BUF OVR ... New capture: CH0: 2024-04-25 18:18:29.0832956 UTC << BUF OVR New capture: CH0: 2024-04-25 18:18:29.0838957 UTC New capture: CH0: 2024-04-25 18:18:29.0841958 UTC New capture: CH0: 2024-04-25 18:18:29.0844958 UTC New capture: CH0: 2024-04-25 18:18:29.0853961 UTC New capture: CH0: 2024-04-25 18:18:29.0856961 UTC New capture: CH0: 2024-04-25 18:18:29.0859962 UTC New capture: CH0: 2024-04-25 18:18:29.0862963 UTC << BUF OVR New capture: CH0: 2024-04-25 18:18:29.0868965 UTC New capture: CH0: 2024-04-25 18:18:29.0871965 UTC New capture: CH0: 2024-04-25 18:18:29.0877967 UTC << BUF OVR New capture: CH0: 2024-04-25 18:18:29.0925979 UTC << BUF OVR New capture: CH0: 2024-04-25 18:18:29.1154036 UTC New capture: CH0: 2024-04-25 18:18:29.1157037 UTC New capture: CH0: 2024-04-25 18:18:29.1160038 UTC New capture: CH0: 2024-04-25 18:18:29.1163039 UTC New capture: CH0: 2024-04-25 18:18:29.1166039 UTC New capture: CH0: 2024-04-25 18:18:29.1172041 UTC New capture: CH0: 2024-04-25 18:18:29.1175041 UTC New capture: CH0: 2024-04-25 18:18:29.1178042 UTC New capture: CH0: 2024-04-25 18:18:29.1181043 UTC New capture: CH0: 2024-04-25 18:18:29.1184044 UTC New capture: CH0: 2024-04-25 18:18:29.1187044 UTC New capture: CH0: 2024-04-25 18:18:29.1193046 UTC New capture: CH0: 2024-04-25 18:18:29.1196047 UTC New capture: CH0: 2024-04-25 18:18:29.1199047 UTC New capture: CH0: 2024-04-25 18:18:29.1202048 UTC New capture: CH0: 2024-04-25 18:18:29.1205049 UTC New capture: CH0: 2024-04-25 18:18:29.1208050 UTC New capture: CH0: 2024-04-25 18:18:29.1214051 UTC New capture: CH0: 2024-04-25 18:18:29.1217052 UTC New capture: CH0: 2024-04-25 18:18:29.1220053 UTC New capture: CH0: 2024-04-25 18:18:29.1223054 UTC New capture: CH0: 2024-04-25 18:18:29.1226054 UTC New capture: CH0: 2024-04-25 18:18:29.1229055 UTC New capture: CH0: 2024-04-25 18:18:29.1235057 UTC New capture: CH0: 2024-04-25 18:18:29.1238057 UTC New capture: CH0: 2024-04-25 18:18:29.1241058 UTC New capture: CH0: 2024-04-25 18:18:29.1244059 UTC New capture: CH0: 2024-04-25 18:18:29.1247060 UTC New capture: CH0: 2024-04-25 18:18:29.1250060 UTC New capture: CH0: 2024-04-25 18:18:29.1256062 UTC New capture: CH0: 2024-04-25 18:18:29.1259063 UTC New capture: CH0: 2024-04-25 18:18:29.1262063 UTC New capture: CH0: 2024-04-25 18:18:29.1265064 UTC New capture: CH0: 2024-04-25 18:18:29.1268065 UTC New capture: CH0: 2024-04-25 18:18:29.1271066 UTC New capture: CH0: 2024-04-25 18:18:29.1277067 UTC New capture: CH0: 2024-04-25 18:18:29.1280068 UTC New capture: CH0: 2024-04-25 18:18:29.1283069 UTC New capture: CH0: 2024-04-25 18:18:29.1286069 UTC New capture: CH0: 2024-04-25 18:18:29.1289070 UTC New capture: CH0: 2024-04-25 18:18:29.1292071 UTC New capture: CH0: 2024-04-25 18:18:29.1295072 UTC New capture: CH0: 2024-04-25 18:18:29.1301073 UTC New capture: CH0: 2024-04-25 18:18:29.1304074 UTC New capture: CH0: 2024-04-25 18:18:29.1307075 UTC New capture: CH0: 2024-04-25 18:18:29.1310075 UTC ... New capture: CH0: 2024-04-25 18:18:30.3712194 UTC New capture: CH0: 2024-04-25 18:18:30.3790214 UTC New capture: CH0: 2024-04-25 18:18:30.3793214 UTC New capture: CH0: 2024-04-25 18:18:30.3796215 UTC New capture: CH0: 2024-04-25 18:18:30.3799216 UTC New capture: CH0: 2024-04-25 18:18:30.3802217 UTC New capture: CH0: 2024-04-25 18:18:30.3805217 UTC New capture: CH0: 2024-04-25 18:18:30.3808218 UTC New capture: CH0: 2024-04-25 18:18:30.3811219 UTC New capture: CH0: 2024-04-25 18:18:30.3817220 UTC New capture: CH0: 2024-04-25 18:18:30.3820221 UTC [root@dhcp-10-163-105-238 ~]# mbggpscap mbggpscap v4.2.24 copyright Meinberg 2001-2023 TCR180PEX 039212025430 (FW 1.21, ASIC 9.00) at port 0xE000, irq 45 Be sure the device has been properly configured to enable capture inputs. On-board FIFO: 583 of 583 entries used. Reading capture events: New capture: CH0: 2024-04-25 18:18:28.8675413 UTC New capture: CH0: 2024-04-25 18:18:28.8678414 UTC << BUF OVR New capture: CH0: 2024-04-25 18:18:28.8684415 UTC New capture: CH0: 2024-04-25 18:18:28.8687416 UTC New capture: CH0: 2024-04-25 18:18:28.8690417 UTC << BUF OVR New capture: CH0: 2024-04-25 18:18:28.8696418 UTC New capture: CH0: 2024-04-25 18:18:28.8705421 UTC New capture: CH0: 2024-04-25 18:18:28.8708421 UTC New capture: CH0: 2024-04-25 18:18:28.8711422 UTC << BUF OVR ... New capture: CH0: 2024-04-25 18:18:29.0832956 UTC << BUF OVR New capture: CH0: 2024-04-25 18:18:29.0838957 UTC New capture: CH0: 2024-04-25 18:18:29.0841958 UTC New capture: CH0: 2024-04-25 18:18:29.0844958 UTC New capture: CH0: 2024-04-25 18:18:29.0853961 UTC New capture: CH0: 2024-04-25 18:18:29.0856961 UTC New capture: CH0: 2024-04-25 18:18:29.0859962 UTC New capture: CH0: 2024-04-25 18:18:29.0862963 UTC << BUF OVR New capture: CH0: 2024-04-25 18:18:29.0868965 UTC New capture: CH0: 2024-04-25 18:18:29.0871965 UTC New capture: CH0: 2024-04-25 18:18:29.0877967 UTC << BUF OVR New capture: CH0: 2024-04-25 18:18:29.0925979 UTC << BUF OVR New capture: CH0: 2024-04-25 18:18:29.1154036 UTC New capture: CH0: 2024-04-25 18:18:29.1157037 UTC New capture: CH0: 2024-04-25 18:18:29.1160038 UTC New capture: CH0: 2024-04-25 18:18:29.1163039 UTC New capture: CH0: 2024-04-25 18:18:29.1166039 UTC New capture: CH0: 2024-04-25 18:18:29.1172041 UTC New capture: CH0: 2024-04-25 18:18:29.1175041 UTC New capture: CH0: 2024-04-25 18:18:29.1178042 UTC New capture: CH0: 2024-04-25 18:18:29.1181043 UTC New capture: CH0: 2024-04-25 18:18:29.1184044 UTC New capture: CH0: 2024-04-25 18:18:29.1187044 UTC New capture: CH0: 2024-04-25 18:18:29.1193046 UTC New capture: CH0: 2024-04-25 18:18:29.1196047 UTC New capture: CH0: 2024-04-25 18:18:29.1199047 UTC New capture: CH0: 2024-04-25 18:18:29.1202048 UTC New capture: CH0: 2024-04-25 18:18:29.1205049 UTC New capture: CH0: 2024-04-25 18:18:29.1208050 UTC New capture: CH0: 2024-04-25 18:18:29.1214051 UTC New capture: CH0: 2024-04-25 18:18:29.1217052 UTC New capture: CH0: 2024-04-25 18:18:29.1220053 UTC New capture: CH0: 2024-04-25 18:18:29.1223054 UTC New capture: CH0: 2024-04-25 18:18:29.1226054 UTC New capture: CH0: 2024-04-25 18:18:29.1229055 UTC New capture: CH0: 2024-04-25 18:18:29.1235057 UTC New capture: CH0: 2024-04-25 18:18:29.1238057 UTC New capture: CH0: 2024-04-25 18:18:29.1241058 UTC New capture: CH0: 2024-04-25 18:18:29.1244059 UTC New capture: CH0: 2024-04-25 18:18:29.1247060 UTC New capture: CH0: 2024-04-25 18:18:29.1250060 UTC New capture: CH0: 2024-04-25 18:18:29.1256062 UTC New capture: CH0: 2024-04-25 18:18:29.1259063 UTC New capture: CH0: 2024-04-25 18:18:29.1262063 UTC New capture: CH0: 2024-04-25 18:18:29.1265064 UTC New capture: CH0: 2024-04-25 18:18:29.1268065 UTC New capture: CH0: 2024-04-25 18:18:29.1271066 UTC New capture: CH0: 2024-04-25 18:18:29.1277067 UTC New capture: CH0: 2024-04-25 18:18:29.1280068 UTC New capture: CH0: 2024-04-25 18:18:29.1283069 UTC New capture: CH0: 2024-04-25 18:18:29.1286069 UTC New capture: CH0: 2024-04-25 18:18:29.1289070 UTC New capture: CH0: 2024-04-25 18:18:29.1292071 UTC New capture: CH0: 2024-04-25 18:18:29.1295072 UTC New capture: CH0: 2024-04-25 18:18:29.1301073 UTC New capture: CH0: 2024-04-25 18:18:29.1304074 UTC New capture: CH0: 2024-04-25 18:18:29.1307075 UTC New capture: CH0: 2024-04-25 18:18:29.1310075 UTC ... New capture: CH0: 2024-04-25 18:18:30.3712194 UTC New capture: CH0: 2024-04-25 18:18:30.3790214 UTC New capture: CH0: 2024-04-25 18:18:30.3793214 UTC New capture: CH0: 2024-04-25 18:18:30.3796215 UTC New capture: CH0: 2024-04-25 18:18:30.3799216 UTC New capture: CH0: 2024-04-25 18:18:30.3802217 UTC New capture: CH0: 2024-04-25 18:18:30.3805217 UTC New capture: CH0: 2024-04-25 18:18:30.3808218 UTC New capture: CH0: 2024-04-25 18:18:30.3811219 UTC New capture: CH0: 2024-04-25 18:18:30.3817220 UTC New capture: CH0: 2024-04-25 18:18:30.3820221 UTC It looks like the meinberg only \"captures\" events every ~300us ~ 3kHz (our max rate). Not sure what \"BUF OVR\" means, but it \"goes away\" after a little bit. 22/04/2024 02:12 I tried boosting the rate as high as I could with the internal trigger. . First I tried 4kHz. The Mater couldn't keep up (only can handle ~3Hz) read_trigger_event : New event, trigger # 253002 [MasterGM2,INFO] End of Run: DC7 Triggers Received 341722 Count triggers 253003 End-of-Run Trigger Number 341722 Frontend AMC13001, fill number 341722 [MasterGM2,INFO] End of Run: fills registered by all frontends match! done Run stopped read_trigger_event : New event, trigger # 253002 [MasterGM2,INFO] End of Run: DC7 Triggers Received 341722 Count triggers 253003 End-of-Run Trigger Number 341722 Frontend AMC13001, fill number 341722 [MasterGM2,INFO] End of Run: fills registered by all frontends match! done Run stopped I didn't reall understand why this was, so I got rid of some hardcoded printing around line 1535: INT read_trigger_event(char *pevent, INT off) { //printf(\"read_trigger_event : New event, trigger # %i\\n\",trigger_time_info.trigger_nr); DWORD *pdata; INT read_trigger_event( char *pevent, INT off) { //printf( \"read_trigger_event : New event, trigger # %i\\n\" ,trigger_time_info.trigger_nr); DWORD *pdata; and ran make to remake the frontend. This didn't seem to help. It seems the master still lags behind: Though, the DAQ doesn't crash for severl minutes. So I'm unsure what if this is intended in some way? Again, the master doesn't complain when a run is stopped. CCC: Starting the run ... Started run 83 EOR received: End of run 83 CCC: Stopping the run ... TTS status at end of run CCC: RDY (BUSY - 0.0 msec ago) CCC: Check run state ... CCC: Get trigger number ... CCC: Update ODB fill number... CCC: Waiting for meinberg trigger to match... MasterGM2: Waiting to readout remaining triggers [MasterGM2,INFO] End of Run: DC7 Triggers Received 432097 Count triggers 335829 End-of-Run Trigger Number 432097 Frontend AMC13001, fill number 432097 [MasterGM2,INFO] End of Run: fills registered by all frontends match! done Run stopped CCC: Starting the run .. . Started run 83 EOR received: End of run 83 CCC: Stopping the run .. . TTS status at end of run CCC: RDY (BUSY - 0.0 msec ago) CCC: Check run state .. . CCC: Get trigger number .. . CCC: Update ODB fill number .. . CCC: Waiting for meinberg trigger to match .. . MasterGM2: Waiting to readout remaining triggers [MasterGM2, INFO ] End of Run: DC7 Triggers Received 432097 Count triggers 335829 End-of- Run Trigger Number 432097 Frontend AMC13001, fill number 432097 [MasterGM2, INFO ] End of Run: fills registered by all frontends match! done Run stopped 22/04/2024 02:23 Trying to set the the internal trigger rate to 1/150us =~6.6kHz immediately caused CCC run abort. It's unclear why. 22/04/2024 02:29 At 5kHz, I was able to run for about 30 seconds, before getting CCC error. I see the Master is still stuck at about the same rate. In short, I can't reproduce the software lagging behind with the internal trigger. The hardware is giving these errors in the crate monitor: 22/04/2024 02:49 I was able to run at 3KHz with the logger for ~15 seconds. I turned it off because large data rates were made. We can test this with fewer digitizers as well. 22/04/2024 16:03 Turning debug on and running at 4kHz and 5kHz, I do actually see ReadXBytes returning -1: ReadXBytes(875): ReadXBytes :: x = 8312 read_trigger_event(3255): made Rider header / trailer databank CB001 size (bytes) 0x00000618, rider[0] 0x f0400009b030002, readout electronics fill number 1713816110 CZ bank, Fill_type 1, frontend_index 1 ReadXBytes: warning read return code -1, errno 104 read_trigger_event(3286): made trailer databank CZ001 size 0x00000008, tail[0] 0x c7dd5b1400a0, readout electronics fill number 1713816110 read_trigger_event(3320): lossless data compression 0 read_trigger_event(3477): lossless compression and bank deletion duration: dt = 0 s 6 us CC bank, Fill_type 1, frontend_index 1 read_trigger_event(3511): made timing databank CC001 size (bytes) 0x000000b0, amc13[0] 0x 800a01f9b030051, readout electronics fill number 1713816110 read_trigger_event(3561): tcp got header to tcp got data duration: dt = 0 s 680 us read_trigger_event(3562): tcp got data to MFE done duration: dt = 0 s 493 us read_trigger_event(3563): tcp got header to MFE done duration: dt = 0 s 1173 us read_trigger_event(3564): gpu done to MFE done duration: dt = 1713816110 s 291121 us read_trigger_event(3565): midas bank size: 43492 [AMC13001,ERROR] [tcp_thread.cxx:893:tcp_thread.cxx,ERROR] ReadXBytes: warning read return code -1, errno 104 [AMC13001,ERROR] [tcp_thread.cxx:1178:tcp_thread.cxx,ERROR] Error when reading from socket, fd 40. Read -1 bytes vs 8312 [AMC13001,ERROR] [tcp_thread.cxx:655:tcp_thread.cxx,ERROR] tcp_thread: break the tcp thread loop becuase of a reading error -1 ReadXBytes(875): ReadXBytes :: x = 8312 read_trigger_event(3255): made Rider header / trailer databank CB001 size (bytes) 0x00000618, rider[0] 0x f0400009b030002, readout electronics fill number 1713816110 CZ bank, Fill_type 1, frontend_index 1 ReadXBytes: warning read return code -1, errno 104 read_trigger_event(3286): made trailer databank CZ001 size 0x00000008, tail[0] 0x c7dd5b1400a0, readout electronics fill number 1713816110 read_trigger_event(3320): lossless data compression 0 read_trigger_event(3477): lossless compression and bank deletion duration: dt = 0 s 6 us CC bank, Fill_type 1, frontend_index 1 read_trigger_event(3511): made timing databank CC001 size (bytes) 0x000000b0, amc13[0] 0x 800a01f9b030051, readout electronics fill number 1713816110 read_trigger_event(3561): tcp got header to tcp got data duration: dt = 0 s 680 us read_trigger_event(3562): tcp got data to MFE done duration: dt = 0 s 493 us read_trigger_event(3563): tcp got header to MFE done duration: dt = 0 s 1173 us read_trigger_event(3564): gpu done to MFE done duration: dt = 1713816110 s 291121 us read_trigger_event(3565): midas bank size: 43492 [AMC13001,ERROR] [tcp_thread.cxx:893:tcp_thread.cxx,ERROR] ReadXBytes: warning read return code -1, errno 104 [AMC13001,ERROR] [tcp_thread.cxx:1178:tcp_thread.cxx,ERROR] Error when reading from socket, fd 40. Read -1 bytes vs 8312 [AMC13001,ERROR] [tcp_thread.cxx:655:tcp_thread.cxx,ERROR] tcp_thread: break the tcp thread loop becuase of a reading error -1 turning debug print off, it stops immediately crashing at 4kHz and 5kHz. The printout, even when screened, causes issues. 22/04/2024 16:16 When running at 9kHz, I quickly run into this issue: 17:09:53.604 2024/04/22 [mhttpd,INFO] Run #95 stopped 17:09:53.583 2024/04/22 [AMC13001,ERROR] [frontend.cpp:2457:frontend.cpp,ERROR] TCP/GPU/Midas fill numbers do not match at the end of the run. 17:09:53.583 2024/04/22 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 17:09:53.583 2024/04/22 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 17:09:53.583 2024/04/22 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 17:09:53.583 2024/04/22 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 17:09:35.430 2024/04/22 [MasterGM2,TALK] Warning: DAQ | Suspect fill number mismatch. Check Event numbers! 17:09:35.430 2024/04/22 [MasterGM2,ERROR] [frontend.cpp:1273:frontend.cpp,ERROR] End of Run: checking other frontend fill numbers, time out! 17:09:35.430 2024/04/22 [MasterGM2,INFO] End of Run: DC7 Triggers Received 78944 Count triggers 27291 17:09:35.430 2024/04/22 [MasterGM2,ERROR] [frontend.cpp:1194:end_of_run,ERROR] FC7-10: Unable to Verify Run has Stopped (Run state still in progress) 17:09:32.005 2024/04/22 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 17:09:27.011 2024/04/22 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 17:09:22.006 2024/04/22 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 17:09:17.012 2024/04/22 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 17:09:12.007 2024/04/22 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 17:09:07.002 2024/04/22 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 17:09:02.008 2024/04/22 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 17:08:57.003 2024/04/22 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 17:08:52.009 2024/04/22 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 17:08:47.004 2024/04/22 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 17:08:42.010 2024/04/22 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 17:08:37.005 2024/04/22 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 17:08:32.011 2024/04/22 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 17:08:27.006 2024/04/22 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 17:08:22.012 2024/04/22 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 17:08:17.007 2024/04/22 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 17:08:12.002 2024/04/22 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 17:08:07.008 2024/04/22 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 17:08:02.344 2024/04/22 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 17:08:02.344 2024/04/22 [AMC13001,TALK] Warning: DAQ | AMC13001 TCP Ring buffer close to full (100.000000%) 17:07:53.591 2024/04/22 [mhttpd,INFO] Run #95 started 17:09:53.604 2024/04/22 [mhttpd,INFO] Run #95 stopped 17:09:53.583 2024/04/22 [AMC13001,ERROR] [frontend.cpp:2457:frontend.cpp,ERROR] TCP/GPU/Midas fill numbers do not match at the end of the run. 17:09:53.583 2024/04/22 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 17:09:53.583 2024/04/22 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 17:09:53.583 2024/04/22 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 17:09:53.583 2024/04/22 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 17:09:35.430 2024/04/22 [MasterGM2,TALK] Warning: DAQ | Suspect fill number mismatch. Check Event numbers! 17:09:35.430 2024/04/22 [MasterGM2,ERROR] [frontend.cpp:1273:frontend.cpp,ERROR] End of Run: checking other frontend fill numbers, time out! 17:09:35.430 2024/04/22 [MasterGM2,INFO] End of Run: DC7 Triggers Received 78944 Count triggers 27291 17:09:35.430 2024/04/22 [MasterGM2,ERROR] [frontend.cpp:1194:end_of_run,ERROR] FC7-10: Unable to Verify Run has Stopped (Run state still in progress) 17:09:32.005 2024/04/22 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 17:09:27.011 2024/04/22 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 17:09:22.006 2024/04/22 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 17:09:17.012 2024/04/22 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 17:09:12.007 2024/04/22 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 17:09:07.002 2024/04/22 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 17:09:02.008 2024/04/22 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 17:08:57.003 2024/04/22 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 17:08:52.009 2024/04/22 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 17:08:47.004 2024/04/22 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 17:08:42.010 2024/04/22 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 17:08:37.005 2024/04/22 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 17:08:32.011 2024/04/22 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 17:08:27.006 2024/04/22 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 17:08:22.012 2024/04/22 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 17:08:17.007 2024/04/22 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 17:08:12.002 2024/04/22 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 17:08:07.008 2024/04/22 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 17:08:02.344 2024/04/22 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 17:08:02.344 2024/04/22 [AMC13001,TALK] Warning: DAQ | AMC13001 TCP Ring buffer close to full (100.000000%) 17:07:53.591 2024/04/22 [mhttpd,INFO] Run #95 started 22/04/2024 17:35 It looks like the CCC error at the beginning of a run is indepedent of rate. It seems to occur almost randomly. Just restarting both the frontend seems to fix the issue.",
    "textLength": 7010
  },
  {
    "kind": "work-log",
    "title": "14_01_2024 - 20_01_2024.html",
    "fileName": "14_01_2024 - 20_01_2024.html",
    "url": "resources/work_logs/14_01_2024 - 20_01_2024.html",
    "createdDate": "2024-01-14",
    "text": "14/01/2024 - 20/01/2024 14/01/2024 - 20/01/2024 16/01/2024 03:07 Attempted to follow this guide: https://numato.com/kb/create-pcie-dma-example-design-for-nereid/ The guide is incomplete, I had to guess at some steps of the way. In particular in this image: The AXI Interconnect (xdma_0_axi_periph) is not mentioned as one of the IPs to add. I can find it and add it by hand. From the displayed ports, I made edits so it only has one slave and one master (indicated by the pairs of S00 and M00). Furthermore, the guide tells you to rename the pins (but not how). So I renamed them in under Block Design-->Design in the External Interfaces and Ports folder. Here is a screenshot of my recreated block diagram: In the end, I was able to generate a .bin file and program the board. However I have the exact same issue as when I try following the \"simpler\" guide ( https://numato.com/kb/getting-started-with-pci-express-on-nereid/ ): lspci no longer shows 05:00.0 Memory Controller: Xilinx Corporation Device 7024 on Linux Mint on newest machine Did not see expected Serial Controller: Xilinx Corporation Device 7024 (prog-if 01 [16450] with lspci -vv on Linux Mint as the guide suggested before or after hitting reset button on board Instead, I saw the same result we had when trying to program using the other \"simpler\" guide: 05:00.0 Memory controller: Xilinx Corporation Device 7024 (rev ff) (prog-if ff) !!! Unknown header type 7f 05 : 00.0 Memory controller: Xilinx Corporation Device 7024 (rev ff) (prog-if ff) !!! Unknown header type 7 f Removing the Xilinx Platform Cable without restarting does not change anything other than lspci and lspci -vv no longer show any Xilinx devices (or any new device in general) All of this makes me suspect that the issue happens somewhere between programming the board and reading the board from the host computer (inclusive). I.e. I don't think anything is wrong with the Vivado block diagrams using IP blocks; it seems that we're writing to the wrong registers somehow. But that's just my guess. 16/01/2024 03:52 Trying to reset the board to it's \"default\" state doesn't work anymore when trying to do the following: 09/01/2024 23:47 I got lspci to once again show 05:00.0 Memory Controller: Xilinx Corporation Device 7024 return by unplugging the xilinx connector cable after a shutdown, making sure S1 is in the \"OFF\" position. I'm unsure what I did differently in this case. I think somehow the act of autoconnecting to the hardware with vivado reset it, the resetting the computer helps register it as a pci device. 16/01/2024 04:12 I tried progamming the device with the \"simpler\" guide's ( https://numato.com/kb/getting-started-with-pci-express-on-nereid/ ) .bin file the following the steps above. But it didn't seem to work 16/01/2024 04:17 Plugging the device into fe01 I am again able to see 05:00.0 Memory Controller: Xilinx Corporation Device 7024 Plugging it back into the newest dektop, I still cannot see it under lspci however. I am confused why this is the case, it means somehow there is a difference between how the two computers are reading the card. 18/01/2024 05:51 I realized I never looked to carefully at the board on fe01 when I used lspci -vv after programming. So I programmed the board using the .bin file generated on Vivado 2023.2 on the newest dektop, powered the desktop down, and swapped the card into fe01. Then, I looked again at lspci -vv and noticed: [root@fe01 pcimem]# lspci -vv | grep -A 34 \"04:00.0\" 04:00.0 Memory controller: Xilinx Corporation Device 7024 Subsystem: Xilinx Corporation Device 0007 Control: I/O+ Mem+ BusMaster+ SpecCycle- MemWINV- VGASnoop- ParErr- Stepping- SERR- FastB2B- DisINTx- Status: Cap+ 66MHz- UDF- FastB2B- ParErr- DEVSEL=fast >TAbort- <TAbort- <MAbort- >SERR- <PERR- INTx- Latency: 0, Cache Line Size: 64 bytes Interrupt: pin A routed to IRQ 11 Region 0: Memory at f5f80000 (32-bit, non-prefetchable) [size=512K] Capabilities: [40] Power Management version 3 Flags: PMEClk- DSI- D1- D2- AuxCurrent=0mA PME(D0+,D1+,D2+,D3hot+,D3cold-) Status: D0 NoSoftRst+ PME-Enable- DSel=0 DScale=0 PME- Capabilities: [48] MSI: Enable- Count=1/1 Maskable- 64bit+ Address: 0000000000000000 Data: 0000 Capabilities: [60] Express (v2) Endpoint, MSI 00 DevCap: MaxPayload 512 bytes, PhantFunc 0, Latency L0s <64ns, L1 unlimited ExtTag- AttnBtn- AttnInd- PwrInd- RBE+ FLReset- SlotPowerLimit 225.000W DevCtl: Report errors: Correctable- Non-Fatal+ Fatal+ Unsupported- RlxdOrd+ ExtTag- PhantFunc- AuxPwr- NoSnoop+ MaxPayload 256 bytes, MaxReadReq 512 bytes DevSta: CorrErr- UncorrErr- FatalErr- UnsuppReq- AuxPwr- TransPend- LnkCap: Port #0, Speed 5GT/s, Width x4, ASPM L0s, Exit Latency L0s unlimited, L1 unlimited ClockPM- Surprise- LLActRep- BwNot- ASPMOptComp- LnkCtl: ASPM Disabled; RCB 64 bytes Disabled- CommClk+ ExtSynch- ClockPM- AutWidDis- BWInt- AutBWInt- LnkSta: Speed 5GT/s, Width x4, TrErr- Train- SlotClk+ DLActive- BWMgmt- ABWMgmt- DevCap2: Completion Timeout: Range B, TimeoutDis-, LTR-, OBFF Not Supported DevCtl2: Completion Timeout: 50us to 50ms, TimeoutDis-, LTR-, OBFF Disabled LnkCtl2: Target Link Speed: 5GT/s, EnterCompliance- SpeedDis- Transmit Margin: Normal Operating Range, EnterModifiedCompliance- ComplianceSOS- Compliance De-emphasis: -6dB LnkSta2: Current De-emphasis Level: -6dB, EqualizationComplete-, EqualizationPhase1- EqualizationPhase2-, EqualizationPhase3-, LinkEqualizationRequest- Capabilities: [100 v1] Device Serial Number 00-00-00-01-01-00-0a-35 06:00.0 Ethernet controller: Broadcom Inc. and subsidiaries NetXtreme BCM5761 Gigabit Ethernet PCIe (rev 10) Subsystem: Dell Device 026d [root@fe01 pcimem]# lspci -vv | grep -A 34 \"04:00.0\" 04:00.0 Memory controller: Xilinx Corporation Device 7024 Subsystem: Xilinx Corporation Device 0007 Control: I/O+ Mem+ BusMaster+ SpecCycle- MemWINV- VGASnoop- ParErr- Stepping- SERR- FastB2B- DisINTx- Status: Cap+ 66MHz- UDF- FastB2B- ParErr- DEVSEL=fast >TAbort- <TAbort- <MAbort- >SERR- <PERR- INTx- Latency: 0, Cache Line Size: 64 bytes Interrupt: pin A routed to IRQ 11 Region 0: Memory at f5f80000 (32-bit, non-prefetchable) [size=512K] Capabilities: [40] Power Management version 3 Flags: PMEClk- DSI- D1- D2- AuxCurrent=0mA PME(D0+,D1+,D2+,D3hot+,D3cold-) Status: D0 NoSoftRst+ PME-Enable- DSel=0 DScale=0 PME- Capabilities: [48] MSI: Enable- Count=1/1 Maskable- 64bit+ Address: 0000000000000000 Data: 0000 Capabilities: [60] Express (v2) Endpoint, MSI 00 DevCap: MaxPayload 512 bytes, PhantFunc 0, Latency L0s <64ns, L1 unlimited ExtTag- AttnBtn- AttnInd- PwrInd- RBE+ FLReset- SlotPowerLimit 225.000W DevCtl: Report errors: Correctable- Non-Fatal+ Fatal+ Unsupported- RlxdOrd+ ExtTag- PhantFunc- AuxPwr- NoSnoop+ MaxPayload 256 bytes, MaxReadReq 512 bytes DevSta: CorrErr- UncorrErr- FatalErr- UnsuppReq- AuxPwr- TransPend- LnkCap: Port #0, Speed 5GT/s, Width x4, ASPM L0s, Exit Latency L0s unlimited, L1 unlimited ClockPM- Surprise- LLActRep- BwNot- ASPMOptComp- LnkCtl: ASPM Disabled; RCB 64 bytes Disabled- CommClk+ ExtSynch- ClockPM- AutWidDis- BWInt- AutBWInt- LnkSta: Speed 5GT/s, Width x4, TrErr- Train- SlotClk+ DLActive- BWMgmt- ABWMgmt- DevCap2: Completion Timeout: Range B, TimeoutDis-, LTR-, OBFF Not Supported DevCtl2: Completion Timeout: 50us to 50ms, TimeoutDis-, LTR-, OBFF Disabled LnkCtl2: Target Link Speed: 5GT/s, EnterCompliance- SpeedDis- Transmit Margin: Normal Operating Range, EnterModifiedCompliance- ComplianceSOS- Compliance De-emphasis: -6dB LnkSta2: Current De-emphasis Level: -6dB, EqualizationComplete-, EqualizationPhase1- EqualizationPhase2-, EqualizationPhase3-, LinkEqualizationRequest- Capabilities: [100 v1] Device Serial Number 00-00-00-01-01-00-0a-35 06:00.0 Ethernet controller: Broadcom Inc. and subsidiaries NetXtreme BCM5761 Gigabit Ethernet PCIe (rev 10) Subsystem: Dell Device 026d In particular, Region 0: Memory at f5f80000 (32-bit, non-prefetchable) [size=512K] no longer looks like: Region 0: Memory at 51100000 (32-bit, non-prefetchable) [disabled] [size=512K] I.e. it's not disabled. That means I should be able to communicate with it. So I used vivado's software to communicate ( https://github.com/numato-viya/pcimem ) And entered the command: sudo ./pcimem /dev/mem 4126670848 w 0xffffff12 where 4126670848 is the decimal value of the hex code f5f80000. And we see we are sucessfully able to write and readback! [root@fe01 pcimem]# sudo ./pcimem /dev/mem 4126670848 w 0xffffff12 /dev/mem opened. Target offset is 0xf5f80000, page size is 4096 mmap(0, 4096, 0x3, 0x1, 3, 0xf5f80000) PCI Memory mapped to address 0x7f1bd8988000. Value at offset 0xF5F80000 (0x7f1bd8988000): 0x0 Written 0xFFFFFF12; readback 0xFFFFFF12 [root@fe01 pcimem]# sudo ./pcimem /dev/mem 4126670848 w 0xffffff12 /dev/mem opened. Target offset is 0xf5f80000 , page size is 4096 mmap( 0 , 4096 , 0x3 , 0x1 , 3 , 0xf5f80000 ) PCI Memory mapped to address 0x7f1bd8988000 . Value at offset 0xF5F80000 ( 0x7f1bd8988000 ): 0x0 Written 0xFFFFFF12 ; readback 0xFFFFFF12",
    "textLength": 1417
  },
  {
    "kind": "work-log",
    "title": "31_03_2024 - 06_03_2024.html",
    "fileName": "31_03_2024 - 06_03_2024.html",
    "url": "resources/work_logs/31_03_2024 - 06_03_2024.html",
    "createdDate": "2024-03-31",
    "text": "31/03/2024 - 06/03/2024 31/03/2024 - 06/03/2024 31/03/2024 18:20 I was able to finally get everything to ping at once, without turning off and on ports: [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# ping 192.168.1.41 PING 192.168.1.41 (192.168.1.41) 56(84) bytes of data. 64 bytes from 192.168.1.41: icmp_seq=1 ttl=255 time=0.477 ms ^C --- 192.168.1.41 ping statistics --- 1 packets transmitted, 1 received, 0% packet loss, time 0ms rtt min/avg/max/mdev = 0.477/0.477/0.477/0.000 ms [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# ping 192.168.1.150 PING 192.168.1.150 (192.168.1.150) 56(84) bytes of data. 64 bytes from 192.168.1.150: icmp_seq=1 ttl=64 time=0.098 ms 64 bytes from 192.168.1.150: icmp_seq=2 ttl=64 time=0.062 ms ^C --- 192.168.1.150 ping statistics --- 2 packets transmitted, 2 received, 0% packet loss, time 999ms rtt min/avg/max/mdev = 0.062/0.080/0.098/0.018 ms [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# ping 192.168.1.41 PING 192.168.1.41 (192.168.1.41) 56(84) bytes of data. 64 bytes from 192.168.1.41: icmp_seq =1 ttl =255 time =0.477 ms ^C --- 192.168.1.41 ping statistics --- 1 packets transmitted, 1 received, 0% packet loss, time 0ms rtt min/avg/max/mdev = 0.477/0.477/0.477/0.000 ms [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# ping 192.168.1.150 PING 192.168.1.150 (192.168.1.150) 56(84) bytes of data. 64 bytes from 192.168.1.150: icmp_seq =1 ttl =64 time =0.098 ms 64 bytes from 192.168.1.150: icmp_seq =2 ttl =64 time =0.062 ms ^C --- 192.168.1.150 ping statistics --- 2 packets transmitted, 2 received, 0% packet loss, time 999ms rtt min/avg/max/mdev = 0.062/0.080/0.098/0.018 ms [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# The top pinging being the 10GbE link, the bottom pinging being the MCH through 1GbE. I followed this strategy: So one thing I may try is shrinking the enp5s0 subnet to 192.168.1.1 to 192.168.1.128, then changing enp1s0f1's subnet to 192.168.1.129 - 192.168.1.255. Then I think I can put the 10GbE NIC of the AMC13 on enp1s0f1's subnet and literally everything else on enp5s0's subnet. Here's what I did: Network scripts /etc/sysconfig/network-script/ifcfg-enp1s0f0 (10GbE) # # Connect to AMC # HWADDR=b4:b5:2f:a4:e7:fc TYPE=Ethernet PROXY_METHOD=none BROWSER_ONLY=no BOOTPROTO=none IPADDR=192.168.1.21 NETMASK=255.255.255.0 DEFROUTE=yes IPV4_FAILURE_FATAL=no IPV6INIT=yes IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_FAILURE_FATAL=no IPV6_ADDR_GEN_MODE=stable-privacy UUID=f1d52da3-687b-3215-a2c0-60c11d0fd3bf ONBOOT=yes AUTOCONNECT_PRIORITY=-999 MTU=9000 DEVICE=enp1s0f1 NAME=enp1s0f1 # # Connect to AMC # HWADDR =b4:b5: 2 f:a4:e7:fc TYPE =Ethernet PROXY_METHOD =none BROWSER_ONLY = no BOOTPROTO =none IPADDR = 192.168 . 1.21 NETMASK = 255.255 . 255.0 DEFROUTE = yes IPV4_FAILURE_FATAL = no IPV6INIT = yes IPV6_AUTOCONF = yes IPV6_DEFROUTE = yes IPV6_FAILURE_FATAL = no IPV6_ADDR_GEN_MODE =stable-privacy UUID =f1d52da3- 687 b- 3215 -a2c0- 60 c11d0fd3bf ONBOOT = yes AUTOCONNECT_PRIORITY =- 999 MTU = 9000 DEVICE =enp1s0f1 NAME =enp1s0f1 Notice I didn't bother changing the netmask here, it still can see everything on 192.168.1.xxx; as long as it has a priority less than enp5s0, this isn't a problem (and once I got it working, I didn't want to touch it.) /etc/sysconfig/network-script/ifcfg-enp5s0 (1GbE) # # Connect to MCH # TYPE=Ethernet BOOTPROTO=static IPADDR=192.168.1.1 NETMASK=255.255.255.128 IPV4_FAILURE_FATAL=no IPV6INIT=no IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_PEERDNS=yes IPV6_PEERROUTES=yes IPV6_FAILURE_FATAL=no NAME=enp5s0 DEVICE=enp5s0 ONBOOT=yes # # Connect to MCH # TYPE =Ethernet BOOTPROTO =static IPADDR = 192.168 . 1.1 NETMASK = 255.255 . 255.128 IPV4_FAILURE_FATAL = no IPV6INIT = no IPV6_AUTOCONF = yes IPV6_DEFROUTE = yes IPV6_PEERDNS = yes IPV6_PEERROUTES = yes IPV6_FAILURE_FATAL = no NAME =enp5s0 DEVICE =enp5s0 ONBOOT = yes Notice here NETMASK=255.255.255.128 . This means that enp5s0 only sees 192.168.1.1 to 192.168.1.127; I'm not sure on the details of exactly how this is works. Reload the network with: ifdown enp5s0 ifdown enp1s0f1 ifup enp5s0 if up enp1s0f1 ifdown enp5s0 ifdown enp1s0f1 ifup enp5s0 if up enp1s0f1 Changing T1 (Spartan) and T2 (Virtex) IPs We had T1 and T2 on 192.168.1.188 and 192.168.1.189 respectively. This is an issue if I want to do the above set-up because it's outside the 1GbE's subnet. So we have to change them. cd /home/installation_testing/packages/experiment/lxedaq/environment_setup source ./setup_environment cd /home/installation_testing/packages/experiment/lxedaq/amc13/amc13_v1_2_18/dev_tools/amc13Config ./applyConfig -i 192.168.1.13 cd /home/installation_testing/packages/experiment/lxedaq/environment_setup source ./setup_environment cd /home/installation_testing/packages/experiment/lxedaq/amc13/amc13_v1_2_18/dev_tools/amc13Config ./applyConfig -i 192.168.1.13 The -i flag in applyConfig tells the script to set T1's IP to 192.168.1.13 and T2's IP to one higher being 192.168.1.14. Now we can test that we can ping T1 and T2: [root@dhcp-10-163-105-238 amc13Config]# ping 192.168.1.13 PING 192.168.1.13 (192.168.1.13) 56(84) bytes of data. 64 bytes from 192.168.1.13: icmp_seq=1 ttl=64 time=0.111 ms 64 bytes from 192.168.1.13: icmp_seq=2 ttl=64 time=0.133 ms ^C --- 192.168.1.13 ping statistics --- 2 packets transmitted, 2 received, 0% packet loss, time 1000ms rtt min/avg/max/mdev = 0.111/0.122/0.133/0.011 ms [root@dhcp-10-163-105-238 amc13Config]# ping 192.168.1.14 PING 192.168.1.14 (192.168.1.14) 56(84) bytes of data. 64 bytes from 192.168.1.14: icmp_seq=1 ttl=64 time=0.174 ms 64 bytes from 192.168.1.14: icmp_seq=2 ttl=64 time=0.133 ms ^C --- 192.168.1.14 ping statistics --- 2 packets transmitted, 2 received, 0% packet loss, time 999ms rtt min/avg/max/mdev = 0.133/0.153/0.174/0.023 ms [root@dhcp-10-163-105-238 amc13Config]# [root@dhcp-10-163-105-238 amc13Config]# ping 192.168.1.13 PING 192.168.1.13 (192.168.1.13) 56(84) bytes of data. 64 bytes from 192.168.1.13: icmp_seq =1 ttl =64 time =0.111 ms 64 bytes from 192.168.1.13: icmp_seq =2 ttl =64 time =0.133 ms ^C --- 192.168.1.13 ping statistics --- 2 packets transmitted, 2 received, 0% packet loss, time 1000ms rtt min/avg/max/mdev = 0.111/0.122/0.133/0.011 ms [root@dhcp-10-163-105-238 amc13Config]# ping 192.168.1.14 PING 192.168.1.14 (192.168.1.14) 56(84) bytes of data. 64 bytes from 192.168.1.14: icmp_seq =1 ttl =64 time =0.174 ms 64 bytes from 192.168.1.14: icmp_seq =2 ttl =64 time =0.133 ms ^C --- 192.168.1.14 ping statistics --- 2 packets transmitted, 2 received, 0% packet loss, time 999ms rtt min/avg/max/mdev = 0.133/0.153/0.174/0.023 ms [root@dhcp-10-163-105-238 amc13Config]# Changing the top 10GbE NIC's IP on the AMC13 The 10GbE NIC on the AMC13 has IP 192.168.1.32 by default. This is no good because it's inside the subnet of enp5s0, which we're trying to avoid. So let's set it to something outside the subnet (I chose 192.168.1.150): export LD_LIBRARY_PATH=/home/installation_testing/packages/experiment/lxedaq/amc13/amc13StandaloneMAN_2014-05-12/lib:$LD_LIBRARY_PATH cd export LD_LIBRARY_PATH=/home/installation_testing/packages/experiment/lxedaq/amc13/amc13StandaloneMAN_2014-05-12/lib:$LD_LIBRARY_PATH bin/AMC13Tool -i 192.168.1.13 export LD_LIBRARY_PATH=/home/installation_testing/packages/experiment/lxedaq/amc13/amc13StandaloneMAN_2014-05-12/lib: $LD_LIBRARY_PATH cd export LD_LIBRARY_PATH=/home/installation_testing/packages/experiment/lxedaq/amc13/amc13StandaloneMAN_2014-05-12/lib: $LD_LIBRARY_PATH bin/AMC13Tool -i 192.168.1.13 This will bring up AMC13Tool, we have to give it a similar -i flag like we did when setting the IPs. I write the register that determines the 10GbE NIC's IP: Pick an action (h for menu): wv 0x1c1c 0xc0a80196 Writing to T1: 00001c1c: c0a80196 Pick an action (h for menu): wv 0x1c1c 0xc0a80196 Writing to T 1 : 00001 c 1 c : c 0 a 80196 This corresponds to 192.168.1.150 because in hex: c0 -> 192 a8 -> 168 01 -> 1 96 -> 150 c0 -> 192 a8 -> 168 01 -> 1 96 -> 150 Then I run ky_init.amc : Pick an action (h for menu): do amc13_scripts/ky_init.amc Pick an action (h for menu): do amc13_scripts/ky_init.amc Really, I think I could equivalently do this: # enables amc slots and SFP outputs wv 0x3 0x1fff # enables amc slots and SFP outputs wv 0 x3 0 x1fff In any event, the result is the 10GbE port is turned on. We can test pinging both the AMC13 10GbE connection and the MCH: [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# ping 192.168.1.41 PING 192.168.1.41 (192.168.1.41) 56(84) bytes of data. 64 bytes from 192.168.1.41: icmp_seq=1 ttl=255 time=0.477 ms ^C --- 192.168.1.41 ping statistics --- 1 packets transmitted, 1 received, 0% packet loss, time 0ms rtt min/avg/max/mdev = 0.477/0.477/0.477/0.000 ms [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# ping 192.168.1.150 PING 192.168.1.150 (192.168.1.150) 56(84) bytes of data. 64 bytes from 192.168.1.150: icmp_seq=1 ttl=64 time=0.098 ms 64 bytes from 192.168.1.150: icmp_seq=2 ttl=64 time=0.062 ms ^C --- 192.168.1.150 ping statistics --- 2 packets transmitted, 2 received, 0% packet loss, time 999ms rtt min/avg/max/mdev = 0.062/0.080/0.098/0.018 ms [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# ping 192.168.1.41 PING 192.168.1.41 (192.168.1.41) 56(84) bytes of data. 64 bytes from 192.168.1.41: icmp_seq =1 ttl =255 time =0.477 ms ^C --- 192.168.1.41 ping statistics --- 1 packets transmitted, 1 received, 0% packet loss, time 0ms rtt min/avg/max/mdev = 0.477/0.477/0.477/0.000 ms [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# ping 192.168.1.150 PING 192.168.1.150 (192.168.1.150) 56(84) bytes of data. 64 bytes from 192.168.1.150: icmp_seq =1 ttl =64 time =0.098 ms 64 bytes from 192.168.1.150: icmp_seq =2 ttl =64 time =0.062 ms ^C --- 192.168.1.150 ping statistics --- 2 packets transmitted, 2 received, 0% packet loss, time 999ms rtt min/avg/max/mdev = 0.062/0.080/0.098/0.018 ms [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# Slightly change to frontend code: Becuase the IP of T1 and T2 is hardcoded in the frontend (for some reason), we have to change this AMC13.cpp:84 from ss_ip_hardcoded << \"192.168.\" << byte3 << \".\" << (188 + sel); ss_ip_hardcoded << \"192.168.\" << byte3 << \".\" << ( 188 + sel); to ss_ip_hardcoded << \"192.168.\" << byte3 << \".\" << (13 + sel); ss_ip_hardcoded << \"192.168.\" << byte3 << \".\" << ( 13 + sel); Aside: I was having some weird errors the first time I tried this. By just changing the IP from 192.168.1.21 --> 192.168.1.100 for enp1s0f1 in the network settings I lost the ability to ping the AMC13 10GbE port at 192.168.1.32. I could change the IP back to 192.168.1.21 and regain the ability to ping. Changing the IP from 192.168.1.32 --> 192.168.1.150 I completely lost the ability to ping, even when I tried to change back from 192.168.1.150 --> 192.168.1.32. I power cycled the crate and restarted the 'be' computer. Then I had no such troubles anymore. I think I must have set some weird network settings while I was playing with routing tables before. I have no idea why I had this behavior. 31/03/2024 18:56 I'm able to sucessfully start both frontends. However, when trying to start a run no data is produced. Furthermore, the CaloReadoutAMC13 frontend ignores the end of run signal and hangs. It just contiously tries to read data Started run 4 ReadXBytes(919): socket file descriptor 24, request 8 bytes, read 0 bytes, tries 1000 tcp_thread(622): start read of new event, fill 0, buffer 0 ... ReadXBytes(919): socket file descriptor 24, request 8 bytes, read 0 bytes, tries 1000 tcp_thread(622): start read of new event, fill 0, buffer 0 ReadXBytes(875): ReadXBytes :: x = 8 Started run 4 ReadXBytes(919): socket file descriptor 24, request 8 bytes, read 0 bytes, tries 1000 tcp_thread(622): start read of new event, fill 0, buffer 0 . .. ReadXBytes(919): socket file descriptor 24, request 8 bytes, read 0 bytes, tries 1000 tcp_thread(622): start read of new event, fill 0, buffer 0 ReadXBytes(875): ReadXBytes : : x = 8 Maybe this issue lies in the Master frontend not \"ending\" first? Frontend Initialization Complete OK BOR Received: Run 4 print(155): /Equipment/MasterGM2/Settings/Globals Trigger source GPS print(156): /Equipment/MasterGM2/Settings/Globals Socket trigger IP address 127.0.0.1 print(157): /Equipment/MasterGM2/Settings/Globals Socket trigger port 55000 print(158): /Equipment/MasterGM2/Settings/Globals Rate 12.000000 print(159): /Equipment/MasterGM2/Settings/Globals Fills per bunch 8 print(160): /Equipment/MasterGM2/Settings/Globals Readout name AMC13 print(161): /Equipment/MasterGM2/Settings/Globals Front End Offset 1 print(162): /Equipment/MasterGM2/Settings/Globals Simulator name CaloSimulatorAMC13 print(163): /Equipment/MasterGM2/Settings/Globals Encoder Front End AMC13001 print(164): /Equipment/MasterGM2/Settings/Globals Send to event builder 1 print(165): /Equipment/MasterGM2/Settings/Globals Verbose 0 print(166): /Equipment/MasterGM2/Settings/Globals CCC 1 print(167): /Equipment/MasterGM2/Settings/Globals Post MTCA Abort State to ECL 1 print(168): /Equipment/MasterGM2/Settings/Globals Preserve TTC Trigger Config 0 print(169): /Equipment/MasterGM2/Settings/Globals Preserve Analog Trigger Config 0 print(170): /Equipment/MasterGM2/Settings/Globals Enable Trigger DB 1 print(171): /Equipment/MasterGM2/Settings/Globals Trigger DB Analog A6 ID 1 print(172): /Equipment/MasterGM2/Settings/Globals Trigger DB Analog T9 ID 1 print(173): /Equipment/MasterGM2/Settings/Globals Trigger DB TTC ID 1 print(174): /Equipment/MasterGM2/Settings/Globals Trigger DB TTC Analog Pulse ID 1 print(175): /Equipment/MasterGM2/Settings/Globals Trigger DB Fanout Delays ID 1 print(176): /Equipment/MasterGM2/Settings/Globals Database Connection pgsql://g2db-priv:5433/gm2_online_prod gm2_writer gm2_4_writer print(177): /Equipment/MasterGM2/Settings/Globals Internal Trig Alarm Thresh (s) 30 print(178): /Equipment/MasterGM2/Settings/Globals T9A6Gap (ns) 8654175 trigger source 3 GPS 3 Buffers Used: 0, Buffers Capacity: 584 Waiting 3 s before starting CCC run ... CCC: Starting the run ... Started run 4 EOR received: End of run 4 CCC: Stopping the run ... TTS status at end of run CCC: RDY (BUSY - 0.0 msec ago) Frontend Initialization Complete OK BOR Received: Run 4 print(155): /Equipment/MasterGM2/Settings/Globals Trigger source GPS print(156): /Equipment/MasterGM2/Settings/Globals Socket trigger IP address 127.0.0.1 print(157): /Equipment/MasterGM2/Settings/Globals Socket trigger port 55000 print(158): /Equipment/MasterGM2/Settings/Globals Rate 12.000000 print(159): /Equipment/MasterGM2/Settings/Globals Fills per bunch 8 print(160): /Equipment/MasterGM2/Settings/Globals Readout name AMC13 print(161): /Equipment/MasterGM2/Settings/Globals Front End Offset 1 print(162): /Equipment/MasterGM2/Settings/Globals Simulator name CaloSimulatorAMC13 print(163): /Equipment/MasterGM2/Settings/Globals Encoder Front End AMC13001 print(164): /Equipment/MasterGM2/Settings/Globals Send to event builder 1 print(165): /Equipment/MasterGM2/Settings/Globals Verbose 0 print(166): /Equipment/MasterGM2/Settings/Globals CCC 1 print(167): /Equipment/MasterGM2/Settings/Globals Post MTCA Abort State to ECL 1 print(168): /Equipment/MasterGM2/Settings/Globals Preserve TTC Trigger Config 0 print(169): /Equipment/MasterGM2/Settings/Globals Preserve Analog Trigger Config 0 print(170): /Equipment/MasterGM2/Settings/Globals Enable Trigger DB 1 print(171): /Equipment/MasterGM2/Settings/Globals Trigger DB Analog A6 ID 1 print(172): /Equipment/MasterGM2/Settings/Globals Trigger DB Analog T9 ID 1 print(173): /Equipment/MasterGM2/Settings/Globals Trigger DB TTC ID 1 print(174): /Equipment/MasterGM2/Settings/Globals Trigger DB TTC Analog Pulse ID 1 print(175): /Equipment/MasterGM2/Settings/Globals Trigger DB Fanout Delays ID 1 print(176): /Equipment/MasterGM2/Settings/Globals Database Connection pgsql://g2db-priv:5433/gm2_online_prod gm2_writer gm2_4_writer print(177): /Equipment/MasterGM2/Settings/Globals Internal Trig Alarm Thresh (s) 30 print(178): /Equipment/MasterGM2/Settings/Globals T9A6Gap (ns) 8654175 trigger source 3 GPS 3 Buffers Used: 0, Buffers Capacity: 584 Waiting 3 s before starting CCC run ... CCC: Starting the run ... Started run 4 EOR received: End of run 4 CCC: Stopping the run ... TTS status at end of run CCC: RDY (BUSY - 0.0 msec ago) Master is the first in the sequence after all: 02/04/2024 14:44 I changed the ODB settings to even more closely match the UW setup: and However, nothing changed. 02/04/2024 14:49 I changed the method: MasterGM2/AMC1300.cpp:921 int FC7_check_run_state() { // get run state int run_in_progress = fc7lib->getRunState(5, 1, fc7[ (crate_info[0].ccc_amc_slot - 1) ], 0); if (run_in_progress == -1) { return -1; } // wait until the run has stopped int MAX_TRIES = 10; int tries = 0; while (run_in_progress == 1) { sleep(1); // pause // check run state run_in_progress = fc7lib->getRunState(5, 1, fc7[ (crate_info[0].ccc_amc_slot - 1) ], 0); if (run_in_progress == -1) { return -1; } tries++; if (tries > MAX_TRIES) { return -2; } } return 0; } // FC7_check_run_state int FC7_check_run_state() { // get run state int run_in_progress = fc7lib->getRunState(5, 1, fc7[ (crate_info[0].ccc_amc_slot - 1) ], 0); if (run_in_progress == -1) { return -1; } // wait until the run has stopped int MAX_TRIES = 10; int tries = 0; while (run_in_progress == 1) { sleep(1); // pause // check run state run_in_progress = fc7lib->getRunState(5, 1, fc7[ (crate_info[0].ccc_amc_slot - 1) ], 0); if (run_in_progress == -1) { return -1; } tries++; if (tries > MAX_TRIES) { return -2; } } return 0; } // FC7_check_run_state and MasterGM2/frontend.cpp:1187 switch (FC7_check_run_state()) { case -1: // Ethernet communication failure cm_msg(MERROR, __FUNCTION__, \"FC7-%02i: Unable to Verify Run has Stopped (Communication Failure)\", crate_info[0].ccc_amc_slot); break; case -2: // Run state stuck in progress cm_msg(MERROR, __FUNCTION__, \"FC7-%02i: Unable to Verify Run has Stopped (Run state still in progress)\", crate_info[0].ccc_amc_slot); break; default: // Otherwise do nothing break; } switch ( FC7_check_run_state ()) { case - 1 : // Ethernet communication failure cm_msg (MERROR, __FUNCTION__ , \"FC7-%02i: Unable to Verify Run has Stopped (Communication Failure)\" , crate_info[ 0 ].ccc_amc_slot); break ; case - 2 : // Run state stuck in progress cm_msg (MERROR, __FUNCTION__ , \"FC7-%02i: Unable to Verify Run has Stopped (Run state still in progress)\" , crate_info[ 0 ].ccc_amc_slot); break ; default : // Otherwise do nothing break ; } Before, there was no number of \"max tries\" which caught the the frontend in a loop when trying to end a run if run_in_progress is stuck at value 1. Why run_in_progress is not changing is beyong me, somehow the FC7 is not recieving and end of run signal(?) 02/04/2024 15:07 Any time I put the 1kHz trigger signal in D6 of the \"D Bank\" like so: I get the following errors when trying to start CaloReadoutAMC13: frontend_init(1923): AMC13 Not Ready 1/3: loc_tts = 4, should be 8 enc_tts = 8, should be 0 frontend_init(1900): AMC13 General Reset frontend_init(1908): AMC13 Counter Reset frontend_init(1915): AMC13 Final Status Check frontend_init(1923): AMC13 Not Ready 2/3: loc_tts = 4, should be 8 enc_tts = 8, should be 0 frontend_init(1900): AMC13 General Reset frontend_init(1908): AMC13 Counter Reset frontend_init(1915): AMC13 Final Status Check frontend_init(1923): AMC13 Not Ready 3/3: loc_tts = 4, should be 8 enc_tts = 8, should be 0 frontend_init ( 1923 ): AMC13 Not Ready 1 / 3 : loc_tts = 4 , should be 8 enc_tts = 8 , should be 0 frontend_init ( 1900 ): AMC13 General Reset frontend_init ( 1908 ): AMC13 Counter Reset frontend_init ( 1915 ): AMC13 Final Status Check frontend_init ( 1923 ): AMC13 Not Ready 2 / 3 : loc_tts = 4 , should be 8 enc_tts = 8 , should be 0 frontend_init ( 1900 ): AMC13 General Reset frontend_init ( 1908 ): AMC13 Counter Reset frontend_init ( 1915 ): AMC13 Final Status Check frontend_init ( 1923 ): AMC13 Not Ready 3 / 3 : loc_tts = 4 , should be 8 enc_tts = 8 , should be 0 Simply taking the trigger out of the \"D Bank\" seems to solve the problem, regardless if internal trigger mode is enabled or not. 04/04/2024 16:19 The meinberg card started complaining, supposedly after Tim tried to feed the trigger signal directly to it: [root@dhcp-10-163-105-238 ~]# mbgstatus mbgstatus v4.2.24 copyright Meinberg 2001-2023 TCR180PEX 039212025430 (FW 1.21, ASIC 9.00) at port 0xE000, irq 45 ** mbg_get_time failed: Input/output error (rc: -73) ** mbg_get_hr_time failed: Input/output error (rc: -73) ** mbg_get_irig_rx_info failed: Input/output error (rc: -73) ** mbg_get_ref_offs failed: Input/output error (rc: -73) ** mbg_get_sync_time failed: Input/output error (rc: -73) Signal: 0% (IRIG) Status info: *** NO INPUT SIGNAL Status info: *** Not synchronized after last RESET Status info: Clock is synchronized [root@dhcp-10-163-105-238 ~]# [root@dhcp-10-163-105-238 ~]# mbgstatus mbgstatus v4.2.24 copyright Meinberg 2001-2023 TCR180PEX 039212025430 (FW 1.21, ASIC 9.00) at port 0xE000, irq 45 ** mbg_get_time failed: Input/output error (rc: -73) ** mbg_get_hr_time failed: Input/output error (rc: -73) ** mbg_get_irig_rx_info failed: Input/output error (rc: -73) ** mbg_get_ref_offs failed: Input/output error (rc: -73) ** mbg_get_sync_time failed: Input/output error (rc: -73) Signal: 0% (IRIG) Status info: *** NO INPUT SIGNAL Status info: *** Not synchronized after last RESET Status info: Clock is synchronized [root@dhcp-10-163-105-238 ~]# I tried: echo 1 > /sys/bus/pci/devices/0000:02:00.0/reset echo 1 > /sys/bus/pci/devices/ 0000 : 02 : 00 . 0 /reset But no luck. After rebooting I remove these errors, getting the same staus as when I first loaded the drivers onto the card: [root@dhcp-10-163-105-238 ~]# mbgstatus mbgstatus v4.2.24 copyright Meinberg 2001-2023 TCR180PEX 039212025430 (FW 1.21, ASIC 9.00) at port 0xE000, irq 45 Date/time: Th, 2024-04-04 20:27:24.09 UTC Signal: 0% (IRIG B122/B123, ** UTC offs not configured **) Status info: *** NO INPUT SIGNAL Status info: *** Ref. Time is Invalid Last sync: We, 2023-10-04 11:36:55.00 UTC ** Warning: The IRIG receiver has not yet been configured! Please make sure the correct IRIG Code Format has been selected, and enter the correct IRIG Time Offset from UTC according to the settings of the IRIG generator. The command \"mbgirigcfg\" can be used to change the settings. [ root@dhcp-10-163-105-238 ~ ] # mbgstatus mbgstatus v4.2.24 copyright Meinberg 2001 -2023 TCR180PEX 039212025430 (FW 1.21 , ASIC 9.00 ) at port 0xE000 , irq 45 Date/time: Th, 2024-04-04 20 :27:24.09 UTC Signal: 0 % (IRIG B122/B123, ** UTC offs not configured **) Status info: *** NO INPUT SIGNAL Status info: *** Ref. Time is Invalid Last sync: We, 2023-10-04 11 :36:55.00 UTC ** Warning: The IRIG receiver has not yet been configured! Please make sure the correct IRIG Code Format has been selected, and enter the correct IRIG Time Offset from UTC according to the settings of the IRIG generator. The command \"mbgirigcfg\" can be used to change the settings. 04/04/2024 16:47 After plugging in an old g-2 10GbE NIC card into fe01 to check some details, I took it out and tried reclosing the system. I think I must have moved some components around because I got this error: After pressing down on some components in an attempt to reseat them, I tried again and got this error: The fans were also louder than normal. I then turned the computer upright and it suddenly began working again. 04/04/2024 16:58 It seems changing the AMC13 into \"DAQLink\" mode made is so we get past this error when trying to put in an external trigger: frontend_init(1923): AMC13 Not Ready 3/3: loc_tts = 4, should be 8 enc_tts = 8, should be 0 frontend_init ( 1923 ): AMC13 Not Ready 3 / 3 : loc_tts = 4 , should be 8 enc_tts = 8 , should be 0 But then I immediately get [AMC13001,ERROR] [frontend.cpp:2305:begin_of_run,ERROR] AMC13 Begin-of-Run Failed. loc_tts: 12, should be 8 enc_tts: 0, should be 0 daq_link: 0, should be 0 [AMC13001,ERROR] [frontend.cpp: 2305 : begin_of_run,ERROR] AMC13 Begin-of-Run Failed. loc_tts: 12 , should be 8 enc_tts: 0 , should be 0 daq_link: 0 , should be 0 instead I simply tried restarting the AMC13001 frontend and this time it work. I saw events in only AMC13001 at a rate of about 33Hz. 31/03/2024 15:56 Trying to follow steps in the readme here: https://github.com/Xilinx/dma_ip_drivers/tree/master/XDMA/linux-kernel I come across the same problem as before. [root@fe01 tests]# ./load_driver.sh interrupt_selection . xdma 87724 0 Loading driver...insmod xdma.ko interrupt_mode=2 ... Error: The Kernel module installed correctly, but no devices were recognized. FAILED [root@fe01 tests]# [root@fe01 tests]# ./load_driver.sh interrupt_selection . xdma 87724 0 Loading driver...insmod xdma.ko interrupt_mode=2 ... Error: The Kernel module installed correctly, but no devices were recognized. FAILED [root@fe01 tests]# The only difference is this time I tried it with the working PCIe 7-series block loaded onto the FPGA, instead of the DMA PCIe block that I couldn't get working. 01/04/2024 15:18 I changed some more ODB settings so they match the UW setup. Really all I did was turn everything to \"no\" here so we don't use the GPU: And then I also copied the FC7 encoder settings: 01/04/2024 15:20 Lawrence linked the firmware: AMC13T1v0x813f_7k325t.mcs So I downloaded that and moved it to 'be' with scp. Then I programmed the device using AMC13Tool: Pick an action (h for menu): pv Current Virtex firmware version: 0x8127 1) AMC13T1v0x810b_7k325t.mcs 2) AMC13T1v0x811f_7k325t.mcs 3) **AMC13T1v0x813f_7k325t.mcs** Select desired MCS file. Hit <CR> to select best highlighted option Type '1-3' to select or '0' for menu: 3 ./AMC13T1v0x813f_7k325t.mcs WARNING: you are about to reprogram flash memory. Are you sure? (y) y Erasing flash sector at address 0x400000 Erasing flash sector at address 0x440000 Erasing flash sector at address 0x480000 Erasing flash sector at address 0x4c0000 Erasing flash sector at address 0x500000 Erasing flash sector at address 0x540000 Erasing flash sector at address 0x580000 Erasing flash sector at address 0x5c0000 Erasing flash sector at address 0x600000 Erasing flash sector at address 0x640000 Erasing flash sector at address 0x680000 Erasing flash sector at address 0x6c0000 Erasing flash sector at address 0x700000 Erasing flash sector at address 0x740000 Erasing flash sector at address 0x780000 Erasing flash sector at address 0x7c0000 Erasing flash sector at address 0x800000 Erasing flash sector at address 0x840000 Erasing flash sector at address 0x880000 Erasing flash sector at address 0x8c0000 Erasing flash sector at address 0x900000 Erasing flash sector at address 0x940000 Erasing flash sector at address 0x980000 Erasing flash sector at address 0x9c0000 Erasing flash sector at address 0xa00000 Erasing flash sector at address 0xa40000 Erasing flash sector at address 0xa80000 Erasing flash sector at address 0xac0000 Erasing flash sector at address 0xb00000 Erasing flash sector at address 0xb40000 Erasing flash sector at address 0xb80000 Erasing flash sector at address 0xbc0000 Erasing flash sector at address 0xc00000 Erasing flash sector at address 0xc40000 Erasing flash sector at address 0xc80000 Erasing flash sector at address 0xcc0000 Erasing flash sector at address 0xd00000 Erasing flash sector at address 0xd40000 Erasing flash sector at address 0xd80000 Erasing flash sector at address 0xdc0000 Erasing flash sector at address 0xe00000 Erasing flash sector at address 0xe40000 Erasing flash sector at address 0xe80000 Erasing flash sector at address 0xec0000 programming flash at address 0xee9e00 programming flash at address 0xe2e700 % done = 6 programming flash at address 0xd72f00 % done = 13 programming flash at address 0xcb7700 % done = 20 programming flash at address 0xbfbf00 % done = 26 programming flash at address 0xb40700 % done = 33 programming flash at address 0xa84f00 % done = 40 programming flash at address 0x9c9700 % done = 47 programming flash at address 0x90df00 % done = 53 programming flash at address 0x852700 % done = 60 programming flash at address 0x796f00 % done = 67 programming flash at address 0x6db700 % done = 73 programming flash at address 0x61ff00 % done = 80 programming flash at address 0x564700 % done = 87 programming flash at address 0x4a8f00 % done = 94 reading flash at address 0x400000 reading flash at address 0x4bb700 % done = 6 reading flash at address 0x576f00 % done = 13 reading flash at address 0x632700 % done = 20 reading flash at address 0x6edf00 % done = 26 reading flash at address 0x7a9700 % done = 33 reading flash at address 0x864f00 % done = 40 reading flash at address 0x920700 % done = 47 reading flash at address 0x9dbf00 % done = 53 reading flash at address 0xa97700 % done = 60 reading flash at address 0xb52f00 % done = 67 reading flash at address 0xc0e700 % done = 73 reading flash at address 0xcc9f00 % done = 80 reading flash at address 0xd85700 % done = 87 reading flash at address 0xe40f00 % done = 94 Verifying flash against ./AMC13T1v0x813f_7k325t.mcs, num pages: 44702 Successfully verified flash programing: file = ./AMC13T1v0x813f_7k325t.mcs pages = 44702 Flash successfully programmed and verified. Load the new flash memory to the chips to complete firmware update Pick an action (h for menu): pv Current Virtex firmware version: 0x8127 1) AMC13T1v0x810b_7k325t.mcs 2) AMC13T1v0x811f_7k325t.mcs 3) **AMC13T1v0x813f_7k325t.mcs** Select desired MCS file. Hit <CR> to select best highlighted option Type '1-3' to select or '0' for menu: 3 ./AMC13T1v0x813f_7k325t.mcs WARNING: you are about to reprogram flash memory. Are you sure? (y) y Erasing flash sector at address 0x400000 Erasing flash sector at address 0x440000 Erasing flash sector at address 0x480000 Erasing flash sector at address 0x4c0000 Erasing flash sector at address 0x500000 Erasing flash sector at address 0x540000 Erasing flash sector at address 0x580000 Erasing flash sector at address 0x5c0000 Erasing flash sector at address 0x600000 Erasing flash sector at address 0x640000 Erasing flash sector at address 0x680000 Erasing flash sector at address 0x6c0000 Erasing flash sector at address 0x700000 Erasing flash sector at address 0x740000 Erasing flash sector at address 0x780000 Erasing flash sector at address 0x7c0000 Erasing flash sector at address 0x800000 Erasing flash sector at address 0x840000 Erasing flash sector at address 0x880000 Erasing flash sector at address 0x8c0000 Erasing flash sector at address 0x900000 Erasing flash sector at address 0x940000 Erasing flash sector at address 0x980000 Erasing flash sector at address 0x9c0000 Erasing flash sector at address 0xa00000 Erasing flash sector at address 0xa40000 Erasing flash sector at address 0xa80000 Erasing flash sector at address 0xac0000 Erasing flash sector at address 0xb00000 Erasing flash sector at address 0xb40000 Erasing flash sector at address 0xb80000 Erasing flash sector at address 0xbc0000 Erasing flash sector at address 0xc00000 Erasing flash sector at address 0xc40000 Erasing flash sector at address 0xc80000 Erasing flash sector at address 0xcc0000 Erasing flash sector at address 0xd00000 Erasing flash sector at address 0xd40000 Erasing flash sector at address 0xd80000 Erasing flash sector at address 0xdc0000 Erasing flash sector at address 0xe00000 Erasing flash sector at address 0xe40000 Erasing flash sector at address 0xe80000 Erasing flash sector at address 0xec0000 programming flash at address 0xee9e00 programming flash at address 0xe2e700 % done = 6 programming flash at address 0xd72f00 % done = 13 programming flash at address 0xcb7700 % done = 20 programming flash at address 0xbfbf00 % done = 26 programming flash at address 0xb40700 % done = 33 programming flash at address 0xa84f00 % done = 40 programming flash at address 0x9c9700 % done = 47 programming flash at address 0x90df00 % done = 53 programming flash at address 0x852700 % done = 60 programming flash at address 0x796f00 % done = 67 programming flash at address 0x6db700 % done = 73 programming flash at address 0x61ff00 % done = 80 programming flash at address 0x564700 % done = 87 programming flash at address 0x4a8f00 % done = 94 reading flash at address 0x400000 reading flash at address 0x4bb700 % done = 6 reading flash at address 0x576f00 % done = 13 reading flash at address 0x632700 % done = 20 reading flash at address 0x6edf00 % done = 26 reading flash at address 0x7a9700 % done = 33 reading flash at address 0x864f00 % done = 40 reading flash at address 0x920700 % done = 47 reading flash at address 0x9dbf00 % done = 53 reading flash at address 0xa97700 % done = 60 reading flash at address 0xb52f00 % done = 67 reading flash at address 0xc0e700 % done = 73 reading flash at address 0xcc9f00 % done = 80 reading flash at address 0xd85700 % done = 87 reading flash at address 0xe40f00 % done = 94 Verifying flash against ./AMC13T1v0x813f_7k325t.mcs, num pages: 44702 Successfully verified flash programing: file = ./AMC13T1v0x813f_7k325t.mcs pages = 44702 Flash successfully programmed and verified. Load the new flash memory to the chips to complete firmware update To load, I then ran: Pick an action (h for menu): L WARNING: you are about to reconfigure both spartan and virtex from flash memory. Are you sure? (y) y Wait 10 seconds to ensure the reconfiguration's completion: 0 Spartan and Virtex have been reconfigured from flash Pick an action (h for menu): L WARNING: you are about to reconfigure both spartan and virtex from flash memory. Are you sure? (y) y Wait 10 seconds to ensure the reconfiguration's completion: 0 Spartan and Virtex have been reconfigured from flash That messed with the connection to the AMC13 T1 and T2 somehow, so I had to set their IPs up again: cd /home/installation_testing/packages/experiment/lxedaq/amc13/amc13_v1_2_18/dev_tools/amc13Config ./applyConfig.py -i 192.168.1.13 cd /home/installation_testing/packages/experiment/lxedaq/amc13/amc13_v1_2_18/dev_tools/amc13Config ./applyConfig.py -i 192.168.1.13 and the IP for the 10GbE connection got reset to default so I had to change that back: Pick an action (h for menu): rv 0x1c1c Reading T1: 00001c1c: c0a80120 Pick an action (h for menu): wv 0x1c1c 0xc0a80196 Writing to T1: 00001c1c: c0a80196 Pick an action (h for menu): rv 0x1c1c Reading T 1 : 00001 c 1 c : c 0 a 80120 Pick an action (h for menu): wv 0x1c1c 0xc0a80196 Writing to T 1 : 00001 c 1 c : c 0 a 80196 I couldn't ping 192.168.1.150, so I tried running: Pick an action (h for menu): wv 0x3 0x1fff Pick an action (h for menu): wv 0 x3 0 x1fff But that wasn't enough, so I ran the whole ky_init script instead: Pick an action (h for menu): do amc13_scripts/ky_init.amc Pick an action (h for menu): do amc13_scripts/ky_init.amc then I was able to ping 192.168.1.150 again. I ran the frontends and encountered the exact same issues as before (but it complained about the firmware version, meaning it successfully updated!). 01/04/2024 16:09 I'm also updating the spartan firmware while I'm at it: cd /home/installation_testing/packages/experiment/lxedaq/amc13/amc13StandaloneMAN_2014-05-12 wget http://physics.bu.edu/~wusx/download/AMC13/AMC13T2v0x002e_6slx45t.mcs cd /home/i nstallation_testing /packages/ experiment /lxedaq/ amc13/amc13StandaloneMAN_2014- 05 - 12 wget http: // physics.bu.edu /~wusx/ download /AMC13/ AMC13T2v0x002e_6slx45t.mcs Then I just repeated everything I did above, this time I used the ps command in AMC13Tool instead. 01/04/2024 16:17 frontend_init(1900): AMC13 General Reset frontend_init(1908): AMC13 Counter Reset frontend_init(1915): AMC13 Final Status Check frontend_init(1923): AMC13 Not Ready 3/3: loc_tts = 2, should be 8 enc_tts = 0, should be 0 [AMC13001,ERROR] [frontend.cpp:1931:frontend_init,ERROR] AMC13 Initialization Failed frontend_init ( 1900 ) : AMC13 General Reset frontend_init ( 1908 ) : AMC13 Counter Reset frontend_init ( 1915 ) : AMC13 Final Status Check frontend_init ( 1923 ) : AMC13 Not Ready 3 / 3 : loc_tts = 2 , should be 8 enc_tts = 0 , should be 0 [AMC13001,ERROR] [frontend.cpp:1931:frontend_init,ERROR] AMC13 Initialization Failed I find myself getting this error a lot. It goes away after just waiting some time. I'm not sure what causes it. All I know is loc_tts corresponds to the node STATUS.T1_TTS_STATE so it has something to do with the TTS state in the Vintex (technically Kintex, whatever) FPGA. I remember this exact same error coming up when I worked on the Cornell DAQ remotely. 01/04/2024 16:22 After updating, we still have the same error. No data being produced and the master hanging when trying to end a run: MasterGM2 Buffers Used: 0, Buffers Capacity: 584 Frontend Initialization Complete OK BOR Received: Run 11 print(155): /Equipment/MasterGM2/Settings/Globals Trigger source GPS print(156): /Equipment/MasterGM2/Settings/Globals Socket trigger IP address 127.0.0.1 print(157): /Equipment/MasterGM2/Settings/Globals Socket trigger port 55000 print(158): /Equipment/MasterGM2/Settings/Globals Rate 12.000000 print(159): /Equipment/MasterGM2/Settings/Globals Fills per bunch 8 print(160): /Equipment/MasterGM2/Settings/Globals Readout name AMC13 print(161): /Equipment/MasterGM2/Settings/Globals Front End Offset 1 print(162): /Equipment/MasterGM2/Settings/Globals Simulator name CaloSimulatorAMC13 print(163): /Equipment/MasterGM2/Settings/Globals Encoder Front End AMC13001 print(164): /Equipment/MasterGM2/Settings/Globals Send to event builder 1 print(165): /Equipment/MasterGM2/Settings/Globals Verbose 0 print(166): /Equipment/MasterGM2/Settings/Globals CCC 1 print(167): /Equipment/MasterGM2/Settings/Globals Post MTCA Abort State to ECL 1 print(168): /Equipment/MasterGM2/Settings/Globals Preserve TTC Trigger Config 0 print(169): /Equipment/MasterGM2/Settings/Globals Preserve Analog Trigger Config 0 print(170): /Equipment/MasterGM2/Settings/Globals Enable Trigger DB 1 print(171): /Equipment/MasterGM2/Settings/Globals Trigger DB Analog A6 ID 1 print(172): /Equipment/MasterGM2/Settings/Globals Trigger DB Analog T9 ID 1 print(173): /Equipment/MasterGM2/Settings/Globals Trigger DB TTC ID 1 print(174): /Equipment/MasterGM2/Settings/Globals Trigger DB TTC Analog Pulse ID 1 print(175): /Equipment/MasterGM2/Settings/Globals Trigger DB Fanout Delays ID 1 print(176): /Equipment/MasterGM2/Settings/Globals Database Connection pgsql://g2db-priv:5433/gm2_online_prod gm2_writer gm2_4_writer print(177): /Equipment/MasterGM2/Settings/Globals Internal Trig Alarm Thresh (s) 30 print(178): /Equipment/MasterGM2/Settings/Globals T9A6Gap (ns) 8654175 trigger source 3 GPS 3 Buffers Used: 0, Buffers Capacity: 584 Waiting 3 s before starting CCC run ... CCC: Starting the run ... Started run 11 EOR received: End of run 11 CCC: Stopping the run ... TTS status at end of run CCC: RDY (BUSY - 0.0 msec ago) Buffers Used: 0, Buffers Capacity: 584 Frontend Initialization Complete OK BOR Received: Run 11 print(155): /Equipment/MasterGM2/Settings/Globals Trigger source GPS print(156): /Equipment/MasterGM2/Settings/Globals Socket trigger IP address 127.0.0.1 print(157): /Equipment/MasterGM2/Settings/Globals Socket trigger port 55000 print(158): /Equipment/MasterGM2/Settings/Globals Rate 12.000000 print(159): /Equipment/MasterGM2/Settings/Globals Fills per bunch 8 print(160): /Equipment/MasterGM2/Settings/Globals Readout name AMC13 print(161): /Equipment/MasterGM2/Settings/Globals Front End Offset 1 print(162): /Equipment/MasterGM2/Settings/Globals Simulator name CaloSimulatorAMC13 print(163): /Equipment/MasterGM2/Settings/Globals Encoder Front End AMC13001 print(164): /Equipment/MasterGM2/Settings/Globals Send to event builder 1 print(165): /Equipment/MasterGM2/Settings/Globals Verbose 0 print(166): /Equipment/MasterGM2/Settings/Globals CCC 1 print(167): /Equipment/MasterGM2/Settings/Globals Post MTCA Abort State to ECL 1 print(168): /Equipment/MasterGM2/Settings/Globals Preserve TTC Trigger Config 0 print(169): /Equipment/MasterGM2/Settings/Globals Preserve Analog Trigger Config 0 print(170): /Equipment/MasterGM2/Settings/Globals Enable Trigger DB 1 print(171): /Equipment/MasterGM2/Settings/Globals Trigger DB Analog A6 ID 1 print(172): /Equipment/MasterGM2/Settings/Globals Trigger DB Analog T9 ID 1 print(173): /Equipment/MasterGM2/Settings/Globals Trigger DB TTC ID 1 print(174): /Equipment/MasterGM2/Settings/Globals Trigger DB TTC Analog Pulse ID 1 print(175): /Equipment/MasterGM2/Settings/Globals Trigger DB Fanout Delays ID 1 print(176): /Equipment/MasterGM2/Settings/Globals Database Connection pgsql://g2db-priv:5433/gm2_online_prod gm2_writer gm2_4_writer print(177): /Equipment/MasterGM2/Settings/Globals Internal Trig Alarm Thresh (s) 30 print(178): /Equipment/MasterGM2/Settings/Globals T9A6Gap (ns) 8654175 trigger source 3 GPS 3 Buffers Used: 0, Buffers Capacity: 584 Waiting 3 s before starting CCC run ... CCC: Starting the run ... Started run 11 EOR received: End of run 11 CCC: Stopping the run ... TTS status at end of run CCC: RDY (BUSY - 0.0 msec ago) CaloReadoutAMC13 OK BOR Received: Run 11 Finished ODB enabled checksmake map between detector array and module, channelsitq = 0 Rider 5...Enabled im = 4, ic = 0, ix = 5, iy = 1 calo segment x,y 5, 1 map_from_caloxy_to_ridermodchan 20 im = 4, ic = 1, ix = 5, iy = 2 calo segment x,y 5, 2 map_from_caloxy_to_ridermodchan 21 im = 4, ic = 2, ix = 5, iy = 3 calo segment x,y 5, 3 map_from_caloxy_to_ridermodchan 22 im = 4, ic = 3, ix = 5, iy = 4 calo segment x,y 5, 4 map_from_caloxy_to_ridermodchan 23 im = 4, ic = 4, ix = 5, iy = 5 calo segment x,y 5, 5 map_from_caloxy_to_ridermodchan 24 make map between detector array and module, channelsitq = 1 Rider 5...Enabled im = 4, ic = 0, ix = 5, iy = 1 calo segment x,y 5, 1 map_from_caloxy_to_ridermodchan 20 im = 4, ic = 1, ix = 5, iy = 2 calo segment x,y 5, 2 map_from_caloxy_to_ridermodchan 21 im = 4, ic = 2, ix = 5, iy = 3 calo segment x,y 5, 3 map_from_caloxy_to_ridermodchan 22 im = 4, ic = 3, ix = 5, iy = 4 calo segment x,y 5, 4 map_from_caloxy_to_ridermodchan 23 im = 4, ic = 4, ix = 5, iy = 5 calo segment x,y 5, 5 map_from_caloxy_to_ridermodchan 24 make map between detector array and module, channelsitq = 2 Rider 5...Enabled im = 4, ic = 0, ix = 5, iy = 1 calo segment x,y 5, 1 map_from_caloxy_to_ridermodchan 20 im = 4, ic = 1, ix = 5, iy = 2 calo segment x,y 5, 2 map_from_caloxy_to_ridermodchan 21 im = 4, ic = 2, ix = 5, iy = 3 calo segment x,y 5, 3 map_from_caloxy_to_ridermodchan 22 im = 4, ic = 3, ix = 5, iy = 4 calo segment x,y 5, 4 map_from_caloxy_to_ridermodchan 23 im = 4, ic = 4, ix = 5, iy = 5 calo segment x,y 5, 5 map_from_caloxy_to_ridermodchan 24 make map between detector array and module, channelsitq = 3 Rider 5...Enabled im = 4, ic = 0, ix = 5, iy = 1 calo segment x,y 5, 1 map_from_caloxy_to_ridermodchan 20 im = 4, ic = 1, ix = 5, iy = 2 calo segment x,y 5, 2 map_from_caloxy_to_ridermodchan 21 im = 4, ic = 2, ix = 5, iy = 3 calo segment x,y 5, 3 map_from_caloxy_to_ridermodchan 22 im = 4, ic = 3, ix = 5, iy = 4 calo segment x,y 5, 4 map_from_caloxy_to_ridermodchan 23 im = 4, ic = 4, ix = 5, iy = 5 calo segment x,y 5, 5 map_from_caloxy_to_ridermodchan 24 --> entering setMasterRegister to write node CBUF.ACQUIRE --> entering getMasterRegister to read node CBUF.ACQUIRE <-- leaving getMasterRegister after success <-- leaving getMasterRegister after success begin_of_run_wfd(2080): Slot 05: Read: Channel FPGA 0 Buffer Size --> entering getMasterRegister to read node STATUS.BUFFER0 <-- leaving getMasterRegister after success begin_of_run_wfd(2093): Slot 05: Read: Channel FPGA 0 Firmware Version begin_of_run_wfd(2080): Slot 05: Read: Channel FPGA 1 Buffer Size --> entering getMasterRegister to read node STATUS.BUFFER1 <-- leaving getMasterRegister after success begin_of_run_wfd(2093): Slot 05: Read: Channel FPGA 1 Firmware Version begin_of_run_wfd(2080): Slot 05: Read: Channel FPGA 2 Buffer Size --> entering getMasterRegister to read node STATUS.BUFFER2 <-- leaving getMasterRegister after success begin_of_run_wfd(2093): Slot 05: Read: Channel FPGA 2 Firmware Version begin_of_run_wfd(2080): Slot 05: Read: Channel FPGA 3 Buffer Size --> entering getMasterRegister to read node STATUS.BUFFER3 <-- leaving getMasterRegister after success begin_of_run_wfd(2093): Slot 05: Read: Channel FPGA 3 Firmware Version begin_of_run_wfd(2080): Slot 05: Read: Channel FPGA 4 Buffer Size --> entering getMasterRegister to read node STATUS.BUFFER4 <-- leaving getMasterRegister after success begin_of_run_wfd(2093): Slot 05: Read: Channel FPGA 4 Firmware Version TTC ASYNC FROM ODB: 0 prescale factor: 20 tcp_thread(622): start read of new event, fill 0, buffer 0 tcp_client_bor(481): begin-of-run TCP fill number 0 ReadXBytes(875): ReadXBytes :: x = 8 Entered setThrottleTriggers from frontend 1 with value 0 Started run 11 ReadXBytes(919): socket file descriptor 24, request 8 bytes, read 0 bytes, tries 1000 tcp_thread(622): start read of new event, fill 0, buffer 0 ReadXBytes(875): ReadXBytes :: x = 8 ... OK BOR Received: Run 11 Finished ODB enabled checksmake map between detector array and module, channelsitq = 0 Rider 5...Enabled im = 4, ic = 0, ix = 5, iy = 1 calo segment x,y 5, 1 map_from_caloxy_to_ridermodchan 20 im = 4, ic = 1, ix = 5, iy = 2 calo segment x,y 5, 2 map_from_caloxy_to_ridermodchan 21 im = 4, ic = 2, ix = 5, iy = 3 calo segment x,y 5, 3 map_from_caloxy_to_ridermodchan 22 im = 4, ic = 3, ix = 5, iy = 4 calo segment x,y 5, 4 map_from_caloxy_to_ridermodchan 23 im = 4, ic = 4, ix = 5, iy = 5 calo segment x,y 5, 5 map_from_caloxy_to_ridermodchan 24 make map between detector array and module, channelsitq = 1 Rider 5...Enabled im = 4, ic = 0, ix = 5, iy = 1 calo segment x,y 5, 1 map_from_caloxy_to_ridermodchan 20 im = 4, ic = 1, ix = 5, iy = 2 calo segment x,y 5, 2 map_from_caloxy_to_ridermodchan 21 im = 4, ic = 2, ix = 5, iy = 3 calo segment x,y 5, 3 map_from_caloxy_to_ridermodchan 22 im = 4, ic = 3, ix = 5, iy = 4 calo segment x,y 5, 4 map_from_caloxy_to_ridermodchan 23 im = 4, ic = 4, ix = 5, iy = 5 calo segment x,y 5, 5 map_from_caloxy_to_ridermodchan 24 make map between detector array and module, channelsitq = 2 Rider 5...Enabled im = 4, ic = 0, ix = 5, iy = 1 calo segment x,y 5, 1 map_from_caloxy_to_ridermodchan 20 im = 4, ic = 1, ix = 5, iy = 2 calo segment x,y 5, 2 map_from_caloxy_to_ridermodchan 21 im = 4, ic = 2, ix = 5, iy = 3 calo segment x,y 5, 3 map_from_caloxy_to_ridermodchan 22 im = 4, ic = 3, ix = 5, iy = 4 calo segment x,y 5, 4 map_from_caloxy_to_ridermodchan 23 im = 4, ic = 4, ix = 5, iy = 5 calo segment x,y 5, 5 map_from_caloxy_to_ridermodchan 24 make map between detector array and module, channelsitq = 3 Rider 5...Enabled im = 4, ic = 0, ix = 5, iy = 1 calo segment x,y 5, 1 map_from_caloxy_to_ridermodchan 20 im = 4, ic = 1, ix = 5, iy = 2 calo segment x,y 5, 2 map_from_caloxy_to_ridermodchan 21 im = 4, ic = 2, ix = 5, iy = 3 calo segment x,y 5, 3 map_from_caloxy_to_ridermodchan 22 im = 4, ic = 3, ix = 5, iy = 4 calo segment x,y 5, 4 map_from_caloxy_to_ridermodchan 23 im = 4, ic = 4, ix = 5, iy = 5 calo segment x,y 5, 5 map_from_caloxy_to_ridermodchan 24 --> entering setMasterRegister to write node CBUF.ACQUIRE --> entering getMasterRegister to read node CBUF.ACQUIRE <-- leaving getMasterRegister after success <-- leaving getMasterRegister after success begin_of_run_wfd(2080): Slot 05: Read: Channel FPGA 0 Buffer Size --> entering getMasterRegister to read node STATUS.BUFFER0 <-- leaving getMasterRegister after success begin_of_run_wfd(2093): Slot 05: Read: Channel FPGA 0 Firmware Version begin_of_run_wfd(2080): Slot 05: Read: Channel FPGA 1 Buffer Size --> entering getMasterRegister to read node STATUS.BUFFER1 <-- leaving getMasterRegister after success begin_of_run_wfd(2093): Slot 05: Read: Channel FPGA 1 Firmware Version begin_of_run_wfd(2080): Slot 05: Read: Channel FPGA 2 Buffer Size --> entering getMasterRegister to read node STATUS.BUFFER2 <-- leaving getMasterRegister after success begin_of_run_wfd(2093): Slot 05: Read: Channel FPGA 2 Firmware Version begin_of_run_wfd(2080): Slot 05: Read: Channel FPGA 3 Buffer Size --> entering getMasterRegister to read node STATUS.BUFFER3 <-- leaving getMasterRegister after success begin_of_run_wfd(2093): Slot 05: Read: Channel FPGA 3 Firmware Version begin_of_run_wfd(2080): Slot 05: Read: Channel FPGA 4 Buffer Size --> entering getMasterRegister to read node STATUS.BUFFER4 <-- leaving getMasterRegister after success begin_of_run_wfd(2093): Slot 05: Read: Channel FPGA 4 Firmware Version TTC ASYNC FROM ODB: 0 prescale factor: 20 tcp_thread(622): start read of new event, fill 0, buffer 0 tcp_client_bor(481): begin-of-run TCP fill number 0 ReadXBytes(875): ReadXBytes :: x = 8 Entered setThrottleTriggers from frontend 1 with value 0 Started run 11 ReadXBytes(919): socket file descriptor 24, request 8 bytes, read 0 bytes, tries 1000 tcp_thread(622): start read of new event, fill 0, buffer 0 ReadXBytes(875): ReadXBytes :: x = 8 ... After forcefully closing the Master: tcp_client_eor(505): end-of-run TCP fill number 0 --> entering setMasterRegister to write node CBUF.ACQUIRE --> entering getMasterRegister to read node CBUF.ACQUIRE <-- leaving getMasterRegister after success <-- leaving getMasterRegister after success ReadXBytes(919): socket file descriptor 24, request 8 bytes, read 0 bytes, tries 1000 Run stopped tcp_client_eor( 505 ): end - of -run TCP fill number 0 --> entering setMasterRegister to write node CBUF.ACQUIRE --> entering getMasterRegister to read node CBUF.ACQUIRE < -- leaving getMasterRegister after success < -- leaving getMasterRegister after success ReadXBytes( 919 ): socket file descriptor 24 , request 8 bytes , read 0 bytes , tries 1000 Run stopped 03/04/2024 13:08 By adding this line: [root@dhcp-10-163-105-238 subprocess_scripts]# cat /root/.screenrc shell -/bin/bash -c \"export LD_LIBRARY_PATH=$LD_LIBRARY_PATH && exec /bin/bash\" [root@dhcp-10-163-105-238 subprocess_scripts]# [root@dhcp -10 -163 -105 -238 subprocess_scripts]# cat /root/.screenrc shell -/bin/bash -c \"export LD_LIBRARY_PATH=$LD_LIBRARY_PATH && exec /bin/bash\" [root@dhcp -10 -163 -105 -238 subprocess_scripts]# And also adding the bottom line to .bashrc: [root@dhcp-10-163-105-238 subprocess_scripts]# cat /root/.bashrc # .bashrc # User specific aliases and functions alias rm='rm -i' alias cp='cp -i' alias mv='mv -i' # Source global definitions if [ -f /etc/bashrc ]; then . /etc/bashrc fi source /home/installation_testing/packages/experiment/lxedaq/environment_setup/setup_environment.sh --silent [root@dhcp-10-163-105-238 subprocess_scripts]# [root@dhcp-10-163-105-238 subprocess_scripts] # cat /root/.bashrc # .bashrc # User specific aliases and functions alias rm = 'rm -i' alias cp = 'cp -i' alias mv = 'mv -i' # Source global definitions if [ -f /etc/bashrc ]; then . /etc/bashrc fi source /home/installation_testing/packages/experiment/lxedaq/environment_setup/setup_environment.sh --silent [root@dhcp-10-163-105-238 subprocess_scripts] # I'm able to screen the master and amc13001 frontends with the following commands cd /home/installation_testing/packages/experiment/lxedaq/frontends/MasterGM2 ./start-fe-uky.sh DAQ master cd /home/installation_testing/packages/experiment/lxedaq/frontends/CaloReadoutAMC13 ./start-fe-uky.sh 1 DAQ amc13001 cd /home/i nstallation_testing /packages/ experiment /lxedaq/ frontends/MasterGM2 ./start-fe-uky.sh DAQ master cd /home/i nstallation_testing /packages/ experiment /lxedaq/ frontends/CaloReadoutAMC13 ./start-fe-uky.sh 1 DAQ amc13001 to make it so you can just click the program in midas, I changed the following settings:",
    "textLength": 8368
  },
  {
    "kind": "work-log",
    "title": "17_03_2024 - 23_03_2024.html",
    "fileName": "17_03_2024 - 23_03_2024.html",
    "url": "resources/work_logs/17_03_2024 - 23_03_2024.html",
    "createdDate": "2024-03-17",
    "text": "17/03/2024 - 23/03/2024 17/03/2024 - 23/03/2024 17/03/2024 22:07 I found the reason and \"solution\" for this change: Change the magic number in this function to correspond to our IP. I hate this code the more I read it. MasterGM2/frontend.cpp:595 +strcpy(master_settings_odb.encoder_fe, \"AMC13000\"); MasterGM2/frontend .cpp : 595 + strcpy (master_settings_odb.encoder_fe, \"AMC13000\" ); overwrite this setting that was set to \"AMC1300\" as opposed to \"AMC13000\" I'm not sure where it originally gets set. I think the extra 0 is a result of Lawrence's hijinx to make frontends have 3 digits as opposed to 2. First off, the reason this change needs to be made is because the change to midas to allow frontends to have 3 digit labels. mfe.cxx line 2580: sprintf(full_frontend_name + strlen(full_frontend_name), \"%02d\", frontend_index); --> >sprintf(full_frontend_name + strlen(full_frontend_name), \"%03d\", frontend_index); But, the master_Settings_odb.encoder_fe is actually the ODB setting under Equipment/MasterGM2/Settings/Globals/Encoder Front End . To make everything \"work\" as Lawrence intended I had to do a few things: Setup environment cd /home/installation_testing/packages/experiment/lxedaq/environment_setup source ./setup_environment.sh cd /home/installation_testing/packages/experiment/lxedaq/environment_setup source ./setup_environment.sh Nuke the ODB $MIDASSYS/bin/odbinit -s 1024MB --cleanup $MIDASSYS /bin/ odbinit -s 1024 MB --cleanup Initialize ODB First let's generate the MasterGM2 settings: cd /home/installation_testing/packages/experiment/lxedaq/frontends/CaloReadoutAMC13 ./frontend -e DAQ cd /home/i nstallation_testing /packages/ experiment /lxedaq/ frontends/CaloReadoutAMC13 ./frontend -e DAQ It should crash, but generate the ODB path Equipment/MasterGM2/Settings/Globals . Under this path, change Front End Offset to 1 and Encoder Front End to AMC13001. Now we move on to initializing the AMC13001 frontend. Make sure /home/installation_testing/packages/experiment/lxedaq/frontends/AMC13xx_config.xml looks something like below (notice frontend id=\"0\" ) <?xml version=\"1.0\" encoding=\"UTF-8\"?> <frontend id=\"0\"> <slot id=\"5\" type=\"WFD\" /> <slot id=\"11\" type=\"FC7\" /> </frontend> <?xml version= \"1.0\" encoding= \"UTF-8\" ?> < frontend id = \"0\" > < slot id = \"5\" type = \"WFD\" /> < slot id = \"11\" type = \"FC7\" /> </ frontend > Then run cd /home/installation_testing/packages/experiment/lxedaq/frontends/ ./initialize_ODB.sh cd /home/i nstallation_testing /packages/ experiment /lxedaq/ frontends/ ./initialize_ODB.sh Rename Equipment/AMC13000 --> Equipment/AMC13001 in the ODB, the run: cd /home/installation_testing/packages/experiment/lxedaq/frontends/CaloReadoutAMC13 ./frontend -i 1 -e DAQ cd /home/i nstallation_testing /packages/ experiment /lxedaq/ frontends/CaloReadoutAMC13 ./frontend -i 1 -e DAQ this will fill AMC13001 with the proper Settings, Common, Variables, Statistics, and Monitors information. Finally, change /home/installation_testing/packages/experiment/lxedaq/frontends/AMC13xx_config.xml frontend id to look something like below <?xml version=\"1.0\" encoding=\"UTF-8\"?> <frontend id=\"1\"> <slot id=\"5\" type=\"WFD\" /> <slot id=\"11\" type=\"FC7\" /> </frontend> <?xml version= \"1.0\" encoding= \"UTF-8\" ?> < frontend id = \"1\" > < slot id = \"5\" type = \"WFD\" /> < slot id = \"11\" type = \"FC7\" /> </ frontend > 4.Now we can run the master frontend without hardcoding the frontend number cd /home/installation_testing/packages/experiment/lxedaq/frontends/CaloReadoutAMC13 ./frontend -e DAQ cd /home/i nstallation_testing /packages/ experiment /lxedaq/ frontends/CaloReadoutAMC13 ./frontend -e DAQ Currently, I'm still stuck with the SFP port error: FC7 Initialization Started FC7_init(174): FC7 Board Presence Check FC7_init(190): Slot 11: Read FC7 IP Address: 192.168.1.11 FC7_init(241): FC7 Ethernet Communication Check: 1/1 FC7_init(288): Slot 11: FC7 Firmware Hard Reset FC7_init(298): Waiting 5 s ... FC7_init(410): Slot 11: Write: Enabled Top SFP Ports top: 1, enable: 1 FC7_init(420): Waiting 15 s ... top_mask[10]: 1 FC7_init(450): Slot 11: Read: Enabled Top SFP Ports: 0 [MasterGM2,ERROR] [AMC1300.cpp:451:FC7_init,ERROR] /AMC1300/Settings/FC7-11/: Enabled Top SFP Ports Failure [MasterGM2,ERROR] [frontend.cpp:904:frontend_init,ERROR] FC7 Initialization Failed FC7 Initialization Started FC7_init ( 174 ) : FC7 Board Presence Check FC7_init ( 190 ) : Slot 11 : Read FC7 IP Address: 192.168 . 1.11 FC7_init ( 241 ) : FC7 Ethernet Communication Check: 1 / 1 FC7_init ( 288 ) : Slot 11 : FC7 Firmware Hard Reset FC7_init ( 298 ) : Waiting 5 s ... FC7_init ( 410 ) : Slot 11 : Write: Enabled Top SFP Ports top : 1 , enable: 1 FC7_init ( 420 ) : Waiting 15 s ... top_mask [10] : 1 FC7_init ( 450 ) : Slot 11 : Read: Enabled Top SFP Ports: 0 [MasterGM2,ERROR] [AMC1300.cpp:451:FC7_init,ERROR] /AMC1300/Settings/FC7- 11 /: Enabled Top SFP Ports Failure [MasterGM2,ERROR] [frontend.cpp:904:frontend_init,ERROR] FC7 Initialization Failed 18/03/2024 01:52 I tried to reprogram the device with 2GB of bar memory instead of 512KB. I don't think it was sucessful, but 'fe01' did see the device as a PCIe device [root@fe01 pcimem]# lspci -vv | grep -A 40 \"04:00.0\" pcilib: sysfs_read_vpd: read failed: Input/output error 04:00.0 Memory controller: Xilinx Corporation Device 7024 Subsystem: Xilinx Corporation Device 0007 Control: I/O- Mem- BusMaster- SpecCycle- MemWINV- VGASnoop- ParErr- Stepping- SERR- FastB2B- DisINTx- Status: Cap+ 66MHz- UDF- FastB2B- ParErr- DEVSEL=fast >TAbort- <TAbort- <MAbort- >SERR- <PERR- INTx- Interrupt: pin A routed to IRQ 35 Capabilities: [40] Power Management version 3 Flags: PMEClk- DSI- D1- D2- AuxCurrent=0mA PME(D0+,D1+,D2+,D3hot+,D3cold-) Status: D0 NoSoftRst+ PME-Enable- DSel=0 DScale=0 PME- Capabilities: [48] MSI: Enable- Count=1/1 Maskable- 64bit+ Address: 0000000000000000 Data: 0000 Capabilities: [60] Express (v2) Endpoint, MSI 00 DevCap: MaxPayload 512 bytes, PhantFunc 0, Latency L0s <64ns, L1 unlimited ExtTag- AttnBtn- AttnInd- PwrInd- RBE+ FLReset- SlotPowerLimit 225.000W DevCtl: Report errors: Correctable- Non-Fatal+ Fatal+ Unsupported- RlxdOrd+ ExtTag- PhantFunc- AuxPwr- NoSnoop+ MaxPayload 256 bytes, MaxReadReq 512 bytes DevSta: CorrErr- UncorrErr+ FatalErr- UnsuppReq+ AuxPwr- TransPend- LnkCap: Port #0, Speed 5GT/s, Width x4, ASPM L0s, Exit Latency L0s unlimited, L1 unlimited ClockPM- Surprise- LLActRep- BwNot- ASPMOptComp- LnkCtl: ASPM Disabled; RCB 64 bytes Disabled- CommClk+ ExtSynch- ClockPM- AutWidDis- BWInt- AutBWInt- LnkSta: Speed 5GT/s, Width x4, TrErr- Train- SlotClk+ DLActive- BWMgmt- ABWMgmt- DevCap2: Completion Timeout: Range B, TimeoutDis-, LTR-, OBFF Not Supported DevCtl2: Completion Timeout: 50us to 50ms, TimeoutDis-, LTR-, OBFF Disabled LnkCtl2: Target Link Speed: 5GT/s, EnterCompliance- SpeedDis- Transmit Margin: Normal Operating Range, EnterModifiedCompliance- ComplianceSOS- Compliance De-emphasis: -6dB LnkSta2: Current De-emphasis Level: -6dB, EqualizationComplete-, EqualizationPhase1- EqualizationPhase2-, EqualizationPhase3-, LinkEqualizationRequest- Capabilities: [100 v1] Device Serial Number 00-00-00-01-01-00-0a-35 Kernel modules: xdma [root@fe01 pcimem]# lspci -vv | grep -A 40 \"04:00.0\" pcilib: sysfs_read_vpd: read failed: Input/output error 04:00.0 Memory controller: Xilinx Corporation Device 7024 Subsystem: Xilinx Corporation Device 0007 Control: I/O- Mem- BusMaster- SpecCycle- MemWINV- VGASnoop- ParErr- Stepping- SERR- FastB2B- DisINTx- Status: Cap+ 66MHz- UDF- FastB2B- ParErr- DEVSEL=fast >TAbort- <TAbort- <MAbort- >SERR- <PERR- INTx- Interrupt: pin A routed to IRQ 35 Capabilities: [40] Power Management version 3 Flags: PMEClk- DSI- D1- D2- AuxCurrent=0mA PME(D0+,D1+,D2+,D3hot+,D3cold-) Status: D0 NoSoftRst+ PME-Enable- DSel=0 DScale=0 PME- Capabilities: [48] MSI: Enable- Count=1/1 Maskable- 64bit+ Address: 0000000000000000 Data: 0000 Capabilities: [60] Express (v2) Endpoint, MSI 00 DevCap: MaxPayload 512 bytes, PhantFunc 0, Latency L0s <64ns, L1 unlimited ExtTag- AttnBtn- AttnInd- PwrInd- RBE+ FLReset- SlotPowerLimit 225.000W DevCtl: Report errors: Correctable- Non-Fatal+ Fatal+ Unsupported- RlxdOrd+ ExtTag- PhantFunc- AuxPwr- NoSnoop+ MaxPayload 256 bytes, MaxReadReq 512 bytes DevSta: CorrErr- UncorrErr+ FatalErr- UnsuppReq+ AuxPwr- TransPend- LnkCap: Port #0, Speed 5GT/s, Width x4, ASPM L0s, Exit Latency L0s unlimited, L1 unlimited ClockPM- Surprise- LLActRep- BwNot- ASPMOptComp- LnkCtl: ASPM Disabled; RCB 64 bytes Disabled- CommClk+ ExtSynch- ClockPM- AutWidDis- BWInt- AutBWInt- LnkSta: Speed 5GT/s, Width x4, TrErr- Train- SlotClk+ DLActive- BWMgmt- ABWMgmt- DevCap2: Completion Timeout: Range B, TimeoutDis-, LTR-, OBFF Not Supported DevCtl2: Completion Timeout: 50us to 50ms, TimeoutDis-, LTR-, OBFF Disabled LnkCtl2: Target Link Speed: 5GT/s, EnterCompliance- SpeedDis- Transmit Margin: Normal Operating Range, EnterModifiedCompliance- ComplianceSOS- Compliance De-emphasis: -6dB LnkSta2: Current De-emphasis Level: -6dB, EqualizationComplete-, EqualizationPhase1- EqualizationPhase2-, EqualizationPhase3-, LinkEqualizationRequest- Capabilities: [100 v1] Device Serial Number 00-00-00-01-01-00-0a-35 Kernel modules: xdma Notice there's no specified region (as opposed to below, where there's a 512K \"Region 0\"): [root@fe01 pcimem]# lspci -vv | grep -A 34 \"04:00.0\" 04:00.0 Memory controller: Xilinx Corporation Device 7024 Subsystem: Xilinx Corporation Device 0007 Control: I/O+ Mem+ BusMaster+ SpecCycle- MemWINV- VGASnoop- ParErr- Stepping- SERR- FastB2B- DisINTx- Status: Cap+ 66MHz- UDF- FastB2B- ParErr- DEVSEL=fast >TAbort- <TAbort- <MAbort- >SERR- <PERR- INTx- Latency: 0, Cache Line Size: 64 bytes Interrupt: pin A routed to IRQ 11 Region 0: Memory at f5f80000 (32-bit, non-prefetchable) [size=512K] Capabilities: [40] Power Management version 3 Flags: PMEClk- DSI- D1- D2- AuxCurrent=0mA PME(D0+,D1+,D2+,D3hot+,D3cold-) Status: D0 NoSoftRst+ PME-Enable- DSel=0 DScale=0 PME- Capabilities: [48] MSI: Enable- Count=1/1 Maskable- 64bit+ Address: 0000000000000000 Data: 0000 Capabilities: [60] Express (v2) Endpoint, MSI 00 DevCap: MaxPayload 512 bytes, PhantFunc 0, Latency L0s <64ns, L1 unlimited ExtTag- AttnBtn- AttnInd- PwrInd- RBE+ FLReset- SlotPowerLimit 225.000W DevCtl: Report errors: Correctable- Non-Fatal+ Fatal+ Unsupported- RlxdOrd+ ExtTag- PhantFunc- AuxPwr- NoSnoop+ MaxPayload 256 bytes, MaxReadReq 512 bytes DevSta: CorrErr- UncorrErr- FatalErr- UnsuppReq- AuxPwr- TransPend- LnkCap: Port #0, Speed 5GT/s, Width x4, ASPM L0s, Exit Latency L0s unlimited, L1 unlimited ClockPM- Surprise- LLActRep- BwNot- ASPMOptComp- LnkCtl: ASPM Disabled; RCB 64 bytes Disabled- CommClk+ ExtSynch- ClockPM- AutWidDis- BWInt- AutBWInt- LnkSta: Speed 5GT/s, Width x4, TrErr- Train- SlotClk+ DLActive- BWMgmt- ABWMgmt- DevCap2: Completion Timeout: Range B, TimeoutDis-, LTR-, OBFF Not Supported DevCtl2: Completion Timeout: 50us to 50ms, TimeoutDis-, LTR-, OBFF Disabled LnkCtl2: Target Link Speed: 5GT/s, EnterCompliance- SpeedDis- Transmit Margin: Normal Operating Range, EnterModifiedCompliance- ComplianceSOS- Compliance De-emphasis: -6dB LnkSta2: Current De-emphasis Level: -6dB, EqualizationComplete-, EqualizationPhase1- EqualizationPhase2-, EqualizationPhase3-, LinkEqualizationRequest- Capabilities: [100 v1] Device Serial Number 00-00-00-01-01-00-0a-35 [root@fe01 pcimem]# lspci -vv | grep -A 34 \"04:00.0\" 04:00.0 Memory controller: Xilinx Corporation Device 7024 Subsystem: Xilinx Corporation Device 0007 Control: I/O+ Mem+ BusMaster+ SpecCycle- MemWINV- VGASnoop- ParErr- Stepping- SERR- FastB2B- DisINTx- Status: Cap+ 66MHz- UDF- FastB2B- ParErr- DEVSEL=fast >TAbort- <TAbort- <MAbort- >SERR- <PERR- INTx- Latency: 0, Cache Line Size: 64 bytes Interrupt: pin A routed to IRQ 11 Region 0: Memory at f5f80000 (32-bit, non-prefetchable) [size=512K] Capabilities: [40] Power Management version 3 Flags: PMEClk- DSI- D1- D2- AuxCurrent=0mA PME(D0+,D1+,D2+,D3hot+,D3cold-) Status: D0 NoSoftRst+ PME-Enable- DSel=0 DScale=0 PME- Capabilities: [48] MSI: Enable- Count=1/1 Maskable- 64bit+ Address: 0000000000000000 Data: 0000 Capabilities: [60] Express (v2) Endpoint, MSI 00 DevCap: MaxPayload 512 bytes, PhantFunc 0, Latency L0s <64ns, L1 unlimited ExtTag- AttnBtn- AttnInd- PwrInd- RBE+ FLReset- SlotPowerLimit 225.000W DevCtl: Report errors: Correctable- Non-Fatal+ Fatal+ Unsupported- RlxdOrd+ ExtTag- PhantFunc- AuxPwr- NoSnoop+ MaxPayload 256 bytes, MaxReadReq 512 bytes DevSta: CorrErr- UncorrErr- FatalErr- UnsuppReq- AuxPwr- TransPend- LnkCap: Port #0, Speed 5GT/s, Width x4, ASPM L0s, Exit Latency L0s unlimited, L1 unlimited ClockPM- Surprise- LLActRep- BwNot- ASPMOptComp- LnkCtl: ASPM Disabled; RCB 64 bytes Disabled- CommClk+ ExtSynch- ClockPM- AutWidDis- BWInt- AutBWInt- LnkSta: Speed 5GT/s, Width x4, TrErr- Train- SlotClk+ DLActive- BWMgmt- ABWMgmt- DevCap2: Completion Timeout: Range B, TimeoutDis-, LTR-, OBFF Not Supported DevCtl2: Completion Timeout: 50us to 50ms, TimeoutDis-, LTR-, OBFF Disabled LnkCtl2: Target Link Speed: 5GT/s, EnterCompliance- SpeedDis- Transmit Margin: Normal Operating Range, EnterModifiedCompliance- ComplianceSOS- Compliance De-emphasis: -6dB LnkSta2: Current De-emphasis Level: -6dB, EqualizationComplete-, EqualizationPhase1- EqualizationPhase2-, EqualizationPhase3-, LinkEqualizationRequest- Capabilities: [100 v1] Device Serial Number 00-00-00-01-01-00-0a-35 I tried to write and readback to an address, but was unable: [root@fe01 pcimem]# sudo ./pcimem /dev/mem 4126670848 w 0xffffff12 /dev/mem opened. Target offset is 0xf5f80000, page size is 4096 mmap(0, 4096, 0x3, 0x1, 3, 0xf5f80000) PCI Memory mapped to address 0x7f758d6f4000. Value at offset 0xF5F80000 (0x7f758d6f4000): 0xFFFFFFFF Written 0xFFFFFF12; readback 0xFFFFFFFF [root@fe01 pcimem]# sudo ./pcimem /dev/mem 4126670848 w 0xffffff12 /dev/mem opened. Target offset is 0xf5f80000 , page size is 4096 mmap( 0 , 4096 , 0x3 , 0x1 , 3 , 0xf5f80000 ) PCI Memory mapped to address 0x7f758d6f4000 . Value at offset 0xF5F80000 ( 0x7f758d6f4000 ): 0xFFFFFFFF Written 0xFFFFFF12 ; readback 0xFFFFFFFF I'm not sure what I'm even doing here since I see no region to write to/read from. 18/03/2024 02:18 If I instead reprogram the device with 1MB of BAR memory, I can see the region [root@fe01 ~]# lspci -vv | grep -A 40 \"04:00.0\" pcilib: sysfs_read_vpd: read failed: Input/output error 04:00.0 Memory controller: Xilinx Corporation Device 7024 Subsystem: Xilinx Corporation Device 0007 Control: I/O+ Mem+ BusMaster- SpecCycle- MemWINV- VGASnoop- ParErr- Stepping- SERR- FastB2B- DisINTx- Status: Cap+ 66MHz- UDF- FastB2B- ParErr- DEVSEL=fast >TAbort- <TAbort- <MAbort- >SERR- <PERR- INTx- Interrupt: pin A routed to IRQ 35 Region 0: Memory at f5f00000 (32-bit, non-prefetchable) [size=1M] Capabilities: [40] Power Management version 3 Flags: PMEClk- DSI- D1- D2- AuxCurrent=0mA PME(D0+,D1+,D2+,D3hot+,D3cold-) Status: D0 NoSoftRst+ PME-Enable- DSel=0 DScale=0 PME- Capabilities: [48] MSI: Enable- Count=1/1 Maskable- 64bit+ Address: 0000000000000000 Data: 0000 Capabilities: [60] Express (v2) Endpoint, MSI 00 DevCap: MaxPayload 512 bytes, PhantFunc 0, Latency L0s <64ns, L1 unlimited ExtTag- AttnBtn- AttnInd- PwrInd- RBE+ FLReset- SlotPowerLimit 225.000W DevCtl: Report errors: Correctable- Non-Fatal+ Fatal+ Unsupported- RlxdOrd+ ExtTag- PhantFunc- AuxPwr- NoSnoop+ MaxPayload 256 bytes, MaxReadReq 512 bytes DevSta: CorrErr- UncorrErr- FatalErr- UnsuppReq- AuxPwr- TransPend- LnkCap: Port #0, Speed 5GT/s, Width x4, ASPM L0s, Exit Latency L0s unlimited, L1 unlimited ClockPM- Surprise- LLActRep- BwNot- ASPMOptComp- LnkCtl: ASPM Disabled; RCB 64 bytes Disabled- CommClk+ ExtSynch- ClockPM- AutWidDis- BWInt- AutBWInt- LnkSta: Speed 5GT/s, Width x4, TrErr- Train- SlotClk+ DLActive- BWMgmt- ABWMgmt- DevCap2: Completion Timeout: Range B, TimeoutDis-, LTR-, OBFF Not Supported DevCtl2: Completion Timeout: 50us to 50ms, TimeoutDis-, LTR-, OBFF Disabled LnkCtl2: Target Link Speed: 5GT/s, EnterCompliance- SpeedDis- Transmit Margin: Normal Operating Range, EnterModifiedCompliance- ComplianceSOS- Compliance De-emphasis: -6dB LnkSta2: Current De-emphasis Level: -6dB, EqualizationComplete-, EqualizationPhase1- EqualizationPhase2-, EqualizationPhase3-, LinkEqualizationRequest- Capabilities: [100 v1] Device Serial Number 00-00-00-01-01-00-0a-35 Kernel modules: xdma [root@fe01 ~]# lspci -vv | grep -A 40 \"04:00.0\" pcilib: sysfs_read_vpd: read failed: Input/output error 04:00.0 Memory controller: Xilinx Corporation Device 7024 Subsystem: Xilinx Corporation Device 0007 Control: I/O+ Mem+ BusMaster- SpecCycle- MemWINV- VGASnoop- ParErr- Stepping- SERR- FastB2B- DisINTx- Status: Cap+ 66MHz- UDF- FastB2B- ParErr- DEVSEL=fast >TAbort- <TAbort- <MAbort- >SERR- <PERR- INTx- Interrupt: pin A routed to IRQ 35 Region 0: Memory at f5f00000 (32-bit, non-prefetchable) [size=1M] Capabilities: [40] Power Management version 3 Flags: PMEClk- DSI- D1- D2- AuxCurrent=0mA PME(D0+,D1+,D2+,D3hot+,D3cold-) Status: D0 NoSoftRst+ PME-Enable- DSel=0 DScale=0 PME- Capabilities: [48] MSI: Enable- Count=1/1 Maskable- 64bit+ Address: 0000000000000000 Data: 0000 Capabilities: [60] Express (v2) Endpoint, MSI 00 DevCap: MaxPayload 512 bytes, PhantFunc 0, Latency L0s <64ns, L1 unlimited ExtTag- AttnBtn- AttnInd- PwrInd- RBE+ FLReset- SlotPowerLimit 225.000W DevCtl: Report errors: Correctable- Non-Fatal+ Fatal+ Unsupported- RlxdOrd+ ExtTag- PhantFunc- AuxPwr- NoSnoop+ MaxPayload 256 bytes, MaxReadReq 512 bytes DevSta: CorrErr- UncorrErr- FatalErr- UnsuppReq- AuxPwr- TransPend- LnkCap: Port #0, Speed 5GT/s, Width x4, ASPM L0s, Exit Latency L0s unlimited, L1 unlimited ClockPM- Surprise- LLActRep- BwNot- ASPMOptComp- LnkCtl: ASPM Disabled; RCB 64 bytes Disabled- CommClk+ ExtSynch- ClockPM- AutWidDis- BWInt- AutBWInt- LnkSta: Speed 5GT/s, Width x4, TrErr- Train- SlotClk+ DLActive- BWMgmt- ABWMgmt- DevCap2: Completion Timeout: Range B, TimeoutDis-, LTR-, OBFF Not Supported DevCtl2: Completion Timeout: 50us to 50ms, TimeoutDis-, LTR-, OBFF Disabled LnkCtl2: Target Link Speed: 5GT/s, EnterCompliance- SpeedDis- Transmit Margin: Normal Operating Range, EnterModifiedCompliance- ComplianceSOS- Compliance De-emphasis: -6dB LnkSta2: Current De-emphasis Level: -6dB, EqualizationComplete-, EqualizationPhase1- EqualizationPhase2-, EqualizationPhase3-, LinkEqualizationRequest- Capabilities: [100 v1] Device Serial Number 00-00-00-01-01-00-0a-35 Kernel modules: xdma And I can write and readback in this case: [root@fe01 pcimem]# sudo ./pcimem /dev/mem 4126146560 w 0xffffff12 /dev/mem opened. Target offset is 0xf5f00000, page size is 4096 mmap(0, 4096, 0x3, 0x1, 3, 0xf5f00000) PCI Memory mapped to address 0x7fd649f4b000. Value at offset 0xF5F00000 (0x7fd649f4b000): 0x0 Written 0xFFFFFF12; readback 0xFFFFFF12 [root@fe01 pcimem]# [root@fe01 pcimem] # sudo ./pcimem /dev/mem 4126146560 w 0xffffff12 /dev/mem opened. Target offset is 0xf5f00000 , page size is 4096 mmap( 0 , 4096 , 0x3 , 0x1 , 3 , 0xf5f00000 ) PCI Memory mapped to address 0x7fd649f4b000 . Value at offset 0xF5F00000 ( 0x7fd649f4b000 ): 0x0 Written 0xFFFFFF12 ; readback 0xFFFFFF12 [root@fe01 pcimem] # 18/03/2024 02:31 AMC13Tool is throwing an error here: void AMC13::buildT1(const std::string& IP, const std::string& AD, const int& IV, const bool& CH) { fpga_.resize(2); try { fpga_.at(T1) = new ipDev(\"hcal.crate42.T1\", IP, AD, IV, CH); } catch(ipDev::exception& e) { printf(\"T1 %s %s %i %i\\n\", IP.c_str(), AD.c_str(), IV, CH); printf(\"Failed to build T1 ipDev object!\\n\"); exit(1); } } void AMC13 :: buildT1 ( const std:: string & IP, const std:: string & AD, const int & IV, const bool & CH) { fpga_. resize ( 2 ); try { fpga_. at (T1) = new ipDev ( \"hcal.crate42.T1\" , IP, AD, IV, CH); } catch (ip Dev :: exception & e) { printf ( \"T1 %s %s %i %i\\n\" , IP. c_str (), AD. c_str (), IV, CH); printf ( \"Failed to build T1 ipDev object!\\n\" ); exit ( 1 ); } } Which means ipDev must fail at construction: ipDev::ipDev (const std::string& p_ID, const std::string& p_IP, const std::string& p_AddMap, const int& IpBusV, const bool& ctrlHub) { // Build HwInterface ID ID = p_ID; // Build HwInterface URI if(!IpBusV) { if(ctrlHub) URI = \"chtcp-1.3://localhost:10203?target=\"+p_IP+\":50001\"; else URI = \"ipbusudp-1.3://\"+p_IP+\":50001\"; } else if(IpBusV) { if(ctrlHub) URI = \"chtcp-2.0://localhost:10203?target=\"+p_IP+\":50001\"; else URI = \"ipbusudp-2.0://\"+p_IP+\":50001\"; } // Build HwInterface Address Map ADD = \"file://\"+p_AddMap; // Construct HwInterface Object try { device = new uhal::HwInterface(uhal::ConnectionManager::getDevice(ID, URI, ADD)); } catch(uhalException& e) { std::cerr << \"Address map: \" << ADD<< std::endl; std::cerr << \"Caught Exception: \" << e.what() << std::endl; throw exception(std::string(\"IPbus Creation Failure at URI \"+URI)); } // Handle Object's AddressTable entries createUhalNodeIDs(); } ipDev::ipDev (const std::string& p_ID, const std::string& p_IP, const std::string& p_AddMap, const int& IpBusV, const bool& ctrlHub) { // Build HwInterface ID ID = p_ID; // Build HwInterface URI if(!IpBusV) { if(ctrlHub) URI = \"chtcp-1.3://localhost:10203?target=\"+p_IP+\":50001\"; else URI = \"ipbusudp-1.3://\"+p_IP+\":50001\"; } else if(IpBusV) { if(ctrlHub) URI = \"chtcp-2.0://localhost:10203?target=\"+p_IP+\":50001\"; else URI = \"ipbusudp-2.0://\"+p_IP+\":50001\"; } // Build HwInterface Address Map ADD = \"file://\"+p_AddMap; // Construct HwInterface Object try { device = new uhal::HwInterface(uhal::ConnectionManager::getDevice(ID, URI, ADD)); } catch(uhalException& e) { std::cerr << \"Address map: \" << ADD<< std::endl; std::cerr << \"Caught Exception: \" << e.what() << std::endl; throw exception(std::string(\"IPbus Creation Failure at URI \"+URI)); } // Handle Object's AddressTable entries createUhalNodeIDs(); } I added some print statements (as seen above) to see the exception has to do with the address table containing dots (there is a similar problem with using FC7.xml in the gm2daq, which makes me think at some point uHAL stopped liking dots in the address map file) [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# bin/AMC13Tool -I 192.168.1.188 Connecting to AMC13... T2 ip 192.168.1.188 T2 ip 192.168.1.188 T1 ip 192.168.1.189 Address map: file://map/AMC13_AddressTable_K7.xml Caught Exception: Invalid node ID '1.0V_ANA_PWR' specified (contains dots) T1 192.168.1.189 map/AMC13_AddressTable_K7.xml 1 1 Failed to build T1 ipDev object! [root@dhcp- 10 - 163 - 105 - 238 amc13StandaloneMAN_2014- 05 - 12 ] # bin/AMC13Tool -I 192.168.1.188 Connecting to AMC13... T2 ip 192.168 . 1.188 T2 ip 192.168 . 1.188 T1 ip 192.168 . 1.189 Address map: file://map/AMC13_AddressTable_K7. xml Caught Exception: Invalid node ID ' 1.0 V_ANA_PWR' specified (contains dots) T1 192.168 . 1.189 map/AMC13_AddressTable_K7. xml 1 1 Failed to build T1 ipDev object! 21/03/2024 00:16 Comparing our set-up with the CENPA DAQ, I think we have the Samtech cable plugged in correctly. Our bank chip: CENPA bank chip: Our FC7 connection: CENPA FC7 connection: 21/03/2024 00:50 Was able to set BARs size to 512MB [root@fe01 ~]# lspci -vv | grep -A 40 \"04:00.0\" pcilib: sysfs_read_vpd: read failed: Input/output error 04:00.0 Memory controller: Xilinx Corporation Device 7024 Subsystem: Xilinx Corporation Device 0007 Control: I/O+ Mem+ BusMaster- SpecCycle- MemWINV- VGASnoop- ParErr- Stepping- SERR- FastB2B- DisINTx- Status: Cap+ 66MHz- UDF- FastB2B- ParErr- DEVSEL=fast >TAbort- <TAbort- <MAbort- >SERR- <PERR- INTx- Interrupt: pin A routed to IRQ 35 Region 0: Memory at c0000000 (32-bit, non-prefetchable) [size=512M] Capabilities: [40] Power Management version 3 Flags: PMEClk- DSI- D1- D2- AuxCurrent=0mA PME(D0+,D1+,D2+,D3hot+,D3cold-) Status: D0 NoSoftRst+ PME-Enable- DSel=0 DScale=0 PME- Capabilities: [48] MSI: Enable- Count=1/1 Maskable- 64bit+ Address: 0000000000000000 Data: 0000 Capabilities: [60] Express (v2) Endpoint, MSI 00 DevCap: MaxPayload 512 bytes, PhantFunc 0, Latency L0s <64ns, L1 unlimited ExtTag- AttnBtn- AttnInd- PwrInd- RBE+ FLReset- SlotPowerLimit 225.000W DevCtl: Report errors: Correctable- Non-Fatal+ Fatal+ Unsupported- RlxdOrd+ ExtTag- PhantFunc- AuxPwr- NoSnoop+ MaxPayload 256 bytes, MaxReadReq 512 bytes DevSta: CorrErr- UncorrErr- FatalErr- UnsuppReq- AuxPwr- TransPend- LnkCap: Port #0, Speed 5GT/s, Width x4, ASPM L0s, Exit Latency L0s unlimited, L1 unlimited ClockPM- Surprise- LLActRep- BwNot- ASPMOptComp- LnkCtl: ASPM Disabled; RCB 64 bytes Disabled- CommClk+ ExtSynch- ClockPM- AutWidDis- BWInt- AutBWInt- LnkSta: Speed 5GT/s, Width x4, TrErr- Train- SlotClk+ DLActive- BWMgmt- ABWMgmt- DevCap2: Completion Timeout: Range B, TimeoutDis-, LTR-, OBFF Not Supported DevCtl2: Completion Timeout: 50us to 50ms, TimeoutDis-, LTR-, OBFF Disabled LnkCtl2: Target Link Speed: 5GT/s, EnterCompliance- SpeedDis- Transmit Margin: Normal Operating Range, EnterModifiedCompliance- ComplianceSOS- Compliance De-emphasis: -6dB LnkSta2: Current De-emphasis Level: -6dB, EqualizationComplete-, EqualizationPhase1- EqualizationPhase2-, EqualizationPhase3-, LinkEqualizationRequest- Capabilities: [100 v1] Device Serial Number 00-00-00-01-01-00-0a-35 Kernel modules: xdma [root@fe01 ~]# lspci -vv | grep -A 40 \"04:00.0\" pcilib: sysfs_read_vpd: read failed: Input/output error 04:00.0 Memory controller: Xilinx Corporation Device 7024 Subsystem: Xilinx Corporation Device 0007 Control: I/O+ Mem+ BusMaster- SpecCycle- MemWINV- VGASnoop- ParErr- Stepping- SERR- FastB2B- DisINTx- Status: Cap+ 66MHz- UDF- FastB2B- ParErr- DEVSEL=fast >TAbort- <TAbort- <MAbort- >SERR- <PERR- INTx- Interrupt: pin A routed to IRQ 35 Region 0: Memory at c0000000 (32-bit, non-prefetchable) [size=512M] Capabilities: [40] Power Management version 3 Flags: PMEClk- DSI- D1- D2- AuxCurrent=0mA PME(D0+,D1+,D2+,D3hot+,D3cold-) Status: D0 NoSoftRst+ PME-Enable- DSel=0 DScale=0 PME- Capabilities: [48] MSI: Enable- Count=1/1 Maskable- 64bit+ Address: 0000000000000000 Data: 0000 Capabilities: [60] Express (v2) Endpoint, MSI 00 DevCap: MaxPayload 512 bytes, PhantFunc 0, Latency L0s <64ns, L1 unlimited ExtTag- AttnBtn- AttnInd- PwrInd- RBE+ FLReset- SlotPowerLimit 225.000W DevCtl: Report errors: Correctable- Non-Fatal+ Fatal+ Unsupported- RlxdOrd+ ExtTag- PhantFunc- AuxPwr- NoSnoop+ MaxPayload 256 bytes, MaxReadReq 512 bytes DevSta: CorrErr- UncorrErr- FatalErr- UnsuppReq- AuxPwr- TransPend- LnkCap: Port #0, Speed 5GT/s, Width x4, ASPM L0s, Exit Latency L0s unlimited, L1 unlimited ClockPM- Surprise- LLActRep- BwNot- ASPMOptComp- LnkCtl: ASPM Disabled; RCB 64 bytes Disabled- CommClk+ ExtSynch- ClockPM- AutWidDis- BWInt- AutBWInt- LnkSta: Speed 5GT/s, Width x4, TrErr- Train- SlotClk+ DLActive- BWMgmt- ABWMgmt- DevCap2: Completion Timeout: Range B, TimeoutDis-, LTR-, OBFF Not Supported DevCtl2: Completion Timeout: 50us to 50ms, TimeoutDis-, LTR-, OBFF Disabled LnkCtl2: Target Link Speed: 5GT/s, EnterCompliance- SpeedDis- Transmit Margin: Normal Operating Range, EnterModifiedCompliance- ComplianceSOS- Compliance De-emphasis: -6dB LnkSta2: Current De-emphasis Level: -6dB, EqualizationComplete-, EqualizationPhase1- EqualizationPhase2-, EqualizationPhase3-, LinkEqualizationRequest- Capabilities: [100 v1] Device Serial Number 00-00-00-01-01-00-0a-35 Kernel modules: xdma and write/readback: [root@fe01 pcimem]# sudo ./pcimem /dev/mem 3221225472 w 0xffffff12 /dev/mem opened. Target offset is 0xc0000000, page size is 4096 mmap(0, 4096, 0x3, 0x1, 3, 0xc0000000) PCI Memory mapped to address 0x7fb23ee93000. Value at offset 0xC0000000 (0x7fb23ee93000): 0x0 Written 0xFFFFFF12; readback 0xFFFFFF12 [root@fe01 pcimem]# [root@fe01 pcimem] # sudo ./pcimem /dev/mem 3221225472 w 0xffffff12 /dev/mem opened. Target offset is 0xc0000000 , page size is 4096 mmap( 0 , 4096 , 0x3 , 0x1 , 3 , 0xc0000000 ) PCI Memory mapped to address 0x7fb23ee93000 . Value at offset 0xC0000000 ( 0x7fb23ee93000 ): 0x0 Written 0xFFFFFF12 ; readback 0xFFFFFF12 [root@fe01 pcimem] # 21/03/2024 00:52 It looks like 1GB also works. I wonder what the issue with 2GB is: [root@fe01 ~]# lspci -vv | grep -A 40 \"04:00.0\" pcilib: sysfs_read_vpd: read failed: Input/output error 04:00.0 Memory controller: Xilinx Corporation Device 7024 Subsystem: Xilinx Corporation Device 0007 Control: I/O+ Mem+ BusMaster- SpecCycle- MemWINV- VGASnoop- ParErr- Stepping- SERR- FastB2B- DisINTx- Status: Cap+ 66MHz- UDF- FastB2B- ParErr- DEVSEL=fast >TAbort- <TAbort- <MAbort- >SERR- <PERR- INTx- Interrupt: pin A routed to IRQ 35 Region 0: Memory at 80000000 (32-bit, non-prefetchable) [size=1G] Capabilities: [40] Power Management version 3 Flags: PMEClk- DSI- D1- D2- AuxCurrent=0mA PME(D0+,D1+,D2+,D3hot+,D3cold-) Status: D0 NoSoftRst+ PME-Enable- DSel=0 DScale=0 PME- Capabilities: [48] MSI: Enable- Count=1/1 Maskable- 64bit+ Address: 0000000000000000 Data: 0000 Capabilities: [60] Express (v2) Endpoint, MSI 00 DevCap: MaxPayload 512 bytes, PhantFunc 0, Latency L0s <64ns, L1 unlimited ExtTag- AttnBtn- AttnInd- PwrInd- RBE+ FLReset- SlotPowerLimit 225.000W DevCtl: Report errors: Correctable- Non-Fatal+ Fatal+ Unsupported- RlxdOrd+ ExtTag- PhantFunc- AuxPwr- NoSnoop+ MaxPayload 256 bytes, MaxReadReq 512 bytes DevSta: CorrErr- UncorrErr- FatalErr- UnsuppReq- AuxPwr- TransPend- LnkCap: Port #0, Speed 5GT/s, Width x4, ASPM L0s, Exit Latency L0s unlimited, L1 unlimited ClockPM- Surprise- LLActRep- BwNot- ASPMOptComp- LnkCtl: ASPM Disabled; RCB 64 bytes Disabled- CommClk+ ExtSynch- ClockPM- AutWidDis- BWInt- AutBWInt- LnkSta: Speed 5GT/s, Width x4, TrErr- Train- SlotClk+ DLActive- BWMgmt- ABWMgmt- DevCap2: Completion Timeout: Range B, TimeoutDis-, LTR-, OBFF Not Supported DevCtl2: Completion Timeout: 50us to 50ms, TimeoutDis-, LTR-, OBFF Disabled LnkCtl2: Target Link Speed: 5GT/s, EnterCompliance- SpeedDis- Transmit Margin: Normal Operating Range, EnterModifiedCompliance- ComplianceSOS- Compliance De-emphasis: -6dB LnkSta2: Current De-emphasis Level: -6dB, EqualizationComplete-, EqualizationPhase1- EqualizationPhase2-, EqualizationPhase3-, LinkEqualizationRequest- Capabilities: [100 v1] Device Serial Number 00-00-00-01-01-00-0a-35 Kernel modules: xdma [root@fe01 ~]# lspci -vv | grep -A 40 \"04:00.0\" pcilib: sysfs_read_vpd: read failed: Input/output error 04:00.0 Memory controller: Xilinx Corporation Device 7024 Subsystem: Xilinx Corporation Device 0007 Control: I/O+ Mem+ BusMaster- SpecCycle- MemWINV- VGASnoop- ParErr- Stepping- SERR- FastB2B- DisINTx- Status: Cap+ 66MHz- UDF- FastB2B- ParErr- DEVSEL=fast >TAbort- <TAbort- <MAbort- >SERR- <PERR- INTx- Interrupt: pin A routed to IRQ 35 Region 0: Memory at 80000000 (32-bit, non-prefetchable) [size=1G] Capabilities: [40] Power Management version 3 Flags: PMEClk- DSI- D1- D2- AuxCurrent=0mA PME(D0+,D1+,D2+,D3hot+,D3cold-) Status: D0 NoSoftRst+ PME-Enable- DSel=0 DScale=0 PME- Capabilities: [48] MSI: Enable- Count=1/1 Maskable- 64bit+ Address: 0000000000000000 Data: 0000 Capabilities: [60] Express (v2) Endpoint, MSI 00 DevCap: MaxPayload 512 bytes, PhantFunc 0, Latency L0s <64ns, L1 unlimited ExtTag- AttnBtn- AttnInd- PwrInd- RBE+ FLReset- SlotPowerLimit 225.000W DevCtl: Report errors: Correctable- Non-Fatal+ Fatal+ Unsupported- RlxdOrd+ ExtTag- PhantFunc- AuxPwr- NoSnoop+ MaxPayload 256 bytes, MaxReadReq 512 bytes DevSta: CorrErr- UncorrErr- FatalErr- UnsuppReq- AuxPwr- TransPend- LnkCap: Port #0, Speed 5GT/s, Width x4, ASPM L0s, Exit Latency L0s unlimited, L1 unlimited ClockPM- Surprise- LLActRep- BwNot- ASPMOptComp- LnkCtl: ASPM Disabled; RCB 64 bytes Disabled- CommClk+ ExtSynch- ClockPM- AutWidDis- BWInt- AutBWInt- LnkSta: Speed 5GT/s, Width x4, TrErr- Train- SlotClk+ DLActive- BWMgmt- ABWMgmt- DevCap2: Completion Timeout: Range B, TimeoutDis-, LTR-, OBFF Not Supported DevCtl2: Completion Timeout: 50us to 50ms, TimeoutDis-, LTR-, OBFF Disabled LnkCtl2: Target Link Speed: 5GT/s, EnterCompliance- SpeedDis- Transmit Margin: Normal Operating Range, EnterModifiedCompliance- ComplianceSOS- Compliance De-emphasis: -6dB LnkSta2: Current De-emphasis Level: -6dB, EqualizationComplete-, EqualizationPhase1- EqualizationPhase2-, EqualizationPhase3-, LinkEqualizationRequest- Capabilities: [100 v1] Device Serial Number 00-00-00-01-01-00-0a-35 Kernel modules: xdma and the write/readback: [root@fe01 pcimem]# sudo ./pcimem /dev/mem 2147483648 w 0xffffff12 /dev/mem opened. Target offset is 0x80000000, page size is 4096 mmap(0, 4096, 0x3, 0x1, 3, 0x80000000) PCI Memory mapped to address 0x7f716ae30000. Value at offset 0x80000000 (0x7f716ae30000): 0x0 Written 0xFFFFFF12; readback 0xFFFFFF12 [root@fe01 pcimem] # sudo ./pcimem /dev/mem 2147483648 w 0xffffff12 /dev/mem opened. Target offset is 0x80000000 , page size is 4096 mmap( 0 , 4096 , 0x3 , 0x1 , 3 , 0x80000000 ) PCI Memory mapped to address 0x7f716ae30000 . Value at offset 0x80000000 ( 0x7f716ae30000 ): 0x0 Written 0xFFFFFF12 ; readback 0xFFFFFF12 21/03/2024 01:41 I was playing with talking with the board over PCIe. I got ChatGPT to make me a script that reads multiple words: #include <stdio.h> #include <stdlib.h> #include <stdint.h> #include <unistd.h> #include <string.h> #include <errno.h> #include <signal.h> #include <fcntl.h> #include <ctype.h> #include <termios.h> #include <sys/types.h> #include <sys/mman.h> #include <sys/time.h> #define PRINT_ERROR \\ do { \\ fprintf(stderr, \"Error at line %d, file %s (%d) [%s]\\n\", \\ __LINE__, __FILE__, errno, strerror(errno)); exit(1); \\ } while(0) #define MAP_SIZE_DEFAULT 4096UL #define MAP_MASK (MAP_SIZE_DEFAULT - 1) int main(int argc, char **argv) { int fd; void *map_base, *virt_addr; uint32_t read_result; char *filename; off_t target; size_t word_count = 0; size_t map_size = MAP_SIZE_DEFAULT; // Default map size struct timeval start, end; double time_taken; if(argc < 4 || argc > 5) { fprintf(stderr, \"\\nUsage:\\t%s { sys file } { offset } { word count } [ map size ]\\n\" \"\\tsys file: sysfs file for the PCI resource to act on\\n\" \"\\toffset : offset into PCI memory region to act upon\\n\" \"\\tword count: number of words to read\\n\" \"\\tmap size (optional): size of memory mapping in bytes (default: 4096)\\n\\n\", argv[0]); exit(1); } filename = argv[1]; target = strtoul(argv[2], 0, 0); word_count = atoi(argv[3]); if(argc == 5) map_size = atoi(argv[4]); if((fd = open(filename, O_RDWR | O_SYNC)) == -1) PRINT_ERROR; printf(\"%s opened.\\n\", filename); /* Map memory */ map_base = mmap(0, map_size, PROT_READ, MAP_SHARED, fd, target & ~MAP_MASK); if(map_base == (void *) -1) PRINT_ERROR; printf(\"PCI Memory mapped to address 0x%08lx with size %lu bytes.\\n\", (unsigned long) map_base, map_size); virt_addr = map_base; printf(\"Reading %lu words from offset 0x%lx:\\n\", word_count, (unsigned long)target); // Measure time taken to read gettimeofday(&start, NULL); // Read and print the specified number of words for(size_t i = 0; i < word_count; ++i) { read_result = *((uint32_t *) virt_addr); printf(\"0x%08x \", read_result); virt_addr = (char *)virt_addr + sizeof(uint32_t); // Move to the next word } printf(\"\\n\"); gettimeofday(&end, NULL); // Calculate time taken in milliseconds time_taken = ((end.tv_sec - start.tv_sec) * 1000 + (end.tv_usec - start.tv_usec) / 1000.0); printf(\"Read operation completed in %.2f milliseconds.\\n\", time_taken); if(munmap(map_base, map_size) == -1) PRINT_ERROR; close(fd); return 0; } #include <stdio.h> #include <stdlib.h> #include <stdint.h> #include <unistd.h> #include <string.h> #include <errno.h> #include <signal.h> #include <fcntl.h> #include <ctype.h> #include <termios.h> #include <sys/types.h> #include <sys/mman.h> #include <sys/time.h> #define PRINT_ERROR \\ do { \\ fprintf(stderr, \"Error at line %d, file %s (%d) [%s]\\n\", \\ __LINE__, __FILE__, errno, strerror(errno)); exit(1); \\ } while(0) #define MAP_SIZE_DEFAULT 4096UL #define MAP_MASK (MAP_SIZE_DEFAULT - 1) int main(int argc, char **argv) { int fd; void *map_base, *virt_addr; uint32_t read_result; char *filename; off_t target; size_t word_count = 0; size_t map_size = MAP_SIZE_DEFAULT; // Default map size struct timeval start, end; double time_taken; if(argc < 4 || argc > 5) { fprintf(stderr, \"\\nUsage:\\t%s { sys file } { offset } { word count } [ map size ]\\n\" \"\\tsys file: sysfs file for the PCI resource to act on\\n\" \"\\toffset : offset into PCI memory region to act upon\\n\" \"\\tword count: number of words to read\\n\" \"\\tmap size (optional): size of memory mapping in bytes (default: 4096)\\n\\n\", argv[0]); exit(1); } filename = argv[1]; target = strtoul(argv[2], 0, 0); word_count = atoi(argv[3]); if(argc == 5) map_size = atoi(argv[4]); if((fd = open(filename, O_RDWR | O_SYNC)) == -1) PRINT_ERROR; printf(\"%s opened.\\n\", filename); /* Map memory */ map_base = mmap(0, map_size, PROT_READ, MAP_SHARED, fd, target & ~MAP_MASK); if(map_base == (void *) -1) PRINT_ERROR; printf(\"PCI Memory mapped to address 0x%08lx with size %lu bytes.\\n\", (unsigned long) map_base, map_size); virt_addr = map_base; printf(\"Reading %lu words from offset 0x%lx:\\n\", word_count, (unsigned long)target); // Measure time taken to read gettimeofday(&start, NULL); // Read and print the specified number of words for(size_t i = 0; i < word_count; ++i) { read_result = *((uint32_t *) virt_addr); printf(\"0x%08x \", read_result); virt_addr = (char *)virt_addr + sizeof(uint32_t); // Move to the next word } printf(\"\\n\"); gettimeofday(&end, NULL); // Calculate time taken in milliseconds time_taken = ((end.tv_sec - start.tv_sec) * 1000 + (end.tv_usec - start.tv_usec) / 1000.0); printf(\"Read operation completed in %.2f milliseconds.\\n\", time_taken); if(munmap(map_base, map_size) == -1) PRINT_ERROR; close(fd); return 0; } I'm pretty sure it works because I can write to registers with the pcimem script and see them appear when I read out, for example: To write the first 4 byte word: [root@fe01 pcimem]# sudo ./pcimem /dev/mem 2147483648 w 0xffffff12 /dev/mem opened. Target offset is 0x80000000, page size is 4096 mmap(0, 4096, 0x3, 0x1, 3, 0x80000000) PCI Memory mapped to address 0x7f0a17ba3000. Value at offset 0x80000000 (0x7f0a17ba3000): 0xFFFFFF12 Written 0xFFFFFF12; readback 0xFFFFFF12 [root@fe01 pcimem]# [root@fe01 pcimem] # sudo ./pcimem /dev/mem 2147483648 w 0xffffff12 /dev/mem opened. Target offset is 0x80000000 , page size is 4096 mmap( 0 , 4096 , 0x3 , 0x1 , 3 , 0x80000000 ) PCI Memory mapped to address 0x7f0a17ba3000 . Value at offset 0x80000000 ( 0x7f0a17ba3000 ): 0xFFFFFF12 Written 0xFFFFFF12 ; readback 0xFFFFFF12 [root@fe01 pcimem] # To write the second 4 byte word: [root@fe01 pcimem]# sudo ./pcimem /dev/mem 2147483652 w 0xffffff13 /dev/mem opened. Target offset is 0x80000004, page size is 4096 mmap(0, 4096, 0x3, 0x1, 3, 0x80000004) PCI Memory mapped to address 0x7fc7f1ba1000. Value at offset 0x80000004 (0x7fc7f1ba1004): 0xFFFFFF12 Written 0xFFFFFF13; readback 0xFFFFFF13 [root@fe01 pcimem] # sudo ./pcimem /dev/mem 2147483652 w 0xffffff13 /dev/mem opened. Target offset is 0x80000004 , page size is 4096 mmap( 0 , 4096 , 0x3 , 0x1 , 3 , 0x80000004 ) PCI Memory mapped to address 0x7fc7f1ba1000 . Value at offset 0x80000004 ( 0x7fc7f1ba1004 ): 0xFFFFFF12 Written 0xFFFFFF13 ; readback 0xFFFFFF13 Now we can read the first 3 4-byte words: [root@fe01 pcimem]# sudo ./pcie_read_dynamic /dev/mem 2147483648 3 /dev/mem opened. PCI Memory mapped to address 0x7f1077abf000 with size 16384 bytes. Reading 3 words from offset 0x80000000: 0xffffff12 0xffffff13 0x00000000 Read operation completed in 0.02 milliseconds. [root@fe01 pcimem] # sudo ./pcie_read_dynamic /dev/mem 2147483648 3 /dev/mem opened. PCI Memory mapped to address 0x7f1077abf000 with size 16384 bytes. Reading 3 words from offset 0x80000000 : 0xffffff12 0xffffff13 0x00000000 Read operation completed in 0.02 milliseconds. I wrote one more word further out too and checked it: [root@fe01 pcimem]# sudo ./pcimem /dev/mem 2147484052 w 0xffffff14 /dev/mem opened. Target offset is 0x80000194, page size is 4096 mmap(0, 4096, 0x3, 0x1, 3, 0x80000194) PCI Memory mapped to address 0x7fe1af562000. Value at offset 0x80000194 (0x7fe1af562194): 0xFFFFFF12 Written 0xFFFFFF14; readback 0xFFFFFF14 [root@fe01 pcimem] # sudo ./pcimem /dev/mem 2147484052 w 0xffffff14 /dev/mem opened. Target offset is 0x80000194 , page size is 4096 mmap( 0 , 4096 , 0x3 , 0x1 , 3 , 0x80000194 ) PCI Memory mapped to address 0x7fe1af562000 . Value at offset 0x80000194 ( 0x7fe1af562194 ): 0xFFFFFF12 Written 0xFFFFFF14 ; readback 0xFFFFFF14 [root@fe01 pcimem]# sudo ./pcie_read_dynamic /dev/mem 2147483648 110 /dev/mem opened. PCI Memory mapped to address 0x7f2df0c91000 with size 4096 bytes. Reading 110 words from offset 0x80000000: 0xffffff12 0xffffff13 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0xffffff14 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 Read operation completed in 0.14 milliseconds. [root@fe01 pcimem]# sudo ./pcie_read_dynamic /dev/mem 2147483648 110 /dev/mem opened. PCI Memory mapped to address 0x7f2df0c91000 with size 4096 bytes. Reading 110 words from offset 0x80000000: 0xffffff12 0xffffff13 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0xffffff14 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 Read operation completed in 0.14 milliseconds. However, I noticed that you can only read 512 4-byte words at a time before things start \"repeating\".There is a max payload size of 512 bytes (as seen in lscpi output further up), but this seems like a different affect? [root@fe01 pcimem]# sudo ./pcie_read_dynamic /dev/mem 2147483648 516 /dev/mem opened. PCI Memory mapped to address 0x7fadda667000 with size 4096 bytes. Reading 516 words from offset 0x80000000: 0xffffff12 0xffffff13 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0xffffff14 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0xffffff12 0xffffff13 0x00000000 0x00000000 Read operation completed in 0.48 milliseconds. [root@fe01 pcimem]# sudo ./pcie_read_dynamic /dev/mem 2147483648 516 /dev/mem opened. PCI Memory mapped to address 0x7fadda667000 with size 4096 bytes. Reading 516 words from offset 0x80000000: 0xffffff12 0xffffff13 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0xffffff14 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0x00000000 0xffffff12 0xffffff13 0x00000000 0x00000000 Read operation completed in 0.48 milliseconds. 21/03/2024 01:59 I noticed with above we're only seeing a data rate of about 1 MB/s. This is the timed part: // Measure time taken to read gettimeofday(&start, NULL); // Read and print the specified number of words for(size_t i = 0; i < word_count; ++i) { read_result = *((uint32_t *) virt_addr); printf(\"0x%08x \", read_result); virt_addr = (char *)virt_addr + sizeof(uint32_t); // Move to the next word } printf(\"\\n\"); gettimeofday(&end, NULL); // Measure time taken to read gettimeofday (&start, NULL ); // Read and print the specified number of words for ( size_t i = 0 ; i < word_count; ++i) { read_result = *(( uint32_t *) virt_addr); printf ( \"0x%08x \" , read_result); virt_addr = ( char *)virt_addr + sizeof ( uint32_t ); // Move to the next word } printf ( \"\\n\" ); gettimeofday (&end, NULL ); But I think this is actually just an artifact of printing. I editted the script to have more timing and removed the printout: #include <stdio.h> #include <stdlib.h> #include <stdint.h> #include <unistd.h> #include <string.h> #include <errno.h> #include <signal.h> #include <fcntl.h> #include <ctype.h> #include <termios.h> #include <sys/types.h> #include <sys/mman.h> #include <sys/time.h> #define PRINT_ERROR \\ do { \\ fprintf(stderr, \"Error at line %d, file %s (%d) [%s]\\n\", \\ __LINE__, __FILE__, errno, strerror(errno)); exit(1); \\ } while(0) #define MAP_SIZE_DEFAULT 4096UL #define MAP_MASK (MAP_SIZE_DEFAULT - 1) int main(int argc, char **argv) { int fd; void *map_base, *virt_addr; uint32_t *read_result; char *filename; off_t target; size_t word_count = 0; size_t map_size = MAP_SIZE_DEFAULT; // Default map size struct timeval start, end; long time_taken_microseconds; if(argc < 4 || argc > 5) { fprintf(stderr, \"\\nUsage:\\t%s { sys file } { offset } { word count } [ map size ]\\n\" \"\\tsys file: sysfs file for the PCI resource to act on\\n\" \"\\toffset : offset into PCI memory region to act upon\\n\" \"\\tword count: number of words to read\\n\" \"\\tmap size (optional): size of memory mapping in bytes (default: 4096)\\n\\n\", argv[0]); exit(1); } filename = argv[1]; target = strtoul(argv[2], 0, 0); word_count = atoi(argv[3]); if(argc == 5) map_size = atoi(argv[4]); gettimeofday(&start, NULL); if((fd = open(filename, O_RDWR | O_SYNC)) == -1) PRINT_ERROR; gettimeofday(&end, NULL); time_taken_microseconds = ((end.tv_sec - start.tv_sec) * 1000000 + (end.tv_usec - start.tv_usec)); printf(\"%s opened in %ld microseconds.\\n\", filename, time_taken_microseconds); gettimeofday(&start, NULL); /* Map memory */ map_base = mmap(0, map_size, PROT_READ, MAP_SHARED, fd, target & ~MAP_MASK); gettimeofday(&end, NULL); time_taken_microseconds = ((end.tv_sec - start.tv_sec) * 1000000 + (end.tv_usec - start.tv_usec)); printf(\"PCI Memory mapped to address 0x%08lx with size %lu bytes in %ld microseconds.\\n\", (unsigned long) map_base, map_size, time_taken_microseconds); virt_addr = map_base; printf(\"Reading %lu words from offset 0x%lx in bulk mode:\\n\", word_count, (unsigned long)target); gettimeofday(&start, NULL); // Read data in bulk mode read_result = (uint32_t *)virt_addr; for(size_t i = 0; i < word_count; ++i) { //printf(\"0x%08x \", read_result[i]); } printf(\"\\n\"); gettimeofday(&end, NULL); time_taken_microseconds = ((end.tv_sec - start.tv_sec) * 1000000 + (end.tv_usec - start.tv_usec)); printf(\"Read operation completed in %ld microseconds.\\n\", time_taken_microseconds); gettimeofday(&start, NULL); if(munmap(map_base, map_size) == -1) PRINT_ERROR; gettimeofday(&end, NULL); time_taken_microseconds = ((end.tv_sec - start.tv_sec) * 1000000 + (end.tv_usec - start.tv_usec)); printf(\"Memory unmapped in %ld microseconds.\\n\", time_taken_microseconds); gettimeofday(&start, NULL); close(fd); gettimeofday(&end, NULL); time_taken_microseconds = ((end.tv_sec - start.tv_sec) * 1000000 + (end.tv_usec - start.tv_usec)); printf(\"%s closed in %ld microseconds.\\n\", filename, time_taken_microseconds); return 0; } #include <stdio.h> #include <stdlib.h> #include <stdint.h> #include <unistd.h> #include <string.h> #include <errno.h> #include <signal.h> #include <fcntl.h> #include <ctype.h> #include <termios.h> #include <sys/types.h> #include <sys/mman.h> #include <sys/time.h> #define PRINT_ERROR \\ do { \\ fprintf(stderr, \"Error at line %d, file %s (%d) [%s]\\n\", \\ __LINE__, __FILE__, errno, strerror(errno)); exit(1); \\ } while(0) #define MAP_SIZE_DEFAULT 4096UL #define MAP_MASK (MAP_SIZE_DEFAULT - 1) int main(int argc, char **argv) { int fd; void *map_base, *virt_addr; uint32_t *read_result; char *filename; off_t target; size_t word_count = 0; size_t map_size = MAP_SIZE_DEFAULT; // Default map size struct timeval start, end; long time_taken_microseconds; if(argc < 4 || argc > 5) { fprintf(stderr, \"\\nUsage:\\t%s { sys file } { offset } { word count } [ map size ]\\n\" \"\\tsys file: sysfs file for the PCI resource to act on\\n\" \"\\toffset : offset into PCI memory region to act upon\\n\" \"\\tword count: number of words to read\\n\" \"\\tmap size (optional): size of memory mapping in bytes (default: 4096)\\n\\n\", argv[0]); exit(1); } filename = argv[1]; target = strtoul(argv[2], 0, 0); word_count = atoi(argv[3]); if(argc == 5) map_size = atoi(argv[4]); gettimeofday(&start, NULL); if((fd = open(filename, O_RDWR | O_SYNC)) == -1) PRINT_ERROR; gettimeofday(&end, NULL); time_taken_microseconds = ((end.tv_sec - start.tv_sec) * 1000000 + (end.tv_usec - start.tv_usec)); printf(\"%s opened in %ld microseconds.\\n\", filename, time_taken_microseconds); gettimeofday(&start, NULL); /* Map memory */ map_base = mmap(0, map_size, PROT_READ, MAP_SHARED, fd, target & ~MAP_MASK); gettimeofday(&end, NULL); time_taken_microseconds = ((end.tv_sec - start.tv_sec) * 1000000 + (end.tv_usec - start.tv_usec)); printf(\"PCI Memory mapped to address 0x%08lx with size %lu bytes in %ld microseconds.\\n\", (unsigned long) map_base, map_size, time_taken_microseconds); virt_addr = map_base; printf(\"Reading %lu words from offset 0x%lx in bulk mode:\\n\", word_count, (unsigned long)target); gettimeofday(&start, NULL); // Read data in bulk mode read_result = (uint32_t *)virt_addr; for(size_t i = 0; i < word_count; ++i) { //printf(\"0x%08x \", read_result[i]); } printf(\"\\n\"); gettimeofday(&end, NULL); time_taken_microseconds = ((end.tv_sec - start.tv_sec) * 1000000 + (end.tv_usec - start.tv_usec)); printf(\"Read operation completed in %ld microseconds.\\n\", time_taken_microseconds); gettimeofday(&start, NULL); if(munmap(map_base, map_size) == -1) PRINT_ERROR; gettimeofday(&end, NULL); time_taken_microseconds = ((end.tv_sec - start.tv_sec) * 1000000 + (end.tv_usec - start.tv_usec)); printf(\"Memory unmapped in %ld microseconds.\\n\", time_taken_microseconds); gettimeofday(&start, NULL); close(fd); gettimeofday(&end, NULL); time_taken_microseconds = ((end.tv_sec - start.tv_sec) * 1000000 + (end.tv_usec - start.tv_usec)); printf(\"%s closed in %ld microseconds.\\n\", filename, time_taken_microseconds); return 0; } output: [root@fe01 pcimem]# sudo ./pcie_read_dynamic /dev/mem 2147483648 512 /dev/mem opened in 6 microseconds. PCI Memory mapped to address 0x7f2302115000 with size 4096 bytes in 13 microseconds. Reading 512 words from offset 0x80000000 in bulk mode: Read operation completed in 7 microseconds. Memory unmapped in 7 microseconds. /dev/mem closed in 3 microseconds. [root@fe01 pcimem] # sudo ./pcie_read_dynamic /dev/mem 2147483648 512 /dev/mem opened in 6 microseconds. PCI Memory mapped to address 0x7f2302115000 with size 4096 bytes in 13 microseconds. Reading 512 words from offset 0x80000000 in bulk mode: Read operation completed in 7 microseconds. Memory unmapped in 7 microseconds. /dev/mem closed in 3 microseconds. Though, this doesn't seem right because it doesn't scale, see trying to read 1 word: [root@fe01 pcimem]# sudo ./pcie_read_dynamic /dev/mem 2147483648 1 /dev/mem opened in 6 microseconds. PCI Memory mapped to address 0x7f897ac92000 with size 4096 bytes in 13 microseconds. Reading 1 words from offset 0x80000000 in bulk mode: Read operation completed in 11 microseconds. Memory unmapped in 7 microseconds. /dev/mem closed in 4 microseconds. [root@fe01 pcimem]# [root@fe01 pcimem] # sudo ./pcie_read_dynamic /dev/mem 2147483648 1 /dev/mem opened in 6 microseconds. PCI Memory mapped to address 0x7f897ac92000 with size 4096 bytes in 13 microseconds. Reading 1 words from offset 0x80000000 in bulk mode: Read operation completed in 11 microseconds. Memory unmapped in 7 microseconds. /dev/mem closed in 4 microseconds. [root@fe01 pcimem] # The size of the map doesn't seem to matter either (set to 4 bytes here): [root@fe01 pcimem]# sudo ./pcie_read_dynamic /dev/mem 2147483648 4 4 /dev/mem opened in 7 microseconds. PCI Memory mapped to address 0x7fcc26247000 with size 4 bytes in 13 microseconds. Reading 4 words from offset 0x80000000 in bulk mode: Read operation completed in 10 microseconds. Memory unmapped in 7 microseconds. /dev/mem closed in 4 microseconds. [root@fe01 pcimem]# [root@fe01 pcimem] # sudo ./pcie_read_dynamic /dev/mem 2147483648 4 4 /dev/mem opened in 7 microseconds. PCI Memory mapped to address 0x7fcc26247000 with size 4 bytes in 13 microseconds. Reading 4 words from offset 0x80000000 in bulk mode: Read operation completed in 10 microseconds. Memory unmapped in 7 microseconds. /dev/mem closed in 4 microseconds. [root@fe01 pcimem] # I believe what's happening here is these timings are just overhead of these system operation of interacting with the memory map on the host computer. This script does not actually deal with any data transfer, rather, I think it incites data transfer (write to a virtual address mapped to target address, then some controller handles copying the data in the virtual address over). This makes timing the actual data transfer rate not as trivial as what I tried above.",
    "textLength": 8571
  },
  {
    "kind": "work-log",
    "title": "01_09_2024 - 07_09_2024.html",
    "fileName": "01_09_2024 - 07_09_2024.html",
    "url": "resources/work_logs/01_09_2024 - 07_09_2024.html",
    "createdDate": "2024-09-01",
    "text": "01/09/2024 - 07/09/2024 01/09/2024 - 07/09/2024 04/09/2024 04:55 It seems there is a statistically signficant difference between the DDR3 DMA and Block RAM DMA. Particularly in host to card (h2c) transfers. This is evidence that changing the firmware may have actually had an effect. It is also possible that the system capabilities vary based on what's running on the system (but I find this doubtful). 04/09/2024 05:11 As a sanity check, I ran the DDR3 tests again. It seems fairly unstable for lower data transfer sizes. But the results seem the same for higher data transfer sizes. 04/09/2024 05:42 Using the python frontend, I tested the data rate it was able to write to the SSD. Example screenshot: I wrote a specified amount of zeros to a midas bank for each event. By changing the amount of zeros I observed the effect on the event rate and the data rate. The target event rate for each of these was 100 Hz. Number of Zeros in Buffer Event Rate [events/s] Data Rate [MB/s] 1000 94.5 0.186 10000 90.9 1.778 50000 86.5 8.451 100000 77.6 15.152 250000 49.1 23.998 500000 43.2 42.201 1250000 18.3 44.647 2500000 3.6 17.757 5000000 0.6 5.976 It appears the max data rate is about 45 MB/s. This is over 20 times worse than the max data rate seen using a similar C++ frontend. Furthermore, achieving the high data throughput causes the event rate to suffer. 04/09/2024 05:48 So I thought, \"okay but what if we could have two frontends spewing data, could we get a higher write rate?\". So I did that using these specs: Number of Zeros in Buffer Event Rate [events/s] Data Rate [MB/s] 1250000 18.3 44.647 Screenshot: And wouldn't you know it, we get effectively double the data rate. Maybe we can avoid this multiple frontend nonsense with some multithreading(?). 05/09/2024 20:39 In response to a message asking how to optomize python data rate performance: https://daq00.triumf.ca/elog-midas/Midas/2826 What limits the rate that poll_func is called in a python frontend? First the general advice: if you reduce the \"period\" of your equipment, then your function will get called more frequently. You can set it to 0 and we'll call it as often as possible. You can set this in the ODB at \"/Equipment/Python Data Simulator/Common/Period\" If that's still not fast enough, then you can return a list of events from your readout_func. I've seen real-world cases of 25kHz+ of midas events generated in this fashion. However in your case the limitation is likely that you're sending 1.25MB per event and we have a lot of data marshalling to do between the python and C++ layer. In particular it takes 15ms on my machine to just pack the data into a memory buffer (see timeit command below). I am sure there must be a faster way to do this packing, especially in the case where the bank contains a numpy array rather than a python list. I'll add it to my to-do list to investigate improving the performance of medium-to-large events in the python code. Cheers, Ben P.S. You may have a bug in your calculations (depending on how you did your testing). In poll_func I think you should be updating the stats every time the function is called, not just the times when you return True. P.P.S. Command I used to test how slow it is to pack the data. One-time setup of creating the buffers, then multiple tests of the pack_into function: python -m timeit -s \"import struct;import ctypes;arr = [0]*1250001;buf = ctypes.create_string_buffer(10000000);fmt = \">1250000d\"\" \"struct.pack_into(fmt, buf, *arr)\" 20 loops, best of 5: 15.3 msec per loop As he suggested in the last line (this just show how long it takes data to move from C++ to python) [root@dhcp-10-163-105-238 frontend_simulator]# python -m timeit -s \"import struct;import ctypes;arr = [0]*1250001;buf = ctypes.create_string_buffer(10000000);fmt = \\\">1250000d\\\"\" \"struct.pack_into(fmt, buf, *arr)\" 10 loops, best of 3: 43.7 msec per loop [root @dhcp -10 -163 -105 -238 frontend_simulator] # python -m timeit -s \"import struct;import ctypes;arr = [0]*1250001;buf = ctypes.create_string_buffer(10000000);fmt = \\\" >1250000d\\ \"\" \"struct.pack_into(fmt, buf, *arr)\" 10 loops, best of 3 : 43.7 msec per loop This suggests our maximum data rate is (1000/43.7) Hz * 1.25 MB/s = 23 MB/s ? This seems wrong, as we surpass this limit. 06/09/2024 15:23 Using the suggestions, I set the rate to unlimited (0 period) and my artificial polling rate to 10kHz with each event being an array of zeros length 10000. I cap out at 60 MB/s per frontend. 06/09/2024 15:53 With no data limitations, I'm able to generate data at around 10kHz 06/09/2024 15:55 Some new data: Number of Zeros in Buffer Target Event Rate [events/s] Event Rate [events/s] Data Rate [MB/s] 1 10000 9700 0.265 1000 10000 7700 15.2 10000 10000 3200 62.9 20000 10000 2000 78.3 30000 10000 1430 84.2 40000 10000 1100 87.0 50000 10000 900 88.4 60000 10000 770 90.5 70000 10000 670 91.6 80000 10000 590 92.1 90000 10000 528 92.6 100000 10000 472 92.3 150000 10000 245 72.2 200000 10000 182 71.1 500000 10000 62 60.1 So our \"new record\" is about 100 MB/s 06/09/2024 16:11 For parameters: Number of Zeros in Buffer Target Event Rate [events/s] Event Rate [events/s] Data Rate [MB/s] 100000 10000 472 92.3 We see limited bottlenecking when another frontend is added: Furthermore, we see limited bottlenecking due to logger on (this screenshot of logger being off)",
    "textLength": 1030
  },
  {
    "kind": "work-log",
    "title": "23_06_2024 - 29_06_2024.html",
    "fileName": "23_06_2024 - 29_06_2024.html",
    "url": "resources/work_logs/23_06_2024 - 29_06_2024.html",
    "createdDate": "2024-06-23",
    "text": "23/06/2024 - 29/06/2024 23/06/2024 - 29/06/2024 26/06/2024 21:12 I got AMC13Tool2.exe to build. I basically just replaced all instances of unordered maps with boost::unordered_maps and then it built. Here are the list of edits: Launcher_commands_status.cc::242 boost::unordered_map<std::string,std::string> parameters = itNode->getParameters(); boost::unordered_map<std::string,std::string>::iterator itTable; boost::unordered_map<std::string,std::string> parameters = itNode->getParameters(); boost::unordered_map<std::string,std::string>::iterator itTable; Launcher_commands_control.cc::588 const boost::unordered_map<std::string,std::string> params = node.getParameters(); for( boost::unordered_map<std::string,std::string>::const_iterator it = params.begin(); const boost ::unordered_map <std ::string ,std ::string > params = node.getParameters(); for( boost ::unordered_map <std ::string ,std ::string > ::const_iterator it = params .begin(); Status.hh::101 std::string ParseRow(boost::unordered_map<std::string,std::string> & parameters, std::string const & addressBase) const; std::string ParseCol(boost::unordered_map<std::string,std::string> & parameters, std::string const & addressBase) const; std:: string ParseRow (boost:: unordered_map <std:: string ,std:: string > & parameters, std:: string const & addressBase) const ; std:: string ParseCol (boost:: unordered_map <std:: string ,std:: string > & parameters, std:: string const & addressBase) const ; Status.cc::534 std::string SparseCellMatrix::ParseCol(boost::unordered_map<std::string,std::string> & parameters, std::string const & addressBase) const std:: string SparseCellMatrix :: ParseCol (boost:: unordered_map <std:: string ,std:: string > & parameters, std:: string const & addressBase) const Status.cc::487 std::string SparseCellMatrix::ParseRow(boost::unordered_map<std::string,std::string> & parameters, std::string const & addressBase) const { std:: string SparseCellMatrix :: ParseRow (boost:: unordered_map <std:: string ,std:: string > & parameters, std:: string const & addressBase) const { Status.cc::350 boost::unordered_map<std::string,std::string> parameters = node.getParameters(); boost::unordered_map<std::string,std::string> parameters = node. getParameters (); Status.cc::70 boost::unordered_map<std::string,std::string> parameters = itNode->getParameters(); boost::unordered_map<std::string,std::string> parameters = itNode -> getParameters (); I also needed to add python to my C++ include path (I didn't feel like editting the make file). There were some errors with some of the python scripts having invalid syntax, but I ignored those. export CPLUS_INCLUDE_PATH=$CPLUS_INCLUDE_PATH:/opt/rh/rh-python36/root/usr/include/python3.6m export CPLUS_INCLUDE_PATH = $CPLUS_INCLUDE_PATH :/opt/rh/rh-python36/root/usr/include/python3 . 6 m After all these edits, I was abel to successfully run make cd /home/installation_testing/packages/experiment/lxedaq/amc13/amc13_v1_2_18/ make cd /home/i nstallation_testing /packages/ experiment /lxedaq/ amc13 /amc13_v1_2_18/ make Which made these files [root@dhcp-10-163-105-238 bin]# pwd /home/installation_testing/packages/experiment/lxedaq/amc13/amc13_v1_2_18/tools/bin [root@dhcp-10-163-105-238 bin]# ls AMC13BenchTest.exe AMC13Tool2.exe AMC13ToolFlash.exe LaTeXprint.exe [root@dhcp-10-163-105-238 bin]# [root@dhcp -10 -163 -105 -238 bin]# pwd /home/installation_testing/packages/experiment/lxedaq/amc13/amc13_v1_2_18/tools/bin [root@dhcp -10 -163 -105 -238 bin]# ls AMC13BenchTest.exe AMC13Tool2.exe AMC13ToolFlash.exe LaTeXprint.exe [root@dhcp -10 -163 -105 -238 bin]# To use AMC13Tool2.exe, I had to the libraries built by the makefile to my LD_LIBRARY_PATH environment variable: export LD_LIBRARY_PATH=/home/installation_testing/packages/experiment/lxedaq/amc13/amc13_v1_2_18/amc13/lib/:$LD_LIBRARY_PATH export LD_LIBRARY_PATH=/home/installation_testing/packages/experiment/lxedaq/amc13/amc13_v1_2_18/tools/lib:$LD_LIBRARY_PATH export LD_LIBRARY_PATH= /home/i nstallation_testing /packages/ experiment /lxedaq/ amc13 /amc13_v1_2_18/ amc13 /lib/ : $LD_LIBRARY_PATH export LD_LIBRARY_PATH= /home/i nstallation_testing /packages/ experiment /lxedaq/ amc13 /amc13_v1_2_18/ tools/lib: $LD_LIBRARY_PATH Finally, I could use the tool with this command (must specify path to board files): [root@dhcp-10-163-105-238 tools]# bin/AMC13Tool2.exe -c 192.168.1.13 -p /home/installation_testing/packages/experiment/lxedaq/address_tables/ Address table path \"/home/installation_testing/packages/experiment/lxedaq/address_tables/\" set on command line use_ch false Created URI from IP address: T2: ipbusudp-2.0://192.168.1.13:50001 T1: ipbusudp-2.0://192.168.1.14:50001 Using AMC13 software ver:0 Read firmware versions 0x813f 0x2e flavor = 5 features = 0x000000b4 > [root@dhcp- 10 - 163 - 105 - 238 tools]# bin /AMC13Tool2.exe -c 192.168.1.13 -p / home /installation_testing/ packages /experiment/ lxedaq /address_tables/ Address table path \"/home/installation_testing/packages/experiment/lxedaq/address_tables/\" set on command line use_ch false Created URI from IP address: T2: ipbusudp- 2.0 : //192.168.1.13:50001 T1: ipbusudp- 2.0 : //192.168.1.14:50001 Using AMC13 software ver: 0 Read firmware versions 0 x813f 0 x2e flavor = 5 features = 0 x000000b4 > 26/06/2024 21:21 https://bucms.bu.edu/twiki/bin/view/BUCMSPublic/AMC13Tool2 Here gives the useful AMC13Tool2 commands. Supposedly you can still edit the AMC13 10gBe link the same way; by editting reigster 0x1c1c I did not actually try configuring the AMC13s with this 26/06/2024 22:02 I swapped the AMC13 we had in crate 2 into crate 1. I configured the system to return to a 1 crate setup (changed T1, T2, and 10GbE IPs to be the same as the AMC!3 that was previously in crate 1, then disabled AMC13002 in midas). I suspect there is something wrong with the AMC13 I took out of crate 1 after doing tests at UW. I'll leave the system running at a high rate to see. 28/06/2024 16:12 Running at 5KHz, I was able to run for 6 hours. 21:00:13.355 2024/06/27 [MasterGM2,TALK] Alarm: CCC Run Aborted 14:55:01.448 2024/06/27 [MasterGM2,TALK] Alarm: DAQ | MasterGM2 discovered severe fill number mismatch 14:53:19.552 2024/06/27 [mhttpd,INFO] Run #246 started 21:00:13.355 2024/06/27 [MasterGM2,TALK] Alarm: CCC Run Aborted 14:55:01.448 2024/06/27 [MasterGM2,TALK] Alarm: DAQ | MasterGM2 discovered severe fill number mismatch 14:53:19.552 2024/06/27 [mhttpd,INFO] Run #246 started Running at ~7kHz, I was able to run for 8 hours: 06:00:13.413 2024/06/27 [MasterGM2,TALK] Alarm: CCC Run Aborted 22:00:50.178 2024/06/26 [MasterGM2,TALK] Alarm: DAQ | MasterGM2 discovered severe fill number mismatch 21:59:38.197 2024/06/26 [mhttpd,INFO] Run #244 start 06:00:13.413 2024/06/27 [MasterGM2,TALK] Alarm: CCC Run Aborted 22:00:50.178 2024/06/26 [MasterGM2,TALK] Alarm: DAQ | MasterGM2 discovered severe fill number mismatch 21:59:38.197 2024/06/26 [mhttpd,INFO] Run #244 start Both of these are much longer than any run we've had before. This is with the publisher off. Trying to start a new run gives the normal errors: So the frontends need to be reset when this happens. 28/06/2024 16:56 I tried programming the \"old\" AMC13 with AMC13Tool2 instead with the following steps: export LD_LIBRARY_PATH=/home/installation_testing/packages/experiment/lxedaq/amc13/amc13_v1_2_18/amc13/lib/:$LD_LIBRARY_PATH export LD_LIBRARY_PATH=/home/installation_testing/packages/experiment/lxedaq/amc13/amc13_v1_2_18/tools/lib:$LD_LIBRARY_PATH bin/AMC13Tool2.exe -c 192.168.2.13 -p /home/installation_testing/packages/experiment/lxedaq/address_tables/ export LD_LIBRARY_PATH= /home/i nstallation_testing /packages/ experiment /lxedaq/ amc13 /amc13_v1_2_18/ amc13 /lib/ : $LD_LIBRARY_PATH export LD_LIBRARY_PATH= /home/i nstallation_testing /packages/ experiment /lxedaq/ amc13 /amc13_v1_2_18/ tools/lib: $LD_LIBRARY_PATH bin /AMC13Tool2.exe -c 192.168.2.13 -p / home /installation_testing/ packages /experiment/ lxedaq /address_tables/ Then inside the CLI: en 1-12 daq 1 wv 0x1c1c 0xc0a83301 rd en 1 - 12 daq 1 wv 0 x1c1c 0 xc0a83301 rd and I was able to ping the 10GbE interface at 192.168.51.1, so it seemed to work. However, whenever starting a running, immedately filled the GPU buffer when running at either 5kHz or 2kHz. This didn't seem to be the case for the 1 crate system, so I tried changing the buffer parameters to the same thing I changed them to at the UW setup: tcp_thread.cxx::98 unsigned int TCPdatasizemax = 0x00800000; ///< max data size 8MB unsigned int TCPdatasizemax = 0x00800000 ; ///< max data size 8MB gpu_thread.cxx::91 int gpu_data_raw_size_max = 0x00800000; // 8MB, same as the tcp max int gpu_data_raw_size_max = 0x00800000 ; // 8MB, same as the tcp max tcp_thread.h::135 #define TCP_BUF_MAX_FILLS 256 # define TCP_BUF_MAX_FILLS 256 gpu_thread.h::45 #define GPU_BUFFER_SIZE 512 # define GPU_BUFFER_SIZE 512 But that didn't seem to to solve the problem. I then turned off trigger throttling by commenting out these lines: gpu_thread.cpp::539 //Do not proceed if the GPU buffer is full //This is currently broken (throttles, but never returns) /* if ( (gpu_buffer_filled >= GPU_BUFFER_SIZE - 1) || (tcp_buffer_filled >= TCP_BUF_MAX_FILLS - 1) ) { fc7help->setThrottleTriggers(encoder_fc7, frontend_index, 1); triggersThrottled = true; // Check if at least 10 minutes have passed since the last message, print warning if so. std::time_t current_time = std::time(nullptr); // Get the current time int seconds_between_messages = 600; if (isElapsedTime(current_time, last_msg_time, seconds_between_messages)) { cm_msg(MINFO, __FILE__, \"Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers.\"); last_msg_time = current_time; // Update the last message time } continue; } else if (triggersThrottled) { fc7help->setThrottleTriggers(encoder_fc7, frontend_index, 0); triggersThrottled = false; cm_msg(MINFO, __FILE__, \"Trigger throttling removed\"); } */ //Do not proceed if the GPU buffer is full //This is currently broken (throttles, but never returns) /* if ( (gpu_buffer_filled >= GPU_BUFFER_SIZE - 1) || (tcp_buffer_filled >= TCP_BUF_MAX_FILLS - 1) ) { fc7help->setThrottleTriggers(encoder_fc7, frontend_index, 1); triggersThrottled = true; // Check if at least 10 minutes have passed since the last message, print warning if so. std::time_t current_time = std::time(nullptr); // Get the current time int seconds_between_messages = 600; if (isElapsedTime(current_time, last_msg_time, seconds_between_messages)) { cm_msg(MINFO, __FILE__, \"Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers.\"); last_msg_time = current_time; // Update the last message time } continue; } else if (triggersThrottled) { fc7help->setThrottleTriggers(encoder_fc7, frontend_index, 0); triggersThrottled = false; cm_msg(MINFO, __FILE__, \"Trigger throttling removed\"); } */ But that didn't do anything but cause the AMC13 to crash instead of throttle. So I power cycled the crate and reconfigured the old AMC13 using AMC13Tool (not AMC13Tool2.exe) but that didn't fix the issue either. Somehow the act of using the 2 crate system is causing the \"old\" AMC13 to lag behind in a way we weren't seeing before? Though the ring buffer is always filling up in the \"new\" AMC13 (I think it's getting ahead somehow, then waiting for the \"old\" AMC13 to catch up): 16:50:16.281 2024/06/28 [mhttpd,INFO] Run #250 stopped 16:50:16.180 2024/06/28 [mhttpd,ERROR] [midas.cxx:4292:cm_transition_call,ERROR] cannot connect to client \"Ebuilder\" on host localhost, port 40454, status 503 16:50:16.180 2024/06/28 [mhttpd,ERROR] [midas.cxx:12142:rpc_client_connect,ERROR] cannot connect to \"localhost\" port 40454: cannot connect to host \"localhost\" port 40454, errno 111 (Connection refused) 16:50:16.081 2024/06/28 [AMC13001,ERROR] [frontend.cpp:2584:frontend.cpp,ERROR] TCP/GPU/Midas fill numbers do not match at the end of the run. 16:50:16.080 2024/06/28 [AMC13002,TALK] Warning: DAQ | End of Run Fill Number Mismatch from AMC13002 16:50:16.080 2024/06/28 [AMC13002,ERROR] [frontend.cpp:2584:frontend.cpp,ERROR] TCP/GPU/Midas fill numbers do not match at the end of the run. 16:49:57.973 2024/06/28 [Ebuilder,INFO] evb exit status 509, auto_restart 0 16:49:57.973 2024/06/28 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 16:49:57.973 2024/06/28 [AMC13001,TALK] Warning: DAQ | AMC13001 GPU Ring buffer close to full (90.039062%) 16:49:57.972 2024/06/28 [AMC13002,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 16:49:51.978 2024/06/28 [mhttpd,INFO] Alarm \"End of Run Master\" reset 16:49:48.949 2024/06/28 [MasterGM2,TALK] Warning: DAQ | Suspect fill number mismatch. Check Event numbers! 16:49:48.949 2024/06/28 [MasterGM2,ERROR] [frontend.cpp:1284:frontend.cpp,ERROR] End of Run: checking other frontend fill numbers, time out! 16:49:48.949 2024/06/28 [MasterGM2,INFO] End of Run: DC7 Triggers Received 8710 Count triggers 3146 16:49:48.949 2024/06/28 [MasterGM2,ERROR] [frontend.cpp:1205:end_of_run,ERROR] FC7-10: Unable to Verify Run has Stopped (Run state still in progress) 16:49:14.561 2024/06/28 [mhttpd,INFO] Alarm \"Frontend GPU Buffer Error\" reset 16:49:13.810 2024/06/28 [mhttpd,INFO] Alarm \"Frontend TCP Buffer Error\" reset 16:48:16.614 2024/06/28 [mhttpd,INFO] Run #250 started 16:50:16.281 2024/06/28 [mhttpd,INFO] Run #250 stopped 16:50:16.180 2024/06/28 [mhttpd,ERROR] [midas.cxx:4292:cm_transition_call,ERROR] cannot connect to client \"Ebuilder\" on host localhost, port 40454, status 503 16:50:16.180 2024/06/28 [mhttpd,ERROR] [midas.cxx:12142:rpc_client_connect,ERROR] cannot connect to \"localhost\" port 40454: cannot connect to host \"localhost\" port 40454, errno 111 (Connection refused) 16:50:16.081 2024/06/28 [AMC13001,ERROR] [frontend.cpp:2584:frontend.cpp,ERROR] TCP/GPU/Midas fill numbers do not match at the end of the run. 16:50:16.080 2024/06/28 [AMC13002,TALK] Warning: DAQ | End of Run Fill Number Mismatch from AMC13002 16:50:16.080 2024/06/28 [AMC13002,ERROR] [frontend.cpp:2584:frontend.cpp,ERROR] TCP/GPU/Midas fill numbers do not match at the end of the run. 16:49:57.973 2024/06/28 [Ebuilder,INFO] evb exit status 509, auto_restart 0 16:49:57.973 2024/06/28 [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 16:49:57.973 2024/06/28 [AMC13001,TALK] Warning: DAQ | AMC13001 GPU Ring buffer close to full (90.039062%) 16:49:57.972 2024/06/28 [AMC13002,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. 16:49:51.978 2024/06/28 [mhttpd,INFO] Alarm \"End of Run Master\" reset 16:49:48.949 2024/06/28 [MasterGM2,TALK] Warning: DAQ | Suspect fill number mismatch. Check Event numbers! 16:49:48.949 2024/06/28 [MasterGM2,ERROR] [frontend.cpp:1284:frontend.cpp,ERROR] End of Run: checking other frontend fill numbers, time out! 16:49:48.949 2024/06/28 [MasterGM2,INFO] End of Run: DC7 Triggers Received 8710 Count triggers 3146 16:49:48.949 2024/06/28 [MasterGM2,ERROR] [frontend.cpp:1205:end_of_run,ERROR] FC7-10: Unable to Verify Run has Stopped (Run state still in progress) 16:49:14.561 2024/06/28 [mhttpd,INFO] Alarm \"Frontend GPU Buffer Error\" reset 16:49:13.810 2024/06/28 [mhttpd,INFO] Alarm \"Frontend TCP Buffer Error\" reset 16:48:16.614 2024/06/28 [mhttpd,INFO] Run #250 started 28/06/2024 17:12 I'm now remembering the ODB mode for the master frontend only looks at AMC13001 for it's triggers (i.e. only works for a 1 crate system). I'm going to \"revive\" the meinberg system. I put the meinberg back in and connected al the cables. When I tried running the 1 crate system I got constant CCC run aborts immediately from the Master. To remedy this, I had to rerun sudo /sbin/modprobe mbgclock sudo /sbin/m odprobe mbgclock After this, it appeared the CCC run aborts went away for the 1 crate system. I then tried enabling the second crate and this seemed to do the trick. The GPU Buffer stopped filling immediately, and runs seemed to work for a bit. 28/06/2024 17:46",
    "textLength": 2527
  },
  {
    "kind": "work-log",
    "title": "05_05_2024 - 11_05_2024.html",
    "fileName": "05_05_2024 - 11_05_2024.html",
    "url": "resources/work_logs/05_05_2024 - 11_05_2024.html",
    "createdDate": "2024-05-05",
    "text": "05/05/2024 - 11/05/2024 05/05/2024 - 11/05/2024 05/05/2024 - 11/05/2024 05/05/2024 23:10 I started getting CCC run abort errors when running for short times (0 to 10 minutes). The crate monitor gives these errors: AMC13 FC7 Not sure what an AMC version mismatch is. 07/05/2024 19:35 UW CPU: [root@cenpa-pioneer j.carlton]# lscpu Architecture: x86_64 CPU op-mode(s): 32-bit, 64-bit Byte Order: Little Endian CPU(s): 6 On-line CPU(s) list: 0-5 Thread(s) per core: 1 Core(s) per socket: 6 Socket(s): 1 NUMA node(s): 1 Vendor ID: GenuineIntel CPU family: 6 Model: 85 Model name: Intel(R) Xeon(R) Bronze 3204 CPU @ 1.90GHz Stepping: 7 CPU MHz: 799.938 CPU max MHz: 1900.0000 CPU min MHz: 800.0000 BogoMIPS: 3800.00 Virtualization: VT-x L1d cache: 32K L1i cache: 32K L2 cache: 1024K L3 cache: 8448K NUMA node0 CPU(s): 0-5 Flags: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb cat_l3 cdp_l3 invpcid_single intel_ppin ssbd mba rsb_ctxsw ibrs ibpb stibp ibrs_enhanced tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm mpx rdt_a avx512f avx512dq rdseed adx smap clflushopt clwb intel_pt avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm arat pln pts hwp hwp_act_window hwp_epp hwp_pkg_req pku ospke avx512_vnni md_clear spec_ctrl intel_stibp flush_l1d arch_capabilities [root@cenpa-pioneer j.carlton]# [root@cenpa-pioneer j.carlton]# lscpu Architecture: x86_64 CPU op-mode(s): 32-bit, 64-bit Byte Order: Little Endian CPU(s): 6 On-line CPU(s) list: 0-5 Thread(s) per core: 1 Core(s) per socket: 6 Socket(s): 1 NUMA node(s): 1 Vendor ID: GenuineIntel CPU family: 6 Model: 85 Model name: Intel(R) Xeon(R) Bronze 3204 CPU @ 1.90GHz Stepping: 7 CPU MHz: 799.938 CPU max MHz: 1900.0000 CPU min MHz: 800.0000 BogoMIPS: 3800.00 Virtualization: VT-x L1d cache: 32K L1i cache: 32K L2 cache: 1024K L3 cache: 8448K NUMA node0 CPU(s): 0-5 Flags: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb cat_l3 cdp_l3 invpcid_single intel_ppin ssbd mba rsb_ctxsw ibrs ibpb stibp ibrs_enhanced tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm mpx rdt_a avx512f avx512dq rdseed adx smap clflushopt clwb intel_pt avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm arat pln pts hwp hwp_act_window hwp_epp hwp_pkg_req pku ospke avx512_vnni md_clear spec_ctrl intel_stibp flush_l1d arch_capabilities [root@cenpa-pioneer j.carlton]# UKY 'be' CPU: [root@dhcp-10-163-105-238 ~]# lscpu Architecture: x86_64 CPU op-mode(s): 32-bit, 64-bit Byte Order: Little Endian CPU(s): 12 On-line CPU(s) list: 0-11 Thread(s) per core: 2 Core(s) per socket: 6 Socket(s): 1 NUMA node(s): 1 Vendor ID: GenuineIntel CPU family: 6 Model: 45 Model name: Intel(R) Core(TM) i7-3930K CPU @ 3.20GHz Stepping: 7 CPU MHz: 3499.804 CPU max MHz: 3800.0000 CPU min MHz: 1200.0000 BogoMIPS: 6404.07 Virtualization: VT-x L1d cache: 32K L1i cache: 32K L2 cache: 256K L3 cache: 12288K NUMA node0 CPU(s): 0-11 Flags: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx est tm2 ssse3 cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic popcnt tsc_deadline_timer aes xsave avx lahf_lm epb ssbd rsb_ctxsw ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid xsaveopt dtherm ida arat pln pts md_clear spec_ctrl intel_stibp flush_l1d [root@dhcp-10-163-105-238 ~]# lscpu Architecture: x86_64 CPU op-mode(s): 32-bit, 64-bit Byte Order: Little Endian CPU(s): 12 On-line CPU(s) list: 0-11 Thread(s) per core: 2 Core(s) per socket: 6 Socket(s): 1 NUMA node(s): 1 Vendor ID: GenuineIntel CPU family: 6 Model: 45 Model name: Intel(R) Core(TM) i7-3930K CPU @ 3.20GHz Stepping: 7 CPU MHz: 3499.804 CPU max MHz: 3800.0000 CPU min MHz: 1200.0000 BogoMIPS: 6404.07 Virtualization: VT-x L1d cache: 32K L1i cache: 32K L2 cache: 256K L3 cache: 12288K NUMA node0 CPU(s): 0-11 Flags: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx est tm2 ssse3 cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic popcnt tsc_deadline_timer aes xsave avx lahf_lm epb ssbd rsb_ctxsw ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid xsaveopt dtherm ida arat pln pts md_clear spec_ctrl intel_stibp flush_l1d",
    "textLength": 957
  },
  {
    "kind": "work-log",
    "title": "20_10_2024 - 26_10_2024.html",
    "fileName": "20_10_2024 - 26_10_2024.html",
    "url": "resources/work_logs/20_10_2024 - 26_10_2024.html",
    "createdDate": "2024-10-20",
    "text": "20/10/2024 - 26/10/2024 20/10/2024 - 26/10/2024 24/10/2024 12:52 Naively I tried adding a \"DDR3 Writer\" IP block to the working ddr3 pcie design. It didn't work (more details below). Instead of making a new project, I built on top of the existing, so I had to waste some time rebuilidng the project. The point of this note is just to say that somehow adding the blocks, then removing and reconnecting screwed something up. Particularly, I tried playing with the MIG IP block, which I think renamed it's IP block somehow in vivado; then vivado could not longer find the board files that configure it. It seems just rebuilding the project from scratch worked. 24/10/2024 13:40 I created a new module AXI module in vivado, loosely following some steps in this manual . I wanted to write a AXI IP block that just writes an incrimneting number to one register in the DDR3 RAM every second (I chose the 0x0000_0000 address for this). I assume the given clock is a 250 MHz clock for this. The only extra logic I added was the following state machine: // Add user logic here // Parameters for state machine states localparam IDLE = 2'b00, INIT_WRITE = 2'b01, WAIT_WRITE = 2'b10; // Register for current state reg [1:0] state; // Counter for 1-second interval reg [31:0] second_counter; // Counter for data to write reg [31:0] write_data_counter; // AXI write address and data reg [C_M00_AXI_ADDR_WIDTH-1 : 0] axi_awaddr; reg [C_M00_AXI_DATA_WIDTH-1 : 0] axi_wdata; reg axi_awvalid; reg axi_wvalid; // 250 MHz clock = 250 million cycles per second localparam ONE_SECOND_COUNT = 250_000_000; // AXI transaction done signal assign m00_axi_awvalid = axi_awvalid; assign m00_axi_wvalid = axi_wvalid; assign m00_axi_awaddr = axi_awaddr; assign m00_axi_wdata = axi_wdata; // Main state machine always @(posedge m00_axi_aclk) begin if (!m00_axi_aresetn) begin state <= IDLE; second_counter <= 0; write_data_counter <= 0; axi_awvalid <= 0; axi_wvalid <= 0; end else begin case (state) IDLE: begin if (second_counter == ONE_SECOND_COUNT - 1) begin // Trigger write operation every second axi_awaddr <= C_M00_AXI_TARGET_SLAVE_BASE_ADDR; // Target register address axi_wdata <= write_data_counter; // Write incrementing data axi_awvalid <= 1; axi_wvalid <= 1; second_counter <= 0; // Reset second counter write_data_counter <= write_data_counter + 1; // Increment data to be written state <= INIT_WRITE; end else begin second_counter <= second_counter + 1; end end INIT_WRITE: begin if (m00_axi_awready && m00_axi_wready) begin axi_awvalid <= 0; axi_wvalid <= 0; state <= WAIT_WRITE; end end WAIT_WRITE: begin if (m00_axi_bvalid) begin // Write complete, back to idle state <= IDLE; end end default: state <= IDLE; endcase end end // User logic ends // Add user logic here // Parameters for state machine states localparam IDLE = 2'b00, INIT_WRITE = 2'b01, WAIT_WRITE = 2'b10; // Register for current state reg [1:0] state; // Counter for 1-second interval reg [31:0] second_counter; // Counter for data to write reg [31:0] write_data_counter; // AXI write address and data reg [C_M00_AXI_ADDR_WIDTH-1 : 0] axi_awaddr; reg [C_M00_AXI_DATA_WIDTH-1 : 0] axi_wdata; reg axi_awvalid; reg axi_wvalid; // 250 MHz clock = 250 million cycles per second localparam ONE_SECOND_COUNT = 250_000_000; // AXI transaction done signal assign m00_axi_awvalid = axi_awvalid; assign m00_axi_wvalid = axi_wvalid; assign m00_axi_awaddr = axi_awaddr; assign m00_axi_wdata = axi_wdata; // Main state machine always @(posedge m00_axi_aclk) begin if (!m00_axi_aresetn) begin state <= IDLE; second_counter <= 0; write_data_counter <= 0; axi_awvalid <= 0; axi_wvalid <= 0; end else begin case (state) IDLE: begin if (second_counter == ONE_SECOND_COUNT - 1) begin // Trigger write operation every second axi_awaddr <= C_M00_AXI_TARGET_SLAVE_BASE_ADDR; // Target register address axi_wdata <= write_data_counter; // Write incrementing data axi_awvalid <= 1; axi_wvalid <= 1; second_counter <= 0; // Reset second counter write_data_counter <= write_data_counter + 1; // Increment data to be written state <= INIT_WRITE; end else begin second_counter <= second_counter + 1; end end INIT_WRITE: begin if (m00_axi_awready && m00_axi_wready) begin axi_awvalid <= 0; axi_wvalid <= 0; state <= WAIT_WRITE; end end WAIT_WRITE: begin if (m00_axi_bvalid) begin // Write complete, back to idle state <= IDLE; end end default: state <= IDLE; endcase end end // User logic ends And the full file looks like this (everything else automatically generated by Vivado): `timescale 1 ns / 1 ps module AXI_DDR3_Writer_v1_0 # ( // Users to add parameters here // User parameters ends // Do not modify the parameters beyond this line // Parameters of Axi Master Bus Interface M00_AXI parameter C_M00_AXI_TARGET_SLAVE_BASE_ADDR = 32'h00000000, parameter integer C_M00_AXI_BURST_LEN = 16, parameter integer C_M00_AXI_ID_WIDTH = 1, parameter integer C_M00_AXI_ADDR_WIDTH = 32, parameter integer C_M00_AXI_DATA_WIDTH = 32, parameter integer C_M00_AXI_AWUSER_WIDTH = 0, parameter integer C_M00_AXI_ARUSER_WIDTH = 0, parameter integer C_M00_AXI_WUSER_WIDTH = 32, parameter integer C_M00_AXI_RUSER_WIDTH = 32, parameter integer C_M00_AXI_BUSER_WIDTH = 0 ) ( // Users to add ports here // User ports ends // Do not modify the ports beyond this line // Ports of Axi Master Bus Interface M00_AXI input wire m00_axi_init_axi_txn, output wire m00_axi_txn_done, output wire m00_axi_error, input wire m00_axi_aclk, input wire m00_axi_aresetn, output wire [C_M00_AXI_ID_WIDTH-1 : 0] m00_axi_awid, output wire [C_M00_AXI_ADDR_WIDTH-1 : 0] m00_axi_awaddr, output wire [7 : 0] m00_axi_awlen, output wire [2 : 0] m00_axi_awsize, output wire [1 : 0] m00_axi_awburst, output wire m00_axi_awlock, output wire [3 : 0] m00_axi_awcache, output wire [2 : 0] m00_axi_awprot, output wire [3 : 0] m00_axi_awqos, output wire [C_M00_AXI_AWUSER_WIDTH-1 : 0] m00_axi_awuser, output wire m00_axi_awvalid, input wire m00_axi_awready, output wire [C_M00_AXI_DATA_WIDTH-1 : 0] m00_axi_wdata, output wire [C_M00_AXI_DATA_WIDTH/8-1 : 0] m00_axi_wstrb, output wire m00_axi_wlast, output wire [C_M00_AXI_WUSER_WIDTH-1 : 0] m00_axi_wuser, output wire m00_axi_wvalid, input wire m00_axi_wready, input wire [C_M00_AXI_ID_WIDTH-1 : 0] m00_axi_bid, input wire [1 : 0] m00_axi_bresp, input wire [C_M00_AXI_BUSER_WIDTH-1 : 0] m00_axi_buser, input wire m00_axi_bvalid, output wire m00_axi_bready, output wire [C_M00_AXI_ID_WIDTH-1 : 0] m00_axi_arid, output wire [C_M00_AXI_ADDR_WIDTH-1 : 0] m00_axi_araddr, output wire [7 : 0] m00_axi_arlen, output wire [2 : 0] m00_axi_arsize, output wire [1 : 0] m00_axi_arburst, output wire m00_axi_arlock, output wire [3 : 0] m00_axi_arcache, output wire [2 : 0] m00_axi_arprot, output wire [3 : 0] m00_axi_arqos, output wire [C_M00_AXI_ARUSER_WIDTH-1 : 0] m00_axi_aruser, output wire m00_axi_arvalid, input wire m00_axi_arready, input wire [C_M00_AXI_ID_WIDTH-1 : 0] m00_axi_rid, input wire [C_M00_AXI_DATA_WIDTH-1 : 0] m00_axi_rdata, input wire [1 : 0] m00_axi_rresp, input wire m00_axi_rlast, input wire [C_M00_AXI_RUSER_WIDTH-1 : 0] m00_axi_ruser, input wire m00_axi_rvalid, output wire m00_axi_rready ); // Instantiation of Axi Bus Interface M00_AXI AXI_DDR3_Writer_v1_0_M00_AXI # ( .C_M_TARGET_SLAVE_BASE_ADDR(C_M00_AXI_TARGET_SLAVE_BASE_ADDR), .C_M_AXI_BURST_LEN(C_M00_AXI_BURST_LEN), .C_M_AXI_ID_WIDTH(C_M00_AXI_ID_WIDTH), .C_M_AXI_ADDR_WIDTH(C_M00_AXI_ADDR_WIDTH), .C_M_AXI_DATA_WIDTH(C_M00_AXI_DATA_WIDTH), .C_M_AXI_AWUSER_WIDTH(C_M00_AXI_AWUSER_WIDTH), .C_M_AXI_ARUSER_WIDTH(C_M00_AXI_ARUSER_WIDTH), .C_M_AXI_WUSER_WIDTH(C_M00_AXI_WUSER_WIDTH), .C_M_AXI_RUSER_WIDTH(C_M00_AXI_RUSER_WIDTH), .C_M_AXI_BUSER_WIDTH(C_M00_AXI_BUSER_WIDTH) ) AXI_DDR3_Writer_v1_0_M00_AXI_inst ( .INIT_AXI_TXN(m00_axi_init_axi_txn), .TXN_DONE(m00_axi_txn_done), .ERROR(m00_axi_error), .M_AXI_ACLK(m00_axi_aclk), .M_AXI_ARESETN(m00_axi_aresetn), .M_AXI_AWID(m00_axi_awid), .M_AXI_AWADDR(m00_axi_awaddr), .M_AXI_AWLEN(m00_axi_awlen), .M_AXI_AWSIZE(m00_axi_awsize), .M_AXI_AWBURST(m00_axi_awburst), .M_AXI_AWLOCK(m00_axi_awlock), .M_AXI_AWCACHE(m00_axi_awcache), .M_AXI_AWPROT(m00_axi_awprot), .M_AXI_AWQOS(m00_axi_awqos), .M_AXI_AWUSER(m00_axi_awuser), .M_AXI_AWVALID(m00_axi_awvalid), .M_AXI_AWREADY(m00_axi_awready), .M_AXI_WDATA(m00_axi_wdata), .M_AXI_WSTRB(m00_axi_wstrb), .M_AXI_WLAST(m00_axi_wlast), .M_AXI_WUSER(m00_axi_wuser), .M_AXI_WVALID(m00_axi_wvalid), .M_AXI_WREADY(m00_axi_wready), .M_AXI_BID(m00_axi_bid), .M_AXI_BRESP(m00_axi_bresp), .M_AXI_BUSER(m00_axi_buser), .M_AXI_BVALID(m00_axi_bvalid), .M_AXI_BREADY(m00_axi_bready), .M_AXI_ARID(m00_axi_arid), .M_AXI_ARADDR(m00_axi_araddr), .M_AXI_ARLEN(m00_axi_arlen), .M_AXI_ARSIZE(m00_axi_arsize), .M_AXI_ARBURST(m00_axi_arburst), .M_AXI_ARLOCK(m00_axi_arlock), .M_AXI_ARCACHE(m00_axi_arcache), .M_AXI_ARPROT(m00_axi_arprot), .M_AXI_ARQOS(m00_axi_arqos), .M_AXI_ARUSER(m00_axi_aruser), .M_AXI_ARVALID(m00_axi_arvalid), .M_AXI_ARREADY(m00_axi_arready), .M_AXI_RID(m00_axi_rid), .M_AXI_RDATA(m00_axi_rdata), .M_AXI_RRESP(m00_axi_rresp), .M_AXI_RLAST(m00_axi_rlast), .M_AXI_RUSER(m00_axi_ruser), .M_AXI_RVALID(m00_axi_rvalid), .M_AXI_RREADY(m00_axi_rready) ); // Add user logic here // Parameters for state machine states localparam IDLE = 2'b00, INIT_WRITE = 2'b01, WAIT_WRITE = 2'b10; // Register for current state reg [1:0] state; // Counter for 1-second interval reg [31:0] second_counter; // Counter for data to write reg [31:0] write_data_counter; // AXI write address and data reg [C_M00_AXI_ADDR_WIDTH-1 : 0] axi_awaddr; reg [C_M00_AXI_DATA_WIDTH-1 : 0] axi_wdata; reg axi_awvalid; reg axi_wvalid; // 250 MHz clock = 250 million cycles per second localparam ONE_SECOND_COUNT = 250_000_000; // AXI transaction done signal assign m00_axi_awvalid = axi_awvalid; assign m00_axi_wvalid = axi_wvalid; assign m00_axi_awaddr = axi_awaddr; assign m00_axi_wdata = axi_wdata; // Main state machine always @(posedge m00_axi_aclk) begin if (!m00_axi_aresetn) begin state <= IDLE; second_counter <= 0; write_data_counter <= 0; axi_awvalid <= 0; axi_wvalid <= 0; end else begin case (state) IDLE: begin if (second_counter == ONE_SECOND_COUNT - 1) begin // Trigger write operation every second axi_awaddr <= C_M00_AXI_TARGET_SLAVE_BASE_ADDR; // Target register address axi_wdata <= write_data_counter; // Write incrementing data axi_awvalid <= 1; axi_wvalid <= 1; second_counter <= 0; // Reset second counter write_data_counter <= write_data_counter + 1; // Increment data to be written state <= INIT_WRITE; end else begin second_counter <= second_counter + 1; end end INIT_WRITE: begin if (m00_axi_awready && m00_axi_wready) begin axi_awvalid <= 0; axi_wvalid <= 0; state <= WAIT_WRITE; end end WAIT_WRITE: begin if (m00_axi_bvalid) begin // Write complete, back to idle state <= IDLE; end end default: state <= IDLE; endcase end end // User logic ends endmodule `timescale 1 ns / 1 ps module AXI_DDR3_Writer_v1_0 # ( // Users to add parameters here // User parameters ends // Do not modify the parameters beyond this line // Parameters of Axi Master Bus Interface M00_AXI parameter C_M00_AXI_TARGET_SLAVE_BASE_ADDR = 32'h00000000, parameter integer C_M00_AXI_BURST_LEN = 16, parameter integer C_M00_AXI_ID_WIDTH = 1, parameter integer C_M00_AXI_ADDR_WIDTH = 32, parameter integer C_M00_AXI_DATA_WIDTH = 32, parameter integer C_M00_AXI_AWUSER_WIDTH = 0, parameter integer C_M00_AXI_ARUSER_WIDTH = 0, parameter integer C_M00_AXI_WUSER_WIDTH = 32, parameter integer C_M00_AXI_RUSER_WIDTH = 32, parameter integer C_M00_AXI_BUSER_WIDTH = 0 ) ( // Users to add ports here // User ports ends // Do not modify the ports beyond this line // Ports of Axi Master Bus Interface M00_AXI input wire m00_axi_init_axi_txn, output wire m00_axi_txn_done, output wire m00_axi_error, input wire m00_axi_aclk, input wire m00_axi_aresetn, output wire [C_M00_AXI_ID_WIDTH-1 : 0] m00_axi_awid, output wire [C_M00_AXI_ADDR_WIDTH-1 : 0] m00_axi_awaddr, output wire [7 : 0] m00_axi_awlen, output wire [2 : 0] m00_axi_awsize, output wire [1 : 0] m00_axi_awburst, output wire m00_axi_awlock, output wire [3 : 0] m00_axi_awcache, output wire [2 : 0] m00_axi_awprot, output wire [3 : 0] m00_axi_awqos, output wire [C_M00_AXI_AWUSER_WIDTH-1 : 0] m00_axi_awuser, output wire m00_axi_awvalid, input wire m00_axi_awready, output wire [C_M00_AXI_DATA_WIDTH-1 : 0] m00_axi_wdata, output wire [C_M00_AXI_DATA_WIDTH/8-1 : 0] m00_axi_wstrb, output wire m00_axi_wlast, output wire [C_M00_AXI_WUSER_WIDTH-1 : 0] m00_axi_wuser, output wire m00_axi_wvalid, input wire m00_axi_wready, input wire [C_M00_AXI_ID_WIDTH-1 : 0] m00_axi_bid, input wire [1 : 0] m00_axi_bresp, input wire [C_M00_AXI_BUSER_WIDTH-1 : 0] m00_axi_buser, input wire m00_axi_bvalid, output wire m00_axi_bready, output wire [C_M00_AXI_ID_WIDTH-1 : 0] m00_axi_arid, output wire [C_M00_AXI_ADDR_WIDTH-1 : 0] m00_axi_araddr, output wire [7 : 0] m00_axi_arlen, output wire [2 : 0] m00_axi_arsize, output wire [1 : 0] m00_axi_arburst, output wire m00_axi_arlock, output wire [3 : 0] m00_axi_arcache, output wire [2 : 0] m00_axi_arprot, output wire [3 : 0] m00_axi_arqos, output wire [C_M00_AXI_ARUSER_WIDTH-1 : 0] m00_axi_aruser, output wire m00_axi_arvalid, input wire m00_axi_arready, input wire [C_M00_AXI_ID_WIDTH-1 : 0] m00_axi_rid, input wire [C_M00_AXI_DATA_WIDTH-1 : 0] m00_axi_rdata, input wire [1 : 0] m00_axi_rresp, input wire m00_axi_rlast, input wire [C_M00_AXI_RUSER_WIDTH-1 : 0] m00_axi_ruser, input wire m00_axi_rvalid, output wire m00_axi_rready ); // Instantiation of Axi Bus Interface M00_AXI AXI_DDR3_Writer_v1_0_M00_AXI # ( .C_M_TARGET_SLAVE_BASE_ADDR(C_M00_AXI_TARGET_SLAVE_BASE_ADDR), .C_M_AXI_BURST_LEN(C_M00_AXI_BURST_LEN), .C_M_AXI_ID_WIDTH(C_M00_AXI_ID_WIDTH), .C_M_AXI_ADDR_WIDTH(C_M00_AXI_ADDR_WIDTH), .C_M_AXI_DATA_WIDTH(C_M00_AXI_DATA_WIDTH), .C_M_AXI_AWUSER_WIDTH(C_M00_AXI_AWUSER_WIDTH), .C_M_AXI_ARUSER_WIDTH(C_M00_AXI_ARUSER_WIDTH), .C_M_AXI_WUSER_WIDTH(C_M00_AXI_WUSER_WIDTH), .C_M_AXI_RUSER_WIDTH(C_M00_AXI_RUSER_WIDTH), .C_M_AXI_BUSER_WIDTH(C_M00_AXI_BUSER_WIDTH) ) AXI_DDR3_Writer_v1_0_M00_AXI_inst ( .INIT_AXI_TXN(m00_axi_init_axi_txn), .TXN_DONE(m00_axi_txn_done), .ERROR(m00_axi_error), .M_AXI_ACLK(m00_axi_aclk), .M_AXI_ARESETN(m00_axi_aresetn), .M_AXI_AWID(m00_axi_awid), .M_AXI_AWADDR(m00_axi_awaddr), .M_AXI_AWLEN(m00_axi_awlen), .M_AXI_AWSIZE(m00_axi_awsize), .M_AXI_AWBURST(m00_axi_awburst), .M_AXI_AWLOCK(m00_axi_awlock), .M_AXI_AWCACHE(m00_axi_awcache), .M_AXI_AWPROT(m00_axi_awprot), .M_AXI_AWQOS(m00_axi_awqos), .M_AXI_AWUSER(m00_axi_awuser), .M_AXI_AWVALID(m00_axi_awvalid), .M_AXI_AWREADY(m00_axi_awready), .M_AXI_WDATA(m00_axi_wdata), .M_AXI_WSTRB(m00_axi_wstrb), .M_AXI_WLAST(m00_axi_wlast), .M_AXI_WUSER(m00_axi_wuser), .M_AXI_WVALID(m00_axi_wvalid), .M_AXI_WREADY(m00_axi_wready), .M_AXI_BID(m00_axi_bid), .M_AXI_BRESP(m00_axi_bresp), .M_AXI_BUSER(m00_axi_buser), .M_AXI_BVALID(m00_axi_bvalid), .M_AXI_BREADY(m00_axi_bready), .M_AXI_ARID(m00_axi_arid), .M_AXI_ARADDR(m00_axi_araddr), .M_AXI_ARLEN(m00_axi_arlen), .M_AXI_ARSIZE(m00_axi_arsize), .M_AXI_ARBURST(m00_axi_arburst), .M_AXI_ARLOCK(m00_axi_arlock), .M_AXI_ARCACHE(m00_axi_arcache), .M_AXI_ARPROT(m00_axi_arprot), .M_AXI_ARQOS(m00_axi_arqos), .M_AXI_ARUSER(m00_axi_aruser), .M_AXI_ARVALID(m00_axi_arvalid), .M_AXI_ARREADY(m00_axi_arready), .M_AXI_RID(m00_axi_rid), .M_AXI_RDATA(m00_axi_rdata), .M_AXI_RRESP(m00_axi_rresp), .M_AXI_RLAST(m00_axi_rlast), .M_AXI_RUSER(m00_axi_ruser), .M_AXI_RVALID(m00_axi_rvalid), .M_AXI_RREADY(m00_axi_rready) ); // Add user logic here // Parameters for state machine states localparam IDLE = 2'b00, INIT_WRITE = 2'b01, WAIT_WRITE = 2'b10; // Register for current state reg [1:0] state; // Counter for 1-second interval reg [31:0] second_counter; // Counter for data to write reg [31:0] write_data_counter; // AXI write address and data reg [C_M00_AXI_ADDR_WIDTH-1 : 0] axi_awaddr; reg [C_M00_AXI_DATA_WIDTH-1 : 0] axi_wdata; reg axi_awvalid; reg axi_wvalid; // 250 MHz clock = 250 million cycles per second localparam ONE_SECOND_COUNT = 250_000_000; // AXI transaction done signal assign m00_axi_awvalid = axi_awvalid; assign m00_axi_wvalid = axi_wvalid; assign m00_axi_awaddr = axi_awaddr; assign m00_axi_wdata = axi_wdata; // Main state machine always @(posedge m00_axi_aclk) begin if (!m00_axi_aresetn) begin state <= IDLE; second_counter <= 0; write_data_counter <= 0; axi_awvalid <= 0; axi_wvalid <= 0; end else begin case (state) IDLE: begin if (second_counter == ONE_SECOND_COUNT - 1) begin // Trigger write operation every second axi_awaddr <= C_M00_AXI_TARGET_SLAVE_BASE_ADDR; // Target register address axi_wdata <= write_data_counter; // Write incrementing data axi_awvalid <= 1; axi_wvalid <= 1; second_counter <= 0; // Reset second counter write_data_counter <= write_data_counter + 1; // Increment data to be written state <= INIT_WRITE; end else begin second_counter <= second_counter + 1; end end INIT_WRITE: begin if (m00_axi_awready && m00_axi_wready) begin axi_awvalid <= 0; axi_wvalid <= 0; state <= WAIT_WRITE; end end WAIT_WRITE: begin if (m00_axi_bvalid) begin // Write complete, back to idle state <= IDLE; end end default: state <= IDLE; endcase end end // User logic ends endmodule 24/10/2024 13:48 This block can be implimented into the block design: AXI_DDR3_Writer is the custom IP block It takes the same 250MHz clock that the DMA Bridge generates It connects to a slave port on the AXI smart connect It takes a constant 1 value for the axi_init_axi_txn port, which means it always wants to initiatie an axi transfer(?) 24/10/2024 13:57 This design passes validation (meaning all the signals going to various ports are more or less what the port excpects). However it does not pass syntehsis for reason: [DRC MDRV-1] Multiple Driver Nets: Net PCIe_DMA_i/AXI_DDR3_Writer_0/inst/UNCONN_OUT has multiple drivers: PCIe_DMA_i/AXI_DDR3_Writer_0/inst/axi_awvalid_reg/Q, and PCIe_DMA_i/AXI_DDR3_Writer_0/inst/AXI_DDR3_Writer_v1_0_M00_AXI_inst/axi_awvalid_reg/Q. [DRC MDRV- 1 ] Multiple Driver Nets: Net PCIe_DMA_i /AXI_DDR3_Writer_0/i nst/UNCONN_OUT has multiple drivers: PCIe_DMA_i /AXI_DDR3_Writer_0/i nst /axi_awvalid_reg/ Q, and PCIe_DMA_i /AXI_DDR3_Writer_0/i nst /AXI_DDR3_Writer_v1_0_M00_AXI_inst/ axi_awvalid_reg/Q. which seems to indicate something is wrong with my code.",
    "textLength": 2035
  },
  {
    "kind": "work-log",
    "title": "28_09_2025 - 04_10_2025.html",
    "fileName": "28_09_2025 - 04_10_2025.html",
    "url": "resources/work_logs/28_09_2025 - 04_10_2025.html",
    "createdDate": "2025-09-28",
    "text": "28/09/2025 - 04/10/2025 28/09/2025 - 04/10/2025 30/09/2025 02:54 Mermaid Diagram: flowchart TD %% Top level A[DataChannelManager] -->|manages multiple| B[DataChannel] %% Channel owns processors + buffer B -->|owns| C[DataChannelProcessesManager] B -->|uses shared| F[DataTransmitter] %% Processes manager drives processors C -->|manages multiple| D[GeneralProcessor] E[DataBuffer] %% Transmitter manager provides sockets F -->|created by| G[DataTransmitterManager] B -->|publish| F %% Socket sends to subscribers F --> |owns| H[(ZMQ Socket)] %% Flow labels D -.->|\"produces serialized output\"| E E -.->|\"provides messages (serialized output)\"| B B -.->|messages| F F -.->|ZMQ PUB| H flowchart TD %% Top level A[DataChannelManager] -->|manages multiple| B[DataChannel] %% Channel owns processors + buffer B -->|owns| C[DataChannelProcessesManager] B -->|uses shared| F[DataTransmitter] %% Processes manager drives processors C -->|manages multiple| D[GeneralProcessor] E[DataBuffer] %% Transmitter manager provides sockets F -->|created by| G[DataTransmitterManager] B -->|publish| F %% Socket sends to subscribers F --> |owns| H[(ZMQ Socket)] %% Flow labels D -.->| \"produces serialized output\" | E E -.->| \"provides messages (serialized output)\" | B B -.->|messages| F F -.->|ZMQ PUB| H 30/09/2025 03:46 DQM webpage Wiki Page Outline Home \u2013 Project overview, badges, screenshots. \u2013 Quick links to all other pages. Getting Started \u2013 Install prerequisites. \u2013 Clone, install, run. \u2013 Access at localhost:3000. Dashboard Layout \u2013 Tabs, adding/deleting. \u2013 Dragging/resizing figures (FigureGrid, FigureTile). \u2013 Layout save/reset/export. Figures \u2013 Base classes (Figure, Plot, Table). \u2013 Settings system. \u2013 Example: waveform traces, histograms. Plugin System \u2013 Concept of plugins. \u2013 Loading methods (ES, eval, script). \u2013 Default plugins, adding/removing/resetting. \u2013 Export/import configs. UI Tutorial \u2705 (new page) \u2013 Step-by-step with screenshots: Launch dashboard. Collapse/expand Sidebar. Add a figure from dropdown. Drag & resize a figure tile. Edit a figure title (double click, FigureTitle). Open figure settings (SettingsMenu). Create/delete tabs (TabsBar in Dashboard). Add/remove plugins via modals. \u2013 End with saving/exporting layout. Creating Custom Figures (Local) \u2013 Add .jsx to /src/figures. \u2013 Auto-registration. \u2013 Example code. Creating Custom Figure Plugins \u2013 Structure a plugin repo. \u2013 Rollup + Babel build. \u2013 Expose PluginRegister. \u2013 Publish via GitHub/jsDelivr. Managers and Registries (Architecture) \u2013 FigureManager, FactoryManager, RegistryManager. \u2013 Interaction with Dashboard and Sidebar. 01/10/2025 04:39 Dependency diagram for ZeroMQ Publisher flowchart TD subgraph Publisher[\"ZeroMQ Publisher (C++)\"] P[\"<b>Publisher Executable</b><br>Top-level app that publishes procssed MIDAS events over ZMQ\"] end %% System / external ROOT[\"<b><a href='https://root.cern/'>ROOT</a></b><br>CERN data analysis framework\"] ZeroMQ[\"<b><a href='https://zeromq.org/'>ZeroMQ</a></b><br>Messaging library\"] cppzmq[\"<b><a href='https://github.com/zeromq/cppzmq'>cppzmq</a></b><br>C++ header-only bindings\"] TBB[\"<b><a href='https://github.com/oneapi-src/oneTBB'>oneTBB</a></b><br>Threading library\"] MIDAS[\"<b><a href='https://midas.triumf.ca/'>MIDAS</a></b><br>DAQ system\"] %% CPM/core deps APcore[\"<b><a href='https://github.com/jaca230/analysis_pipeline_core'>analysis_pipeline_core</a></b><br>Core pipeline framework \"] JSON[\"<b><a href='https://github.com/nlohmann/json'>nlohmann_json</a></b><br>Header-only JSON\"] SPDLOG[\"<b><a href='https://github.com/gabime/spdlog'>spdlog</a></b><br>Header-only logging\"] AP[\"<b><a href='https://github.com/jaca230/analysis_pipeline'>analysis_pipeline</a></b><br>Pipeline orchestration and stages\"] MR[\"<b><a href='https://github.com/jaca230/midas_receiver'>midas_receiver</a></b><br>Receives event streams from MIDAS\"] UPcore[\"<b><a href='https://github.com/jaca230/unpacker_data_products_core'>unpacker_data_products_core</a></b><br>Common unpacker data products\"] MUplugin[\"<b><a href='https://github.com/jaca230/midas_event_unpacker_plugin'>midas_event_unpacker_plugin</a></b><br>Plugin to unpack MIDAS events\"] %% Core dependencies APcore -->|Depends on| ROOT APcore -->|Depends on| JSON APcore -->|Depends on| SPDLOG AP -->|Depends on| APcore AP -->|Depends on| TBB UPcore -->|Depends on| APcore MUplugin -->|Depends on| UPcore MR -->|Depends on| MIDAS %% Publisher P -->|Depends on| AP P -->|Depends on| MR P -->|Depends on| ZeroMQ P -->|Depends on| cppzmq %% Runtime plugin loading AP -.->|Runtime load| MUplugin AP -.->|Runtime load| UPcore flowchart TD subgraph Publisher[\"ZeroMQ Publisher (C++)\"] P[\"<b>Publisher Executable</b><br>Top-level app that publishes procssed MIDAS events over ZMQ\"] end %% System / external ROOT[\"<b><a href='https://root.cern/'>ROOT</a></b><br>CERN data analysis framework\"] ZeroMQ[\"<b><a href='https://zeromq.org/'>ZeroMQ</a></b><br>Messaging library\"] cppzmq[\"<b><a href='https://github.com/zeromq/cppzmq'>cppzmq</a></b><br>C++ header-only bindings\"] TBB[\"<b><a href='https://github.com/oneapi-src/oneTBB'>oneTBB</a></b><br>Threading library\"] MIDAS[\"<b><a href='https://midas.triumf.ca/'>MIDAS</a></b><br>DAQ system\"] %% CPM/core deps APcore[\"<b><a href='https://github.com/jaca230/analysis_pipeline_core'>analysis_pipeline_core</a></b><br>Core pipeline framework \"] JSON[\"<b><a href='https://github.com/nlohmann/json'>nlohmann_json</a></b><br>Header-only JSON\"] SPDLOG[\"<b><a href='https://github.com/gabime/spdlog'>spdlog</a></b><br>Header-only logging\"] AP[\"<b><a href='https://github.com/jaca230/analysis_pipeline'>analysis_pipeline</a></b><br>Pipeline orchestration and stages\"] MR[\"<b><a href='https://github.com/jaca230/midas_receiver'>midas_receiver</a></b><br>Receives event streams from MIDAS\"] UPcore[\"<b><a href='https://github.com/jaca230/unpacker_data_products_core'>unpacker_data_products_core</a></b><br>Common unpacker data products\"] MUplugin[\"<b><a href='https://github.com/jaca230/midas_event_unpacker_plugin'>midas_event_unpacker_plugin</a></b><br>Plugin to unpack MIDAS events\"] %% Core dependencies APcore -->|Depends on| ROOT APcore -->|Depends on| JSON APcore -->|Depends on| SPDLOG AP -->|Depends on| APcore AP -->|Depends on| TBB UPcore -->|Depends on| APcore MUplugin -->|Depends on| UPcore MR -->|Depends on| MIDAS %% Publisher P -->|Depends on| AP P -->|Depends on| MR P -->|Depends on| ZeroMQ P -->|Depends on| cppzmq %% Runtime plugin loading AP -.->|Runtime load| MUplugin AP -.->|Runtime load| UPcore 01/10/2025 04:55 Dependency diagram for ZMQSUB_to_FASTAPI flowchart TD subgraph Backend[\"ZMQSUB_to_FastAPI (Python)\"] B[\"<b><a href='https://github.com/jaca230/ZMQSUB_to_FastAPI'>ZMQSUB_to_FastAPI</a></b><br>Backend server: FastAPI + ZMQ receiver + dynamic services\"] end %% External deps FastAPI[\"<b><a href='https://fastapi.tiangolo.com/'>FastAPI</a></b><br>Web framework\"] Uvicorn[\"<b><a href='https://www.uvicorn.org/'>Uvicorn</a></b><br>ASGI server\"] PyZMQ[\"<b><a href='https://github.com/zeromq/pyzmq'>pyzmq</a></b><br>ZeroMQ Python bindings\"] NumPy[\"<b><a href='https://numpy.org/'>NumPy</a></b><br>Buffer and array utilities\"] JSONptr[\"<b><a href='https://github.com/stefankoegl/python-json-pointer'>jsonpointer</a></b><br>JSON pointer queries\"] %% Edges external B -->|Depends on| FastAPI B -->|Depends on| Uvicorn B -->|Depends on| PyZMQ B -->|Depends on| NumPy B -->|Depends on| JSONptr 01/10/2025 05:03 Dependency diagram for DQM React based webserver flowchart TD subgraph Frontend[\"DQM Webapp (React/JS)\"] F[\"<b><a href='https://github.com/jaca230/DQM_webpage'>DQM_webpage</a></b><br>Interactive dashboard for monitoring & visualization\"] end %% Core runtime Node[\"<b><a href='https://nodejs.org/'>Node.js</a></b><br>JS runtime & package manager\"] %% React ecosystem React[\"<b><a href='https://react.dev/'>React</a></b><br>UI framework\"] ReactDOM[\"react-dom<br/>DOM bindings\"] LayoutLibs[\"react-grid-layout / react-resizable / react-rnd<br/>Grid, resize & drag components\"] ReactSelect[\"react-select<br/>Dropdown UI component\"] ContentEditable[\"react-contenteditable<br/>Editable text field\"] Lucide[\"lucide-react<br/>Icon set\"] %% Plotting Plotly[\"<b><a href='https://plotly.com/javascript/'>Plotly.js</a></b><br>Interactive plotting\"] ReactPlotly[\"react-plotly.js<br/>React wrapper for Plotly\"] %% Dependencies F -->|Depends on| Node F -->|Depends on| React React --> ReactDOM React --> LayoutLibs React --> ReactSelect React --> ContentEditable React --> Lucide F -->|Depends on| Plotly F -->|Depends on| ReactPlotly ReactPlotly --> Plotly flowchart TD subgraph Frontend[\"DQM Webapp (React/JS)\"] F[\"<b><a href='https://github.com/jaca230/DQM_webpage'>DQM_webpage</a></b><br>Interactive dashboard for monitoring & visualization\"] end %% Core runtime Node[\"<b><a href='https://nodejs.org/'>Node.js</a></b><br>JS runtime & package manager\"] %% React ecosystem React[\"<b><a href='https://react.dev/'>React</a></b><br>UI framework\"] ReactDOM[\"react-dom<br/>DOM bindings\"] LayoutLibs[\"react-grid-layout / react-resizable / react-rnd<br/>Grid, resize & drag components\"] ReactSelect[\"react-select<br/>Dropdown UI component\"] ContentEditable[\"react-contenteditable<br/>Editable text field\"] Lucide[\"lucide-react<br/>Icon set\"] %% Plotting Plotly[\"<b><a href='https://plotly.com/javascript/'>Plotly.js</a></b><br>Interactive plotting\"] ReactPlotly[\"react-plotly.js<br/>React wrapper for Plotly\"] %% Dependencies F -->|Depends on| Node F -->|Depends on| React React --> ReactDOM React --> LayoutLibs React --> ReactSelect React --> ContentEditable React --> Lucide F -->|Depends on| Plotly F -->|Depends on| ReactPlotly ReactPlotly --> Plotly 02/10/2025 03:12 Some questions for SAMPic experts: SAMPIC Meeting Questions 1. System Throughput Is the SAMPIC system rate-limited just by the 1 GbE link (theoretical ~125 MB/s limit)? Or are there other bottlenecks (firmware, FPGA processing, library overhead, etc.)? 2. Multiple Frontend Boards Say the crate has slots 0,1,2,3. If we have FE boards in slots 1 and 3: Will they get mapped to indices 0,1 by the library? Or will they stay as 1 and 3? In other words: should I configure them with fe_index 0,1 or 1,3? It looks like they get mapped to 0,1, which isn\u2019t great if we have different settings between FE boards (requires switching many ODB params instead of just one if boards are removed). 3. Calibration Handling How critical is running Init_CrateCalibParams() before operation? What happens if calibration files are missing or inconsistent? 4. MIDAS Buffer Integration EventStruct vs ML_Frame Is the expectation that users always wrap the dense EventStruct into their DAQ event (i.e. copy ~0.5\u20131 MB/event regardless of occupancy)? Or is there a recommended way to work directly from ML_Frame[] to build a more compact event record? Sparse Encoding If we only want to log active channels (sparse representation), does the library provide helper routines for decoding ML_Frame[] \u2192 channel traces ? Or is the unpacking logic internal/private, meaning we must always use EventStruct ? Performance Guidance At what trigger rates / event sizes have you benchmarked the EventStruct path? Do you consider the memory overhead negligible compared to transport limits? Recommended Strategy For DAQ frameworks like MIDAS, what\u2019s the \u201cofficially supported\u201d path? Copy full EventStruct into MIDAS banks, or Parse ML_Frame[] and build custom MIDAS structures? Do you have example code for either? 5. MIDAS Parameters Could I get feedback on this struct (directly translated to MIDAS ODB settings): What are good default parameters? Should any functions not be called every time a run is started (only on initialization)? I have code that will go through and set all these parameters, but I don\u2019t know what defaults are recommended. #ifndef SAMPIC_CONFIG_H #define SAMPIC_CONFIG_H #include <string> #include <cstdint> #include <map> extern \"C\" { #include <SAMPIC_256Ch_Type.h> } // ============================== // Channel (lowest level) // ============================== struct SampicChannelConfig { bool enabled = true; // Global enable for channel SAMPIC_ChannelTriggerMode_t trigger_mode = SAMPIC_CHANNEL_EXT_TRIGGER_MODE; // SAMPIC256CH_SetSampicChannelTriggerMode float internal_threshold = 0.0; // SAMPIC256CH_SetSampicChannelInternalThreshold EdgeType_t trigger_edge = RISING_EDGE; // SAMPIC256CH_SetChannelSelflTriggerEdge bool external_threshold_mode = false; // SAMPIC256CH_SetSampicExternalThresholdMode bool enable_for_central_trigger = true; // SAMPIC256CH_SetSampicChannelSourceForCT bool pulse_mode = false; // SAMPIC256CH_SetSampicChannelPulseMode }; using SampicChannelSettings = std::map<std::string, SampicChannelConfig>; // ============================== // Chip (contains channels) // ============================== struct SampicChipConfig { bool enabled = true; // Global enable for chip float baseline_reference = DEFAULT_SAMPIC_BASELINE; // SAMPIC256CH_SetBaselineReference float external_threshold = 0.5; // SAMPIC256CH_SetSampicExternalThreshold SAMPIC_TOTRange_t tot_range = SAMPIC_TOT_RANGE_MAX_25_NS; // SAMPIC256CH_SetSampicTOTRange bool enable_post_trigger = true; // SAMPIC256CH_SetSampicPostTrigParams int post_trigger_value = 7; // SAMPIC256CH_SetSampicPostTrigParams SampicCentralTriggerMode_t central_trigger_mode = CENTRAL_OR; // SAMPIC256CH_SetSampicCentralTriggerMode SampicCentralTriggerEffect_t central_trigger_effect = TRIG_CHANNEL_ONLY_IF_PARTICIPATING_TO_CT; // SAMPIC256CH_SetSampicCentralTriggerEffect SAMPIC_CT_PrimitivesMode_t primitives_mode = RAW_PRIMITIVES_FOR_CT; // SAMPIC256CH_SetSampicCentralTriggerPrimitivesOptions int primitives_gate_length = DEFAULT_PRIMITIVES_GATE_LENGTH; // SAMPIC256CH_SetSampicCentralTriggerPrimitivesOptions bool tot_filter_enable = false; // SAMPIC256CH_SetSampicTOTFilterParams bool tot_wide_cap = false; // SAMPIC256CH_SetSampicTOTFilterParams float tot_min_width_ns = 0.0; // SAMPIC256CH_SetSampicTOTFilterParams SampicChannelSettings channels { {\"channel0\", {}}, {\"channel1\", {}}, {\"channel2\", {}}, {\"channel3\", {}}, {\"channel4\", {}}, {\"channel5\", {}}, {\"channel6\", {}}, {\"channel7\", {}}, {\"channel8\", {}}, {\"channel9\", {}}, {\"channel10\", {}}, {\"channel11\", {}}, {\"channel12\", {}}, {\"channel13\", {}}, {\"channel14\", {}}, {\"channel15\", {}} }; }; using SampicChipSettings = std::map<std::string, SampicChipConfig>; // ============================== // Board (contains chips) // ============================== struct SampicFrontEndConfig { bool enabled = true; // Global enable for this FE board FebGlobalTrigger_t global_trigger_option = FEB_GLOBAL_TRIGGER_IS_L2; // SAMPIC256CH_SetFrontEndBoardGlobalTriggerOption unsigned char level2_ext_trig_gate = DEFAULT_EXT_TRIG_GATE; // SAMPIC256CH_SetLevel2ExtTrigGate bool level2_coincidence_ext_gate = false; // SAMPIC256CH_SetLevel2CoincidenceModeWithExtTrigGate SampicChipSettings sampics { {\"sampic0\", {}}, {\"sampic1\", {}}, {\"sampic2\", {}}, {\"sampic3\", {}} }; }; using SampicFrontEndSettings = std::map<std::string, SampicFrontEndConfig>; // ============================== // Crate (top-level system) // ============================== struct SampicSystemSettings { std::string ip_address = \"192.168.0.4\"; //DEFAULT_CTRL_IP_ADDRESS int port = DEFAULT_UDP_CTRL_PORT; // UDP control port ConnectionType_t connection_type = UDP_CONNECTION; // SAMPIC256CH_OpenCrateConnection ControlType_t control_type = CTRL_AND_DAQ; // SAMPIC256CH_OpenCrateConnection // Acquisition int sampling_frequency_mhz = DEFAULT_FREQ_ECH; // SAMPIC256CH_SetSamplingFrequency bool use_external_clock = false; int frames_per_block = MAX_NB_OF_FRAMES_PER_BLOCK; // SAMPIC256CH_SetNbOfFramesPerBlock bool enable_tot = false; // SAMPIC256CH_SetTOTMeasurementMode int adc_bits = DEFAULT_ADC_NB_OF_BITS; // Set_SystemADCNbOfBits bool smart_read_mode = false; // SAMPIC256CH_SetSmartReadMode int read_offset = 0; int samples_to_read = MAX_NB_OF_SAMPLES; // Trigger ExternalTriggerType_t external_trigger_type = SOFTWARE; // SAMPIC256CH_SetExternalTriggerType SignalLevel_t signal_level = TTL_SIG; // SAMPIC256CH_SetExternalTriggerSigLevel EdgeType_t trigger_edge = RISING_EDGE; // SAMPIC256CH_SetExternalTriggerEdge std::uint8_t triggers_per_event = DEFAULT_NB_OF_TRIGGERS_PER_TRIGGER_EVENT; // SAMPIC256CH_SetMinNbOfTriggersPerEvent bool level2_trigger_build = false; // SAMPIC256CH_SetLevel2TriggerBuildOption bool level3_trigger_build = false; // SAMPIC256CH_SetLevel3TriggerLogic SampicTriggerOption_t trigger_option = SAMPIC_TRIGGER_IS_L1; // SAMPIC256CH_SetSampicTriggerOption unsigned char level3_ext_trig_gate = DEFAULT_EXT_TRIG_GATE; // SAMPIC256CH_SetLevel3ExtTrigGate bool level3_coincidence_ext_gate = false; // SAMPIC256CH_SetLevel3CoincidenceModeWithExtTrigGate unsigned char primitives_gate_length = DEFAULT_PRIMITIVES_GATE_LENGTH; // SAMPIC256CH_SetPrimitivesGateLength unsigned char latency_gate_length = DEFAULT_LEVEL_2_LATENCY_GATE; // SAMPIC256CH_SetLevel2LatencyGateLength // Pulser bool pulser_enable = false; // SAMPIC256CH_SetPulserMode PulserSourceType_t pulser_source = PULSER_SRC_IS_SOFT_CMD; bool pulser_synchronous = true; int pulser_period = DEFAULT_AUTO_PULSE_PERIOD; // SAMPIC256CH_SetAutoPulserPeriod unsigned char pulser_width = DEFAULT_PULSER_WIDTH; // SAMPIC256CH_SetSampicPulserWidth // Sync + corrections bool sync_mode = false; // SAMPIC256CH_SetCrateSycnhronisationMode bool master_mode = false; bool coincidence_mode = false; EdgeType_t sync_edge = RISING_EDGE; // SAMPIC256CH_SetExternalSyncEdge SignalLevel_t sync_level = TTL_SIG; // SAMPIC256CH_SetExternalSyncSigLevel bool adc_linearity_correction = false; // SAMPIC256CH_SetCrateCorrectionLevels bool time_inl_correction = false; bool residual_pedestal_correction = false; std::string calibration_directory = \".\"; // SAMPIC256CH_LoadAllCalibValuesFromFiles SampicFrontEndSettings front_end_boards { {\"feb0\", {}}, {\"feb1\", {}}, {\"feb2\", {}}, {\"feb3\", {}} }; bool verbose = false; // for logging verbosity }; #endif // SAMPIC_CONFIG_H # ifndef SAMPIC_CONFIG_H # define SAMPIC_CONFIG_H # include <string> # include <cstdint> # include <map> extern \"C\" { # include <SAMPIC_256Ch_Type.h> } // ============================== // Channel (lowest level) // ============================== struct SampicChannelConfig { bool enabled = true ; // Global enable for channel SAMPIC_ChannelTriggerMode_t trigger_mode = SAMPIC_CHANNEL_EXT_TRIGGER_MODE; // SAMPIC256CH_SetSampicChannelTriggerMode float internal_threshold = 0.0 ; // SAMPIC256CH_SetSampicChannelInternalThreshold EdgeType_t trigger_edge = RISING_EDGE; // SAMPIC256CH_SetChannelSelflTriggerEdge bool external_threshold_mode = false ; // SAMPIC256CH_SetSampicExternalThresholdMode bool enable_for_central_trigger = true ; // SAMPIC256CH_SetSampicChannelSourceForCT bool pulse_mode = false ; // SAMPIC256CH_SetSampicChannelPulseMode }; using SampicChannelSettings = std::map<std::string, SampicChannelConfig>; // ============================== // Chip (contains channels) // ============================== struct SampicChipConfig { bool enabled = true ; // Global enable for chip float baseline_reference = DEFAULT_SAMPIC_BASELINE; // SAMPIC256CH_SetBaselineReference float external_threshold = 0.5 ; // SAMPIC256CH_SetSampicExternalThreshold SAMPIC_TOTRange_t tot_range = SAMPIC_TOT_RANGE_MAX_25_NS; // SAMPIC256CH_SetSampicTOTRange bool enable_post_trigger = true ; // SAMPIC256CH_SetSampicPostTrigParams int post_trigger_value = 7 ; // SAMPIC256CH_SetSampicPostTrigParams SampicCentralTriggerMode_t central_trigger_mode = CENTRAL_OR; // SAMPIC256CH_SetSampicCentralTriggerMode SampicCentralTriggerEffect_t central_trigger_effect = TRIG_CHANNEL_ONLY_IF_PARTICIPATING_TO_CT; // SAMPIC256CH_SetSampicCentralTriggerEffect SAMPIC_CT_PrimitivesMode_t primitives_mode = RAW_PRIMITIVES_FOR_CT; // SAMPIC256CH_SetSampicCentralTriggerPrimitivesOptions int primitives_gate_length = DEFAULT_PRIMITIVES_GATE_LENGTH; // SAMPIC256CH_SetSampicCentralTriggerPrimitivesOptions bool tot_filter_enable = false ; // SAMPIC256CH_SetSampicTOTFilterParams bool tot_wide_cap = false ; // SAMPIC256CH_SetSampicTOTFilterParams float tot_min_width_ns = 0.0 ; // SAMPIC256CH_SetSampicTOTFilterParams SampicChannelSettings channels { { \"channel0\" , {}}, { \"channel1\" , {}}, { \"channel2\" , {}}, { \"channel3\" , {}}, { \"channel4\" , {}}, { \"channel5\" , {}}, { \"channel6\" , {}}, { \"channel7\" , {}}, { \"channel8\" , {}}, { \"channel9\" , {}}, { \"channel10\" , {}}, { \"channel11\" , {}}, { \"channel12\" , {}}, { \"channel13\" , {}}, { \"channel14\" , {}}, { \"channel15\" , {}} }; }; using SampicChipSettings = std::map<std::string, SampicChipConfig>; // ============================== // Board (contains chips) // ============================== struct SampicFrontEndConfig { bool enabled = true ; // Global enable for this FE board FebGlobalTrigger_t global_trigger_option = FEB_GLOBAL_TRIGGER_IS_L2; // SAMPIC256CH_SetFrontEndBoardGlobalTriggerOption unsigned char level2_ext_trig_gate = DEFAULT_EXT_TRIG_GATE; // SAMPIC256CH_SetLevel2ExtTrigGate bool level2_coincidence_ext_gate = false ; // SAMPIC256CH_SetLevel2CoincidenceModeWithExtTrigGate SampicChipSettings sampics { { \"sampic0\" , {}}, { \"sampic1\" , {}}, { \"sampic2\" , {}}, { \"sampic3\" , {}} }; }; using SampicFrontEndSettings = std::map<std::string, SampicFrontEndConfig>; // ============================== // Crate (top-level system) // ============================== struct SampicSystemSettings { std::string ip_address = \"192.168.0.4\" ; //DEFAULT_CTRL_IP_ADDRESS int port = DEFAULT_UDP_CTRL_PORT; // UDP control port ConnectionType_t connection_type = UDP_CONNECTION; // SAMPIC256CH_OpenCrateConnection ControlType_t control_type = CTRL_AND_DAQ; // SAMPIC256CH_OpenCrateConnection // Acquisition int sampling_frequency_mhz = DEFAULT_FREQ_ECH; // SAMPIC256CH_SetSamplingFrequency bool use_external_clock = false ; int frames_per_block = MAX_NB_OF_FRAMES_PER_BLOCK; // SAMPIC256CH_SetNbOfFramesPerBlock bool enable_tot = false ; // SAMPIC256CH_SetTOTMeasurementMode int adc_bits = DEFAULT_ADC_NB_OF_BITS; // Set_SystemADCNbOfBits bool smart_read_mode = false ; // SAMPIC256CH_SetSmartReadMode int read_offset = 0 ; int samples_to_read = MAX_NB_OF_SAMPLES; // Trigger ExternalTriggerType_t external_trigger_type = SOFTWARE; // SAMPIC256CH_SetExternalTriggerType SignalLevel_t signal_level = TTL_SIG; // SAMPIC256CH_SetExternalTriggerSigLevel EdgeType_t trigger_edge = RISING_EDGE; // SAMPIC256CH_SetExternalTriggerEdge std:: uint8_t triggers_per_event = DEFAULT_NB_OF_TRIGGERS_PER_TRIGGER_EVENT; // SAMPIC256CH_SetMinNbOfTriggersPerEvent bool level2_trigger_build = false ; // SAMPIC256CH_SetLevel2TriggerBuildOption bool level3_trigger_build = false ; // SAMPIC256CH_SetLevel3TriggerLogic SampicTriggerOption_t trigger_option = SAMPIC_TRIGGER_IS_L1; // SAMPIC256CH_SetSampicTriggerOption unsigned char level3_ext_trig_gate = DEFAULT_EXT_TRIG_GATE; // SAMPIC256CH_SetLevel3ExtTrigGate bool level3_coincidence_ext_gate = false ; // SAMPIC256CH_SetLevel3CoincidenceModeWithExtTrigGate unsigned char primitives_gate_length = DEFAULT_PRIMITIVES_GATE_LENGTH; // SAMPIC256CH_SetPrimitivesGateLength unsigned char latency_gate_length = DEFAULT_LEVEL_2_LATENCY_GATE; // SAMPIC256CH_SetLevel2LatencyGateLength // Pulser bool pulser_enable = false ; // SAMPIC256CH_SetPulserMode PulserSourceType_t pulser_source = PULSER_SRC_IS_SOFT_CMD; bool pulser_synchronous = true ; int pulser_period = DEFAULT_AUTO_PULSE_PERIOD; // SAMPIC256CH_SetAutoPulserPeriod unsigned char pulser_width = DEFAULT_PULSER_WIDTH; // SAMPIC256CH_SetSampicPulserWidth // Sync + corrections bool sync_mode = false ; // SAMPIC256CH_SetCrateSycnhronisationMode bool master_mode = false ; bool coincidence_mode = false ; EdgeType_t sync_edge = RISING_EDGE; // SAMPIC256CH_SetExternalSyncEdge SignalLevel_t sync_level = TTL_SIG; // SAMPIC256CH_SetExternalSyncSigLevel bool adc_linearity_correction = false ; // SAMPIC256CH_SetCrateCorrectionLevels bool time_inl_correction = false ; bool residual_pedestal_correction = false ; std::string calibration_directory = \".\" ; // SAMPIC256CH_LoadAllCalibValuesFromFiles SampicFrontEndSettings front_end_boards { { \"feb0\" , {}}, { \"feb1\" , {}}, { \"feb2\" , {}}, { \"feb3\" , {}} }; bool verbose = false ; // for logging verbosity }; # endif // SAMPIC_CONFIG_H 6. Thread Safety Are the crate APIs thread-safe? Can multiple threads call BusReadWords on different FEBs simultaneously? If not, what is the correct concurrency model? 02/10/2025 08:41 Use the getters to determine default parameters, don't set something if getter returns same value as in ODB, this will save time when setting things. Some settings explanations: Frames per block: each sampic waits til it has 31 (parameterized) events before it sends it. triggers per event trigger counter must be on to see this(?) 127 is the max look for trigger counter switch, set parameter for it samples to read max samples to read is 64 part of the smart read mode settings setting it to below 64 you need to set the offset to make sure things are in a \"good\" order external trigger type Right now it's software But can be set to internal as well For changing the trigger to internal trigger mode, the following need to be set: baseline reference internal threshold trigger edge trigger mode It seems reading everything is viable (all least for the test beam use case). Pulser mode pulser mode will send signals to channel from the FPGA directly, no need for an external signal in a channel,",
    "textLength": 2658
  },
  {
    "kind": "work-log",
    "title": "08_09_2024 - 14_09_2024.html",
    "fileName": "08_09_2024 - 14_09_2024.html",
    "url": "resources/work_logs/08_09_2024 - 14_09_2024.html",
    "createdDate": "2024-09-08",
    "text": "08/09/2024 - 14/09/2024 08/09/2024 - 14/09/2024 10/09/2024 19:35 This output seems to verify we are indeed reading and writing to the device [root@fe01 tests]# ./run_test.sh Info: Number of enabled h2c channels = 2 Info: Number of enabled c2h channels = 2 Info: The PCIe DMA core is memory mapped. Info: Running PCIe DMA memory mapped write read test transfer size: 1024 transfer count: 1 Info: Writing to h2c channel 0 at address offset 0. Info: Writing to h2c channel 1 at address offset 1024. Info: Wait for current transactions to complete. sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000000 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_h2c_0, address = 0x00000000, size = 0x00000400, offset = 0x00000000, count = 1 Host memory buffer = 0x196f400 Data read from file into buffer at 0x196f400 (size: 1024 bytes): 10 11 12 13 14 15 16 17 18 19 1a 1b 1c 1d 1e 1f 20 21 22 23 24 25 26 27 28 29 2a 2b 2c 2d 2e 2f sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000001 Data written to FPGA device at 0x196f400 (iteration 0): device = /dev/xdma0_h2c_1, address = 0x00000400, size = 0x00000400, offset = 0x00000000, count = 1 10 11 12 13 14 15 16 17 18 19 1a 1b 1c 1d 1e 1f 20 21 22 23 24 25 26 27 28 29 2a 2b 2c 2d 2e 2f Host memory buffer = 0xcf1400 CLOCK_MONOTONIC reports 0.000065215 seconds (total) for last transfer of 1024 bytes Data read from file into buffer at 0xcf1400 (size: 1024 bytes): Transfer speed: 14.97 MB/s 00 00 00 00 01 00 00 00 02 00 00 00 03 00 00 00 04 00 00 00 05 00 00 00 06 00 00 00 07 00 00 00 Data written to FPGA device at 0xcf1400 (iteration 0): 00 00 00 00 01 00 00 00 02 00 00 00 03 00 00 00 04 00 00 00 05 00 00 00 06 00 00 00 07 00 00 00 CLOCK_MONOTONIC reports 0.000054443 seconds (total) for last transfer of 1024 bytes Transfer speed: 17.94 MB/s Info: Writing to h2c channel 0 at address offset 2048. Info: Writing to h2c channel 1 at address offset 3072. Info: Wait for current transactions to complete. sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000800 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_h2c_0, address = 0x00000800, size = 0x00000400, offset = 0x00000000, count = 1 Host memory buffer = 0x7e4400 Data read from file into buffer at 0x7e4400 (size: 1024 bytes): ff ff 00 00 ff fe 00 01 ff fd 00 02 ff fc 00 03 ff fb 00 04 ff fa 00 05 ff f9 00 06 ff f8 00 07 Data written to FPGA device at 0x7e4400 (iteration 0): ff ff 00 00 ff fe 00 01 ff fd 00 02 ff fc 00 03 ff fb 00 04 ff fa 00 05 ff f9 00 06 ff f8 00 07 CLOCK_MONOTONIC reports 0.000058135 seconds (total) for last transfer of 1024 bytes Transfer speed: 16.80 MB/s sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000c00 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_h2c_1, address = 0x00000c00, size = 0x00000400, offset = 0x00000000, count = 1 Host memory buffer = 0x135b400 Data read from file into buffer at 0x135b400 (size: 1024 bytes): 00 01 02 03 04 05 06 07 08 09 0a 0b 0c 0d 0e 0f 10 11 12 13 14 15 16 17 18 19 1a 1b 1c 1d 1e 1f Data written to FPGA device at 0x135b400 (iteration 0): 00 01 02 03 04 05 06 07 08 09 0a 0b 0c 0d 0e 0f 10 11 12 13 14 15 16 17 18 19 1a 1b 1c 1d 1e 1f CLOCK_MONOTONIC reports 0.000040952 seconds (total) for last transfer of 1024 bytes Transfer speed: 23.85 MB/s Info: Reading from c2h channel 0 at address offset 0. sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000000 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_c2h_0, address = 0x00000000, size = 0x00000400, offset = 0x00000000, count = 1 Host memory buffer = 0x1f3c000 Info: Reading from c2h channel 1 at address offset 1024. Data read into buffer at 0x1f3c000 (iteration 0): 10 11 12 13 14 15 16 17 18 19 1a 1b 1c 1d 1e 1f 20 21 22 23 24 25 26 27 28 29 2a 2b 2c 2d 2e 2f Info: Wait for the current transactions to complete. sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_c2h_1, address = 0x00000400, size = 0x00000400, offset = 0x00000000, count = 1 Host memory buffer = 0x1fcb000 Data read into buffer at 0x1fcb000 (iteration 0): 00 00 00 00 01 00 00 00 02 00 00 00 03 00 00 00 04 00 00 00 05 00 00 00 06 00 00 00 07 00 00 00 CLOCK_MONOTONIC reports 0.000024453 seconds (total) for last transfer of 1024 bytes Transfer speed: 39.94 MB/s CLOCK_MONOTONIC reports 0.000021195 seconds (total) for last transfer of 1024 bytes Transfer speed: 46.08 MB/s Info: Reading from c2h channel 0 at address offset 2048. sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000800 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_c2h_0, address = 0x00000800, size = 0x00000400, offset = 0x00000000, count = 1 Host memory buffer = 0x1c62000 Info: Reading from c2h channel 1 at address offset 3072. Data read into buffer at 0x1c62000 (iteration 0): ff ff 00 00 ff fe 00 01 ff fd 00 02 ff fc 00 03 ff fb 00 04 ff fa 00 05 ff f9 00 06 ff f8 00 07 Info: Wait for the current transactions to complete. sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000c00 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_c2h_1, address = 0x00000c00, size = 0x00000400, offset = 0x00000000, count = 1 Host memory buffer = 0x6d6000 Data read into buffer at 0x6d6000 (iteration 0): 00 01 02 03 04 05 06 07 08 09 0a 0b 0c 0d 0e 0f 10 11 12 13 14 15 16 17 18 19 1a 1b 1c 1d 1e 1f CLOCK_MONOTONIC reports 0.000025026 seconds (total) for last transfer of 1024 bytes Transfer speed: 39.02 MB/s CLOCK_MONOTONIC reports 0.000022440 seconds (total) for last transfer of 1024 bytes Transfer speed: 43.52 MB/s Info: Checking data integrity. Info: Data check passed for address range 0 - 1024. Info: Data check passed for address range 1024 - 2048. Info: Data check passed for address range 2048 - 3072. Info: Data check passed for address range 3072 - 4096. Info: All PCIe DMA memory mapped tests passed. Info: All tests in run_tests.sh passed. [root@fe01 tests]# [root@fe01 tests]# ./run_test.sh Info: Number of enabled h2c channels = 2 Info: Number of enabled c2h channels = 2 Info: The PCIe DMA core is memory mapped. Info: Running PCIe DMA memory mapped write read test transfer size: 1024 transfer count: 1 Info: Writing to h2c channel 0 at address offset 0. Info: Writing to h2c channel 1 at address offset 1024. Info: Wait for current transactions to complete. sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000000 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_h2c_0, address = 0x00000000, size = 0x00000400, offset = 0x00000000, count = 1 Host memory buffer = 0x196f400 Data read from file into buffer at 0x196f400 (size: 1024 bytes): 10 11 12 13 14 15 16 17 18 19 1a 1b 1c 1d 1e 1f 20 21 22 23 24 25 26 27 28 29 2a 2b 2c 2d 2e 2f sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000001 Data written to FPGA device at 0x196f400 (iteration 0): device = /dev/xdma0_h2c_1, address = 0x00000400, size = 0x00000400, offset = 0x00000000, count = 1 10 11 12 13 14 15 16 17 18 19 1a 1b 1c 1d 1e 1f 20 21 22 23 24 25 26 27 28 29 2a 2b 2c 2d 2e 2f Host memory buffer = 0xcf1400 CLOCK_MONOTONIC reports 0.000065215 seconds (total) for last transfer of 1024 bytes Data read from file into buffer at 0xcf1400 (size: 1024 bytes): Transfer speed: 14.97 MB/s 00 00 00 00 01 00 00 00 02 00 00 00 03 00 00 00 04 00 00 00 05 00 00 00 06 00 00 00 07 00 00 00 Data written to FPGA device at 0xcf1400 (iteration 0): 00 00 00 00 01 00 00 00 02 00 00 00 03 00 00 00 04 00 00 00 05 00 00 00 06 00 00 00 07 00 00 00 CLOCK_MONOTONIC reports 0.000054443 seconds (total) for last transfer of 1024 bytes Transfer speed: 17.94 MB/s Info: Writing to h2c channel 0 at address offset 2048. Info: Writing to h2c channel 1 at address offset 3072. Info: Wait for current transactions to complete. sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000800 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_h2c_0, address = 0x00000800, size = 0x00000400, offset = 0x00000000, count = 1 Host memory buffer = 0x7e4400 Data read from file into buffer at 0x7e4400 (size: 1024 bytes): ff ff 00 00 ff fe 00 01 ff fd 00 02 ff fc 00 03 ff fb 00 04 ff fa 00 05 ff f9 00 06 ff f8 00 07 Data written to FPGA device at 0x7e4400 (iteration 0): ff ff 00 00 ff fe 00 01 ff fd 00 02 ff fc 00 03 ff fb 00 04 ff fa 00 05 ff f9 00 06 ff f8 00 07 CLOCK_MONOTONIC reports 0.000058135 seconds (total) for last transfer of 1024 bytes Transfer speed: 16.80 MB/s sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000c00 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_h2c_1, address = 0x00000c00, size = 0x00000400, offset = 0x00000000, count = 1 Host memory buffer = 0x135b400 Data read from file into buffer at 0x135b400 (size: 1024 bytes): 00 01 02 03 04 05 06 07 08 09 0a 0b 0c 0d 0e 0f 10 11 12 13 14 15 16 17 18 19 1a 1b 1c 1d 1e 1f Data written to FPGA device at 0x135b400 (iteration 0): 00 01 02 03 04 05 06 07 08 09 0a 0b 0c 0d 0e 0f 10 11 12 13 14 15 16 17 18 19 1a 1b 1c 1d 1e 1f CLOCK_MONOTONIC reports 0.000040952 seconds (total) for last transfer of 1024 bytes Transfer speed: 23.85 MB/s Info: Reading from c2h channel 0 at address offset 0. sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000000 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_c2h_0, address = 0x00000000, size = 0x00000400, offset = 0x00000000, count = 1 Host memory buffer = 0x1f3c000 Info: Reading from c2h channel 1 at address offset 1024. Data read into buffer at 0x1f3c000 (iteration 0): 10 11 12 13 14 15 16 17 18 19 1a 1b 1c 1d 1e 1f 20 21 22 23 24 25 26 27 28 29 2a 2b 2c 2d 2e 2f Info: Wait for the current transactions to complete. sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_c2h_1, address = 0x00000400, size = 0x00000400, offset = 0x00000000, count = 1 Host memory buffer = 0x1fcb000 Data read into buffer at 0x1fcb000 (iteration 0): 00 00 00 00 01 00 00 00 02 00 00 00 03 00 00 00 04 00 00 00 05 00 00 00 06 00 00 00 07 00 00 00 CLOCK_MONOTONIC reports 0.000024453 seconds (total) for last transfer of 1024 bytes Transfer speed: 39.94 MB/s CLOCK_MONOTONIC reports 0.000021195 seconds (total) for last transfer of 1024 bytes Transfer speed: 46.08 MB/s Info: Reading from c2h channel 0 at address offset 2048. sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000800 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_c2h_0, address = 0x00000800, size = 0x00000400, offset = 0x00000000, count = 1 Host memory buffer = 0x1c62000 Info: Reading from c2h channel 1 at address offset 3072. Data read into buffer at 0x1c62000 (iteration 0): ff ff 00 00 ff fe 00 01 ff fd 00 02 ff fc 00 03 ff fb 00 04 ff fa 00 05 ff f9 00 06 ff f8 00 07 Info: Wait for the current transactions to complete. sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000c00 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_c2h_1, address = 0x00000c00, size = 0x00000400, offset = 0x00000000, count = 1 Host memory buffer = 0x6d6000 Data read into buffer at 0x6d6000 (iteration 0): 00 01 02 03 04 05 06 07 08 09 0a 0b 0c 0d 0e 0f 10 11 12 13 14 15 16 17 18 19 1a 1b 1c 1d 1e 1f CLOCK_MONOTONIC reports 0.000025026 seconds (total) for last transfer of 1024 bytes Transfer speed: 39.02 MB/s CLOCK_MONOTONIC reports 0.000022440 seconds (total) for last transfer of 1024 bytes Transfer speed: 43.52 MB/s Info: Checking data integrity. Info: Data check passed for address range 0 - 1024. Info: Data check passed for address range 1024 - 2048. Info: Data check passed for address range 2048 - 3072. Info: Data check passed for address range 3072 - 4096. Info: All PCIe DMA memory mapped tests passed. Info: All tests in run_tests.sh passed. [root@fe01 tests]# and the output of the script I wrote seems to verify we are indeed reading the same thing: [root@fe01 bin]# ./PCIe_DMA_Readout /dev/xdma0_c2h_0 0x00000000 16 Transfer speed: 0.11 MB/s 0000: 10 11 12 13 14 15 16 17 18 19 1a 1b 1c 1d 1e 1f |................| [root@fe01 bin]# ./PCIe_DMA_Readout /dev/xdma0_c2h_0 0x00000000 32 Transfer speed: 1.24 MB/s 0000: 10 11 12 13 14 15 16 17 18 19 1a 1b 1c 1d 1e 1f |................| 0010: 20 21 22 23 24 25 26 27 28 29 2a 2b 2c 2d 2e 2f | !\"#$%&'()*+,-./| [root@fe01 bin]# ./PCIe_DMA_Readout /dev/xdma0_c2h_0 0x00001000 32 Transfer speed: 1.02 MB/s 0000: f7 9f 7f ff ff ff bf ff f7 7e ef fe ff 7f c4 ce |.........~......| 0010: 2d a3 06 ef 47 1e ec fa a6 7d cc b0 f1 5d 7d 2f |-...G....}...]}/| [root@fe01 bin]# ./PCIe_DMA_Readout /dev/xdma0_c2h_0 0x00000400 32 Transfer speed: 1.00 MB/s 0000: 00 00 00 00 01 00 00 00 02 00 00 00 03 00 00 00 |................| 0010: 04 00 00 00 05 00 00 00 06 00 00 00 07 00 00 00 |................| [root@fe01 bin]# ./PCIe_DMA_Readout /dev/xdma0_c2h_0 0x00000800 32 Transfer speed: 0.21 MB/s 0000: ff ff 00 00 ff fe 00 01 ff fd 00 02 ff fc 00 03 |................| 0010: ff fb 00 04 ff fa 00 05 ff f9 00 06 ff f8 00 07 |................| [root@fe01 bin]# ./PCIe_DMA_Readout /dev/xdma0_c2h_0 0x00000800 32 [root@fe01 bin]# ./PCIe_DMA_Readout /dev/xdma0_c2h_0 0x00000000 16 Transfer speed: 0.11 MB/s 0000: 10 11 12 13 14 15 16 17 18 19 1a 1b 1c 1d 1e 1f |................| [root@fe01 bin]# ./PCIe_DMA_Readout /dev/xdma0_c2h_0 0x00000000 32 Transfer speed: 1.24 MB/s 0000: 10 11 12 13 14 15 16 17 18 19 1a 1b 1c 1d 1e 1f |................| 0010: 20 21 22 23 24 25 26 27 28 29 2a 2b 2c 2d 2e 2f | !\"#$%&'()*+,-./| [root@fe01 bin]# ./PCIe_DMA_Readout /dev/xdma0_c2h_0 0x00001000 32 Transfer speed: 1.02 MB/s 0000: f7 9f 7f ff ff ff bf ff f7 7e ef fe ff 7f c4 ce |.........~......| 0010: 2d a3 06 ef 47 1e ec fa a6 7d cc b0 f1 5d 7d 2f |-...G....}...]}/| [root@fe01 bin]# ./PCIe_DMA_Readout /dev/xdma0_c2h_0 0x00000400 32 Transfer speed: 1.00 MB/s 0000: 00 00 00 00 01 00 00 00 02 00 00 00 03 00 00 00 |................| 0010: 04 00 00 00 05 00 00 00 06 00 00 00 07 00 00 00 |................| [root@fe01 bin]# ./PCIe_DMA_Readout /dev/xdma0_c2h_0 0x00000800 32 Transfer speed: 0.21 MB/s 0000: ff ff 00 00 ff fe 00 01 ff fd 00 02 ff fc 00 03 |................| 0010: ff fb 00 04 ff fa 00 05 ff f9 00 06 ff f8 00 07 |................| [root@fe01 bin]# ./PCIe_DMA_Readout /dev/xdma0_c2h_0 0x00000800 32 12/09/2024 04:56 I updated fe01 to ALMA9 Linux. This updated the kernel. The XIlinx XDMA repository is not up to date for our kenel version given by: [root@dhcp-10-163-102-46 drivers]# uname -r 5.14.0-427.33.1.el9_4.x86_64 [root@dhcp -10 -163 -102 -46 drivers]# uname -r 5.14.0 -427 .33.1.el9_4.x86_64 However, there is a pull request that updates the driver for the newer kernel methods . Which can be added with: git remote add upstream https://github.com/Xilinx/dma_ip_drivers.git git fetch upstream pull/142/head:pull-142 git checkout pull-142 git remote add upstream https://github.com/Xilinx/dma_ip_drivers.git git fetch upstream pull/ 142 /head:pull- 142 git checkout pull- 142 However, this fails: [root@dhcp-10-163-102-46 xdma]# make install Makefile:17: XVC_FLAGS: . make -C /lib/modules/5.14.0-427.33.1.el9_4.x86_64/build M=/home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma modules make[1]: Entering directory '/usr/src/kernels/5.14.0-427.33.1.el9_4.x86_64' /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/Makefile:17: XVC_FLAGS: . CC [M] /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma_cdev.o CC [M] /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_ctrl.o CC [M] /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_sgdma.o /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_sgdma.c: In function \u2018async_io_handler\u2019: /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_sgdma.c:111:17: error: too many arguments to function \u2018caio->iocb->ki_complete\u2019 111 | caio->iocb->ki_complete(caio->iocb, res, res2); | ^~~~ /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_sgdma.c:130:9: error: too many arguments to function \u2018caio->iocb->ki_complete\u2019 130 | caio->iocb->ki_complete(caio->iocb, numbytes, -EBUSY); | ^~~~ /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_sgdma.c: In function \u2018cdev_write_iter\u2019: /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_sgdma.c:574:41: error: \u2018struct iov_iter\u2019 has no member named \u2018iov\u2019; did you mean \u2018__iov\u2019? 574 | return cdev_aio_write(iocb, io->iov, io->nr_segs, io->iov_offset); | ^~~ | __iov /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_sgdma.c: In function \u2018cdev_read_iter\u2019: /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_sgdma.c:583:40: error: \u2018struct iov_iter\u2019 has no member named \u2018iov\u2019; did you mean \u2018__iov\u2019? 583 | return cdev_aio_read(iocb, io->iov, io->nr_segs, io->iov_offset); | ^~~ | __iov /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_sgdma.c: In function \u2018cdev_write_iter\u2019: /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_sgdma.c:578:1: error: control reaches end of non-void function [-Werror=return-type] 578 | } | ^ /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_sgdma.c: In function \u2018cdev_read_iter\u2019: /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_sgdma.c:587:1: error: control reaches end of non-void function [-Werror=return-type] 587 | } | ^ cc1: some warnings being treated as errors make[2]: *** [scripts/Makefile.build:299: /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_sgdma.o] Error 1 make[1]: *** [Makefile:1936: /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma] Error 2 make[1]: Leaving directory '/usr/src/kernels/5.14.0-427.33.1.el9_4.x86_64' make: *** [Makefile:39: all] Error 2 [root@dhcp-10-163-102-46 xdma]# make install Makefile:17: XVC_FLAGS: . make -C /lib/modules/5.14.0-427.33.1.el9_4.x86_64/build M=/home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma modules make[1]: Entering directory '/usr/src/kernels/5.14.0-427.33.1.el9_4.x86_64' /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/Makefile:17: XVC_FLAGS: . CC [M] /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma_cdev.o CC [M] /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_ctrl.o CC [M] /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_sgdma.o /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_sgdma.c: In function \u2018async_io_handler\u2019: /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_sgdma.c:111:17: error: too many arguments to function \u2018caio->iocb->ki_complete\u2019 111 | caio->iocb->ki_complete(caio->iocb, res, res2); | ^~~~ /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_sgdma.c:130:9: error: too many arguments to function \u2018caio->iocb->ki_complete\u2019 130 | caio->iocb->ki_complete(caio->iocb, numbytes, -EBUSY); | ^~~~ /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_sgdma.c: In function \u2018cdev_write_iter\u2019: /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_sgdma.c:574:41: error: \u2018struct iov_iter\u2019 has no member named \u2018iov\u2019; did you mean \u2018__iov\u2019? 574 | return cdev_aio_write(iocb, io->iov, io->nr_segs, io->iov_offset); | ^~~ | __iov /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_sgdma.c: In function \u2018cdev_read_iter\u2019: /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_sgdma.c:583:40: error: \u2018struct iov_iter\u2019 has no member named \u2018iov\u2019; did you mean \u2018__iov\u2019? 583 | return cdev_aio_read(iocb, io->iov, io->nr_segs, io->iov_offset); | ^~~ | __iov /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_sgdma.c: In function \u2018cdev_write_iter\u2019: /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_sgdma.c:578:1: error: control reaches end of non-void function [-Werror=return-type] 578 | } | ^ /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_sgdma.c: In function \u2018cdev_read_iter\u2019: /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_sgdma.c:587:1: error: control reaches end of non-void function [-Werror=return-type] 587 | } | ^ cc1: some warnings being treated as errors make[2]: *** [scripts/Makefile.build:299: /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_sgdma.o] Error 1 make[1]: *** [Makefile:1936: /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma] Error 2 make[1]: Leaving directory '/usr/src/kernels/5.14.0-427.33.1.el9_4.x86_64' make: *** [Makefile:39: all] Error 2 It seems there linux versions cutoffs are wrong? I went into c_dev_sgma.c and manually changed these lines: c_dev_sgma.c::108 : -#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 16, 0) +#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 13, 0) - #if LINUX_VERSION_CODE >= KERNEL_VERSION ( 5 , 16 , 0 ) + #if LINUX_VERSION_CODE >= KERNEL_VERSION ( 5 , 13 , 0 ) c_dev_sgma.c::127 : -#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 16, 0) +#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 13, 0) - #if LINUX_VERSION_CODE >= KERNEL_VERSION ( 5 , 16 , 0 ) + #if LINUX_VERSION_CODE >= KERNEL_VERSION ( 5 , 13 , 0 ) c_dev_sgma.c::573 : -#if LINUX_VERSION_CODE >= KERNEL_VERSION(6, 4, 0) +#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 4, 0) - #if LINUX_VERSION_CODE >= KERNEL_VERSION ( 6 , 4 , 0 ) + #if LINUX_VERSION_CODE >= KERNEL_VERSION ( 5 , 4 , 0 ) c_dev_sgma.c::582 : -#if LINUX_VERSION_CODE >= KERNEL_VERSION(6, 4, 0) +#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 4, 0) - #if LINUX_VERSION_CODE >= KERNEL_VERSION ( 6 , 4 , 0 ) + #if LINUX_VERSION_CODE >= KERNEL_VERSION ( 5 , 4 , 0 ) and then I was able to make install : [root@dhcp-10-163-102-46 xdma]# make install Makefile:17: XVC_FLAGS: . make -C /lib/modules/5.14.0-427.33.1.el9_4.x86_64/build M=/home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma modules make[1]: Entering directory '/usr/src/kernels/5.14.0-427.33.1.el9_4.x86_64' /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/Makefile:17: XVC_FLAGS: . CC [M] /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_sgdma.o CC [M] /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_xvc.o CC [M] /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_bypass.o CC [M] /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma_mod.o CC [M] /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma_thread.o LD [M] /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma.o /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/Makefile:17: XVC_FLAGS: . MODPOST /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/Module.symvers CC [M] /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma.mod.o LD [M] /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma.ko BTF [M] /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma.ko Skipping BTF generation for /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma.ko due to unavailability of vmlinux make[1]: Leaving directory '/usr/src/kernels/5.14.0-427.33.1.el9_4.x86_64' make -C /lib/modules/5.14.0-427.33.1.el9_4.x86_64/build M=/home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma modules_install make[1]: Entering directory '/usr/src/kernels/5.14.0-427.33.1.el9_4.x86_64' INSTALL /lib/modules/5.14.0-427.33.1.el9_4.x86_64/extra/xdma.ko SIGN /lib/modules/5.14.0-427.33.1.el9_4.x86_64/extra/xdma.ko At main.c:167: - SSL error:FFFFFFFF80000002:system library::No such file or directory: crypto/bio/bss_file.c:67 - SSL error:10000080:BIO routines::no such file: crypto/bio/bss_file.c:75 sign-file: certs/signing_key.pem: No such file or directory DEPMOD /lib/modules/5.14.0-427.33.1.el9_4.x86_64 make[1]: Leaving directory '/usr/src/kernels/5.14.0-427.33.1.el9_4.x86_64' [root@dhcp-10-163-102-46 xdma]# [root@dhcp-10-163-102-46 xdma]# make install Makefile:17: XVC_FLAGS: . make -C /lib/modules/5.14.0-427.33.1.el9_4.x86_64/build M=/home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma modules make[1]: Entering directory '/usr/src/kernels/5.14.0-427.33.1.el9_4.x86_64' /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/Makefile:17: XVC_FLAGS: . CC [M] /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_sgdma.o CC [M] /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_xvc.o CC [M] /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_bypass.o CC [M] /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma_mod.o CC [M] /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma_thread.o LD [M] /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma.o /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/Makefile:17: XVC_FLAGS: . MODPOST /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/Module.symvers CC [M] /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma.mod.o LD [M] /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma.ko BTF [M] /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma.ko Skipping BTF generation for /home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma.ko due to unavailability of vmlinux make[1]: Leaving directory '/usr/src/kernels/5.14.0-427.33.1.el9_4.x86_64' make -C /lib/modules/5.14.0-427.33.1.el9_4.x86_64/build M=/home/drivers/dma_ip_drivers/XDMA/linux-kernel/xdma modules_install make[1]: Entering directory '/usr/src/kernels/5.14.0-427.33.1.el9_4.x86_64' INSTALL /lib/modules/5.14.0-427.33.1.el9_4.x86_64/extra/xdma.ko SIGN /lib/modules/5.14.0-427.33.1.el9_4.x86_64/extra/xdma.ko At main.c:167: - SSL error:FFFFFFFF80000002:system library::No such file or directory: crypto/bio/bss_file.c:67 - SSL error:10000080:BIO routines::no such file: crypto/bio/bss_file.c:75 sign-file: certs/signing_key.pem: No such file or directory DEPMOD /lib/modules/5.14.0-427.33.1.el9_4.x86_64 make[1]: Leaving directory '/usr/src/kernels/5.14.0-427.33.1.el9_4.x86_64' [root@dhcp-10-163-102-46 xdma]# [root@dhcp-10-163-102-46 linux-kernel]# cd tests/ [root@dhcp-10-163-102-46 tests]# ls data dma_memory_mapped_test.sh dma_streaming_test.sh load_driver.sh perform_hwcount.sh run_test.sh scripts_mm [root@dhcp-10-163-102-46 tests]# ./load_driver.sh interrupt_selection . Loading driver...insmod xdma.ko interrupt_mode=2 ... The Kernel module installed correctly and the xmda devices were recognized. DONE [root@dhcp-10-163-102-46 tests]# ./run_test.sh Info: Number of enabled h2c channels = 2 Info: Number of enabled c2h channels = 2 Info: The PCIe DMA core is memory mapped. Info: Running PCIe DMA memory mapped write read test transfer size: 1024, count: 1 Info: Writing to h2c channel 0 at address offset 0. Info: Writing to h2c channel 1 at address offset 1024. Info: Wait for current transactions to complete. /dev/xdma0_h2c_1 ** Average BW = 1024, 2.040885 /dev/xdma0_h2c_0 ** Average BW = 1024, 1.269210 Info: Writing to h2c channel 0 at address offset 2048. Info: Writing to h2c channel 1 at address offset 3072. Info: Wait for current transactions to complete. /dev/xdma0_h2c_0 ** Average BW = 1024, 1.371362 /dev/xdma0_h2c_1 ** Average BW = 1024, 1.563163 Info: Reading from c2h channel 0 at address offset 0. Info: Reading from c2h channel 1 at address offset 1024. Info: Wait for current transactions to complete. /dev/xdma0_c2h_0 ** Average BW = 1024, 0.610432 /dev/xdma0_c2h_1 ** Average BW = 1024, 9.607986 Info: Reading from c2h channel 0 at address offset 2048. Info: Reading from c2h channel 1 at address offset 3072. Info: Wait for current transactions to complete. /dev/xdma0_c2h_0 ** Average BW = 1024, 3.289019 /dev/xdma0_c2h_1 ** Average BW = 1024, 3.509698 Info: Checking data integrity. Info: Data check passed for address range 0 - 1024 Info: Data check passed for address range 1024 - 2048 Info: Data check passed for address range 2048 - 3072 Info: Data check passed for address range 3072 - 4096 Info: All PCIe DMA memory mapped tests passed. Info: All tests in run_tests.sh passed. [root@dhcp-10-163-102-46 linux-kernel]# cd tests/ [root@dhcp-10-163-102-46 tests]# ls data dma_memory_mapped_test.sh dma_streaming_test.sh load_driver.sh perform_hwcount.sh run_test.sh scripts_mm [root@dhcp-10-163-102-46 tests]# ./load_driver.sh interrupt_selection . Loading driver...insmod xdma.ko interrupt_mode=2 ... The Kernel module installed correctly and the xmda devices were recognized. DONE [root@dhcp-10-163-102-46 tests]# ./run_test.sh Info: Number of enabled h2c channels = 2 Info: Number of enabled c2h channels = 2 Info: The PCIe DMA core is memory mapped. Info: Running PCIe DMA memory mapped write read test transfer size: 1024, count: 1 Info: Writing to h2c channel 0 at address offset 0. Info: Writing to h2c channel 1 at address offset 1024. Info: Wait for current transactions to complete. /dev/xdma0_h2c_1 ** Average BW = 1024, 2.040885 /dev/xdma0_h2c_0 ** Average BW = 1024, 1.269210 Info: Writing to h2c channel 0 at address offset 2048. Info: Writing to h2c channel 1 at address offset 3072. Info: Wait for current transactions to complete. /dev/xdma0_h2c_0 ** Average BW = 1024, 1.371362 /dev/xdma0_h2c_1 ** Average BW = 1024, 1.563163 Info: Reading from c2h channel 0 at address offset 0. Info: Reading from c2h channel 1 at address offset 1024. Info: Wait for current transactions to complete. /dev/xdma0_c2h_0 ** Average BW = 1024, 0.610432 /dev/xdma0_c2h_1 ** Average BW = 1024, 9.607986 Info: Reading from c2h channel 0 at address offset 2048. Info: Reading from c2h channel 1 at address offset 3072. Info: Wait for current transactions to complete. /dev/xdma0_c2h_0 ** Average BW = 1024, 3.289019 /dev/xdma0_c2h_1 ** Average BW = 1024, 3.509698 Info: Checking data integrity. Info: Data check passed for address range 0 - 1024 Info: Data check passed for address range 1024 - 2048 Info: Data check passed for address range 2048 - 3072 Info: Data check passed for address range 3072 - 4096 Info: All PCIe DMA memory mapped tests passed. Info: All tests in run_tests.sh passed. Thing seem to work in the tests. Also they seem to work in my XDMA library: [root@dhcp-10-163-102-46 bin]# ./PCIe_DMA_Readout /dev/xdma0_c2h_0 /dev/xdma0_h2c_0 /dev/xdma0_control 0x00000000 32 Write operation successful. Time taken: 0.000468421 seconds. Transfer speed: 0 MB/s Read operation successful, 32 bytes read. Time taken: 0.000114502 seconds. 0: ffffffac ffffffac ffffffac ffffffac ffffffac ffffffac ffffffac ffffffac ffffffac ffffffac ffffffac ffffffac ffffffac ffffffac ffffffac ffffffac |................| 10: ffffffac ffffffac ffffffac ffffffac ffffffac ffffffac ffffffac ffffffac ffffffac ffffffac ffffffac ffffffac ffffffac ffffffac ffffffac ffffffac |................| Transfer speed: 0.272418 MB/s [root@dhcp-10-163-102-46 bin]# [root @dhcp-10-163-102-46 bin]# ./PCIe_DMA_Readout /dev/xdma0_c2h_0 /dev/xdma0_h2c_0 /dev/xdma0_control 0x00000000 32 Write operation successful. Time taken: 0.000468421 seconds. Transfer speed: 0 MB/s Read operation successful, 32 bytes read. Time taken: 0.000114502 seconds. 0: ffffffac ffffffac ffffffac ffffffac ffffffac ffffffac ffffffac ffffffac ffffffac ffffffac ffffffac ffffffac ffffffac ffffffac ffffffac ffffffac |................| 10: ffffffac ffffffac ffffffac ffffffac ffffffac ffffffac ffffffac ffffffac ffffffac ffffffac ffffffac ffffffac ffffffac ffffffac ffffffac ffffffac |................| Transfer speed: 0.272418 MB/s [root@ dhcp -10 -163 -102 -46 bin] # 12/09/2024 06:36 I wrote a frontend that just writes and reads data, incrimenting things a little bit as it goes. It seems to work: #include <stdio.h> #include <stdlib.h> #include <math.h> #include <string.h> #include <iostream> #include <fstream> #include <sstream> #include <vector> #include <chrono> #include \"midas.h\" #include \"mfe.h\" #include \"xdma_device_read.h\" #include \"xdma_device_write.h\" // Define your PCIe devices XDMADeviceRead deviceRead(\"/dev/xdma0_c2h_0\"); XDMADeviceWrite deviceWrite(\"/dev/xdma0_h2c_0\"); // Globals const char *frontend_name = \"DataSimulator\"; const char *frontend_file_name = __FILE__; BOOL frontend_call_loop = FALSE; INT display_period = 1000; INT max_event_size = 1024 * 1024; INT max_event_size_frag = 5 * max_event_size; INT event_buffer_size = 5 * max_event_size; // Define a vector to store 16-bit words std::vector<int16_t> data; // Global variable to keep track of the last poll time std::chrono::steady_clock::time_point last_poll_time; const std::chrono::microseconds polling_interval(1000*1000); // Global variable to cycle the write pattern uint8_t write_value = 0x00; // Starting value // Function declarations INT frontend_init(void); INT frontend_exit(void); INT begin_of_run(INT run_number, char *error); INT end_of_run(INT run_number, char *error); INT pause_run(INT run_number, char *error); INT resume_run(INT run_number, char *error); INT frontend_loop(void); INT read_trigger_event(char *pevent, INT off); INT read_periodic_event(char *pevent, INT off); INT poll_event(INT source, INT count, BOOL test); INT interrupt_configure(INT cmd, INT source, POINTER_T adr); // Equipment list BOOL equipment_common_overwrite = TRUE; EQUIPMENT equipment[] = { {\"Data Simulator\", {2, 0, \"SYSTEM\", EQ_POLLED, 0, \"MIDAS\", TRUE, RO_RUNNING | RO_TRANSITIONS | RO_ODB, 10, 0, 0, TRUE, \"\", \"\", \"\",}, read_trigger_event }, {\"\"} }; // Trigger Update void trigger_update(INT hDB, INT hkey, void*) { } // Frontend Init int frontend_init() { // Initialize PCIe devices deviceRead = XDMADeviceRead(\"/dev/xdma0_c2h_0\"); deviceWrite = XDMADeviceWrite(\"/dev/xdma0_h2c_0\"); deviceRead.initialize(); deviceWrite.initialize(); return SUCCESS; } // Frontend Exit INT frontend_exit() { return SUCCESS; } // Begin of Run INT begin_of_run(INT run_number, char *error) { return SUCCESS; } // End of Run INT end_of_run(INT run_number, char *error) { return SUCCESS; } // Pause Run INT pause_run(INT run_number, char *error) { return SUCCESS; } // Resume Run INT resume_run(INT run_number, char *error) { return SUCCESS; } // Frontend Loop INT frontend_loop() { return SUCCESS; } // Poll Event INT poll_event(INT source, INT count, BOOL test) { auto now = std::chrono::steady_clock::now(); if (now - last_poll_time >= polling_interval) { last_poll_time = now; return TRUE; } if (test) { return FALSE; } return FALSE; } // Interrupt Configuration INT interrupt_configure(INT cmd, INT source, POINTER_T adr) { switch (cmd) { case CMD_INTERRUPT_ENABLE: break; case CMD_INTERRUPT_DISABLE: break; case CMD_INTERRUPT_ATTACH: break; case CMD_INTERRUPT_DETACH: break; } return SUCCESS; } // Event Readout INT read_trigger_event(char *pevent, INT off) { // Init bank structure bk_init32(pevent); // Create a bank named \"CR00\" and specify the data type as TID_SHORT short *pdata; bk_create(pevent, \"CR00\", TID_SHORT, (void **)&pdata); // Write a cycling pattern to the PCIe device size_t size = 1024; // Adjust size as needed std::vector<char> buffer(size); for (size_t i = 0; i < size; ++i) { buffer[i] = write_value; } // Assuming address is 0 for the write operation, you can adjust as needed deviceWrite.writeToDevice(0, size, buffer.data()); // Increment the write value and wrap around if needed write_value += 0x01; if (write_value > 0xAA) { write_value = 0x00; } // Read data from the PCIe device std::vector<char> read_buffer = deviceRead.readFromDevice(0, size); // Convert char buffer to short and copy to pdata for (size_t i = 0; i < size / sizeof(short); ++i) { // Ensure the buffer has enough data if (i * sizeof(short) + sizeof(short) <= read_buffer.size()) { *pdata++ = *reinterpret_cast<short*>(&read_buffer[i * sizeof(short)]); } } // Close the bank bk_close(pevent, pdata); return bk_size(pevent); } // Periodic Event INT read_periodic_event(char *pevent, INT off) { // Init bank structure bk_init32(pevent); // Create a bank named \"CR00\" and specify the data type as TID_SHORT short *pdata; bk_create(pevent, \"CR00\", TID_SHORT, (void **)&pdata); // Read data from the PCIe device size_t size = 1024; // Adjust size as needed std::vector<char> buffer = deviceRead.readFromDevice(0, size); // Convert char buffer to short and copy to pdata for (size_t i = 0; i < size / sizeof(short); ++i) { // Ensure the buffer has enough data if (i * sizeof(short) + sizeof(short) <= buffer.size()) { *pdata++ = *reinterpret_cast<short*>(&buffer[i * sizeof(short)]); } } // Close the bank bk_close(pevent, pdata); return bk_size(pevent); } #include <stdio.h> #include <stdlib.h> #include <math.h> #include <string.h> #include <iostream> #include <fstream> #include <sstream> #include <vector> #include <chrono> #include \"midas.h\" #include \"mfe.h\" #include \"xdma_device_read.h\" #include \"xdma_device_write.h\" // Define your PCIe devices XDMADeviceRead deviceRead(\"/dev/xdma0_c2h_0\"); XDMADeviceWrite deviceWrite(\"/dev/xdma0_h2c_0\"); // Globals const char *frontend_name = \"DataSimulator\"; const char *frontend_file_name = __FILE__; BOOL frontend_call_loop = FALSE; INT display_period = 1000; INT max_event_size = 1024 * 1024; INT max_event_size_frag = 5 * max_event_size; INT event_buffer_size = 5 * max_event_size; // Define a vector to store 16-bit words std::vector<int16_t> data; // Global variable to keep track of the last poll time std::chrono::steady_clock::time_point last_poll_time; const std::chrono::microseconds polling_interval(1000*1000); // Global variable to cycle the write pattern uint8_t write_value = 0x00; // Starting value // Function declarations INT frontend_init(void); INT frontend_exit(void); INT begin_of_run(INT run_number, char *error); INT end_of_run(INT run_number, char *error); INT pause_run(INT run_number, char *error); INT resume_run(INT run_number, char *error); INT frontend_loop(void); INT read_trigger_event(char *pevent, INT off); INT read_periodic_event(char *pevent, INT off); INT poll_event(INT source, INT count, BOOL test); INT interrupt_configure(INT cmd, INT source, POINTER_T adr); // Equipment list BOOL equipment_common_overwrite = TRUE; EQUIPMENT equipment[] = { {\"Data Simulator\", {2, 0, \"SYSTEM\", EQ_POLLED, 0, \"MIDAS\", TRUE, RO_RUNNING | RO_TRANSITIONS | RO_ODB, 10, 0, 0, TRUE, \"\", \"\", \"\",}, read_trigger_event }, {\"\"} }; // Trigger Update void trigger_update(INT hDB, INT hkey, void*) { } // Frontend Init int frontend_init() { // Initialize PCIe devices deviceRead = XDMADeviceRead(\"/dev/xdma0_c2h_0\"); deviceWrite = XDMADeviceWrite(\"/dev/xdma0_h2c_0\"); deviceRead.initialize(); deviceWrite.initialize(); return SUCCESS; } // Frontend Exit INT frontend_exit() { return SUCCESS; } // Begin of Run INT begin_of_run(INT run_number, char *error) { return SUCCESS; } // End of Run INT end_of_run(INT run_number, char *error) { return SUCCESS; } // Pause Run INT pause_run(INT run_number, char *error) { return SUCCESS; } // Resume Run INT resume_run(INT run_number, char *error) { return SUCCESS; } // Frontend Loop INT frontend_loop() { return SUCCESS; } // Poll Event INT poll_event(INT source, INT count, BOOL test) { auto now = std::chrono::steady_clock::now(); if (now - last_poll_time >= polling_interval) { last_poll_time = now; return TRUE; } if (test) { return FALSE; } return FALSE; } // Interrupt Configuration INT interrupt_configure(INT cmd, INT source, POINTER_T adr) { switch (cmd) { case CMD_INTERRUPT_ENABLE: break; case CMD_INTERRUPT_DISABLE: break; case CMD_INTERRUPT_ATTACH: break; case CMD_INTERRUPT_DETACH: break; } return SUCCESS; } // Event Readout INT read_trigger_event(char *pevent, INT off) { // Init bank structure bk_init32(pevent); // Create a bank named \"CR00\" and specify the data type as TID_SHORT short *pdata; bk_create(pevent, \"CR00\", TID_SHORT, (void **)&pdata); // Write a cycling pattern to the PCIe device size_t size = 1024; // Adjust size as needed std::vector<char> buffer(size); for (size_t i = 0; i < size; ++i) { buffer[i] = write_value; } // Assuming address is 0 for the write operation, you can adjust as needed deviceWrite.writeToDevice(0, size, buffer.data()); // Increment the write value and wrap around if needed write_value += 0x01; if (write_value > 0xAA) { write_value = 0x00; } // Read data from the PCIe device std::vector<char> read_buffer = deviceRead.readFromDevice(0, size); // Convert char buffer to short and copy to pdata for (size_t i = 0; i < size / sizeof(short); ++i) { // Ensure the buffer has enough data if (i * sizeof(short) + sizeof(short) <= read_buffer.size()) { *pdata++ = *reinterpret_cast<short*>(&read_buffer[i * sizeof(short)]); } } // Close the bank bk_close(pevent, pdata); return bk_size(pevent); } // Periodic Event INT read_periodic_event(char *pevent, INT off) { // Init bank structure bk_init32(pevent); // Create a bank named \"CR00\" and specify the data type as TID_SHORT short *pdata; bk_create(pevent, \"CR00\", TID_SHORT, (void **)&pdata); // Read data from the PCIe device size_t size = 1024; // Adjust size as needed std::vector<char> buffer = deviceRead.readFromDevice(0, size); // Convert char buffer to short and copy to pdata for (size_t i = 0; i < size / sizeof(short); ++i) { // Ensure the buffer has enough data if (i * sizeof(short) + sizeof(short) <= buffer.size()) { *pdata++ = *reinterpret_cast<short*>(&buffer[i * sizeof(short)]); } } // Close the bank bk_close(pevent, pdata); return bk_size(pevent); } With mdump outputs: [root@dhcp-10-163-102-46 pcie_data_simulator]# $MIDASSYS/bin/mdump - MIDAS revision: Fri Feb 2 18:49:36 2024 -0500 - on branch pioneerMidas -- Enter <!> to Exit ------- Midas Dump --- ------------------------ Event# 1 ------------------------ Evid:0002- Mask:0000- Serial:54- Time:0x66e2c434- Dsize:1044/0x414 #banks:1 - Bank list:-CR00- Bank:CR00 Length: 1024(I*1)/256(I*4)/512(Type) Type:Signed Integer*2 1-> 13878 13878 13878 13878 13878 13878 13878 13878 9-> 13878 13878 13878 13878 13878 13878 13878 13878 17-> 13878 13878 13878 13878 13878 13878 13878 13878 25-> 13878 13878 13878 13878 13878 13878 13878 13878 33-> 13878 13878 13878 13878 13878 13878 13878 13878 41-> 13878 13878 13878 13878 13878 13878 13878 13878 49-> 13878 13878 13878 13878 13878 13878 13878 13878 57-> 13878 13878 13878 13878 13878 13878 13878 13878 65-> 13878 13878 13878 13878 13878 13878 13878 13878 73-> 13878 13878 13878 13878 13878 13878 13878 13878 81-> 13878 13878 13878 13878 13878 13878 13878 13878 89-> 13878 13878 13878 13878 13878 13878 13878 13878 97-> 13878 13878 13878 13878 13878 13878 13878 13878 105-> 13878 13878 13878 13878 13878 13878 13878 13878 113-> 13878 13878 13878 13878 13878 13878 13878 13878 121-> 13878 13878 13878 13878 13878 13878 13878 13878 129-> 13878 13878 13878 13878 13878 13878 13878 13878 137-> 13878 13878 13878 13878 13878 13878 13878 13878 145-> 13878 13878 13878 13878 13878 13878 13878 13878 153-> 13878 13878 13878 13878 13878 13878 13878 13878 161-> 13878 13878 13878 13878 13878 13878 13878 13878 169-> 13878 13878 13878 13878 13878 13878 13878 13878 177-> 13878 13878 13878 13878 13878 13878 13878 13878 185-> 13878 13878 13878 13878 13878 13878 13878 13878 193-> 13878 13878 13878 13878 13878 13878 13878 13878 201-> 13878 13878 13878 13878 13878 13878 13878 13878 209-> 13878 13878 13878 13878 13878 13878 13878 13878 217-> 13878 13878 13878 13878 13878 13878 13878 13878 225-> 13878 13878 13878 13878 13878 13878 13878 13878 233-> 13878 13878 13878 13878 13878 13878 13878 13878 241-> 13878 13878 13878 13878 13878 13878 13878 13878 249-> 13878 13878 13878 13878 13878 13878 13878 13878 257-> 13878 13878 13878 13878 13878 13878 13878 13878 265-> 13878 13878 13878 13878 13878 13878 13878 13878 273-> 13878 13878 13878 13878 13878 13878 13878 13878 281-> 13878 13878 13878 13878 13878 13878 13878 13878 289-> 13878 13878 13878 13878 13878 13878 13878 13878 297-> 13878 13878 13878 13878 13878 13878 13878 13878 305-> 13878 13878 13878 13878 13878 13878 13878 13878 313-> 13878 13878 13878 13878 13878 13878 13878 13878 321-> 13878 13878 13878 13878 13878 13878 13878 13878 329-> 13878 13878 13878 13878 13878 13878 13878 13878 337-> 13878 13878 13878 13878 13878 13878 13878 13878 345-> 13878 13878 13878 13878 13878 13878 13878 13878 353-> 13878 13878 13878 13878 13878 13878 13878 13878 361-> 13878 13878 13878 13878 13878 13878 13878 13878 369-> 13878 13878 13878 13878 13878 13878 13878 13878 377-> 13878 13878 13878 13878 13878 13878 13878 13878 385-> 13878 13878 13878 13878 13878 13878 13878 13878 393-> 13878 13878 13878 13878 13878 13878 13878 13878 401-> 13878 13878 13878 13878 13878 13878 13878 13878 409-> 13878 13878 13878 13878 13878 13878 13878 13878 417-> 13878 13878 13878 13878 13878 13878 13878 13878 425-> 13878 13878 13878 13878 13878 13878 13878 13878 433-> 13878 13878 13878 13878 13878 13878 13878 13878 441-> 13878 13878 13878 13878 13878 13878 13878 13878 449-> 13878 13878 13878 13878 13878 13878 13878 13878 457-> 13878 13878 13878 13878 13878 13878 13878 13878 465-> 13878 13878 13878 13878 13878 13878 13878 13878 473-> 13878 13878 13878 13878 13878 13878 13878 13878 481-> 13878 13878 13878 13878 13878 13878 13878 13878 489-> 13878 13878 13878 13878 13878 13878 13878 13878 497-> 13878 13878 13878 13878 13878 13878 13878 13878 505-> 13878 13878 13878 13878 13878 13878 13878 13878 [root@dhcp-10-163-102-46 pcie_data_simulator]# $MIDASSYS/bin/mdump - MIDAS revision: Fri Feb 2 18:49:36 2024 -0500 - on branch pioneerMidas -- Enter <!> to Exit ------- Midas Dump --- ------------------------ Event# 1 ------------------------ Evid:0002- Mask:0000- Serial:55- Time:0x66e2c435- Dsize:1044/0x414 #banks:1 - Bank list:-CR00- Bank:CR00 Length: 1024(I*1)/256(I*4)/512(Type) Type:Signed Integer*2 1-> 14135 14135 14135 14135 14135 14135 14135 14135 9-> 14135 14135 14135 14135 14135 14135 14135 14135 17-> 14135 14135 14135 14135 14135 14135 14135 14135 25-> 14135 14135 14135 14135 14135 14135 14135 14135 33-> 14135 14135 14135 14135 14135 14135 14135 14135 41-> 14135 14135 14135 14135 14135 14135 14135 14135 49-> 14135 14135 14135 14135 14135 14135 14135 14135 57-> 14135 14135 14135 14135 14135 14135 14135 14135 65-> 14135 14135 14135 14135 14135 14135 14135 14135 73-> 14135 14135 14135 14135 14135 14135 14135 14135 81-> 14135 14135 14135 14135 14135 14135 14135 14135 89-> 14135 14135 14135 14135 14135 14135 14135 14135 97-> 14135 14135 14135 14135 14135 14135 14135 14135 105-> 14135 14135 14135 14135 14135 14135 14135 14135 113-> 14135 14135 14135 14135 14135 14135 14135 14135 121-> 14135 14135 14135 14135 14135 14135 14135 14135 129-> 14135 14135 14135 14135 14135 14135 14135 14135 137-> 14135 14135 14135 14135 14135 14135 14135 14135 145-> 14135 14135 14135 14135 14135 14135 14135 14135 153-> 14135 14135 14135 14135 14135 14135 14135 14135 161-> 14135 14135 14135 14135 14135 14135 14135 14135 169-> 14135 14135 14135 14135 14135 14135 14135 14135 177-> 14135 14135 14135 14135 14135 14135 14135 14135 185-> 14135 14135 14135 14135 14135 14135 14135 14135 193-> 14135 14135 14135 14135 14135 14135 14135 14135 201-> 14135 14135 14135 14135 14135 14135 14135 14135 209-> 14135 14135 14135 14135 14135 14135 14135 14135 217-> 14135 14135 14135 14135 14135 14135 14135 14135 225-> 14135 14135 14135 14135 14135 14135 14135 14135 233-> 14135 14135 14135 14135 14135 14135 14135 14135 241-> 14135 14135 14135 14135 14135 14135 14135 14135 249-> 14135 14135 14135 14135 14135 14135 14135 14135 257-> 14135 14135 14135 14135 14135 14135 14135 14135 265-> 14135 14135 14135 14135 14135 14135 14135 14135 273-> 14135 14135 14135 14135 14135 14135 14135 14135 281-> 14135 14135 14135 14135 14135 14135 14135 14135 289-> 14135 14135 14135 14135 14135 14135 14135 14135 297-> 14135 14135 14135 14135 14135 14135 14135 14135 305-> 14135 14135 14135 14135 14135 14135 14135 14135 313-> 14135 14135 14135 14135 14135 14135 14135 14135 321-> 14135 14135 14135 14135 14135 14135 14135 14135 329-> 14135 14135 14135 14135 14135 14135 14135 14135 337-> 14135 14135 14135 14135 14135 14135 14135 14135 345-> 14135 14135 14135 14135 14135 14135 14135 14135 353-> 14135 14135 14135 14135 14135 14135 14135 14135 361-> 14135 14135 14135 14135 14135 14135 14135 14135 369-> 14135 14135 14135 14135 14135 14135 14135 14135 377-> 14135 14135 14135 14135 14135 14135 14135 14135 385-> 14135 14135 14135 14135 14135 14135 14135 14135 393-> 14135 14135 14135 14135 14135 14135 14135 14135 401-> 14135 14135 14135 14135 14135 14135 14135 14135 409-> 14135 14135 14135 14135 14135 14135 14135 14135 417-> 14135 14135 14135 14135 14135 14135 14135 14135 425-> 14135 14135 14135 14135 14135 14135 14135 14135 433-> 14135 14135 14135 14135 14135 14135 14135 14135 441-> 14135 14135 14135 14135 14135 14135 14135 14135 449-> 14135 14135 14135 14135 14135 14135 14135 14135 457-> 14135 14135 14135 14135 14135 14135 14135 14135 465-> 14135 14135 14135 14135 14135 14135 14135 14135 473-> 14135 14135 14135 14135 14135 14135 14135 14135 481-> 14135 14135 14135 14135 14135 14135 14135 14135 489-> 14135 14135 14135 14135 14135 14135 14135 14135 497-> 14135 14135 14135 14135 14135 14135 14135 14135 505-> 14135 14135 14135 14135 14135 14135 14135 14135 [root@dhcp-10-163-102-46 pcie_data_simulator]# [root@dhcp-10-163-102-46 pcie_data_simulator]# $MIDASSYS/bin/mdump - MIDAS revision: Fri Feb 2 18:49:36 2024 -0500 - on branch pioneerMidas -- Enter <!> to Exit ------- Midas Dump --- ------------------------ Event# 1 ------------------------ Evid:0002- Mask:0000- Serial:54- Time:0x66e2c434- Dsize:1044/0x414 #banks:1 - Bank list:-CR00- Bank:CR00 Length: 1024(I*1)/256(I*4)/512(Type) Type:Signed Integer*2 1-> 13878 13878 13878 13878 13878 13878 13878 13878 9-> 13878 13878 13878 13878 13878 13878 13878 13878 17-> 13878 13878 13878 13878 13878 13878 13878 13878 25-> 13878 13878 13878 13878 13878 13878 13878 13878 33-> 13878 13878 13878 13878 13878 13878 13878 13878 41-> 13878 13878 13878 13878 13878 13878 13878 13878 49-> 13878 13878 13878 13878 13878 13878 13878 13878 57-> 13878 13878 13878 13878 13878 13878 13878 13878 65-> 13878 13878 13878 13878 13878 13878 13878 13878 73-> 13878 13878 13878 13878 13878 13878 13878 13878 81-> 13878 13878 13878 13878 13878 13878 13878 13878 89-> 13878 13878 13878 13878 13878 13878 13878 13878 97-> 13878 13878 13878 13878 13878 13878 13878 13878 105-> 13878 13878 13878 13878 13878 13878 13878 13878 113-> 13878 13878 13878 13878 13878 13878 13878 13878 121-> 13878 13878 13878 13878 13878 13878 13878 13878 129-> 13878 13878 13878 13878 13878 13878 13878 13878 137-> 13878 13878 13878 13878 13878 13878 13878 13878 145-> 13878 13878 13878 13878 13878 13878 13878 13878 153-> 13878 13878 13878 13878 13878 13878 13878 13878 161-> 13878 13878 13878 13878 13878 13878 13878 13878 169-> 13878 13878 13878 13878 13878 13878 13878 13878 177-> 13878 13878 13878 13878 13878 13878 13878 13878 185-> 13878 13878 13878 13878 13878 13878 13878 13878 193-> 13878 13878 13878 13878 13878 13878 13878 13878 201-> 13878 13878 13878 13878 13878 13878 13878 13878 209-> 13878 13878 13878 13878 13878 13878 13878 13878 217-> 13878 13878 13878 13878 13878 13878 13878 13878 225-> 13878 13878 13878 13878 13878 13878 13878 13878 233-> 13878 13878 13878 13878 13878 13878 13878 13878 241-> 13878 13878 13878 13878 13878 13878 13878 13878 249-> 13878 13878 13878 13878 13878 13878 13878 13878 257-> 13878 13878 13878 13878 13878 13878 13878 13878 265-> 13878 13878 13878 13878 13878 13878 13878 13878 273-> 13878 13878 13878 13878 13878 13878 13878 13878 281-> 13878 13878 13878 13878 13878 13878 13878 13878 289-> 13878 13878 13878 13878 13878 13878 13878 13878 297-> 13878 13878 13878 13878 13878 13878 13878 13878 305-> 13878 13878 13878 13878 13878 13878 13878 13878 313-> 13878 13878 13878 13878 13878 13878 13878 13878 321-> 13878 13878 13878 13878 13878 13878 13878 13878 329-> 13878 13878 13878 13878 13878 13878 13878 13878 337-> 13878 13878 13878 13878 13878 13878 13878 13878 345-> 13878 13878 13878 13878 13878 13878 13878 13878 353-> 13878 13878 13878 13878 13878 13878 13878 13878 361-> 13878 13878 13878 13878 13878 13878 13878 13878 369-> 13878 13878 13878 13878 13878 13878 13878 13878 377-> 13878 13878 13878 13878 13878 13878 13878 13878 385-> 13878 13878 13878 13878 13878 13878 13878 13878 393-> 13878 13878 13878 13878 13878 13878 13878 13878 401-> 13878 13878 13878 13878 13878 13878 13878 13878 409-> 13878 13878 13878 13878 13878 13878 13878 13878 417-> 13878 13878 13878 13878 13878 13878 13878 13878 425-> 13878 13878 13878 13878 13878 13878 13878 13878 433-> 13878 13878 13878 13878 13878 13878 13878 13878 441-> 13878 13878 13878 13878 13878 13878 13878 13878 449-> 13878 13878 13878 13878 13878 13878 13878 13878 457-> 13878 13878 13878 13878 13878 13878 13878 13878 465-> 13878 13878 13878 13878 13878 13878 13878 13878 473-> 13878 13878 13878 13878 13878 13878 13878 13878 481-> 13878 13878 13878 13878 13878 13878 13878 13878 489-> 13878 13878 13878 13878 13878 13878 13878 13878 497-> 13878 13878 13878 13878 13878 13878 13878 13878 505-> 13878 13878 13878 13878 13878 13878 13878 13878 [root@dhcp-10-163-102-46 pcie_data_simulator]# $MIDASSYS/bin/mdump - MIDAS revision: Fri Feb 2 18:49:36 2024 -0500 - on branch pioneerMidas -- Enter <!> to Exit ------- Midas Dump --- ------------------------ Event# 1 ------------------------ Evid:0002- Mask:0000- Serial:55- Time:0x66e2c435- Dsize:1044/0x414 #banks:1 - Bank list:-CR00- Bank:CR00 Length: 1024(I*1)/256(I*4)/512(Type) Type:Signed Integer*2 1-> 14135 14135 14135 14135 14135 14135 14135 14135 9-> 14135 14135 14135 14135 14135 14135 14135 14135 17-> 14135 14135 14135 14135 14135 14135 14135 14135 25-> 14135 14135 14135 14135 14135 14135 14135 14135 33-> 14135 14135 14135 14135 14135 14135 14135 14135 41-> 14135 14135 14135 14135 14135 14135 14135 14135 49-> 14135 14135 14135 14135 14135 14135 14135 14135 57-> 14135 14135 14135 14135 14135 14135 14135 14135 65-> 14135 14135 14135 14135 14135 14135 14135 14135 73-> 14135 14135 14135 14135 14135 14135 14135 14135 81-> 14135 14135 14135 14135 14135 14135 14135 14135 89-> 14135 14135 14135 14135 14135 14135 14135 14135 97-> 14135 14135 14135 14135 14135 14135 14135 14135 105-> 14135 14135 14135 14135 14135 14135 14135 14135 113-> 14135 14135 14135 14135 14135 14135 14135 14135 121-> 14135 14135 14135 14135 14135 14135 14135 14135 129-> 14135 14135 14135 14135 14135 14135 14135 14135 137-> 14135 14135 14135 14135 14135 14135 14135 14135 145-> 14135 14135 14135 14135 14135 14135 14135 14135 153-> 14135 14135 14135 14135 14135 14135 14135 14135 161-> 14135 14135 14135 14135 14135 14135 14135 14135 169-> 14135 14135 14135 14135 14135 14135 14135 14135 177-> 14135 14135 14135 14135 14135 14135 14135 14135 185-> 14135 14135 14135 14135 14135 14135 14135 14135 193-> 14135 14135 14135 14135 14135 14135 14135 14135 201-> 14135 14135 14135 14135 14135 14135 14135 14135 209-> 14135 14135 14135 14135 14135 14135 14135 14135 217-> 14135 14135 14135 14135 14135 14135 14135 14135 225-> 14135 14135 14135 14135 14135 14135 14135 14135 233-> 14135 14135 14135 14135 14135 14135 14135 14135 241-> 14135 14135 14135 14135 14135 14135 14135 14135 249-> 14135 14135 14135 14135 14135 14135 14135 14135 257-> 14135 14135 14135 14135 14135 14135 14135 14135 265-> 14135 14135 14135 14135 14135 14135 14135 14135 273-> 14135 14135 14135 14135 14135 14135 14135 14135 281-> 14135 14135 14135 14135 14135 14135 14135 14135 289-> 14135 14135 14135 14135 14135 14135 14135 14135 297-> 14135 14135 14135 14135 14135 14135 14135 14135 305-> 14135 14135 14135 14135 14135 14135 14135 14135 313-> 14135 14135 14135 14135 14135 14135 14135 14135 321-> 14135 14135 14135 14135 14135 14135 14135 14135 329-> 14135 14135 14135 14135 14135 14135 14135 14135 337-> 14135 14135 14135 14135 14135 14135 14135 14135 345-> 14135 14135 14135 14135 14135 14135 14135 14135 353-> 14135 14135 14135 14135 14135 14135 14135 14135 361-> 14135 14135 14135 14135 14135 14135 14135 14135 369-> 14135 14135 14135 14135 14135 14135 14135 14135 377-> 14135 14135 14135 14135 14135 14135 14135 14135 385-> 14135 14135 14135 14135 14135 14135 14135 14135 393-> 14135 14135 14135 14135 14135 14135 14135 14135 401-> 14135 14135 14135 14135 14135 14135 14135 14135 409-> 14135 14135 14135 14135 14135 14135 14135 14135 417-> 14135 14135 14135 14135 14135 14135 14135 14135 425-> 14135 14135 14135 14135 14135 14135 14135 14135 433-> 14135 14135 14135 14135 14135 14135 14135 14135 441-> 14135 14135 14135 14135 14135 14135 14135 14135 449-> 14135 14135 14135 14135 14135 14135 14135 14135 457-> 14135 14135 14135 14135 14135 14135 14135 14135 465-> 14135 14135 14135 14135 14135 14135 14135 14135 473-> 14135 14135 14135 14135 14135 14135 14135 14135 481-> 14135 14135 14135 14135 14135 14135 14135 14135 489-> 14135 14135 14135 14135 14135 14135 14135 14135 497-> 14135 14135 14135 14135 14135 14135 14135 14135 505-> 14135 14135 14135 14135 14135 14135 14135 14135 [root@dhcp-10-163-102-46 pcie_data_simulator]# It looks like it's just cycling between 0xFFFFFF00 and 0xFFFFFFFF which is expected (but not intended) behavior in this case.",
    "textLength": 9039
  },
  {
    "kind": "work-log",
    "title": "29_09_2024 - 04_10_2024.html",
    "fileName": "29_09_2024 - 04_10_2024.html",
    "url": "resources/work_logs/29_09_2024 - 04_10_2024.html",
    "createdDate": "2024-09-29",
    "text": "29/09/2024 - 04/10/2024 29/09/2024 - 04/10/2024 03/10/2024 03:15 I was able to read from both channels of the Xilinx DMA engine from the FPGA by running to midas frontends concurrently. You could also imagine reading within one frontend with a thread for each read. The result was nearly doubling the total read rate from ~600 MB/s to 1GB/s. frontend.cpp #include <stdio.h> #include <stdlib.h> #include <math.h> #include <string.h> #include <iostream> #include <fstream> #include <sstream> #include <vector> #include <chrono> #include <thread> #include <atomic> #include <mutex> #include \"midas.h\" #include \"odbxx.h\" #include \"mfe.h\" #include \"xdma_device_read.h\" #include \"xdma_device_write.h\" // Define your PCIe devices as pointers to allow dynamic initialization XDMADeviceRead* deviceRead = nullptr; XDMADeviceWrite* deviceWrite = nullptr; // Timing flag #define ENABLE_TIMING 1 // Globals const char *frontend_name = \"DataSimulator\"; const char *frontend_file_name = __FILE__; BOOL frontend_call_loop = FALSE; INT display_period = 0; INT max_event_size = 128 * 1024 * 1024; INT max_event_size_frag = 5 * max_event_size; INT event_buffer_size = 5 * max_event_size; INT frontend_index; // frontend index from command line argument -i char settings_path[100]; // Define a vector to store 16-bit words std::vector<int16_t> data; size_t write_size = 1; size_t read_size = 1; // Global variable to keep track of the last poll time std::chrono::steady_clock::time_point last_poll_time; std::chrono::microseconds polling_interval(1000 * 1000); std::chrono::microseconds write_sleep_interval(1000 * 1000); // Global atomic flags and mutex std::atomic<bool> write_thread_active(false); // Initialized to false std::atomic<bool> new_data_available(false); std::mutex settings_mutex; bool read_only = false; // Global variable for Read Only flag // Verbosity flag bool verbose = false; // Function to start timing, returns the start time std::chrono::steady_clock::time_point start_timing() { return std::chrono::steady_clock::now(); } // Function to end timing, accepts the start time and message void end_timing(const std::chrono::steady_clock::time_point& start_time, const std::string& msg) { if (verbose) { auto end_time = std::chrono::steady_clock::now(); long long duration = std::chrono::duration_cast<std::chrono::microseconds>(end_time - start_time).count(); std::cout << msg << \" took \" << duration << \" \u00b5s\" << std::endl; } } // Function to perform writing operations in a separate thread void write_thread_function() { int16_t write_value = 0; std::vector<int16_t> buffer(write_size); // Generate data once if the value doesn't change auto time_start1 = start_timing(); std::fill_n(buffer.data(), write_size, write_value); end_timing(time_start1, \"Generate Data Operation\"); while (write_thread_active) { auto time_start2 = start_timing(); deviceWrite->writeToDevice(0, buffer.data(), write_size * sizeof(int16_t)); end_timing(time_start2, \"PCIe Write Operation\"); if (verbose) { deviceWrite->printTransferSpeed(); } new_data_available = true; // Indicate that new data is available write_value += 1; std::this_thread::sleep_for(write_sleep_interval); } } // Function declarations INT frontend_init(void); INT frontend_exit(void); INT begin_of_run(INT run_number, char *error); INT end_of_run(INT run_number, char *error); INT pause_run(INT run_number, char *error); INT resume_run(INT run_number, char *error); INT frontend_loop(void); INT read_trigger_event(char *pevent, INT off); INT read_periodic_event(char *pevent, INT off); INT poll_event(INT source, INT count, BOOL test); INT interrupt_configure(INT cmd, INT source, POINTER_T adr); // Equipment list BOOL equipment_common_overwrite = TRUE; EQUIPMENT equipment[] = { {\"Data Simulator %02d\", {2, 0, \"BUF%02d\", EQ_POLLED, 0, \"MIDAS\", TRUE, RO_RUNNING, // Removed RO_ODB flag 1, // poll time in milliseconds 0, 0, TRUE, \"\", \"\", \"\",}, read_trigger_event }, {\"\"} }; // Trigger Update void trigger_update(INT hDB, INT hkey, void*) { } // Frontend Init int frontend_init() { //Get settings path for this frontend frontend_index = get_frontend_index(); const char* unformatted_settings_path = \"/Equipment/Data Simulator %02d/Settings\"; snprintf(settings_path, sizeof(settings_path), unformatted_settings_path, frontend_index); // Define ODB settings with default values midas::odb o = { {\"Polling Interval (us)\", 1000}, {\"Write Size\", 1024}, {\"Read Size\", 1024}, {\"Write Sleep Interval (us)\", 10}, {\"Read Only\", FALSE}, {\"Verbose\", FALSE}, {\"Device Read Path\", \"initial_value\"}, {\"Device Write Path\", \"initial_value\"} }; // Connect to the ODB path o.connect(settings_path); // Retrieve device paths from ODB settings std::string read_path = static_cast<std::string>(o[\"Device Read Path\"]); std::string write_path = static_cast<std::string>(o[\"Device Write Path\"]); // Check and update Device Read Path if it has the initial placeholder value if (read_path == \"initial_value\") { std::string new_read_path = \"/dev/xdma0_c2h_0\"; o[\"Device Read Path\"] = new_read_path; read_path = new_read_path; // Update local variable to reflect the new path } // Check and update Device Write Path if it has the initial placeholder value if (write_path == \"initial_value\") { std::string new_write_path = \"/dev/xdma0_h2c_0\"; o[\"Device Write Path\"] = new_write_path; write_path = new_write_path; // Update local variable to reflect the new path } // Initialize devices with paths from ODB deviceRead = new XDMADeviceRead(read_path.c_str()); deviceWrite = new XDMADeviceWrite(write_path.c_str()); // Initialize the devices deviceRead->initialize(); deviceWrite->initialize(); return SUCCESS; } // Frontend Exit INT frontend_exit() { if (write_thread_active) { write_thread_active = false; std::this_thread::sleep_for(std::chrono::milliseconds(100)); } // Clean up dynamically allocated devices if (deviceRead) { delete deviceRead; deviceRead = nullptr; } if (deviceWrite) { delete deviceWrite; deviceWrite = nullptr; } return SUCCESS; } // Begin of Run INT begin_of_run(INT run_number, char *error) { { std::lock_guard<std::mutex> lock(settings_mutex); //Supposedly you can use `midas::odb settings(settings_path);` but that segfaults for some reason. midas::odb settings = { }; settings.connect(settings_path); polling_interval = std::chrono::microseconds(static_cast<int>(settings[\"Polling Interval (us)\"])); write_size = static_cast<size_t>(static_cast<int>(settings[\"Write Size\"])); read_size = static_cast<size_t>(static_cast<int>(settings[\"Read Size\"])); write_sleep_interval = std::chrono::microseconds(static_cast<int>(settings[\"Write Sleep Interval (us)\"])); read_only = static_cast<bool>(settings[\"Read Only\"]); verbose = static_cast<bool>(settings[\"Verbose\"]); } if (!read_only) { write_thread_active = true; std::thread write_thread(write_thread_function); write_thread.detach(); } else { write_thread_active = false; } return SUCCESS; } // End of Run INT end_of_run(INT run_number, char *error) { if (write_thread_active) { write_thread_active = false; std::this_thread::sleep_for(std::chrono::milliseconds(100)); } return SUCCESS; } // Pause Run INT pause_run(INT run_number, char *error) { return SUCCESS; } // Resume Run INT resume_run(INT run_number, char *error) { return SUCCESS; } // Frontend Loop INT frontend_loop() { return SUCCESS; } // Poll Event INT poll_event(INT source, INT count, BOOL test) { auto now = std::chrono::steady_clock::now(); if (now - last_poll_time >= polling_interval) { last_poll_time = now; if (read_only) { // In read-only mode, assume data is always available if (test) { return TRUE; } return TRUE; } else { // In write mode, check if new data is available if (new_data_available) { if (test) { return TRUE; } new_data_available = false; // Reset the flag after acknowledging return TRUE; } } } if (test) { return FALSE; } return FALSE; } // Interrupt Configuration INT interrupt_configure(INT cmd, INT source, POINTER_T adr) { switch (cmd) { case CMD_INTERRUPT_ENABLE: break; case CMD_INTERRUPT_DISABLE: break; case CMD_INTERRUPT_ATTACH: break; case CMD_INTERRUPT_DETACH: break; } return SUCCESS; } // Event Readout INT read_trigger_event(char *pevent, INT off) { bk_init32(pevent); short *pdata; bk_create(pevent, \"CR%02d\", TID_SHORT, (void **)&pdata); auto time_start1 = start_timing(); std::vector<std::byte> read_buffer = deviceRead->readFromDevice(0, read_size); end_timing(time_start1, \"PCIe Read Operation\"); if (verbose) { deviceRead->printTransferSpeed(); } auto time_start2 = start_timing(); // Ensure that the size of pdata is sufficient size_t num_bytes = read_buffer.size(); size_t num_shorts = num_bytes / sizeof(short); // Perform a bulk copy memcpy(pdata, read_buffer.data(), num_bytes); // Advance pdata pointer pdata += num_shorts; end_timing(time_start2, \"Memory Copy Operation\"); bk_close(pevent, pdata); return bk_size(pevent); } // Periodic Event INT read_periodic_event(char *pevent, INT off) { bk_init32(pevent); short *pdata; bk_create(pevent, \"CR%02d\", TID_SHORT, (void **)&pdata); size_t size = 1024; std::vector<std::byte> buffer = deviceRead->readFromDevice(0, size); size_t num_bytes = buffer.size(); size_t num_shorts = num_bytes / sizeof(short); memcpy(pdata, buffer.data(), num_bytes); pdata += num_shorts; bk_close(pevent, pdata); return bk_size(pevent); } #include <stdio.h> #include <stdlib.h> #include <math.h> #include <string.h> #include <iostream> #include <fstream> #include <sstream> #include <vector> #include <chrono> #include <thread> #include <atomic> #include <mutex> #include \"midas.h\" #include \"odbxx.h\" #include \"mfe.h\" #include \"xdma_device_read.h\" #include \"xdma_device_write.h\" // Define your PCIe devices as pointers to allow dynamic initialization XDMADeviceRead* deviceRead = nullptr; XDMADeviceWrite* deviceWrite = nullptr; // Timing flag #define ENABLE_TIMING 1 // Globals const char *frontend_name = \"DataSimulator\"; const char *frontend_file_name = __FILE__; BOOL frontend_call_loop = FALSE; INT display_period = 0; INT max_event_size = 128 * 1024 * 1024; INT max_event_size_frag = 5 * max_event_size; INT event_buffer_size = 5 * max_event_size; INT frontend_index; // frontend index from command line argument -i char settings_path[100]; // Define a vector to store 16-bit words std::vector<int16_t> data; size_t write_size = 1; size_t read_size = 1; // Global variable to keep track of the last poll time std::chrono::steady_clock::time_point last_poll_time; std::chrono::microseconds polling_interval(1000 * 1000); std::chrono::microseconds write_sleep_interval(1000 * 1000); // Global atomic flags and mutex std::atomic<bool> write_thread_active(false); // Initialized to false std::atomic<bool> new_data_available(false); std::mutex settings_mutex; bool read_only = false; // Global variable for Read Only flag // Verbosity flag bool verbose = false; // Function to start timing, returns the start time std::chrono::steady_clock::time_point start_timing() { return std::chrono::steady_clock::now(); } // Function to end timing, accepts the start time and message void end_timing(const std::chrono::steady_clock::time_point& start_time, const std::string& msg) { if (verbose) { auto end_time = std::chrono::steady_clock::now(); long long duration = std::chrono::duration_cast<std::chrono::microseconds>(end_time - start_time).count(); std::cout << msg << \" took \" << duration << \" \u00b5s\" << std::endl; } } // Function to perform writing operations in a separate thread void write_thread_function() { int16_t write_value = 0; std::vector<int16_t> buffer(write_size); // Generate data once if the value doesn't change auto time_start1 = start_timing(); std::fill_n(buffer.data(), write_size, write_value); end_timing(time_start1, \"Generate Data Operation\"); while (write_thread_active) { auto time_start2 = start_timing(); deviceWrite->writeToDevice(0, buffer.data(), write_size * sizeof(int16_t)); end_timing(time_start2, \"PCIe Write Operation\"); if (verbose) { deviceWrite->printTransferSpeed(); } new_data_available = true; // Indicate that new data is available write_value += 1; std::this_thread::sleep_for(write_sleep_interval); } } // Function declarations INT frontend_init(void); INT frontend_exit(void); INT begin_of_run(INT run_number, char *error); INT end_of_run(INT run_number, char *error); INT pause_run(INT run_number, char *error); INT resume_run(INT run_number, char *error); INT frontend_loop(void); INT read_trigger_event(char *pevent, INT off); INT read_periodic_event(char *pevent, INT off); INT poll_event(INT source, INT count, BOOL test); INT interrupt_configure(INT cmd, INT source, POINTER_T adr); // Equipment list BOOL equipment_common_overwrite = TRUE; EQUIPMENT equipment[] = { {\"Data Simulator %02d\", {2, 0, \"BUF%02d\", EQ_POLLED, 0, \"MIDAS\", TRUE, RO_RUNNING, // Removed RO_ODB flag 1, // poll time in milliseconds 0, 0, TRUE, \"\", \"\", \"\",}, read_trigger_event }, {\"\"} }; // Trigger Update void trigger_update(INT hDB, INT hkey, void*) { } // Frontend Init int frontend_init() { //Get settings path for this frontend frontend_index = get_frontend_index(); const char* unformatted_settings_path = \"/Equipment/Data Simulator %02d/Settings\"; snprintf(settings_path, sizeof(settings_path), unformatted_settings_path, frontend_index); // Define ODB settings with default values midas::odb o = { {\"Polling Interval (us)\", 1000}, {\"Write Size\", 1024}, {\"Read Size\", 1024}, {\"Write Sleep Interval (us)\", 10}, {\"Read Only\", FALSE}, {\"Verbose\", FALSE}, {\"Device Read Path\", \"initial_value\"}, {\"Device Write Path\", \"initial_value\"} }; // Connect to the ODB path o.connect(settings_path); // Retrieve device paths from ODB settings std::string read_path = static_cast<std::string>(o[\"Device Read Path\"]); std::string write_path = static_cast<std::string>(o[\"Device Write Path\"]); // Check and update Device Read Path if it has the initial placeholder value if (read_path == \"initial_value\") { std::string new_read_path = \"/dev/xdma0_c2h_0\"; o[\"Device Read Path\"] = new_read_path; read_path = new_read_path; // Update local variable to reflect the new path } // Check and update Device Write Path if it has the initial placeholder value if (write_path == \"initial_value\") { std::string new_write_path = \"/dev/xdma0_h2c_0\"; o[\"Device Write Path\"] = new_write_path; write_path = new_write_path; // Update local variable to reflect the new path } // Initialize devices with paths from ODB deviceRead = new XDMADeviceRead(read_path.c_str()); deviceWrite = new XDMADeviceWrite(write_path.c_str()); // Initialize the devices deviceRead->initialize(); deviceWrite->initialize(); return SUCCESS; } // Frontend Exit INT frontend_exit() { if (write_thread_active) { write_thread_active = false; std::this_thread::sleep_for(std::chrono::milliseconds(100)); } // Clean up dynamically allocated devices if (deviceRead) { delete deviceRead; deviceRead = nullptr; } if (deviceWrite) { delete deviceWrite; deviceWrite = nullptr; } return SUCCESS; } // Begin of Run INT begin_of_run(INT run_number, char *error) { { std::lock_guard<std::mutex> lock(settings_mutex); //Supposedly you can use `midas::odb settings(settings_path);` but that segfaults for some reason. midas::odb settings = { }; settings.connect(settings_path); polling_interval = std::chrono::microseconds(static_cast<int>(settings[\"Polling Interval (us)\"])); write_size = static_cast<size_t>(static_cast<int>(settings[\"Write Size\"])); read_size = static_cast<size_t>(static_cast<int>(settings[\"Read Size\"])); write_sleep_interval = std::chrono::microseconds(static_cast<int>(settings[\"Write Sleep Interval (us)\"])); read_only = static_cast<bool>(settings[\"Read Only\"]); verbose = static_cast<bool>(settings[\"Verbose\"]); } if (!read_only) { write_thread_active = true; std::thread write_thread(write_thread_function); write_thread.detach(); } else { write_thread_active = false; } return SUCCESS; } // End of Run INT end_of_run(INT run_number, char *error) { if (write_thread_active) { write_thread_active = false; std::this_thread::sleep_for(std::chrono::milliseconds(100)); } return SUCCESS; } // Pause Run INT pause_run(INT run_number, char *error) { return SUCCESS; } // Resume Run INT resume_run(INT run_number, char *error) { return SUCCESS; } // Frontend Loop INT frontend_loop() { return SUCCESS; } // Poll Event INT poll_event(INT source, INT count, BOOL test) { auto now = std::chrono::steady_clock::now(); if (now - last_poll_time >= polling_interval) { last_poll_time = now; if (read_only) { // In read-only mode, assume data is always available if (test) { return TRUE; } return TRUE; } else { // In write mode, check if new data is available if (new_data_available) { if (test) { return TRUE; } new_data_available = false; // Reset the flag after acknowledging return TRUE; } } } if (test) { return FALSE; } return FALSE; } // Interrupt Configuration INT interrupt_configure(INT cmd, INT source, POINTER_T adr) { switch (cmd) { case CMD_INTERRUPT_ENABLE: break; case CMD_INTERRUPT_DISABLE: break; case CMD_INTERRUPT_ATTACH: break; case CMD_INTERRUPT_DETACH: break; } return SUCCESS; } // Event Readout INT read_trigger_event(char *pevent, INT off) { bk_init32(pevent); short *pdata; bk_create(pevent, \"CR%02d\", TID_SHORT, (void **)&pdata); auto time_start1 = start_timing(); std::vector<std::byte> read_buffer = deviceRead->readFromDevice(0, read_size); end_timing(time_start1, \"PCIe Read Operation\"); if (verbose) { deviceRead->printTransferSpeed(); } auto time_start2 = start_timing(); // Ensure that the size of pdata is sufficient size_t num_bytes = read_buffer.size(); size_t num_shorts = num_bytes / sizeof(short); // Perform a bulk copy memcpy(pdata, read_buffer.data(), num_bytes); // Advance pdata pointer pdata += num_shorts; end_timing(time_start2, \"Memory Copy Operation\"); bk_close(pevent, pdata); return bk_size(pevent); } // Periodic Event INT read_periodic_event(char *pevent, INT off) { bk_init32(pevent); short *pdata; bk_create(pevent, \"CR%02d\", TID_SHORT, (void **)&pdata); size_t size = 1024; std::vector<std::byte> buffer = deviceRead->readFromDevice(0, size); size_t num_bytes = buffer.size(); size_t num_shorts = num_bytes / sizeof(short); memcpy(pdata, buffer.data(), num_bytes); pdata += num_shorts; bk_close(pevent, pdata); return bk_size(pevent); }",
    "textLength": 2153
  },
  {
    "kind": "work-log",
    "title": "13_04_2025 - 19_04_2025.html",
    "fileName": "13_04_2025 - 19_04_2025.html",
    "url": "resources/work_logs/13_04_2025 - 19_04_2025.html",
    "createdDate": "2025-04-13",
    "text": "13/04/2025 - 19/04/2025 13/04/2025 - 19/04/2025 16/04/2025 19:01 Using this pattern finding playground I wrote in python, we can test different reco algorithms. Here we're testing Sean's kmeans clustering vertex finding algorithm \\boldsymbol{\\pi^+ \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 e + + \u03bd e \\boldsymbol{\\pi^+ \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 e + + \u03bd e \u200b : \\boldsymbol{\\pi^+ \\rightarrow \\mu^+ + \\nu_\\mu \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 \u03bc + + \u03bd \u03bc \u2192 e + + \u03bd e \\boldsymbol{\\pi^+ \\rightarrow \\mu^+ + \\nu_\\mu \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 \u03bc + + \u03bd \u03bc \u200b \u2192 e + + \u03bd e \u200b 16/04/2025 19:05 Here's some performance metric information for the \\boldsymbol{\\pi^+ \\rightarrow \\mu^+ + \\nu_\\mu \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 \u03bc + + \u03bd \u03bc \u2192 e + + \u03bd e \\boldsymbol{\\pi^+ \\rightarrow \\mu^+ + \\nu_\\mu \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 \u03bc + + \u03bd \u03bc \u200b \u2192 e + + \u03bd e \u200b data set pattern finding: Above conveys that sometimes the pattern count is correct (in this case it should always be 1 pattern), but we fail validation (validation here is just checking that every reconstructed pattern contains the same tracklets as the true patterns). This (in combination with the pattern reconsturction by particle composition plots above) shows evidence that sometimes we are missing tracklets from our patterns. My guess is somehow there are tracklets in the truth pattern that do not make hits in the ATAR, so they are not added to the reco pattern. The above conveys that when we have \"complete\" information in both the \"front\"/(x,z) ATAR planes and the \"back\"/(y,z) ATAR planes, then we rarely misconstruct the event. It's only when we have incomplete information in one of the planes that a problem happens. I should note here, that only the (x,z) ATAR planes are used to determine the reconstruction here; in other words, validation is only based on the (x,z) ATAR planes. This above plot was generated by constructing vertices from either just the (y,z) ATAR plane information or just the (x,z) ATAR plane information, and comparing how successfuly each of those approaches were. The above conveys that ~99% of the time, either the (x,z) or (y,z) planes contain enough information to correctly reconstruct that patterns. However, ~15% of the time one of the planes does not have enough information. In our \"final\" algorithm, we should definetly use the information from both planes in conjunction (this can be a little tricky). The above shows a small parameter scan using the parameters \"sigma\" and \"n_iters\" of Sean's vertex finding clustering algorithm. Sigma controls the \"penalty\" for points being distant from a centroid while n_iters is how many iterations of moving the centroids the algorithm goes through. We'd expect performance (average validation == percent of events that were valid) to increase with n_iters, but we don't see that. Also, we expect a \"sigma sweet spot\" smaller than 10 but we don't see that. I don't fully trust this plot was generated correctly; i.e. there may be some bug creating false information or otherwise. 16/04/2025 19:22 Sean did a bug fix where he prevented that clustering algorithm from adding vertices which no points are attached to. It didn't seem to change results: 16/04/2025 19:24 Here's what I was talking about when I said it's tricky to use both the (x,z) and (y,z) ATAR plane information, by simply throwing in (x,y,z) endpoints created from fitting both the (x,z) and (y,z) ATAR planes into the clustering algorithm, we get worse performance. My guess is we get the \"worst of both worlds\"; i.e. when either endpoint finding algorithm fails, the pattern reconstruction seems to fail. But the last plot seems to not support that hypothesis 16/04/2025 20:39 Here are some more \\boldsymbol{\\pi^+ \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 e + + \u03bd e \\boldsymbol{\\pi^+ \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 e + + \u03bd e \u200b : plots: Reconstruction using 3D information (both planes) instead of either (x,z) or (y,z): 16/04/2025 20:48 I find a few things interesting: The \\boldsymbol{\\pi^+ \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 e + + \u03bd e \\boldsymbol{\\pi^+ \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 e + + \u03bd e \u200b events don't seem to suffer as much perfromance drop from using 3D data as the \\boldsymbol{\\pi^+ \\rightarrow \\mu^+ + \\nu_\\mu \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 \u03bc + + \u03bd \u03bc \u2192 e + + \u03bd e \\boldsymbol{\\pi^+ \\rightarrow \\mu^+ + \\nu_\\mu \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 \u03bc + + \u03bd \u03bc \u200b \u2192 e + + \u03bd e \u200b events do. There is a much larger portion of \\boldsymbol{\\pi^+ \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 e + + \u03bd e \\boldsymbol{\\pi^+ \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 e + + \u03bd e \u200b events where the (x,z) planes and (y,z) planes both fail to pass validation as compared to the \\boldsymbol{\\pi^+ \\rightarrow \\mu^+ + \\nu_\\mu \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 \u03bc + + \u03bd \u03bc \u2192 e + + \u03bd e \\boldsymbol{\\pi^+ \\rightarrow \\mu^+ + \\nu_\\mu \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 \u03bc + + \u03bd \u03bc \u200b \u2192 e + + \u03bd e \u200b events. There are much more \\boldsymbol{\\pi^+ \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 e + + \u03bd e \\boldsymbol{\\pi^+ \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 e + + \u03bd e \u200b events that fail validation even when the (x,z) and (y,z) \"match\" (i.e. form the same vertices) as compared to the \\boldsymbol{\\pi^+ \\rightarrow \\mu^+ + \\nu_\\mu \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 \u03bc + + \u03bd \u03bc \u2192 e + + \u03bd e \\boldsymbol{\\pi^+ \\rightarrow \\mu^+ + \\nu_\\mu \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 \u03bc + + \u03bd \u03bc \u200b \u2192 e + + \u03bd e \u200b events. The (sigma,n_iters) parameter space seems to have the same trend for both the \\boldsymbol{\\pi^+ \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 e + + \u03bd e \\boldsymbol{\\pi^+ \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 e + + \u03bd e \u200b and \\boldsymbol{\\pi^+ \\rightarrow \\mu^+ + \\nu_\\mu \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 \u03bc + + \u03bd \u03bc \u2192 e + + \u03bd e \\boldsymbol{\\pi^+ \\rightarrow \\mu^+ + \\nu_\\mu \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 \u03bc + + \u03bd \u03bc \u200b \u2192 e + + \u03bd e \u200b events",
    "textLength": 975
  },
  {
    "kind": "work-log",
    "title": "29_12_2024 - 04_01_2025.html",
    "fileName": "29_12_2024 - 04_01_2025.html",
    "url": "resources/work_logs/29_12_2024 - 04_01_2025.html",
    "createdDate": "2024-12-29",
    "text": "29/12/2024 - 04/01/2025 29/12/2024 - 04/01/2025 02/01/2025 04:52 I was playing around with making MIDAS clients. I found out you can't create multiple clients in on C++ program. It leads to race conditions within MIDAS. I wish I knew that before spending 4 hours creating a library to launch mutliple clients. receiver_lib_test: /home/pioneer/packages/midas/src/system.cxx:2976: INT ss_mutex_create(MUTEX_T**, BOOL): Assertion `status == 0' failed. receiver_lib_test: /home/ pioneer /packages/mi das /src/ system.cxx: 2976 : INT ss_mutex_create(MUTEX_T**, BOOL): Assertion `status == 0 ' failed. Here is the github of the branch of my \"midas_receiver\" that fails: On the bright side, I still have my working branch that just launches one client. That branch is available here 29/12/2024 20:06 Just a note that at low rates, I was able to run the g-2 modified DAQ for 20 hours without erroring out. Providing evidence that CCC: Run abort s are indeed caused by higher rate applications somehow. by 29/12/2024 20:45 This is in $MIDASSYS/midasio/midasio.h for reference: class TMEvent { public: // event data bool error; ///< event has an error - incomplete, truncated, inconsistent or corrupted uint16_t event_id; ///< MIDAS event ID uint16_t trigger_mask; ///< MIDAS trigger mask uint32_t serial_number; ///< MIDAS event serial number uint32_t time_stamp; ///< MIDAS event time stamp (unix time in sec) uint32_t data_size; ///< MIDAS event data size size_t event_header_size; ///< size of MIDAS event header uint32_t bank_header_flags; ///< flags from the MIDAS event bank header std::vector<TMBank> banks; ///< list of MIDAS banks, fill using FindAllBanks() std::vector<char> data; ///< MIDAS event bytes public: // internal data bool found_all_banks; ///< all the banks in the event data have been discovered size_t bank_scan_position; ///< location where scan for MIDAS banks was last stopped public: // constructors TMEvent(); // ctor TMEvent(const void* buf, size_t buf_size); // ctor void Reset(); ///< reset everything void ParseEvent(); ///< parse event data void ParseHeader(const void* buf, size_t buf_size); ///< parse event header void Init(uint16_t event_id, uint16_t trigger_mask = 0, uint32_t serial_number = 0, uint32_t time_stamp = 0, size_t capacity = 0); public: // read data void FindAllBanks(); ///< scan the MIDAS event, find all data banks TMBank* FindBank(const char* bank_name); ///< scan the MIDAS event char* GetEventData(); ///< get pointer to MIDAS event data const char* GetEventData() const; ///< get pointer to MIDAS event data char* GetBankData(const TMBank*); ///< get pointer to MIDAS data bank const char* GetBankData(const TMBank*) const; ///< get pointer to MIDAS data bank public: // add data void AddBank(const char* bank_name, int tid, const char* buf, size_t size); ///< add new MIDAS bank public: // bank manipulation //void DeleteBank(const TMBank*); ///< delete MIDAS bank public: // information methods std::string HeaderToString() const; ///< print the MIDAS event header std::string BankListToString() const; ///< print the list of MIDAS banks std::string BankToString(const TMBank*) const; ///< print definition of one MIDAS bank void PrintHeader() const; void PrintBanks(int level = 0); void DumpHeader() const; }; class TMEvent { public: // event data bool error; ///< event has an error - incomplete, truncated, inconsistent or corrupted uint16_t event_id; ///< MIDAS event ID uint16_t trigger_mask; ///< MIDAS trigger mask uint32_t serial_number; ///< MIDAS event serial number uint32_t time_stamp; ///< MIDAS event time stamp (unix time in sec) uint32_t data_size; ///< MIDAS event data size size_t event_header_size; ///< size of MIDAS event header uint32_t bank_header_flags; ///< flags from the MIDAS event bank header std::vector<TMBank> banks; ///< list of MIDAS banks, fill using FindAllBanks() std::vector<char> data; ///< MIDAS event bytes public: // internal data bool found_all_banks; ///< all the banks in the event data have been discovered size_t bank_scan_position; ///< location where scan for MIDAS banks was last stopped public: // constructors TMEvent(); // ctor TMEvent(const void* buf, size_t buf_size); // ctor void Reset(); ///< reset everything void ParseEvent(); ///< parse event data void ParseHeader(const void* buf, size_t buf_size); ///< parse event header void Init(uint16_t event_id, uint16_t trigger_mask = 0, uint32_t serial_number = 0, uint32_t time_stamp = 0, size_t capacity = 0); public: // read data void FindAllBanks(); ///< scan the MIDAS event, find all data banks TMBank* FindBank(const char* bank_name); ///< scan the MIDAS event char* GetEventData(); ///< get pointer to MIDAS event data const char* GetEventData() const; ///< get pointer to MIDAS event data char* GetBankData(const TMBank*); ///< get pointer to MIDAS data bank const char* GetBankData(const TMBank*) const; ///< get pointer to MIDAS data bank public: // add data void AddBank(const char* bank_name, int tid, const char* buf, size_t size); ///< add new MIDAS bank public: // bank manipulation //void DeleteBank(const TMBank*); ///< delete MIDAS bank public: // information methods std::string HeaderToString() const; ///< print the MIDAS event header std::string BankListToString() const; ///< print the list of MIDAS banks std::string BankToString(const TMBank*) const; ///< print definition of one MIDAS bank void PrintHeader() const; void PrintBanks(int level = 0); void DumpHeader() const; }; This is just a class for handling event data, useful reference.",
    "textLength": 777
  },
  {
    "kind": "work-log",
    "title": "04_02_2024 - 10_02_2024.html",
    "fileName": "04_02_2024 - 10_02_2024.html",
    "url": "resources/work_logs/04_02_2024 - 10_02_2024.html",
    "createdDate": "2024-02-04",
    "text": "04/02/2024 - 10/02/2024 04/02/2024 - 10/02/2024 06/02/2024 01:55 The full crate setup: The best picture I have that includes the network box Firstly, the MCH we have look a lot different than the MCH in the picture. There is also a black wire connected to the MCH that I do not know where it is going. The SFP+ connector needed for AMC Module Things we're missing: SFP+ Connector as pictured above An ethernet network splitter (though, I don't understand the point of this one) The blue ribbon connectors for the trigger boxes to FC7 trigger part of that card 06/02/2024 02:24 I'm lacking a vocabulary to describe this issues. But the piece that connects to the FC7 so that triggers can be read in is in two pieces. It's pretty obvious how to fit those two pieces together. But I cannot see for the life of me how they connect to the FC7. 07/02/2024 22:32 Tried installing XDMA driver ( https://github.com/Xilinx/dma_ip_drivers/ ) on the newest machine running Linux Mint. This OS is not officially supported (as mentioned in the readme here: https://github.com/Xilinx/dma_ip_drivers/blob/master/XDMA/linux-kernel/readme.txt ) and consequently(?) it fails to make. 07/02/2024 22:35 -- From https://www.xilinx.com/video/technology/dma-for-pci-express.html It seems to imply that our board (kintex-7) isn't supported by DMA for PCIe. The Kintex-7 is also not explicitly listed in supported FPGAs for the XDMA driver: The PCIe DMA supports UltraScale+, UltraScale, Virtex-7 XT and 7 Series Gen2 devices. Please refer to the Xilinx documentation \"PG195 DMA/Bridge Subsystem for PCI Express\" for details of the IP. -- From https://github.com/Xilinx/dma_ip_drivers/blob/master/XDMA/linux-kernel/readme.txt It is unclear whether Kintex-7 falls under \"7-series\" or not. In the PG195 product guide for the IP block, it is equally ambigious Supports AMD UltraScale+\u2122 , AMD UltraScale\u2122 , AMD Virtex\u2122 7 XT Gen3 (Endpoint), and 7 series 2.1 (Endpoint) Integrated Blocks for PCIe. 7A15T and 7A25T are not supported -- From https://docs.xilinx.com/r/en-US/pg195-pcie-dma/Introduction However, it is clear that people (at numato and otherwise) have gotten DMA transfers to work using this IP block. 07/02/2024 22:49 Following the steps here: https://github.com/Xilinx/dma_ip_drivers/blob/master/XDMA/linux-kernel/readme.txt I was able to install the driver on the 'be' machine. I realized the last output message of a successful make install on 'be' was \u2018xdma.ko\u2019 -> \u2018/lib/modules/3.10.0-1160.76.1.el7.x86_64/xdma/xdma.ko\u2019 \u2018xdma.ko\u2019 -> \u2018 /lib/m odules /3.10.0-1160.76.1.el7.x86_64/ xdma/xdma.ko\u2019 But the last two output messages of make install on 'fe01' were \u2018xdma.ko\u2019 -> \u2018/lib/modules/3.10.0-1160.76.1.el7.x86_64/xdma/xdma.ko\u2019 depmod: ERROR: fstat(4, nvidia-peermem.ko.xz): No such file or directory \u2018xdma.ko\u2019 -> \u2018 /lib/ modules/ 3.10 .0 -1160.76 .1 .el7.x86_64 /xdma/ xdma.ko\u2019 depmod: ERROR: fstat( 4 , nvidia-peermem.ko.xz): No such file or directory This made me think this error message on 'fe01' has nothing to do with the actual xilinx driver installation. So I continued through the instructions of the readme and was able to ./load_driver.sh on both the 'fe01' and 'be' machines. 07/02/2024 23:37 In order to follow the Xilinx XDMA guide ( https://www.xilinx.com/video/technology/dma-for-pci-express.html ), I realized they do not load from flash memory, but rather directly upload a bitstream. So my plan is to program from my laptop while the device is in 'fe01' while 'fe01' is on. To do this, I need to see if echo 1 > /sys/bus/pci/rescan echo 1 > /sys/ bus /pci/ rescan truly works as a \"reset\" for the pcie bus to load a new FPGA bitstream (in this case from flash memory). Following these steps I was able to reproduce the ability to communicate with the card over PCIe. Plug in the pcie card into 'fe01', turn it on. I don't see the card under lspci Load the bitstream into flash memory following the getting started nereid guide ( https://numato.com/kb/getting-started-with-pci-express-on-nereid/ ) Following the suggestion of this comment on reddit ( https://www.reddit.com/r/FPGA/comments/1993seu/comment/kicczq1/?utm_source=share&utm_medium=web2x&context=3 ) we boot the FPGA from configuration memory echo 1 > /sys/bus/pci/rescan Using the steps below, check ability to reproduce talking with card over pcie 18/01/2024 05:51 I realized I never looked to carefully at the board on fe01 when I used lspci -vv after programming. So I programmed the board using the .bin file generated on Vivado 2023.2 on the newest dektop, powered the desktop down, and swapped the card into fe01. Then, I looked again at lspci -vv and noticed: [root@fe01 pcimem]# lspci -vv | grep -A 34 \"04:00.0\" 04:00.0 Memory controller: Xilinx Corporation Device 7024 Subsystem: Xilinx Corporation Device 0007 Control: I/O+ Mem+ BusMaster+ SpecCycle- MemWINV- VGASnoop- ParErr- Stepping- SERR- FastB2B- DisINTx- Status: Cap+ 66MHz- UDF- FastB2B- ParErr- DEVSEL=fast >TAbort- <TAbort- SERR- <PERR- INTx- Latency: 0, Cache Line Size: 64 bytes Interrupt: pin A routed to IRQ 11 Region 0: Memory at f5f80000 (32-bit, non-prefetchable) [size=512K] Capabilities: [40] Power Management version 3 Flags: PMEClk- DSI- D1- D2- AuxCurrent=0mA PME(D0+,D1+,D2+,D3hot+,D3cold-) Status: D0 NoSoftRst+ PME-Enable- DSel=0 DScale=0 PME- Capabilities: [48] MSI: Enable- Count=1/1 Maskable- 64bit+ Address: 0000000000000000 Data: 0000 Capabilities: [60] Express (v2) Endpoint, MSI 00 DevCap: MaxPayload 512 bytes, PhantFunc 0, Latency L0s <64ns, L1 unlimited ExtTag- AttnBtn- AttnInd- PwrInd- RBE+ FLReset- SlotPowerLimit 225.000W DevCtl: Report errors: Correctable- Non-Fatal+ Fatal+ Unsupported- RlxdOrd+ ExtTag- PhantFunc- AuxPwr- NoSnoop+ MaxPayload 256 bytes, MaxReadReq 512 bytes DevSta: CorrErr- UncorrErr- FatalErr- UnsuppReq- AuxPwr- TransPend- LnkCap: Port #0, Speed 5GT/s, Width x4, ASPM L0s, Exit Latency L0s unlimited, L1 unlimited ClockPM- Surprise- LLActRep- BwNot- ASPMOptComp- LnkCtl: ASPM Disabled; RCB 64 bytes Disabled- CommClk+ ExtSynch- ClockPM- AutWidDis- BWInt- AutBWInt- LnkSta: Speed 5GT/s, Width x4, TrErr- Train- SlotClk+ DLActive- BWMgmt- ABWMgmt- DevCap2: Completion Timeout: Range B, TimeoutDis-, LTR-, OBFF Not Supported DevCtl2: Completion Timeout: 50us to 50ms, TimeoutDis-, LTR-, OBFF Disabled LnkCtl2: Target Link Speed: 5GT/s, EnterCompliance- SpeedDis- Transmit Margin: Normal Operating Range, EnterModifiedCompliance- ComplianceSOS- Compliance De-emphasis: -6dB LnkSta2: Current De-emphasis Level: -6dB, EqualizationComplete-, EqualizationPhase1- EqualizationPhase2-, EqualizationPhase3-, LinkEqualizationRequest- Capabilities: [100 v1] Device Serial Number 00-00-00-01-01-00-0a-35 06:00.0 Ethernet controller: Broadcom Inc. and subsidiaries NetXtreme BCM5761 Gigabit Ethernet PCIe (rev 10) Subsystem: Dell Device 026d In particular, Region 0: Memory at f5f80000 (32-bit, non-prefetchable) [size=512K] no longer looks like: Region 0: Memory at 51100000 (32-bit, non-prefetchable) [disabled] [size=512K] I.e. it's not disabled. That means I should be able to communicate with it. So I used vivado's software to communicate ( https://github.com/numato-viya/pcimem ) And entered the command: sudo ./pcimem /dev/mem 4126670848 w 0xffffff12 where 4126670848 is the decimal value of the hex code f5f80000. And we see we are sucessfully able to write and readback! [root@fe01 pcimem]# sudo ./pcimem /dev/mem 4126670848 w 0xffffff12 /dev/mem opened. Target offset is 0xf5f80000, page size is 4096 mmap(0, 4096, 0x3, 0x1, 3, 0xf5f80000) PCI Memory mapped to address 0x7f1bd8988000. Value at offset 0xF5F80000 (0x7f1bd8988000): 0x0 Written 0xFFFFFF12; readback 0xFFFFFF12 08/02/2024 00:12 An attempt at communicating with board's DDR3 memory following this guide: https://www.xilinx.com/video/technology/dma-for-pci-express.html I had make some edits, for one he's using a different board so I substitute my board in. Create a new block design Go to the board tab Drag PCI Express from the list of IPs, click 4x lanes Drag the DDR3 SRAM from the list of IPs Run Block Automation. Change the h2c and c2h channels to 1 each. Run Connection Automation for everything by hitting the top checkbox on the left Click the \"optomize routing\" button just to clena up the display. My display looks like this when all this is done: Now go to File->Save Block Design Under the sources tab, right click the design and create and HDL Wrapper. Keep the bubble that lets vivado automatically handle it checked. Then click generate bitstream. Allow it to run syntehsis and implementation first. This fails to generate bitstream with this error: [DRC NSTD-1] Unspecified I/O Standard: 1 out of 137 logical ports use I/O standard (IOSTANDARD) value 'DEFAULT', instead of a user assigned specific value. This may cause I/O contention or incompatibility with the board power or connectivity affecting performance, signal integrity or in extreme cases cause damage to the device or the components to which it is connected. To correct this violation, specify all I/O standards. This design will fail to generate a bitstream unless all logical ports have a user specified I/O standard value defined. To allow bitstream creation with unspecified I/O standard values (not recommended), use this command: set_property SEVERITY {Warning} [get_drc_checks NSTD-1]. NOTE: When using the Vivado Runs infrastructure (e.g. launch_runs Tcl command), add this command to a .tcl file and add that file as a pre-hook for write_bitstream step for the implementation run. Problem ports: sys_clk_i. I wlll try to see if I can resolve this by playing with the clock input 08/02/2024 01:15 Replaced the clock with the clcoking wizard instead (similar to how they do it in this guide https://numato.com/kb/vivado-design-suite-create-microblaze-based-design-using-ip-integrator-with-nereid-kintex-7-pci-express-development-board/ ). This allowed the bitstream to compile, but I was not able to get lspci to recognize the programmred board. Furthermore, ./load_driver.sh still complained it could not find the board.",
    "textLength": 1701
  },
  {
    "kind": "work-log",
    "title": "14_04_2024 - 20_04_2024.html",
    "fileName": "14_04_2024 - 20_04_2024.html",
    "url": "resources/work_logs/14_04_2024 - 20_04_2024.html",
    "createdDate": "2024-04-14",
    "text": "14/04/2024 - 20/04/2024 14/04/2024 - 20/04/2024 16/04/2024 13:54 Running internal trigger at 2000Hz: 18:23:31.409 2024/04/15 [MasterGM2,TALK] Alarm: CCC Run Aborted 17:10:10.587 2024/04/15 [mhttpd,INFO] Run #81 started 18 : 23 : 31 . 409 2024 / 04 / 15 [MasterGM2,TALK] Alarm: CCC Run Aborted 17:10:10.587 2024/04/15 [mhttpd,INFO] Run #81 started But we didn't see the tcp thread fall behind in this hour. And this time, no digitizers became \"nonrecoverable\"",
    "textLength": 92
  },
  {
    "kind": "work-log",
    "title": "21_01_2024 - 27_01_2024.html",
    "fileName": "21_01_2024 - 27_01_2024.html",
    "url": "resources/work_logs/21_01_2024 - 27_01_2024.html",
    "createdDate": "2024-01-21",
    "text": "21/01/2024 - 27/01/2024 21/01/2024 - 27/01/2024 22/01/2024 11:59 I asked for some help on reddit here: https://www.reddit.com/r/FPGA/comments/1993seu/board_disappears_from_lspci_after_programming/ following: You have to trigger the FPGA to load your bitstream from the config flash, either by power cycling the board or by sending the right JTAG command (e.g. by right-clicking on the FPGA in Hardware Manager and selecting \"Boot from configuration memory\"). You'll also need to either reboot the host computer to trigger PCIe device enumeration, or use these commands: echo 1 > /sys/bus/pci/devices/0000\\:05\\:00.0/remove echo 1 > /sys/bus/pci/rescan echo 1 > /sys/bus/pci/devices/ 0000 \\: 05 \\: 00 . 0 /remove echo 1 > /sys/bus/pci/rescan Did not seem to help on the newest dektop running linux mint. I.e. the board was still not found after a rescan. I had the starting guide ( https://numato.com/kb/getting-started-with-pci-express-on-nereid/ ) bitstream in the flash memory. The same one that works without doing anything fancy on fe01 running CentOS7. Trying this fix for the dma guide's flash memory bitstream ( https://numato.com/kb/create-pcie-dma-example-design-for-nereid/ ) also fails on fe01 runnign CentOS7. 22/01/2024 13:06 Tried following the \"simple\" DDR3 guide: https://numato.com/kb/simple-ddr3-interfacing-on-nereid-using-xilinx-mig-7/ There's a point in step 6 where it says to select \"MT8KTF51264HZ-1G9\" as the base part. However, that does not exist in the dropdown menu reached by following the previous steps. I just left that dropdown as the default and continued through the guide, but unsuprisingly was unable to generate a bitstream. 24/01/2024 21:47 I tried following this guide: https://numato.com/kb/create-pcie-dma-example-design-for-nereid/ Once again. This time I ignored the extra block in the image and followed the guide word for word otherwise. The same result as before. I cannot see the device in either our newest desktop or fe01. 24/01/2024 22:19 Tried installing Xilinx dma_ip_drivers by following this readme https://github.com/Xilinx/dma_ip_drivers/tree/master/XDMA/linux-kernel But I get this error when trying the first make: [root@fe01 xdma]# make install Makefile:17: XVC_FLAGS: . make -C /lib/modules/3.10.0-1160.76.1.el7.x86_64/build M=/root/dma_ip_drivers/XDMA/linux-kernel/xdma modules make[1]: Entering directory `/usr/src/kernels/3.10.0-1160.76.1.el7.x86_64' /root/dma_ip_drivers/XDMA/linux-kernel/xdma/Makefile:17: XVC_FLAGS: . CC [M] /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: xdma_engine_stop.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: engine_service_shutdown.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: user_irq_service.isra.0.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: xdma_isr.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: xdma_user_irq.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: engine_transfer_completion.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: irq_teardown.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: engine_status_read.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: engine_start.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: engine_service.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: engine_service_work.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: xdma_channel_irq.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: xdma_init_request.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: transfer_queue.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: engine_destroy.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: remove_engines.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: get_perf_stats.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: engine_service_poll.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: engine_cyclic_stop.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: xdma_xfer_aperture.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: xdma_xfer_submit.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: xdma_xfer_completion.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: xdma_xfer_submit_nowait.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: xdma_performance_submit.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: xdma_device_close.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: xdma_device_offline.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: xdma_device_online.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: xdma_device_restart.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: xdma_user_isr_register.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: xdma_user_isr_enable.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: xdma_user_isr_disable.cold()+0x0: frame pointer state mismatch CC [M] /root/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma_cdev.o /root/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma_cdev.o: warning: objtool: create_xcdev.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma_cdev.o: warning: objtool: destroy_xcdev.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma_cdev.o: warning: objtool: xcdev_check.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma_cdev.o: warning: objtool: char_open.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma_cdev.o: warning: objtool: char_close.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma_cdev.o: warning: objtool: xpdev_destroy_interfaces.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma_cdev.o: warning: objtool: xpdev_create_interfaces.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma_cdev.o: warning: objtool: xdma_cdev_init.cold()+0x0: frame pointer state mismatch CC [M] /root/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_ctrl.o /root/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_ctrl.o: warning: objtool: char_ctrl_write.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_ctrl.o: warning: objtool: char_ctrl_ioctl.cold()+0x0: frame pointer state mismatch CC [M] /root/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_events.o /root/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_events.o: warning: objtool: char_events_poll.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_events.o: warning: objtool: char_events_read.cold()+0x0: frame pointer state mismatch CC [M] /root/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_sgdma.o /root/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_sgdma.o: warning: objtool: char_sgdma_unmap_user_buf.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_sgdma.o: warning: objtool: async_io_handler.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_sgdma.o: warning: objtool: check_transfer_align.constprop.0.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_sgdma.o: warning: objtool: char_sgdma_map_user_buf_to_sgl.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_sgdma.o: warning: objtool: ioctl_do_aperture_dma.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_sgdma.o: warning: objtool: cdev_aio_write.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_sgdma.o: warning: objtool: cdev_aio_read.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_sgdma.o: warning: objtool: char_sgdma_read_write.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_sgdma.o: warning: objtool: char_sgdma_ioctl.cold()+0x0: frame pointer state mismatch CC [M] /root/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_xvc.o /root/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_xvc.o: warning: objtool: xvc_ioctl.cold()+0x0: frame pointer state mismatch CC [M] /root/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_bypass.o CC [M] /root/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma_mod.o /root/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma_mod.o: warning: objtool: xdma_slot_reset.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma_mod.o: warning: objtool: xdma_error_detected.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma_mod.o: warning: objtool: probe_one.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma_mod.o: warning: objtool: remove_one.cold()+0x0: frame pointer state mismatch CC [M] /root/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma_thread.o /root/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma_thread.o: warning: objtool: xdma_kthread_start.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma_thread.o: warning: objtool: xdma_kthread_stop.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma_thread.o: warning: objtool: xdma_threads_create.cold()+0x0: frame pointer state mismatch LD [M] /root/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma.o Building modules, stage 2. /root/dma_ip_drivers/XDMA/linux-kernel/xdma/Makefile:17: XVC_FLAGS: . MODPOST 1 modules CC /root/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma.mod.o LD [M] /root/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma.ko make[1]: Leaving directory `/usr/src/kernels/3.10.0-1160.76.1.el7.x86_64' installing kernel modules to /lib/modules/3.10.0-1160.76.1.el7.x86_64/xdma ... removed \u2018/lib/modules/3.10.0-1160.76.1.el7.x86_64/xdma/xdma.ko\u2019 \u2018xdma.ko\u2019 -> \u2018/lib/modules/3.10.0-1160.76.1.el7.x86_64/xdma/xdma.ko\u2019 depmod: ERROR: fstatat(4, nvidia-peermem.ko.xz): No such file or directory [root@fe01 xdma]# make install Makefile:17: XVC_FLAGS: . make -C /lib/modules/3.10.0-1160.76.1.el7.x86_64/build M=/root/dma_ip_drivers/XDMA/linux-kernel/xdma modules make[1]: Entering directory `/usr/src/kernels/3.10.0-1160.76.1.el7.x86_64' /root/dma_ip_drivers/XDMA/linux-kernel/xdma/Makefile:17: XVC_FLAGS: . CC [M] /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: xdma_engine_stop.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: engine_service_shutdown.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: user_irq_service.isra.0.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: xdma_isr.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: xdma_user_irq.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: engine_transfer_completion.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: irq_teardown.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: engine_status_read.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: engine_start.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: engine_service.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: engine_service_work.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: xdma_channel_irq.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: xdma_init_request.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: transfer_queue.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: engine_destroy.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: remove_engines.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: get_perf_stats.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: engine_service_poll.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: engine_cyclic_stop.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: xdma_xfer_aperture.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: xdma_xfer_submit.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: xdma_xfer_completion.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: xdma_xfer_submit_nowait.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: xdma_performance_submit.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: xdma_device_close.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: xdma_device_offline.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: xdma_device_online.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: xdma_device_restart.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: xdma_user_isr_register.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: xdma_user_isr_enable.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/libxdma.o: warning: objtool: xdma_user_isr_disable.cold()+0x0: frame pointer state mismatch CC [M] /root/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma_cdev.o /root/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma_cdev.o: warning: objtool: create_xcdev.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma_cdev.o: warning: objtool: destroy_xcdev.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma_cdev.o: warning: objtool: xcdev_check.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma_cdev.o: warning: objtool: char_open.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma_cdev.o: warning: objtool: char_close.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma_cdev.o: warning: objtool: xpdev_destroy_interfaces.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma_cdev.o: warning: objtool: xpdev_create_interfaces.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma_cdev.o: warning: objtool: xdma_cdev_init.cold()+0x0: frame pointer state mismatch CC [M] /root/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_ctrl.o /root/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_ctrl.o: warning: objtool: char_ctrl_write.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_ctrl.o: warning: objtool: char_ctrl_ioctl.cold()+0x0: frame pointer state mismatch CC [M] /root/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_events.o /root/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_events.o: warning: objtool: char_events_poll.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_events.o: warning: objtool: char_events_read.cold()+0x0: frame pointer state mismatch CC [M] /root/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_sgdma.o /root/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_sgdma.o: warning: objtool: char_sgdma_unmap_user_buf.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_sgdma.o: warning: objtool: async_io_handler.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_sgdma.o: warning: objtool: check_transfer_align.constprop.0.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_sgdma.o: warning: objtool: char_sgdma_map_user_buf_to_sgl.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_sgdma.o: warning: objtool: ioctl_do_aperture_dma.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_sgdma.o: warning: objtool: cdev_aio_write.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_sgdma.o: warning: objtool: cdev_aio_read.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_sgdma.o: warning: objtool: char_sgdma_read_write.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_sgdma.o: warning: objtool: char_sgdma_ioctl.cold()+0x0: frame pointer state mismatch CC [M] /root/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_xvc.o /root/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_xvc.o: warning: objtool: xvc_ioctl.cold()+0x0: frame pointer state mismatch CC [M] /root/dma_ip_drivers/XDMA/linux-kernel/xdma/cdev_bypass.o CC [M] /root/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma_mod.o /root/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma_mod.o: warning: objtool: xdma_slot_reset.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma_mod.o: warning: objtool: xdma_error_detected.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma_mod.o: warning: objtool: probe_one.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma_mod.o: warning: objtool: remove_one.cold()+0x0: frame pointer state mismatch CC [M] /root/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma_thread.o /root/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma_thread.o: warning: objtool: xdma_kthread_start.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma_thread.o: warning: objtool: xdma_kthread_stop.cold()+0x0: frame pointer state mismatch /root/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma_thread.o: warning: objtool: xdma_threads_create.cold()+0x0: frame pointer state mismatch LD [M] /root/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma.o Building modules, stage 2. /root/dma_ip_drivers/XDMA/linux-kernel/xdma/Makefile:17: XVC_FLAGS: . MODPOST 1 modules CC /root/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma.mod.o LD [M] /root/dma_ip_drivers/XDMA/linux-kernel/xdma/xdma.ko make[1]: Leaving directory `/usr/src/kernels/3.10.0-1160.76.1.el7.x86_64' installing kernel modules to /lib/modules/3.10.0-1160.76.1.el7.x86_64/xdma ... removed \u2018/lib/modules/3.10.0-1160.76.1.el7.x86_64/xdma/xdma.ko\u2019 \u2018xdma.ko\u2019 -> \u2018/lib/modules/3.10.0-1160.76.1.el7.x86_64/xdma/xdma.ko\u2019 depmod: ERROR: fstatat(4, nvidia-peermem.ko.xz): No such file or directory Similar issue from 2.5 years ago with no answer: https://support.xilinx.com/s/question/0D52E00006hpREWSA2/qdmaipdriver-depmod-error-fstatat4-xclmgmtkoxz-depmod-error-fstatat4-xoclkoxz?language=en_US 24/01/2024 22:43 I took a look at how much code is behind a \"Simple\" FPGA PCIe Interface and... Each of the files is hundreds of lines of code. The screenshot contains about half the files. It is complete unfeasible to write this on my own. 26/01/2024 19:26 Tried to just use the PCIe parts of the DMA project, but face the same issues as before (device not showing up with lspci). What I did was: Created a block diagram Went to the \"board\" section (these development board have automatically configured IP block) Added the pcie block (which automatically added the pcie dma interface block) Added no other block, hit run blocka automation and run connection automation In sources, I made and hdl wrapper for the block diagarm Then I right clicked generate bit stream to check the .bin file box to generate a bin file Then I generated a bitstream After the bitstream was generated, I auto connected to the board I right cliicked the xc7.... whatever to create a new configuration memory Micron, 128, spi, clicked the one with L Programmed with the generated .bin file located in the {projectname}.runs Programming was sucessful, moved the card to fe01, but was not able to see the board with lspci. I didn't explitly save the block diagram I made, so there's a chance that messed things up; though I find it doubtful since it took so long to synthesize and all that. 26/01/2024 20:33 Trying to follow this guide: https://numato.com/kb/vivado-design-suite-create-microblaze-based-design-using-ip-integrator-with-nereid-kintex-7-pci-express-development-board/ I fail at STep 14 because the guide is outdared. SDK was removed from Vivado in 2019, it now uses Vitis. Trying to lanch Vitis IDE from the Tools menu in Vivado fails for some reason. Though, I should be able to open it somehow (maybe I don't have it installed on my laptop? Hard to tell.)",
    "textLength": 3324
  },
  {
    "kind": "work-log",
    "title": "09_02_2025 - 15_02_2025.html",
    "fileName": "09_02_2025 - 15_02_2025.html",
    "url": "resources/work_logs/09_02_2025 - 15_02_2025.html",
    "createdDate": "2025-02-09",
    "text": "09/02/2025 - 15/02/2025 09/02/2025 - 15/02/2025 09/02/2025 17:06 I accidentally discovered there are sometimes errenous packets with extra information... Invalid packet size: 90 Invalid packet size: 106 Invalid packet size: 90 Invalid packet size: 90 Invalid packet size: 106 Invalid packet size: 90 They seem to have a multiplicity of 16 extra bytes and they throw off the parsing: here are some examples: Channel: 0, Trigger Time: 16047600 Logical Position: 0, Physical Position: 60 Samples: 1518 1473 1471 1492 1489 1498 1471 1469 1442 1476 1504 1504 1467 1492 1423 1474 1487 1513 1516 1485 1512 1495 1486 1494 1468 1494 1472 1024 0 0 0 0 Footer: 0, 0 ------------------------------------------------- Channel: 0, Trigger Time: 16065155 Logical Position: 0, Physical Position: 7 Samples: 1486 1498 1502 1512 1489 1496 1490 1486 1490 1510 1466 1494 1490 1470 1478 1460 1467 1496 1511 1498 1472 1024 0 0 0 0 0 0 0 1460 1504 1496 Footer: 5, 212 ------------------------------------------------- Channel: 0, Trigger Time: 16083744 Logical Position: 0, Physical Position: 58 Samples: 1496 1451 1472 1487 1486 1489 1468 1474 1472 1513 1466 1476 1465 1498 1465 1024 0 0 0 0 0 0 0 1474 1492 1537 1504 1487 1491 1487 1443 1480 Footer: 5, 224 ------------------------------------------------- Channel: 0, Trigger Time: 16101300 Logical Position: 0, Physical Position: 6 Samples: 1530 1478 1437 1521 1487 1518 1476 1474 1486 1024 0 0 0 0 0 0 0 1486 1486 1490 1487 1462 1478 1472 1475 1513 1520 1493 1504 1525 1516 1520 Footer: 5, 238 ------------------------------------------------- Channel: 0, Trigger Time: 16119889 Logical Position: 0, Physical Position: 57 Samples: 1494 1491 1518 1024 0 0 0 0 0 0 0 1517 1465 1500 1504 1468 1504 1506 1510 1463 1484 1492 1515 1494 1512 1542 1516 1492 1502 1503 1496 1464 Footer: 5, 224 ------------------------------------------------- Channel: 0, Trigger Time: 16047600 Logical Position: 0, Physical Position: 60 Samples: 1518 1473 1471 1492 1489 1498 1471 1469 1442 1476 1504 1504 1467 1492 1423 1474 1487 1513 1516 1485 1512 1495 1486 1494 1468 1494 1472 1024 0 0 0 0 Footer: 0, 0 ------------------------------------------------- Channel: 0, Trigger Time: 16065155 Logical Position: 0, Physical Position: 7 Samples: 1486 1498 1502 1512 1489 1496 1490 1486 1490 1510 1466 1494 1490 1470 1478 1460 1467 1496 1511 1498 1472 1024 0 0 0 0 0 0 0 1460 1504 1496 Footer: 5, 212 ------------------------------------------------- Channel: 0, Trigger Time: 16083744 Logical Position: 0, Physical Position: 58 Samples: 1496 1451 1472 1487 1486 1489 1468 1474 1472 1513 1466 1476 1465 1498 1465 1024 0 0 0 0 0 0 0 1474 1492 1537 1504 1487 1491 1487 1443 1480 Footer: 5, 224 ------------------------------------------------- Channel: 0, Trigger Time: 16101300 Logical Position: 0, Physical Position: 6 Samples: 1530 1478 1437 1521 1487 1518 1476 1474 1486 1024 0 0 0 0 0 0 0 1486 1486 1490 1487 1462 1478 1472 1475 1513 1520 1493 1504 1525 1516 1520 Footer: 5, 238 ------------------------------------------------- Channel: 0, Trigger Time: 16119889 Logical Position: 0, Physical Position: 57 Samples: 1494 1491 1518 1024 0 0 0 0 0 0 0 1517 1465 1500 1504 1468 1504 1506 1510 1463 1484 1492 1515 1494 1512 1542 1516 1492 1502 1503 1496 1464 Footer: 5, 224 ------------------------------------------------- It seems like zome zeros are just randomly inserted into the packet? Not sure what's going on here? Something with UDP??? 09/02/2025 18:10 By \"optomizing\" the packet reading, I'm able to read in packets at around 300 MB/s is C++ (corresponding to an actual trace data rate of ~48 data bytes/72 packet byes ~ 2/3, then 2/3 * 300 MB/s ~ 200 MB/s): Running the executable... File reading time: 0.0528991 seconds Error count: 1004 Total count: 14225 Error Percentage: 7.058% Chunking time: 0.00230152 seconds Raw parsing time: 0.000647574 seconds Non-raw parsing time: 0.00704113 seconds First 5 raw parsed packets: Channel: 0, Trigger Time: 16031077 Logical Position: 0, Physical Position: 29 Raw Samples: 5 216 5 231 5 223 5 235 5 194 5 209 5 212 5 190 5 208 5 210 5 206 5 187 5 184 5 186 5 200 5 214 5 184 5 226 5 217 5 205 5 209 5 209 5 216 5 236 5 228 5 164 5 202 5 184 5 214 5 206 5 209 6 23 Footer: 250, 90 ------------------------------------------------- Channel: 0, Trigger Time: 16032109 Logical Position: 0, Physical Position: 7 Raw Samples: 5 209 5 218 5 224 5 234 5 208 5 217 5 210 5 208 5 212 5 228 5 188 5 210 5 211 5 191 5 200 5 181 5 187 5 216 5 232 5 218 5 188 5 181 5 225 5 220 5 212 5 207 5 240 5 214 5 224 5 215 5 214 5 238 Footer: 250, 90 ------------------------------------------------- Channel: 0, Trigger Time: 16033142 Logical Position: 0, Physical Position: 48 Raw Samples: 5 229 5 175 5 162 5 239 5 248 5 201 5 235 5 214 5 226 5 217 5 200 5 214 5 184 5 197 5 209 5 203 5 229 5 231 5 211 5 204 5 214 5 208 5 161 5 188 5 192 5 214 5 194 5 186 5 187 5 206 5 247 5 213 Footer: 250, 90 ------------------------------------------------- Channel: 0, Trigger Time: 16034175 Logical Position: 0, Physical Position: 27 Raw Samples: 5 198 5 226 5 212 5 240 5 178 5 215 5 187 5 189 5 196 5 224 5 232 5 206 5 188 5 214 5 238 5 224 5 211 5 243 5 236 5 214 5 222 5 181 5 172 5 163 5 211 5 240 5 232 5 215 5 208 5 220 5 193 5 242 Footer: 250, 90 ------------------------------------------------- Channel: 0, Trigger Time: 16035207 Logical Position: 0, Physical Position: 5 Raw Samples: 5 223 5 210 5 165 5 232 5 211 5 211 5 216 5 216 5 163 5 225 5 234 5 222 5 203 5 162 5 216 5 210 5 210 5 214 5 222 5 232 5 223 5 208 5 228 5 211 5 210 5 219 5 205 5 174 5 178 5 194 5 206 5 231 Footer: 250, 90 ------------------------------------------------- First 5 non-raw parsed packets: Channel: 0, Trigger Time: 16031077 Logical Position: 0, Physical Position: 29 Samples: 1496 1511 1503 1515 1474 1489 1492 1470 1488 1490 1486 1467 1464 1466 1480 1494 1464 1506 1497 1485 1489 1489 1496 1516 1508 1444 1482 1464 1494 1486 1489 1559 Footer: 250, 90 ------------------------------------------------- Channel: 0, Trigger Time: 16032109 Logical Position: 0, Physical Position: 7 Samples: 1489 1498 1504 1514 1488 1497 1490 1488 1492 1508 1468 1490 1491 1471 1480 1461 1467 1496 1512 1498 1468 1461 1505 1500 1492 1487 1520 1494 1504 1495 1494 1518 Footer: 250, 90 ------------------------------------------------- Channel: 0, Trigger Time: 16033142 Logical Position: 0, Physical Position: 48 Samples: 1509 1455 1442 1519 1528 1481 1515 1494 1506 1497 1480 1494 1464 1477 1489 1483 1509 1511 1491 1484 1494 1488 1441 1468 1472 1494 1474 1466 1467 1486 1527 1493 Footer: 250, 90 ------------------------------------------------- Channel: 0, Trigger Time: 16034175 Logical Position: 0, Physical Position: 27 Samples: 1478 1506 1492 1520 1458 1495 1467 1469 1476 1504 1512 1486 1468 1494 1518 1504 1491 1523 1516 1494 1502 1461 1452 1443 1491 1520 1512 1495 1488 1500 1473 1522 Footer: 250, 90 ------------------------------------------------- Channel: 0, Trigger Time: 16035207 Logical Position: 0, Physical Position: 5 Samples: 1503 1490 1445 1512 1491 1491 1496 1496 1443 1505 1514 1502 1483 1442 1496 1490 1490 1494 1502 1512 1503 1488 1508 1491 1490 1499 1485 1454 1458 1474 1486 1511 Footer: 250, 90 ------------------------------------------------- Error count: 1004 Total count: 14225 Error Percentage: 7.058% Error count: 1004 Total count: 14225 Error Percentage: 7.058% Raw parsing results: Total packets processed (raw): 13221 Packets processed per second (raw): 4.31875e+06 Total data rate (raw): 296.545 MB/s Effective data rate (raw): 197.697 MB/s Total data processed (raw): 0.907814 MB Non-raw parsing results: Total packets processed (non-raw): 13221 Packets processed per second (non-raw): 1.30742e+06 Total data rate (non-raw): 89.7736 MB/s Effective data rate (non-raw): 59.8491 MB/s Total data processed (non-raw): 0.907814 MB Running the executable... File reading time: 0.0528991 seconds Error count: 1004 Total count: 14225 Error Percentage: 7.058% Chunking time: 0.00230152 seconds Raw parsing time: 0.000647574 seconds Non-raw parsing time: 0.00704113 seconds First 5 raw parsed packets: Channel: 0, Trigger Time: 16031077 Logical Position: 0, Physical Position: 29 Raw Samples: 5 216 5 231 5 223 5 235 5 194 5 209 5 212 5 190 5 208 5 210 5 206 5 187 5 184 5 186 5 200 5 214 5 184 5 226 5 217 5 205 5 209 5 209 5 216 5 236 5 228 5 164 5 202 5 184 5 214 5 206 5 209 6 23 Footer: 250, 90 ------------------------------------------------- Channel: 0, Trigger Time: 16032109 Logical Position: 0, Physical Position: 7 Raw Samples: 5 209 5 218 5 224 5 234 5 208 5 217 5 210 5 208 5 212 5 228 5 188 5 210 5 211 5 191 5 200 5 181 5 187 5 216 5 232 5 218 5 188 5 181 5 225 5 220 5 212 5 207 5 240 5 214 5 224 5 215 5 214 5 238 Footer: 250, 90 ------------------------------------------------- Channel: 0, Trigger Time: 16033142 Logical Position: 0, Physical Position: 48 Raw Samples: 5 229 5 175 5 162 5 239 5 248 5 201 5 235 5 214 5 226 5 217 5 200 5 214 5 184 5 197 5 209 5 203 5 229 5 231 5 211 5 204 5 214 5 208 5 161 5 188 5 192 5 214 5 194 5 186 5 187 5 206 5 247 5 213 Footer: 250, 90 ------------------------------------------------- Channel: 0, Trigger Time: 16034175 Logical Position: 0, Physical Position: 27 Raw Samples: 5 198 5 226 5 212 5 240 5 178 5 215 5 187 5 189 5 196 5 224 5 232 5 206 5 188 5 214 5 238 5 224 5 211 5 243 5 236 5 214 5 222 5 181 5 172 5 163 5 211 5 240 5 232 5 215 5 208 5 220 5 193 5 242 Footer: 250, 90 ------------------------------------------------- Channel: 0, Trigger Time: 16035207 Logical Position: 0, Physical Position: 5 Raw Samples: 5 223 5 210 5 165 5 232 5 211 5 211 5 216 5 216 5 163 5 225 5 234 5 222 5 203 5 162 5 216 5 210 5 210 5 214 5 222 5 232 5 223 5 208 5 228 5 211 5 210 5 219 5 205 5 174 5 178 5 194 5 206 5 231 Footer: 250, 90 ------------------------------------------------- First 5 non-raw parsed packets: Channel: 0, Trigger Time: 16031077 Logical Position: 0, Physical Position: 29 Samples: 1496 1511 1503 1515 1474 1489 1492 1470 1488 1490 1486 1467 1464 1466 1480 1494 1464 1506 1497 1485 1489 1489 1496 1516 1508 1444 1482 1464 1494 1486 1489 1559 Footer: 250, 90 ------------------------------------------------- Channel: 0, Trigger Time: 16032109 Logical Position: 0, Physical Position: 7 Samples: 1489 1498 1504 1514 1488 1497 1490 1488 1492 1508 1468 1490 1491 1471 1480 1461 1467 1496 1512 1498 1468 1461 1505 1500 1492 1487 1520 1494 1504 1495 1494 1518 Footer: 250, 90 ------------------------------------------------- Channel: 0, Trigger Time: 16033142 Logical Position: 0, Physical Position: 48 Samples: 1509 1455 1442 1519 1528 1481 1515 1494 1506 1497 1480 1494 1464 1477 1489 1483 1509 1511 1491 1484 1494 1488 1441 1468 1472 1494 1474 1466 1467 1486 1527 1493 Footer: 250, 90 ------------------------------------------------- Channel: 0, Trigger Time: 16034175 Logical Position: 0, Physical Position: 27 Samples: 1478 1506 1492 1520 1458 1495 1467 1469 1476 1504 1512 1486 1468 1494 1518 1504 1491 1523 1516 1494 1502 1461 1452 1443 1491 1520 1512 1495 1488 1500 1473 1522 Footer: 250, 90 ------------------------------------------------- Channel: 0, Trigger Time: 16035207 Logical Position: 0, Physical Position: 5 Samples: 1503 1490 1445 1512 1491 1491 1496 1496 1443 1505 1514 1502 1483 1442 1496 1490 1490 1494 1502 1512 1503 1488 1508 1491 1490 1499 1485 1454 1458 1474 1486 1511 Footer: 250, 90 ------------------------------------------------- Error count: 1004 Total count: 14225 Error Percentage: 7.058% Error count: 1004 Total count: 14225 Error Percentage: 7.058% Raw parsing results: Total packets processed (raw): 13221 Packets processed per second (raw): 4.31875e+06 Total data rate (raw): 296.545 MB/s Effective data rate (raw): 197.697 MB/s Total data processed (raw): 0.907814 MB Non-raw parsing results: Total packets processed (non-raw): 13221 Packets processed per second (non-raw): 1.30742e+06 Total data rate (non-raw): 89.7736 MB/s Effective data rate (non-raw): 59.8491 MB/s Total data processed (non-raw): 0.907814 MB I tried to see if I could use pybind to call tehse same methods in python with similar rates. I could not: Total packets processed: 13221 Packets processed per second: 84074.5658 Total data rate: 5.7729 MB/s Effective data rate: 3.8486 MB/s Total data processed: 0.9078 MB Total packets processed: 13221 Packets processed per second: 84074 . 5658 Total data rate: 5 . 7729 MB/s Effective data rate: 3 . 8486 MB/s Total data processed: 0 . 9078 MB It's somehow even slower than doing it in python by hand. Not sure why... 09/02/2025 18:19 I also computed how many packets have an error (i.e. are not size 74) when chunking packets and I get: Error count: 1004 Total count: 14225 Error Percentage: 7.058% Error count: 1004 Total count: 14225 Error Percentage: 7.058% This becomes difficult to work around when events are constructed from many packets. You can calculate the chance that a full event is errorless with formula: \\begin{align*} & P(w,c,E) = (1-E)^{wc} \\end{align*} P ( w , c , E ) = ( 1 \u2212 E ) w c \\begin{align*} & P(w,c,E) = (1-E)^{wc} \\end{align*} \u200b P ( w , c , E ) = ( 1 \u2212 E ) w c \u200b where w \\equiv w \u2261 w \\equiv w \u2261 windows, c\\equiv c \u2261 c\\equiv c \u2261 channels, and E\\equiv E \u2261 E\\equiv E \u2261 Error rate. For example P(w=1,c=32,E=0.07)\\approx 0.10 P ( w = 1 , c = 32 , E = 0.07 ) \u2248 0.10 P(w=1,c=32,E=0.07)\\approx 0.10 P ( w = 1 , c = 32 , E = 0.07 ) \u2248 0.10 . So even in a very optomistic estimate of our use case, most events will still contain an error. So I must do some error scrubbing to correct for this. 10/02/2025 11:54 It seems every packet with an error has one or multiple copies of this 16 byte string \"randomly\" jamed in there: b\"\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\" My best guess is this is some \"heartbeat\" signal? 10/02/2025 12:52 Here's an example packet: Packet: b'\\x0e\\x03\\x0bV\\x08\\x93\\x00\\x01\\x07\\x00\\x06\\xe6\\x06\\xf0\\x06\\xe8\\x078\\x06\\xf0\\x06\\xcb\\x06\\xdd\\x07\\x02\\x06\\xe7\\x06\\xc4\\x06\\xf2\\x06\\xb5\\x06\\xec\\x06\\xea\\x07\\x06\\x06\\xe4\\x06\\xed\\x06\\xe3\\x06\\xea\\x06\\xe6\\x06\\xda\\x06\\xf8\\x07\\x05\\x06\\xe0\\x06\\xea\\x06\\xe8\\x06\\xd2\\x06\\xcb\\x06\\xd6\\x06\\xe5\\x06\\xe8\\xfaZ' Packet: b'\\ x 0 e\\ x 03 \\ x 0 bV\\ x 08 \\ x 93 \\ x 00 \\ x 01 \\ x 07 \\ x 00 \\ x 06 \\xe 6 \\ x 06 \\xf 0 \\ x 06 \\xe 8 \\ x 078 \\ x 06 \\xf 0 \\ x 06 \\xcb\\ x 06 \\xdd\\ x 07 \\ x 02 \\ x 06 \\xe 7 \\ x 06 \\xc 4 \\ x 06 \\xf 2 \\ x 06 \\xb 5 \\ x 06 \\xec\\ x 06 \\xea\\ x 07 \\ x 06 \\ x 06 \\xe 4 \\ x 06 \\xed\\ x 06 \\xe 3 \\ x 06 \\xea\\ x 06 \\xe 6 \\ x 06 \\xda\\ x 06 \\xf 8 \\ x 07 \\ x 05 \\ x 06 \\xe 0 \\ x 06 \\xea\\ x 06 \\xe 8 \\ x 06 \\xd 2 \\ x 06 \\xcb\\ x 06 \\xd 6 \\ x 06 \\xe 5 \\ x 06 \\xe 8 \\xfaZ' I'm pretty sure the start being 0x0E is erroneous . This is a bad header because it can show up in normal operation. example 0x0E 0x0E if a valid 4 bytes of digitized data. If we could assume there are exactly 72 bytes preceeding the trailer word 0xFA 0x5A (which prints out as xfaZ becuase 0x5A is the unicode character for Z ), then this wouldn't be a problem. However, becuase b\"\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\" are randomly crammed in the data sometimes, we can't do that. I.e. there could be a case where we see 0x0E and 0xFA 0x5A seperated by exactly 72 bytes, but 0x0E actually corresponds to data, not a header word. If this header word was 0xE0 , we could get around this problem, because b\"\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\" only shifts the data by an even amount, and while 0xE0 can show up naturally in odd bytes, it cannot in even bytes (All data is 12 bytes and must start with 0 , so the even \"data\" bytes must start with 0 ). This would mean we could look for the trailer word 0xFA 0x5A and look backwards 72 + 16\\cdot m 72 + 16 \u22c5 m 72 + 16\\cdot m 72 + 16 \u22c5 m bytes where m m m m is some integer. Eventually we would find a 0xE0 . Unless b\"\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\" can show up between the two trailer bytes 0xFA 0x5A , then we'd have a problem. All this is to say is seems the only solution is to scrub all occurences of b\"\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\" out before splitting the data into packets, which causes the efficiency to take a hit, but the results seem to indicate this cleans the data up: Total packets: 13837 Skipped packets: 1 Error Percentage: 0.01% Total packets: 13837 Skipped packets: 1 Error Percentage: 0.01% Where the last packet is skipped because it's cut off. 10/02/2025 13:20 Python can handle parsing packets in a more efficient \"chopping\" manner at around 16 MB/s. Still way too slow, C++ is needed. 13/02/2025 19:45 Note: when I say \"error bytes\" I mean the sequence: vector<unsigned char> error_bytes = { 0x04, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00 }; vector< unsigned char > error_bytes = { 0x04 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 , 0x00 }; that shows up seemingly \"randomly\" in data packets. I was able to very slightly speed things up (~20%) by only \"scrubbing\" packets that have errors as opposed to the whole bytestream. The splitting into packets algorithm is now the bottleneck because it has to go through a series of steps to clean up errors. It goes like this: Setup: Scrub the first N (=200 seems sufficient) bytes by removing the error bytes. Find the first occurence of the end word. Verify the start index is 1 packet length behind the end word (if not search for the next occurence of the end word and repeat). This is your first packet. This should only be necessary for the very first packet received in a run. Standard operation: For subsequent packets, we know the index should be set at the end of the last packet, so we skip one packet length ahead to check if the stop word is there. If the stop word is there, we add the packet and continue to the next. Fast error correction: If the stop word isn't there, we begin a error correcting sequence. We again search for the stop word \\text{packet length} + 16\\cdot m packet length + 16 \u22c5 m \\text{packet length} + 16\\cdot m packet length + 16 \u22c5 m bytes away where m m m m is an integer. The errors come in 16 byte sequences, so the stop word should only be displaced by 16 bytes. We move in steps of 16 up to some threshold number of times (default 5). Once we find the stop word, we scrub the bytes between this stop word and the previous, take the final packet_length bytes, and append the packet to list of split packets, then go back to step 2. Brute force error correction: If the fast error correction fails, we indefintely search for the next stop word by moving 1 byte at a time. This is slow, but guarentees we find the next stop word if it's there. Once we find the stop word, we scrub the bytes between this stop word and the previous, take the final packet_length bytes, and append the packet to list of split packets, then go back to step 2.. Old Performance Example: (base) jack@DESKTOP-FFN8B5L:~/cpp_projects/nalu_packet_collection_test/scripts$ ./run_test.sh Running the executable... --- General Processing Stats --- Time taken to read binary file: 0.000708517 seconds Time taken to scrub byte stream: 0.00535157 seconds Time taken to split packets: 0.00218371 seconds Time taken to parse packets: 0.000847597 seconds --- Standard Event Collection --- Collected events: 15 Time taken to collect events (standard mode): 0.00327157 seconds Event lengths (packets per event): Event 14: 800 packets Event 13: 992 packets Event 12: 992 packets Event 11: 992 packets Event 10: 992 packets Event 9: 992 packets Event 8: 992 packets Event 7: 992 packets Event 6: 992 packets Event 5: 992 packets Event 4: 992 packets Event 3: 992 packets Event 2: 992 packets Event 1: 992 packets Event 0: 140 packets --- Lazy Mode Event Collection --- Collected events: 15 Time taken to collect events (lazy mode): 0.00103559 seconds Event lengths (packets per event): Event 15: 800 packets Event 14: 992 packets Event 13: 992 packets Event 12: 992 packets Event 11: 992 packets Event 10: 992 packets Event 9: 992 packets Event 8: 992 packets Event 7: 992 packets Event 6: 992 packets Event 5: 992 packets Event 4: 992 packets Event 3: 992 packets Event 2: 992 packets Event 1: 140 packets --- Data Rates --- Standard Mode: Total processing time: 0.012363 seconds Full data rate: 76.8459 MB/s True data rate: 51.2306 MB/s Lazy Mode: Total processing time: 0.010127 seconds Full data rate: 93.813 MB/s True data rate: 62.542 MB/s (base) jack@DESKTOP-FFN8B5L:~/cpp_projects/nalu_packet_collection_test/scripts$ ./run_test.sh Running the executable... --- General Processing Stats --- Time taken to read binary file: 0.000708517 seconds Time taken to scrub byte stream: 0.00535157 seconds Time taken to split packets: 0.00218371 seconds Time taken to parse packets: 0.000847597 seconds --- Standard Event Collection --- Collected events: 15 Time taken to collect events (standard mode): 0.00327157 seconds Event lengths (packets per event): Event 14: 800 packets Event 13: 992 packets Event 12: 992 packets Event 11: 992 packets Event 10: 992 packets Event 9: 992 packets Event 8: 992 packets Event 7: 992 packets Event 6: 992 packets Event 5: 992 packets Event 4: 992 packets Event 3: 992 packets Event 2: 992 packets Event 1: 992 packets Event 0: 140 packets --- Lazy Mode Event Collection --- Collected events: 15 Time taken to collect events (lazy mode): 0.00103559 seconds Event lengths (packets per event): Event 15: 800 packets Event 14: 992 packets Event 13: 992 packets Event 12: 992 packets Event 11: 992 packets Event 10: 992 packets Event 9: 992 packets Event 8: 992 packets Event 7: 992 packets Event 6: 992 packets Event 5: 992 packets Event 4: 992 packets Event 3: 992 packets Event 2: 992 packets Event 1: 140 packets --- Data Rates --- Standard Mode: Total processing time: 0.012363 seconds Full data rate: 76.8459 MB/s True data rate: 51.2306 MB/s Lazy Mode: Total processing time: 0.010127 seconds Full data rate: 93.813 MB/s True data rate: 62.542 MB/s New Performance Example: (base) jack@DESKTOP-FFN8B5L:~/cpp_projects/nalu_packet_collection_test/scripts$ ./run_test.sh Running the executable... --- General Processing Stats --- Time taken to read binary file: 0.000612517 seconds Time taken to split packets: 0.00529511 seconds Time taken to parse packets: 0.000746628 seconds --- Standard Event Collection --- Collected events: 15 Time taken to collect events (standard mode): 0.00282787 seconds Event lengths (packets per event): Event 14: 800 packets Event 13: 992 packets Event 12: 992 packets Event 11: 992 packets Event 10: 992 packets Event 9: 992 packets Event 8: 992 packets Event 7: 992 packets Event 6: 992 packets Event 5: 992 packets Event 4: 992 packets Event 3: 992 packets Event 2: 992 packets Event 1: 992 packets Event 0: 139 packets --- Lazy Mode Event Collection --- Collected events: 15 Time taken to collect events (lazy mode): 0.00103136 seconds Event lengths (packets per event): Event 15: 800 packets Event 14: 992 packets Event 13: 992 packets Event 12: 992 packets Event 11: 992 packets Event 10: 992 packets Event 9: 992 packets Event 8: 992 packets Event 7: 992 packets Event 6: 992 packets Event 5: 992 packets Event 4: 992 packets Event 3: 992 packets Event 2: 992 packets Event 1: 139 packets --- Data Rates --- Standard Mode: Total processing time: 0.00948212 seconds Full data rate: 100.186 MB/s True data rate: 66.7905 MB/s Lazy Mode: Total processing time: 0.00768562 seconds Full data rate: 123.604 MB/s True data rate: 82.4027 MB/s (base) jack@DESKTOP-FFN8B5L:~/cpp_projects/nalu_packet_collection_test/scripts$ ./run_test.sh Running the executable... --- General Processing Stats --- Time taken to read binary file: 0.000612517 seconds Time taken to split packets: 0.00529511 seconds Time taken to parse packets: 0.000746628 seconds --- Standard Event Collection --- Collected events: 15 Time taken to collect events (standard mode): 0.00282787 seconds Event lengths (packets per event): Event 14: 800 packets Event 13: 992 packets Event 12: 992 packets Event 11: 992 packets Event 10: 992 packets Event 9: 992 packets Event 8: 992 packets Event 7: 992 packets Event 6: 992 packets Event 5: 992 packets Event 4: 992 packets Event 3: 992 packets Event 2: 992 packets Event 1: 992 packets Event 0: 139 packets --- Lazy Mode Event Collection --- Collected events: 15 Time taken to collect events (lazy mode): 0.00103136 seconds Event lengths (packets per event): Event 15: 800 packets Event 14: 992 packets Event 13: 992 packets Event 12: 992 packets Event 11: 992 packets Event 10: 992 packets Event 9: 992 packets Event 8: 992 packets Event 7: 992 packets Event 6: 992 packets Event 5: 992 packets Event 4: 992 packets Event 3: 992 packets Event 2: 992 packets Event 1: 139 packets --- Data Rates --- Standard Mode: Total processing time: 0.00948212 seconds Full data rate: 100.186 MB/s True data rate: 66.7905 MB/s Lazy Mode: Total processing time: 0.00768562 seconds Full data rate: 123.604 MB/s True data rate: 82.4027 MB/s 13/02/2025 21:45 It seems there are other types of \"error byte\" sequences, take this for example: (base) jack@DESKTOP-FFN8B5L:~/cpp_projects/nalu_packet_collection_test/scripts$ ./run_test.sh Running the executable... Malformed packet at: 88366 Malformed packet length: 90 bytes Malformed packet bytes: e 0 0 bc 3 57 0 37 5 a0 5 e6 5 be 5 ea e 0 f 49 d 65 0 1d 5 d8 5 e7 5 df 5 eb 5 c2 5 d1 5 d4 5 be 5 d0 5 d2 5 ce 5 bb 5 b8 5 ba 5 c8 5 d6 5 b8 5 e2 5 d9 5 cd 5 d1 5 d1 5 d8 5 ec 5 e4 5 a4 5 ca 5 b8 5 d6 5 ce 5 d1 6 17 fa 5a Malformed packet at: 176766 Malformed packet length: 90 bytes Malformed packet bytes: e 0 0 bc 3 57 0 37 5 a0 5 e6 5 be 5 ea e 0 f 49 d 65 0 1d 5 d8 5 e7 5 df 5 eb 5 c2 5 d1 5 d4 5 be 5 d0 5 d2 5 ce 5 bb 5 b8 5 ba 5 c8 5 d6 5 b8 5 e2 5 d9 5 cd 5 d1 5 d1 5 d8 5 ec 5 e4 5 a4 5 ca 5 b8 5 d6 5 ce 5 d1 6 17 fa 5a Malformed packet at: 265166 Malformed packet length: 90 bytes Malformed packet bytes: e 0 0 bc 3 57 0 37 5 a0 5 e6 5 be 5 ea e 0 f 49 d 65 0 1d 5 d8 5 e7 5 df 5 eb 5 c2 5 d1 5 d4 5 be 5 d0 5 d2 5 ce 5 bb 5 b8 5 ba 5 c8 5 d6 5 b8 5 e2 5 d9 5 cd 5 d1 5 d1 5 d8 5 ec 5 e4 5 a4 5 ca 5 b8 5 d6 5 ce 5 d1 6 17 fa 5a Malformed packet at: 353566 Malformed packet length: 90 bytes Malformed packet bytes: e 0 0 bc 3 57 0 37 5 a0 5 e6 5 be 5 ea e 0 f 49 d 65 0 1d 5 d8 5 e7 5 df 5 eb 5 c2 5 d1 5 d4 5 be 5 d0 5 d2 5 ce 5 bb 5 b8 5 ba 5 c8 5 d6 5 b8 5 e2 5 d9 5 cd 5 d1 5 d1 5 d8 5 ec 5 e4 5 a4 5 ca 5 b8 5 d6 5 ce 5 d1 6 17 fa 5a Malformed packet at: 443018 Malformed packet length: 78 bytes Malformed packet bytes: e 0 0 c0 e 0 f 49 d 65 0 1d 5 d8 5 e7 5 df 5 eb 5 c2 5 d1 5 d4 5 be 5 d0 5 d2 5 ce 5 bb 5 b8 5 ba 5 c8 5 d6 5 b8 5 e2 5 d9 5 cd 5 d1 5 d1 5 d8 5 ec 5 e4 5 a4 5 ca 5 b8 5 d6 5 ce 5 d1 6 17 fa 5a Malformed packet at: 532458 Malformed packet length: 78 bytes Malformed packet bytes: e 0 0 c0 e 0 f 49 d 65 0 1d 5 d8 5 e7 5 df 5 eb 5 c2 5 d1 5 d4 5 be 5 d0 5 d2 5 ce 5 bb 5 b8 5 ba 5 c8 5 d6 5 b8 5 e2 5 d9 5 cd 5 d1 5 d1 5 d8 5 ec 5 e4 5 a4 5 ca 5 b8 5 d6 5 ce 5 d1 6 17 fa 5a Malformed packet at: 621898 Malformed packet length: 78 bytes Malformed packet bytes: e 0 0 c0 e 0 f 49 d 65 0 1d 5 d8 5 e7 5 df 5 eb 5 c2 5 d1 5 d4 5 be 5 d0 5 d2 5 ce 5 bb 5 b8 5 ba 5 c8 5 d6 5 b8 5 e2 5 d9 5 cd 5 d1 5 d1 5 d8 5 ec 5 e4 5 a4 5 ca 5 b8 5 d6 5 ce 5 d1 6 17 fa 5a Malformed packet at: 711338 Malformed packet length: 78 bytes Malformed packet bytes: e 0 0 c0 e 0 f 49 d 65 0 1d 5 d8 5 e7 5 df 5 eb 5 c2 5 d1 5 d4 5 be 5 d0 5 d2 5 ce 5 bb 5 b8 5 ba 5 c8 5 d6 5 b8 5 e2 5 d9 5 cd 5 d1 5 d1 5 d8 5 ec 5 e4 5 a4 5 ca 5 b8 5 d6 5 ce 5 d1 6 17 fa 5a Malformed packet at: 800778 Malformed packet length: 78 bytes Malformed packet bytes: e 0 0 c0 e 0 f 49 d 65 0 1d 5 d8 5 e7 5 df 5 eb 5 c2 5 d1 5 d4 5 be 5 d0 5 d2 5 ce 5 bb 5 b8 5 ba 5 c8 5 d6 5 b8 5 e2 5 d9 5 cd 5 d1 5 d1 5 d8 5 ec 5 e4 5 a4 5 ca 5 b8 5 d6 5 ce 5 d1 6 17 fa 5a Malformed packet at: 890218 Malformed packet length: 78 bytes Malformed packet bytes: e 0 0 c0 e 0 f 49 d 65 0 1d 5 d8 5 e7 5 df 5 eb 5 c2 5 d1 5 d4 5 be 5 d0 5 d2 5 ce 5 bb 5 b8 5 ba 5 c8 5 d6 5 b8 5 e2 5 d9 5 cd 5 d1 5 d1 5 d8 5 ec 5 e4 5 a4 5 ca 5 b8 5 d6 5 ce 5 d1 6 17 fa 5a Malformed packet at: 979658 Malformed packet length: 78 bytes Malformed packet bytes: e 0 0 c0 e 0 f 49 d 65 0 1d 5 d8 5 e7 5 df 5 eb 5 c2 5 d1 5 d4 5 be 5 d0 5 d2 5 ce 5 bb 5 b8 5 ba 5 c8 5 d6 5 b8 5 e2 5 d9 5 cd 5 d1 5 d1 5 d8 5 ec 5 e4 5 a4 5 ca 5 b8 5 d6 5 ce 5 d1 6 17 fa 5a (base) jack@DESKTOP-FFN8B5L:~/cpp_projects/nalu_packet_collection_test/scripts$ ./run_test.sh Running the executable... Malformed packet at: 88366 Malformed packet length: 90 bytes Malformed packet bytes: e 0 0 bc 3 57 0 37 5 a0 5 e6 5 be 5 ea e 0 f 49 d 65 0 1d 5 d8 5 e7 5 df 5 eb 5 c2 5 d1 5 d4 5 be 5 d0 5 d2 5 ce 5 bb 5 b8 5 ba 5 c8 5 d6 5 b8 5 e2 5 d9 5 cd 5 d1 5 d1 5 d8 5 ec 5 e4 5 a4 5 ca 5 b8 5 d6 5 ce 5 d1 6 17 fa 5a Malformed packet at: 176766 Malformed packet length: 90 bytes Malformed packet bytes: e 0 0 bc 3 57 0 37 5 a0 5 e6 5 be 5 ea e 0 f 49 d 65 0 1d 5 d8 5 e7 5 df 5 eb 5 c2 5 d1 5 d4 5 be 5 d0 5 d2 5 ce 5 bb 5 b8 5 ba 5 c8 5 d6 5 b8 5 e2 5 d9 5 cd 5 d1 5 d1 5 d8 5 ec 5 e4 5 a4 5 ca 5 b8 5 d6 5 ce 5 d1 6 17 fa 5a Malformed packet at: 265166 Malformed packet length: 90 bytes Malformed packet bytes: e 0 0 bc 3 57 0 37 5 a0 5 e6 5 be 5 ea e 0 f 49 d 65 0 1d 5 d8 5 e7 5 df 5 eb 5 c2 5 d1 5 d4 5 be 5 d0 5 d2 5 ce 5 bb 5 b8 5 ba 5 c8 5 d6 5 b8 5 e2 5 d9 5 cd 5 d1 5 d1 5 d8 5 ec 5 e4 5 a4 5 ca 5 b8 5 d6 5 ce 5 d1 6 17 fa 5a Malformed packet at: 353566 Malformed packet length: 90 bytes Malformed packet bytes: e 0 0 bc 3 57 0 37 5 a0 5 e6 5 be 5 ea e 0 f 49 d 65 0 1d 5 d8 5 e7 5 df 5 eb 5 c2 5 d1 5 d4 5 be 5 d0 5 d2 5 ce 5 bb 5 b8 5 ba 5 c8 5 d6 5 b8 5 e2 5 d9 5 cd 5 d1 5 d1 5 d8 5 ec 5 e4 5 a4 5 ca 5 b8 5 d6 5 ce 5 d1 6 17 fa 5a Malformed packet at: 443018 Malformed packet length: 78 bytes Malformed packet bytes: e 0 0 c0 e 0 f 49 d 65 0 1d 5 d8 5 e7 5 df 5 eb 5 c2 5 d1 5 d4 5 be 5 d0 5 d2 5 ce 5 bb 5 b8 5 ba 5 c8 5 d6 5 b8 5 e2 5 d9 5 cd 5 d1 5 d1 5 d8 5 ec 5 e4 5 a4 5 ca 5 b8 5 d6 5 ce 5 d1 6 17 fa 5a Malformed packet at: 532458 Malformed packet length: 78 bytes Malformed packet bytes: e 0 0 c0 e 0 f 49 d 65 0 1d 5 d8 5 e7 5 df 5 eb 5 c2 5 d1 5 d4 5 be 5 d0 5 d2 5 ce 5 bb 5 b8 5 ba 5 c8 5 d6 5 b8 5 e2 5 d9 5 cd 5 d1 5 d1 5 d8 5 ec 5 e4 5 a4 5 ca 5 b8 5 d6 5 ce 5 d1 6 17 fa 5a Malformed packet at: 621898 Malformed packet length: 78 bytes Malformed packet bytes: e 0 0 c0 e 0 f 49 d 65 0 1d 5 d8 5 e7 5 df 5 eb 5 c2 5 d1 5 d4 5 be 5 d0 5 d2 5 ce 5 bb 5 b8 5 ba 5 c8 5 d6 5 b8 5 e2 5 d9 5 cd 5 d1 5 d1 5 d8 5 ec 5 e4 5 a4 5 ca 5 b8 5 d6 5 ce 5 d1 6 17 fa 5a Malformed packet at: 711338 Malformed packet length: 78 bytes Malformed packet bytes: e 0 0 c0 e 0 f 49 d 65 0 1d 5 d8 5 e7 5 df 5 eb 5 c2 5 d1 5 d4 5 be 5 d0 5 d2 5 ce 5 bb 5 b8 5 ba 5 c8 5 d6 5 b8 5 e2 5 d9 5 cd 5 d1 5 d1 5 d8 5 ec 5 e4 5 a4 5 ca 5 b8 5 d6 5 ce 5 d1 6 17 fa 5a Malformed packet at: 800778 Malformed packet length: 78 bytes Malformed packet bytes: e 0 0 c0 e 0 f 49 d 65 0 1d 5 d8 5 e7 5 df 5 eb 5 c2 5 d1 5 d4 5 be 5 d0 5 d2 5 ce 5 bb 5 b8 5 ba 5 c8 5 d6 5 b8 5 e2 5 d9 5 cd 5 d1 5 d1 5 d8 5 ec 5 e4 5 a4 5 ca 5 b8 5 d6 5 ce 5 d1 6 17 fa 5a Malformed packet at: 890218 Malformed packet length: 78 bytes Malformed packet bytes: e 0 0 c0 e 0 f 49 d 65 0 1d 5 d8 5 e7 5 df 5 eb 5 c2 5 d1 5 d4 5 be 5 d0 5 d2 5 ce 5 bb 5 b8 5 ba 5 c8 5 d6 5 b8 5 e2 5 d9 5 cd 5 d1 5 d1 5 d8 5 ec 5 e4 5 a4 5 ca 5 b8 5 d6 5 ce 5 d1 6 17 fa 5a Malformed packet at: 979658 Malformed packet length: 78 bytes Malformed packet bytes: e 0 0 c0 e 0 f 49 d 65 0 1d 5 d8 5 e7 5 df 5 eb 5 c2 5 d1 5 d4 5 be 5 d0 5 d2 5 ce 5 bb 5 b8 5 ba 5 c8 5 d6 5 b8 5 e2 5 d9 5 cd 5 d1 5 d1 5 d8 5 ec 5 e4 5 a4 5 ca 5 b8 5 d6 5 ce 5 d1 6 17 fa 5a There are two error cases here: Extra byte sequence: e 0 0 bc 3 57 0 37 5 a0 5 e6 5 be 5 ea at the begininning Extra byte sequence e 0 0 bc at the beginning We can correct this by additionally scrubbing for these, but it seems like an exercise in futility if I can't identify every possible error... 13/02/2025 21:50 Here's an additional malformed packet where I have no idea what's wrong Malformed packet at: 629116 Malformed packet length: 140 bytes Malformed packet bytes: e 0 f b 9 1 0 2e 6 6 5 b8 5 c2 5 e6 5 d8 5 ee 5 e5 5 e4 5 d5 5 e2 5 d8 5 da 5 b8 5 d3 5 b1 5 c5 5 c7 5 d5 5 d3 5 c4 5 fd 5 f2 5 bd 5 ee 5 d4 5 e7 5 dc 5 d2 5 d7 e 0 d b1 c c9 0 1 5 d6 5 ee 5 e2 5 eb 5 e0 5 e9 5 ca 5 c9 5 ce 5 d2 5 dd 5 ea 5 c2 5 c4 5 db 5 ee 5 dc 5 fe 5 e0 5 d6 5 d4 5 d1 5 f2 5 f6 5 f0 5 fd 5 d0 5 d6 5 f0 5 ec 5 e2 6 8 fa 5a Malformed packet at: 629116 Malformed packet length: 140 bytes Malformed packet bytes: e 0 f b 9 1 0 2 e 6 6 5 b8 5 c2 5 e6 5 d8 5 ee 5 e5 5 e4 5 d5 5 e2 5 d8 5 da 5 b8 5 d3 5 b1 5 c5 5 c7 5 d5 5 d3 5 c4 5 fd 5 f2 5 bd 5 ee 5 d4 5 e7 5 dc 5 d2 5 d7 e 0 d b1 c c9 0 1 5 d6 5 ee 5 e2 5 eb 5 e0 5 e9 5 ca 5 c9 5 ce 5 d2 5 dd 5 ea 5 c2 5 c4 5 db 5 ee 5 dc 5 fe 5 e0 5 d6 5 d4 5 d1 5 f2 5 f6 5 f0 5 fd 5 d0 5 d6 5 f0 5 ec 5 e2 6 8 fa 5 a These additional cases 13/02/2025 22:15 I think I was able to get around bytes being jammed in between packets with this function void handle_scrubbed_segment(std::vector<uint8_t>& scrubbed_segment, std::vector<std::vector<uint8_t>>& packets, size_t error_packet_start, size_t expected_size, uint8_t start_marker) { // Compute the start index where the expected start word should be size_t start_index = scrubbed_segment.size() - expected_size; // Check if the start word is present at the computed start index if (scrubbed_segment[start_index] == start_marker) { packets.emplace_back(scrubbed_segment.begin() + start_index, scrubbed_segment.end()); return; } // Handle malformed packet case std::cerr << \"Malformed packet at: \" << error_packet_start << \"\\nMalformed packet length: \" << scrubbed_segment.size() << \" bytes\" << \"\\nMalformed packet bytes: \"; // Use a single loop with a range-based for and output formatting for (uint8_t byte : scrubbed_segment) { std::cerr << std::hex << static_cast<int>(byte) << \" \"; } std::cerr << std::dec << std::endl; // Reset to decimal } void handle_scrubbed_segment(std::vector<uint8_t>& scrubbed_segment, std::vector<std::vector<uint8_t>>& packets, size_t error_packet_start, size_t expected_size, uint8_t start_marker) { // Compute the start index where the expected start word should be size_t start_index = scrubbed_segment.size() - expected_size; // Check if the start word is present at the computed start index if (scrubbed_segment[start_index] == start_marker) { packets.emplace_back(scrubbed_segment.begin() + start_index, scrubbed_segment.end()); return; } // Handle malformed packet case std::cerr << \"Malformed packet at: \" << error_packet_start << \"\\nMalformed packet length: \" << scrubbed_segment.size() << \" bytes\" << \"\\nMalformed packet bytes: \"; // Use a single loop with a range-based for and output formatting for (uint8_t byte : scrubbed_segment) { std::cerr << std::hex << static_cast<int>(byte) << \" \"; } std::cerr << std::dec << std::endl; // Reset to decimal } Basically after scrubbing, we just return the 74 (or packet size) bytes that correspond to the packet. I.e. any extra bytes at the beginning of the \"packet\" are ignored. 13/02/2025 22:21 In one of my files, there is a packet that is repeated, but doesn't get matched to any event (perhaps there's another copy somewhere actually in an event?) Sample Incorrect Events: Event 272 (1 packets): Packet 0 { Ch: 0, Time: 15776001, Logical: 0, Physical: 45, Index: 16741, Samples: [ Samples: [ 1543, 1515, 1496, 1526, 1530, 1522, 1512, 1520, 1524, 1525, 1506, 1516, 1497, 1493, 1483, 1488, 1516, 1533, 1519, 1488, 1511, 1487, 1512, 1518, 1516, 1489, 1524, 1467, 1472, 1491, 1480, 1521 ], Footer: [ 250, 90 ] } Event 136 (1 packets): Packet 0 { Ch: 0, Time: 15776001, Logical: 0, Physical: 45, Index: 8370, Samples: [ Samples: [ 1543, 1515, 1496, 1526, 1530, 1522, 1512, 1520, 1524, 1525, 1506, 1516, 1497, 1493, 1483, 1488, 1516, 1533, 1519, 1488, 1511, 1487, 1512, 1518, 1516, 1489, 1524, 1467, 1472, 1491, 1480, 1521 ], Footer: [ 250, 90 ] } Sample Incorrect Events: Event 272 (1 packets): Packet 0 { Ch: 0 , Time: 15776001 , Logical: 0 , Physical: 45 , Index: 16741 , Samples: [ Samples: [ 1543 , 1515 , 1496 , 1526 , 1530 , 1522 , 1512 , 1520 , 1524 , 1525 , 1506 , 1516 , 1497 , 1493 , 1483 , 1488 , 1516 , 1533 , 1519 , 1488 , 1511 , 1487 , 1512 , 1518 , 1516 , 1489 , 1524 , 1467 , 1472 , 1491 , 1480 , 1521 ], Footer: [ 250 , 90 ] } Event 136 (1 packets): Packet 0 { Ch: 0 , Time: 15776001 , Logical: 0 , Physical: 45 , Index: 8370 , Samples: [ Samples: [ 1543 , 1515 , 1496 , 1526 , 1530 , 1522 , 1512 , 1520 , 1524 , 1525 , 1506 , 1516 , 1497 , 1493 , 1483 , 1488 , 1516 , 1533 , 1519 , 1488 , 1511 , 1487 , 1512 , 1518 , 1516 , 1489 , 1524 , 1467 , 1472 , 1491 , 1480 , 1521 ], Footer: [ 250 , 90 ] } The index here shows that they were processed over 8000 packets away from each other, so there is no expected reason they're duplicate like that. Once I build the full collector class, this will be the type of events to be binned in \"errors\" somehow. 13/02/2025 22:38 If the error correcting could somehow be avoided, I could probably speed things up by a factor of 2; i.e. the collector would be the bottleneck. But for now we'll have to settle for ~100 MB/s. 15/02/2025 17:54 I was a bit suspicious adding an error code may slow things down, so I tested. Basically, testing the difference between doing something like: uint8_t error_code = 0; // Calculate or assign the error code // Create a vector with space for the error code + packet data std::vector<uint8_t> packet_data(packet_size + 1); // Set the error code at the beginning packet_data[0] = error_code; // Copy the packet data into the remaining space std::memcpy(packet_data.data() + 1, processed_stream.data() + start_index, packet_size); // Emplace the packet with the error code at the beginning packets.emplace_back(std::move(packet_data)); uint8_t error_code = 0 ; // Calculate or assign the error code // Create a vector with space for the error code + packet data std::vector< uint8_t > packet_data (packet_size + 1 ) ; // Set the error code at the beginning packet_data[ 0 ] = error_code; // Copy the packet data into the remaining space std:: memcpy (packet_data. data () + 1 , processed_stream. data () + start_index, packet_size); // Emplace the packet with the error code at the beginning packets. emplace_back (std:: move (packet_data)); versus: packets.emplace_back(processed_stream.begin() + start_index, processed_stream.begin() + i + 2); packets.emplace_back(processed_stream. begin () + start_index, processed_stream. begin () + i + 2 ); Error code appending (two tests): 1. --- General Processing Stats --- Time taken to read binary file: 0.000748234 seconds Time taken to split packets: 0.00657799 seconds Time taken to parse packets: 0.000870217 seconds --- Data Rates --- Standard Mode: Total processing time: 0.0118354 seconds Full data rate: 97.131 MB/s True data rate: 64.754 MB/s Lazy Mode: Total processing time: 0.00944776 seconds Full data rate: 121.678 MB/s True data rate: 81.1185 MB/s 2. --- General Processing Stats --- Time taken to read binary file: 0.000839936 seconds Time taken to split packets: 0.0070777 seconds Time taken to parse packets: 0.00091615 seconds --- Data Rates --- Standard Mode: Total processing time: 0.0125845 seconds Full data rate: 91.3487 MB/s True data rate: 60.8992 MB/s Lazy Mode: Total processing time: 0.0101386 seconds Full data rate: 113.387 MB/s True data rate: 75.5913 MB/s 1. --- General Processing Stats --- Time taken to read binary file : 0.000748234 seconds Time taken to split packets: 0.00657799 seconds Time taken to parse packets: 0.000870217 seconds --- Data Rates --- Standard Mode: Total processing time : 0.0118354 seconds Full data rate: 97.131 MB/s True data rate: 64.754 MB/s Lazy Mode: Total processing time : 0.00944776 seconds Full data rate: 121.678 MB/s True data rate: 81.1185 MB/s 2. --- General Processing Stats --- Time taken to read binary file : 0.000839936 seconds Time taken to split packets: 0.0070777 seconds Time taken to parse packets: 0.00091615 seconds --- Data Rates --- Standard Mode: Total processing time : 0.0125845 seconds Full data rate: 91.3487 MB/s True data rate: 60.8992 MB/s Lazy Mode: Total processing time : 0.0101386 seconds Full data rate: 113.387 MB/s True data rate: 75.5913 MB/s Not appending error codes (two tests): 1. --- General Processing Stats --- Time taken to read binary file: 0.0015994 seconds Time taken to split packets: 0.00754936 seconds Time taken to parse packets: 0.0011617 seconds --- Data Rates --- Standard Mode: Total processing time: 0.0142625 seconds Full data rate: 80.6016 MB/s True data rate: 53.7344 MB/s Lazy Mode: Total processing time: 0.0116362 seconds Full data rate: 98.7939 MB/s True data rate: 65.8626 MB/s 2. --- General Processing Stats --- Time taken to read binary file: 0.000951511 seconds Time taken to split packets: 0.00735596 seconds Time taken to parse packets: 0.00112426 seconds --- Data Rates --- Standard Mode: Total processing time: 0.0133406 seconds Full data rate: 86.1719 MB/s True data rate: 57.448 MB/s Lazy Mode: Total processing time: 0.0108559 seconds Full data rate: 105.895 MB/s True data rate: 70.5964 MB/s 1. --- General Processing Stats --- Time taken to read binary file : 0.0015994 seconds Time taken to split packets: 0.00754936 seconds Time taken to parse packets: 0.0011617 seconds --- Data Rates --- Standard Mode: Total processing time : 0.0142625 seconds Full data rate: 80.6016 MB/s True data rate: 53.7344 MB/s Lazy Mode: Total processing time : 0.0116362 seconds Full data rate: 98.7939 MB/s True data rate: 65.8626 MB/s 2. --- General Processing Stats --- Time taken to read binary file : 0.000951511 seconds Time taken to split packets: 0.00735596 seconds Time taken to parse packets: 0.00112426 seconds --- Data Rates --- Standard Mode: Total processing time : 0.0133406 seconds Full data rate: 86.1719 MB/s True data rate: 57.448 MB/s Lazy Mode: Total processing time : 0.0108559 seconds Full data rate: 105.895 MB/s True data rate: 70.5964 MB/s In conclusion, it doesn't appear adding the error code causes any slowdown.",
    "textLength": 8538
  },
  {
    "kind": "work-log",
    "title": "03_03_2024 - 09_03_2024.html",
    "fileName": "03_03_2024 - 09_03_2024.html",
    "url": "resources/work_logs/03_03_2024 - 09_03_2024.html",
    "createdDate": "2024-03-03",
    "text": "03/03/2024 - 09/03/2024 03/03/2024 - 09/03/2024 06/03/2024 13:13 Tim was able to get scripts to work using the -m flag with argument 0x20 . Somehow this specifies a local address, from https://linux.die.net/man/1/ipmitool: -m <local_address> Set the local IPMB address. The default is 0x20 and there should be no need to change it for normal operation. This is very confusing because it should be 0x20 by default, without needing to specify with the -m flag, but here we are I guess. Example where we set the IPs for the two FPGAs on the AMC13 module: [root@dhcp-10-163-105-238 amc13Config]# ./readIPs.py --slot 13 Reading IP addresses of board in slot 13 from host 192.168.1.41 T2 IP Bytes: ipmitool -H 192.168.1.41 -U '' -P '' -m 0x20 -B 0 -T 0x82 -b 7 -t 0xa4 raw 0x32 0x34 0 11 0 4 ['c0', 'a8', '1a', '0a'] [192, 168, 26, 10] T1 IP Bytes: ipmitool -H 192.168.1.41 -U '' -P '' -m 0x20 -B 0 -T 0x82 -b 7 -t 0xa4 raw 0x32 0x34 1 11 0 4 ['c0', 'a8', '1a', '0b'] [192, 168, 26, 11] [root@dhcp-10-163-105-238 amc13Config]# ./readIPs.py --slot 13 Reading IP addresses of board in slot 13 from host 192.168.1.41 T2 IP Bytes: ipmitool -H 192.168.1.41 -U '' -P '' -m 0x20 -B 0 -T 0x82 -b 7 -t 0xa4 raw 0x32 0x34 0 11 0 4 [ 'c0' , 'a8' , '1a' , '0a' ] [192, 168, 26, 10] T1 IP Bytes: ipmitool -H 192.168.1.41 -U '' -P '' -m 0x20 -B 0 -T 0x82 -b 7 -t 0xa4 raw 0x32 0x34 1 11 0 4 [ 'c0' , 'a8' , '1a' , '0b' ] [192, 168, 26, 11] And pinging afterwards: [root@dhcp-10-163-105-238 amc13Config]# ping 192.168.26.10 PING 192.168.26.10 (192.168.26.10) 56(84) bytes of data. 64 bytes from 192.168.26.10: icmp_seq=1 ttl=64 time=0.190 ms 64 bytes from 192.168.26.10: icmp_seq=2 ttl=64 time=0.132 ms [root@dhcp-10-163-105-238 amc13Config]# ping 192.168.26.11 PING 192.168.26.11 (192.168.26.11) 56(84) bytes of data. 64 bytes from 192.168.26.11: icmp_seq=1 ttl=64 time=0.178 ms 64 bytes from 192.168.26.11: icmp_seq=2 ttl=64 time=0.089 ms [root@dhcp-10-163-105-238 amc13Config]# ping 192.168.26.10 PING 192.168.26.10 (192.168.26.10) 56(84) bytes of data. 64 bytes from 192.168.26.10: icmp_seq =1 ttl =64 time =0.190 ms 64 bytes from 192.168.26.10: icmp_seq =2 ttl =64 time =0.132 ms [root@dhcp-10-163-105-238 amc13Config]# ping 192.168.26.11 PING 192.168.26.11 (192.168.26.11) 56(84) bytes of data. 64 bytes from 192.168.26.11: icmp_seq =1 ttl =64 time =0.178 ms 64 bytes from 192.168.26.11: icmp_seq =2 ttl =64 time =0.089 ms 06/03/2024 13:17 There's a makefile in here [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# pwd /home/installation_testing/packages/experiment/lxedaq/amc13/amc13StandaloneMAN_2014-05-12 [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# ls amc13Config AMC13T2v0x0021_6slx25t.mcs lib map uhalEnv.csh amc13_mcs AMC13T2v0x0026_6slx25t.mcs log obj uhalEnv.sh amc13_scripts AMC13T2v0x0026_6slx45t.mcs Makefile README.txt uhalEnv.sh.backup AMC13T1v0x810b_7k325t.mcs bin Makefile.18May2014 save_Makefile AMC13T1v0x811f_7k325t.mcs include Makefile.before18May2014 src [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# [root@dhcp -10 -163 -105 -238 amc13StandaloneMAN_2014 -05 -12 ]# pwd /home/installation_testing/packages/experiment/lxedaq/amc13/amc13StandaloneMAN_2014 -05 -12 [root@dhcp -10 -163 -105 -238 amc13StandaloneMAN_2014 -05 -12 ]# ls amc13Config AMC13T2v0x0021_6slx25t.mcs lib map uhalEnv.csh amc13_mcs AMC13T2v0x0026_6slx25t.mcs log obj uhalEnv.sh amc13_scripts AMC13T2v0x0026_6slx45t.mcs Makefile README.txt uhalEnv.sh.backup AMC13T1v0x810b_7k325t.mcs bin Makefile.18May2014 save_Makefile AMC13T1v0x811f_7k325t.mcs include Makefile.before18May2014 src [root@dhcp -10 -163 -105 -238 amc13StandaloneMAN_2014 -05 -12 ]# That creates a bin folder and builds one of the targets \"AMC13Tool\". I was able to get it to make by editting the makefile by changing some lines; I added BOOST_ROOT and PUGIXML_ROOT to the include path, as well as to the library path. I swapped out the external pugi root used in cactus for the normal pugi root flag -lpugixml . These choices were made after debugging, I'm sure some other environment could be setup to make it work as \"standard\". ... INCLUDE_PATH = \\ -Iinclude \\ -I${CACTUS_ROOT}/include \\ -I${ROOTSYS}/usr/include \\ -I${BOOST_ROOT}/include \\ -I${PUGIXML_ROOT}/include LIBNAME = uhalamc13 LIBRARY = lib/lib${LIBNAME}.so LIBRARY_SOURCES = $(wildcard src/common/*.cc) LIBRARY_OBJECT_FILES = $(patsubst src/common/%.cc,obj/%.o,${LIBRARY_SOURCES}) EXECUTABLE_SOURCES = $(wildcard src/common/*.cxx) EXECUTABLE_OBJECT_FILES = $(patsubst src/common/%.cxx,obj/%.o,${EXECUTABLE_SOURCES}) EXECUTABLES = $(patsubst src/common/%.cxx,bin/%,${EXECUTABLE_SOURCES}) LIBRARY_PATH = \\ -L${CACTUS_ROOT}/lib \\ -L${AMC13_ROOT}/lib \\ -L/lib64 \\ -L${ROOTSYS}/usr/lib64 \\ -L${ROOTSYS}/lib64 \\ -L${BOOST_ROOT}/lib \\ -I${PUGIXML_ROOT}/lib64 LIBRARIES = \\ -lpthread \\ \\ -lboost_filesystem \\ -lboost_regex \\ -lboost_system \\ -lboost_thread \\ \\ -lpugixml \\ -lcactus_uhal_log \\ -lcactus_uhal_grammars \\ -lcactus_uhal_uhal #-lcactus_extern_pugixml ... ... INCLUDE_PATH = \\ -Iinclude \\ -I${CACTUS_ROOT}/include \\ -I${ROOTSYS}/usr/include \\ -I${BOOST_ROOT}/include \\ -I${PUGIXML_ROOT}/include LIBNAME = uhalamc13 LIBRARY = lib/lib${LIBNAME}.so LIBRARY_SOURCES = $(wildcard src/common/*.cc) LIBRARY_OBJECT_FILES = $(patsubst src/common/%.cc,obj/%.o,${LIBRARY_SOURCES}) EXECUTABLE_SOURCES = $(wildcard src/common/*.cxx) EXECUTABLE_OBJECT_FILES = $(patsubst src/common/%.cxx,obj/%.o,${EXECUTABLE_SOURCES}) EXECUTABLES = $(patsubst src/common/%.cxx,bin/%,${EXECUTABLE_SOURCES}) LIBRARY_PATH = \\ -L${CACTUS_ROOT}/lib \\ -L${AMC13_ROOT}/lib \\ -L/lib64 \\ -L${ROOTSYS}/usr/lib64 \\ -L${ROOTSYS}/lib64 \\ -L${BOOST_ROOT}/lib \\ -I${PUGIXML_ROOT}/lib64 LIBRARIES = \\ -lpthread \\ \\ -lboost_filesystem \\ -lboost_regex \\ -lboost_system \\ -lboost_thread \\ \\ -lpugixml \\ -lcactus_uhal_log \\ -lcactus_uhal_grammars \\ -lcactus_uhal_uhal #-lcactus_extern_pugixml ... This requires defining some environment variables: Apply the environment variables for BOOST_ROOT and PUGIXML_ROOT to the shell session: cd /home/installation_testing/packages/experiment/gm2daq/environment_setup source setup_environment.sh cd /home/installation_testing/packages/experiment/gm2daq/environment_setup source setup_environment.sh Add the built library to the shell session's library path: export LD_LIBRARY_PATH=/home/installation_testing/packages/experiment/lxedaq/amc13/amc13StandaloneMAN_2014-05-12/lib:$LD_LIBRARY_PATH export LD_LIBRARY_PATH= /home/i nstallation_testing /packages/ experiment /lxedaq/ amc13 /amc13StandaloneMAN_2014-05-12/ lib: $LD_LIBRARY_PATH I get this error: [root@dhcp-10-163-105-238 bin]# ./AMC13Tool terminate called after throwing an instance of 'std::logic_error' what(): basic_string::_S_construct null not valid Aborted (core dumped) [root@dhcp-10-163-105-238 bin]# ./AMC13Tool -u terminate called after throwing an instance of 'std::logic_error' what(): basic_string::_S_construct null not valid Aborted (core dumped) [root@dhcp-10-163-105-238 bin]# [root@dhcp-10-163-105-238 bin] # ./AMC13Tool terminate called after throwing an instance of 'std::logic_error' what(): basic_string::_S_construct null not valid Aborted (core dumped) [root@dhcp-10-163-105-238 bin] # ./AMC13Tool -u terminate called after throwing an instance of 'std::logic_error' what(): basic_string::_S_construct null not valid Aborted (core dumped) [root@dhcp-10-163-105-238 bin] # But Tim does not: [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# bin/AMC13Tool -u Connecting to AMC13... T2 ip 192.168.1.188 T2 ip 192.168.1.188 T1 ip 192.168.1.189 T1 192.168.1.189 map/AMC13_AddressTable_K7.xml 1 0 Failed to build T1 ipDev object! [root@dhcp- 10-163-105-238 amc13StandaloneMAN_ 2014-05-12 ]# bin/AMC13Tool -u Connecting to AMC13... T2 ip 192.168.1.188 T2 ip 192.168.1.188 T1 ip 192.168.1.189 T 1 192.168.1 . 189 map/AMC13_AddressTable_K7.xml 1 0 Failed to build T1 ipDev object! It might have something to do with where the script is called, i.e. calling it a directory back might read some file or something dumb like that. 06/03/2024 13:45 Tim was able to set the WFD5 IPs (I'm sure he had to make slight edits to the script, particularly to include the -m 0x20 flag) [root@dhcp-10-163-105-238 software]# python store_ip.py 1 5 192.168.1.42 ipmitool -I lan -H 192.168.1.41 -U '' -P '' -m 0x20 -B 0x0 -T 0x82 -b 7 -t 0x7a raw 0x32 0x51 0x2a 0x01 0xa8 0xc0 [root@dhcp- 10 - 163 - 105 - 238 software]# python store_ip. py 1 5 192.168 . 1.42 ipmitool -I lan -H 192.168 . 1.41 -U '' - P '' - m 0 x20 -B 0 x0 -T 0 x82 - b 7 -t 0 x7a raw 0 x32 0 x51 0 x2a 0 x01 0 xa8 0 xc0 pull/push hotswap button on the WFD5 [root@dhcp-10-163-105-238 /]# ping 192.168.1.42 PING 192.168.1.42 (192.168.1.42) 56(84) bytes of data. 64 bytes from 192.168.1.42: icmp_seq=1 ttl=64 time=0.264 ms 64 bytes from 192.168.1.42: icmp_seq=2 ttl=64 time=0.126 ms [root@dhcp-10-163-105-238 /]# ping 192.168.1.42 PING 192.168.1.42 (192.168.1.42) 56(84) bytes of data. 64 bytes from 192.168.1.42: icmp_seq =1 ttl =64 time =0.264 ms 64 bytes from 192.168.1.42: icmp_seq =2 ttl =64 time =0.126 ms 06/03/2024 13:47 I was able to set the FC7 IPs. First, I cloned this repository from the PIONEER github: https://github.com/PIONEER-Experiment/unifiedCCC On the 'be' computer under /home/installation_testing/packages/unifiedCCC /home/i nstallation_testing /packages/u nifiedCCC I editted the script unifiedCCC/software/store_ip.py unifiedCCC /software/ store_ip.py to use the 192.168.1.41 host (instead of the 192.168.1.15 host) and added the -m 0x20 flag. I think I was able to assign an IP and ping the FC7: [root@dhcp-10-163-105-238 software]# python3 store_ip.py 1 11 192.168.1.11 ipmitool -I lan -H 192.168.1.41 -U shelf -P shelf -m 0x20 -B 0x0 -T 0x82 -b 7 -t 0x86 raw 0x30 0x03 0xc0 0xa8 0x01 0x0b ipmitool -I lan -H 192.168.1.41 -U shelf -P shelf -m 0x20 -B 0x0 -T 0x82 -b 7 -t 0x86 raw 0x30 0x01 0xFE 0xEF [root@dhcp-10-163-105-238 software]# ping 192.168.1.11 PING 192.168.1.11 (192.168.1.11) 56(84) bytes of data. 64 bytes from 192.168.1.11: icmp_seq=1 ttl=64 time=0.174 ms 64 bytes from 192.168.1.11: icmp_seq=2 ttl=64 time=0.123 ms 64 bytes from 192.168.1.11: icmp_seq=3 ttl=64 time=0.138 ms ^C --- 192.168.1.11 ping statistics --- 3 packets transmitted, 3 received, 0% packet loss, time 2000ms rtt min/avg/max/mdev = 0.123/0.145/0.174/0.021 ms [root@dhcp-10-163-105-238 software]# [root@dhcp-10-163-105-238 software]# python3 store_ip.py 1 11 192.168.1.11 ipmitool -I lan -H 192.168.1.41 -U shelf -P shelf -m 0x20 -B 0x0 -T 0x82 -b 7 -t 0x86 raw 0x30 0x03 0xc0 0xa8 0x01 0x0b ipmitool -I lan -H 192.168.1.41 -U shelf -P shelf -m 0x20 -B 0x0 -T 0x82 -b 7 -t 0x86 raw 0x30 0x01 0xFE 0xEF [root@dhcp-10-163-105-238 software]# ping 192.168.1.11 PING 192.168.1.11 (192.168.1.11) 56(84) bytes of data. 64 bytes from 192.168.1.11: icmp_seq =1 ttl =64 time =0.174 ms 64 bytes from 192.168.1.11: icmp_seq =2 ttl =64 time =0.123 ms 64 bytes from 192.168.1.11: icmp_seq =3 ttl =64 time =0.138 ms ^C --- 192.168.1.11 ping statistics --- 3 packets transmitted, 3 received, 0% packet loss, time 2000ms rtt min/avg/max/mdev = 0.123/0.145/0.174/0.021 ms [root@dhcp-10-163-105-238 software]#",
    "textLength": 1973
  },
  {
    "kind": "work-log",
    "title": "09_11_2025 - 15_11_2025.html",
    "fileName": "09_11_2025 - 15_11_2025.html",
    "url": "resources/work_logs/09_11_2025 - 15_11_2025.html",
    "createdDate": "2025-11-09",
    "text": "09/11/2025 - 15/11/2025 09/11/2025 - 15/11/2025 10/11/2025 17:41 I added these debug lines: //============================================================================== // SAMPIC256CH_ErrCode SAMPIC256CH_LoadAllCalibValuesFromFiles( CrateInfoStruct *crateInfoParams, CrateParamStruct *crateParams, char directory[MAX_PATHNAME_LENGTH]) //============================================================================== // { printf(\"[DEBUG] Entering SAMPIC256CH_LoadAllCalibValuesFromFiles()\\n\"); printf(\"[DEBUG] Calibration directory: %s\\n\", directory); SAMPIC256CH_ErrCode error = SAMPIC256CH_Success; Boolean allCalibFilesLoaded = TRUE; int feBoard, channel; Boolean allResidualPedestalsFilesLoaded = TRUE; Boolean allTimeINLFilesLoaded = TRUE; printf(\"[DEBUG] Initializing crate calibration parameters...\\n\"); Init_CrateCalibParams(crateInfoParams); printf(\"[DEBUG] Init_CrateCalibParams() done.\\n\"); strcpy(crateInfoParams->CrateCalibInfo.LastCalibDirectory, directory); printf(\"[DEBUG] Saved directory to CrateCalibInfo.LastCalibDirectory: %s\\n\", crateInfoParams->CrateCalibInfo.LastCalibDirectory); printf(\"[DEBUG] Starting calibration file reads...\\n\"); if (crateInfoParams->SystemType == SAMPET_SYSTEM) { printf(\"[DEBUG] System type = SAMPET_SYSTEM, reading ADC Ramp calib values...\\n\"); Read_ADCRampCalibValues_From_Files(crateInfoParams, crateParams, directory); } else { printf(\"[DEBUG] Reading ADC Ramp calib values...\\n\"); allCalibFilesLoaded &= Read_ADCRampCalibValues_From_Files(crateInfoParams, crateParams, directory); } printf(\"[DEBUG] Reading ADC Linearity calib values...\\n\"); allCalibFilesLoaded &= Read_ADCLinearityCalibValues_From_Files(crateInfoParams, crateParams, directory); printf(\"[DEBUG] Reading INL values...\\n\"); allCalibFilesLoaded &= Read_INLValues_From_Files(crateInfoParams, crateParams, directory); if (crateInfoParams->SystemType == SAMPET_SYSTEM) { printf(\"[DEBUG] Reading Internal Trigger Threshold Offset (SAMPET_SYSTEM mode)...\\n\"); Read_InternalTriggerThresholdOffset_From_Files(crateInfoParams, crateParams, directory); } else { printf(\"[DEBUG] Reading Internal Trigger Threshold Offset...\\n\"); allCalibFilesLoaded &= Read_InternalTriggerThresholdOffset_From_Files(crateInfoParams, crateParams, directory); } printf(\"[DEBUG] Reading TOT calib values...\\n\"); allCalibFilesLoaded &= Read_TOTCalibValues_From_Files(crateInfoParams, crateParams, directory); printf(\"[DEBUG] allCalibFilesLoaded = %s\\n\", allCalibFilesLoaded ? \"TRUE\" : \"FALSE\"); if (allCalibFilesLoaded == FALSE) error = SAMPIC256CH_AtLeastOneCalibFileNotFound; printf(\"[DEBUG] Checking channel-level calib load statuses...\\n\"); for (feBoard = 0; feBoard < crateInfoParams->NbOfFeBoards; feBoard++) { printf(\"[DEBUG] FE board %d of %d\\n\", feBoard + 1, crateInfoParams->NbOfFeBoards); for (channel = 0; channel < NB_OF_CHANNELS_IN_FE_BOARD; channel++) { if (crateInfoParams->CrateCalibInfo.CalibStatus.ResidualPedestalCalibStatus[feBoard][channel].CalibStatus == CALIB_VALUES_NOT_LOADED) { printf(\"[DEBUG] Residual pedestal not loaded for FE %d, channel %d\\n\", feBoard, channel); allResidualPedestalsFilesLoaded = FALSE; } } for (channel = 0; channel < NB_OF_CHANNELS_IN_FE_BOARD; channel++) { if (crateInfoParams->CrateCalibInfo.CalibStatus.TimeINLCalibStatus[feBoard][channel].CalibStatus == CALIB_VALUES_NOT_LOADED) { printf(\"[DEBUG] Time INL not loaded for FE %d, channel %d\\n\", feBoard, channel); allTimeINLFilesLoaded = FALSE; } } } printf(\"[DEBUG] ADC linearity crate calib status: %s\\n\", crateInfoParams->CrateCalibInfo.CalibStatus.ADCLinearityCrateCalibStatus.CalibStatus == CALIB_VALUES_LOADED_FROM_FILE ? \"LOADED\" : \"NOT LOADED\"); if (crateInfoParams->CrateCalibInfo.CalibStatus.ADCLinearityCrateCalibStatus.CalibStatus == CALIB_VALUES_LOADED_FROM_FILE) { crateParams->CommonParams.ADCLinearityCorrection = TRUE; } else { crateParams->CommonParams.ADCLinearityCorrection = FALSE; } if (allResidualPedestalsFilesLoaded == TRUE) crateParams->CommonParams.ResidualPedestalCorrection = TRUE; else crateParams->CommonParams.ResidualPedestalCorrection = FALSE; if (allTimeINLFilesLoaded == TRUE) crateParams->CommonParams.INLCorrection = TRUE; else crateParams->CommonParams.INLCorrection = FALSE; printf(\"[DEBUG] Summary:\\n\"); printf(\" allCalibFilesLoaded = %s\\n\", allCalibFilesLoaded ? \"TRUE\" : \"FALSE\"); printf(\" allResidualPedestalsFilesLoaded = %s\\n\", allResidualPedestalsFilesLoaded ? \"TRUE\" : \"FALSE\"); printf(\" allTimeINLFilesLoaded = %s\\n\", allTimeINLFilesLoaded ? \"TRUE\" : \"FALSE\"); printf(\" ADCLinearityCorrection = %s\\n\", crateParams->CommonParams.ADCLinearityCorrection ? \"TRUE\" : \"FALSE\"); printf(\" ResidualPedestalCorrection = %s\\n\", crateParams->CommonParams.ResidualPedestalCorrection ? \"TRUE\" : \"FALSE\"); printf(\" INLCorrection = %s\\n\", crateParams->CommonParams.INLCorrection ? \"TRUE\" : \"FALSE\"); printf(\" Return code: %d\\n\", error); printf(\"[DEBUG] Leaving SAMPIC256CH_LoadAllCalibValuesFromFiles()\\n\"); return error; } //============================================================================== // SAMPIC256CH_ErrCode SAMPIC256CH_LoadAllCalibValuesFromFiles ( CrateInfoStruct *crateInfoParams, CrateParamStruct *crateParams, char directory[MAX_PATHNAME_LENGTH]) //============================================================================== // { printf ( \"[DEBUG] Entering SAMPIC256CH_LoadAllCalibValuesFromFiles()\\n\" ); printf ( \"[DEBUG] Calibration directory: %s\\n\" , directory); SAMPIC256CH_ErrCode error = SAMPIC256CH_Success; Boolean allCalibFilesLoaded = TRUE; int feBoard, channel; Boolean allResidualPedestalsFilesLoaded = TRUE; Boolean allTimeINLFilesLoaded = TRUE; printf ( \"[DEBUG] Initializing crate calibration parameters...\\n\" ); Init_CrateCalibParams (crateInfoParams); printf ( \"[DEBUG] Init_CrateCalibParams() done.\\n\" ); strcpy (crateInfoParams->CrateCalibInfo.LastCalibDirectory, directory); printf ( \"[DEBUG] Saved directory to CrateCalibInfo.LastCalibDirectory: %s\\n\" , crateInfoParams->CrateCalibInfo.LastCalibDirectory); printf ( \"[DEBUG] Starting calibration file reads...\\n\" ); if (crateInfoParams->SystemType == SAMPET_SYSTEM) { printf ( \"[DEBUG] System type = SAMPET_SYSTEM, reading ADC Ramp calib values...\\n\" ); Read_ADCRampCalibValues_From_Files (crateInfoParams, crateParams, directory); } else { printf ( \"[DEBUG] Reading ADC Ramp calib values...\\n\" ); allCalibFilesLoaded &= Read_ADCRampCalibValues_From_Files (crateInfoParams, crateParams, directory); } printf ( \"[DEBUG] Reading ADC Linearity calib values...\\n\" ); allCalibFilesLoaded &= Read_ADCLinearityCalibValues_From_Files (crateInfoParams, crateParams, directory); printf ( \"[DEBUG] Reading INL values...\\n\" ); allCalibFilesLoaded &= Read_INLValues_From_Files (crateInfoParams, crateParams, directory); if (crateInfoParams->SystemType == SAMPET_SYSTEM) { printf ( \"[DEBUG] Reading Internal Trigger Threshold Offset (SAMPET_SYSTEM mode)...\\n\" ); Read_InternalTriggerThresholdOffset_From_Files (crateInfoParams, crateParams, directory); } else { printf ( \"[DEBUG] Reading Internal Trigger Threshold Offset...\\n\" ); allCalibFilesLoaded &= Read_InternalTriggerThresholdOffset_From_Files (crateInfoParams, crateParams, directory); } printf ( \"[DEBUG] Reading TOT calib values...\\n\" ); allCalibFilesLoaded &= Read_TOTCalibValues_From_Files (crateInfoParams, crateParams, directory); printf ( \"[DEBUG] allCalibFilesLoaded = %s\\n\" , allCalibFilesLoaded ? \"TRUE\" : \"FALSE\" ); if (allCalibFilesLoaded == FALSE) error = SAMPIC256CH_AtLeastOneCalibFileNotFound; printf ( \"[DEBUG] Checking channel-level calib load statuses...\\n\" ); for (feBoard = 0 ; feBoard < crateInfoParams->NbOfFeBoards; feBoard++) { printf ( \"[DEBUG] FE board %d of %d\\n\" , feBoard + 1 , crateInfoParams->NbOfFeBoards); for (channel = 0 ; channel < NB_OF_CHANNELS_IN_FE_BOARD; channel++) { if (crateInfoParams->CrateCalibInfo.CalibStatus.ResidualPedestalCalibStatus[feBoard][channel].CalibStatus == CALIB_VALUES_NOT_LOADED) { printf ( \"[DEBUG] Residual pedestal not loaded for FE %d, channel %d\\n\" , feBoard, channel); allResidualPedestalsFilesLoaded = FALSE; } } for (channel = 0 ; channel < NB_OF_CHANNELS_IN_FE_BOARD; channel++) { if (crateInfoParams->CrateCalibInfo.CalibStatus.TimeINLCalibStatus[feBoard][channel].CalibStatus == CALIB_VALUES_NOT_LOADED) { printf ( \"[DEBUG] Time INL not loaded for FE %d, channel %d\\n\" , feBoard, channel); allTimeINLFilesLoaded = FALSE; } } } printf ( \"[DEBUG] ADC linearity crate calib status: %s\\n\" , crateInfoParams->CrateCalibInfo.CalibStatus.ADCLinearityCrateCalibStatus.CalibStatus == CALIB_VALUES_LOADED_FROM_FILE ? \"LOADED\" : \"NOT LOADED\" ); if (crateInfoParams->CrateCalibInfo.CalibStatus.ADCLinearityCrateCalibStatus.CalibStatus == CALIB_VALUES_LOADED_FROM_FILE) { crateParams->CommonParams.ADCLinearityCorrection = TRUE; } else { crateParams->CommonParams.ADCLinearityCorrection = FALSE; } if (allResidualPedestalsFilesLoaded == TRUE) crateParams->CommonParams.ResidualPedestalCorrection = TRUE; else crateParams->CommonParams.ResidualPedestalCorrection = FALSE; if (allTimeINLFilesLoaded == TRUE) crateParams->CommonParams.INLCorrection = TRUE; else crateParams->CommonParams.INLCorrection = FALSE; printf ( \"[DEBUG] Summary:\\n\" ); printf ( \" allCalibFilesLoaded = %s\\n\" , allCalibFilesLoaded ? \"TRUE\" : \"FALSE\" ); printf ( \" allResidualPedestalsFilesLoaded = %s\\n\" , allResidualPedestalsFilesLoaded ? \"TRUE\" : \"FALSE\" ); printf ( \" allTimeINLFilesLoaded = %s\\n\" , allTimeINLFilesLoaded ? \"TRUE\" : \"FALSE\" ); printf ( \" ADCLinearityCorrection = %s\\n\" , crateParams->CommonParams.ADCLinearityCorrection ? \"TRUE\" : \"FALSE\" ); printf ( \" ResidualPedestalCorrection = %s\\n\" , crateParams->CommonParams.ResidualPedestalCorrection ? \"TRUE\" : \"FALSE\" ); printf ( \" INLCorrection = %s\\n\" , crateParams->CommonParams.INLCorrection ? \"TRUE\" : \"FALSE\" ); printf ( \" Return code: %d\\n\" , error); printf ( \"[DEBUG] Leaving SAMPIC256CH_LoadAllCalibValuesFromFiles()\\n\" ); return error; } To the sampic library, it had this output: [DEBUG] Entering SAMPIC256CH_LoadAllCalibValuesFromFiles() [DEBUG] Calibration directory: resources/calib [DEBUG] Initializing crate calibration parameters... [DEBUG] Init_CrateCalibParams() done. [DEBUG] Saved directory to CrateCalibInfo.LastCalibDirectory: resources/calib [DEBUG] Starting calibration file reads... [DEBUG] Reading ADC Ramp calib values... [DEBUG] Reading ADC Linearity calib values... [DEBUG] Reading INL values... [DEBUG] Reading Internal Trigger Threshold Offset... [DEBUG] Reading TOT calib values... [DEBUG] allCalibFilesLoaded = TRUE [DEBUG] Checking channel-level calib load statuses... [DEBUG] FE board 1 of 1 [DEBUG] Residual pedestal not loaded for FE 0, channel 0 [DEBUG] Residual pedestal not loaded for FE 0, channel 1 [DEBUG] Residual pedestal not loaded for FE 0, channel 2 [DEBUG] Residual pedestal not loaded for FE 0, channel 3 [DEBUG] Residual pedestal not loaded for FE 0, channel 4 [DEBUG] Residual pedestal not loaded for FE 0, channel 5 [DEBUG] Residual pedestal not loaded for FE 0, channel 6 [DEBUG] Residual pedestal not loaded for FE 0, channel 7 [DEBUG] Residual pedestal not loaded for FE 0, channel 8 [DEBUG] Residual pedestal not loaded for FE 0, channel 9 [DEBUG] Residual pedestal not loaded for FE 0, channel 10 [DEBUG] Residual pedestal not loaded for FE 0, channel 11 [DEBUG] Residual pedestal not loaded for FE 0, channel 12 [DEBUG] Residual pedestal not loaded for FE 0, channel 13 [DEBUG] Residual pedestal not loaded for FE 0, channel 14 [DEBUG] Residual pedestal not loaded for FE 0, channel 15 [DEBUG] Residual pedestal not loaded for FE 0, channel 16 [DEBUG] Residual pedestal not loaded for FE 0, channel 17 [DEBUG] Residual pedestal not loaded for FE 0, channel 18 [DEBUG] Residual pedestal not loaded for FE 0, channel 19 [DEBUG] Residual pedestal not loaded for FE 0, channel 20 [DEBUG] Residual pedestal not loaded for FE 0, channel 21 [DEBUG] Residual pedestal not loaded for FE 0, channel 22 [DEBUG] Residual pedestal not loaded for FE 0, channel 23 [DEBUG] Residual pedestal not loaded for FE 0, channel 24 [DEBUG] Residual pedestal not loaded for FE 0, channel 25 [DEBUG] Residual pedestal not loaded for FE 0, channel 26 [DEBUG] Residual pedestal not loaded for FE 0, channel 27 [DEBUG] Residual pedestal not loaded for FE 0, channel 28 [DEBUG] Residual pedestal not loaded for FE 0, channel 29 [DEBUG] Residual pedestal not loaded for FE 0, channel 30 [DEBUG] Residual pedestal not loaded for FE 0, channel 31 [DEBUG] Residual pedestal not loaded for FE 0, channel 32 [DEBUG] Residual pedestal not loaded for FE 0, channel 33 [DEBUG] Residual pedestal not loaded for FE 0, channel 34 [DEBUG] Residual pedestal not loaded for FE 0, channel 35 [DEBUG] Residual pedestal not loaded for FE 0, channel 36 [DEBUG] Residual pedestal not loaded for FE 0, channel 37 [DEBUG] Residual pedestal not loaded for FE 0, channel 38 [DEBUG] Residual pedestal not loaded for FE 0, channel 39 [DEBUG] Residual pedestal not loaded for FE 0, channel 40 [DEBUG] Residual pedestal not loaded for FE 0, channel 41 [DEBUG] Residual pedestal not loaded for FE 0, channel 42 [DEBUG] Residual pedestal not loaded for FE 0, channel 43 [DEBUG] Residual pedestal not loaded for FE 0, channel 44 [DEBUG] Residual pedestal not loaded for FE 0, channel 45 [DEBUG] Residual pedestal not loaded for FE 0, channel 46 [DEBUG] Residual pedestal not loaded for FE 0, channel 47 [DEBUG] Residual pedestal not loaded for FE 0, channel 48 [DEBUG] Residual pedestal not loaded for FE 0, channel 49 [DEBUG] Residual pedestal not loaded for FE 0, channel 50 [DEBUG] Residual pedestal not loaded for FE 0, channel 51 [DEBUG] Residual pedestal not loaded for FE 0, channel 52 [DEBUG] Residual pedestal not loaded for FE 0, channel 53 [DEBUG] Residual pedestal not loaded for FE 0, channel 54 [DEBUG] Residual pedestal not loaded for FE 0, channel 55 [DEBUG] Residual pedestal not loaded for FE 0, channel 56 [DEBUG] Residual pedestal not loaded for FE 0, channel 57 [DEBUG] Residual pedestal not loaded for FE 0, channel 58 [DEBUG] Residual pedestal not loaded for FE 0, channel 59 [DEBUG] Residual pedestal not loaded for FE 0, channel 60 [DEBUG] Residual pedestal not loaded for FE 0, channel 61 [DEBUG] Residual pedestal not loaded for FE 0, channel 62 [DEBUG] Residual pedestal not loaded for FE 0, channel 63 [DEBUG] ADC linearity crate calib status: LOADED [DEBUG] Summary: allCalibFilesLoaded = TRUE allResidualPedestalsFilesLoaded = FALSE allTimeINLFilesLoaded = TRUE ADCLinearityCorrection = TRUE ResidualPedestalCorrection = FALSE INLCorrection = TRUE Return code: 0 [DEBUG] Leaving SAMPIC256CH_LoadAllCalibValuesFromFiles() [DEBUG] Entering SAMPIC256CH_LoadAllCalibValuesFromFiles() [DEBUG] Calibration directory: resources/calib [DEBUG] Initializing crate calibration parameters... [DEBUG] Init_CrateCalibParams() done. [DEBUG] Saved directory to CrateCalibInfo.LastCalibDirectory: resources/calib [DEBUG] Starting calibration file reads... [DEBUG] Reading ADC Ramp calib values... [DEBUG] Reading ADC Linearity calib values... [DEBUG] Reading INL values... [DEBUG] Reading Internal Trigger Threshold Offset... [DEBUG] Reading TOT calib values... [DEBUG] allCalibFilesLoaded = TRUE [DEBUG] Checking channel-level calib load statuses... [DEBUG] FE board 1 of 1 [DEBUG] Residual pedestal not loaded for FE 0, channel 0 [DEBUG] Residual pedestal not loaded for FE 0, channel 1 [DEBUG] Residual pedestal not loaded for FE 0, channel 2 [DEBUG] Residual pedestal not loaded for FE 0, channel 3 [DEBUG] Residual pedestal not loaded for FE 0, channel 4 [DEBUG] Residual pedestal not loaded for FE 0, channel 5 [DEBUG] Residual pedestal not loaded for FE 0, channel 6 [DEBUG] Residual pedestal not loaded for FE 0, channel 7 [DEBUG] Residual pedestal not loaded for FE 0, channel 8 [DEBUG] Residual pedestal not loaded for FE 0, channel 9 [DEBUG] Residual pedestal not loaded for FE 0, channel 10 [DEBUG] Residual pedestal not loaded for FE 0, channel 11 [DEBUG] Residual pedestal not loaded for FE 0, channel 12 [DEBUG] Residual pedestal not loaded for FE 0, channel 13 [DEBUG] Residual pedestal not loaded for FE 0, channel 14 [DEBUG] Residual pedestal not loaded for FE 0, channel 15 [DEBUG] Residual pedestal not loaded for FE 0, channel 16 [DEBUG] Residual pedestal not loaded for FE 0, channel 17 [DEBUG] Residual pedestal not loaded for FE 0, channel 18 [DEBUG] Residual pedestal not loaded for FE 0, channel 19 [DEBUG] Residual pedestal not loaded for FE 0, channel 20 [DEBUG] Residual pedestal not loaded for FE 0, channel 21 [DEBUG] Residual pedestal not loaded for FE 0, channel 22 [DEBUG] Residual pedestal not loaded for FE 0, channel 23 [DEBUG] Residual pedestal not loaded for FE 0, channel 24 [DEBUG] Residual pedestal not loaded for FE 0, channel 25 [DEBUG] Residual pedestal not loaded for FE 0, channel 26 [DEBUG] Residual pedestal not loaded for FE 0, channel 27 [DEBUG] Residual pedestal not loaded for FE 0, channel 28 [DEBUG] Residual pedestal not loaded for FE 0, channel 29 [DEBUG] Residual pedestal not loaded for FE 0, channel 30 [DEBUG] Residual pedestal not loaded for FE 0, channel 31 [DEBUG] Residual pedestal not loaded for FE 0, channel 32 [DEBUG] Residual pedestal not loaded for FE 0, channel 33 [DEBUG] Residual pedestal not loaded for FE 0, channel 34 [DEBUG] Residual pedestal not loaded for FE 0, channel 35 [DEBUG] Residual pedestal not loaded for FE 0, channel 36 [DEBUG] Residual pedestal not loaded for FE 0, channel 37 [DEBUG] Residual pedestal not loaded for FE 0, channel 38 [DEBUG] Residual pedestal not loaded for FE 0, channel 39 [DEBUG] Residual pedestal not loaded for FE 0, channel 40 [DEBUG] Residual pedestal not loaded for FE 0, channel 41 [DEBUG] Residual pedestal not loaded for FE 0, channel 42 [DEBUG] Residual pedestal not loaded for FE 0, channel 43 [DEBUG] Residual pedestal not loaded for FE 0, channel 44 [DEBUG] Residual pedestal not loaded for FE 0, channel 45 [DEBUG] Residual pedestal not loaded for FE 0, channel 46 [DEBUG] Residual pedestal not loaded for FE 0, channel 47 [DEBUG] Residual pedestal not loaded for FE 0, channel 48 [DEBUG] Residual pedestal not loaded for FE 0, channel 49 [DEBUG] Residual pedestal not loaded for FE 0, channel 50 [DEBUG] Residual pedestal not loaded for FE 0, channel 51 [DEBUG] Residual pedestal not loaded for FE 0, channel 52 [DEBUG] Residual pedestal not loaded for FE 0, channel 53 [DEBUG] Residual pedestal not loaded for FE 0, channel 54 [DEBUG] Residual pedestal not loaded for FE 0, channel 55 [DEBUG] Residual pedestal not loaded for FE 0, channel 56 [DEBUG] Residual pedestal not loaded for FE 0, channel 57 [DEBUG] Residual pedestal not loaded for FE 0, channel 58 [DEBUG] Residual pedestal not loaded for FE 0, channel 59 [DEBUG] Residual pedestal not loaded for FE 0, channel 60 [DEBUG] Residual pedestal not loaded for FE 0, channel 61 [DEBUG] Residual pedestal not loaded for FE 0, channel 62 [DEBUG] Residual pedestal not loaded for FE 0, channel 63 [DEBUG] ADC linearity crate calib status: LOADED [DEBUG] Summary: allCalibFilesLoaded = TRUE allResidualPedestalsFilesLoaded = FALSE allTimeINLFilesLoaded = TRUE ADCLinearityCorrection = TRUE ResidualPedestalCorrection = FALSE INLCorrection = TRUE Return code: 0 [DEBUG] Leaving SAMPIC256CH_LoadAllCalibValuesFromFiles() Despite this, when I unpack the data and observe in jupyter, I see the ADC values are not calibrated: === Hit 0 === fe_board_index : 0 channel : 29 hit_number : 0 sampic_index : 1 channel_index : 13 inl_corrected : False adc_corrected : False residual_pedestal_corrected: False cell_info : 0 first_cell_physical_index : 5 corrected_waveform length : 64 first 5 samples : { 1183.00f, 1177.00f, 1202.00f, 1199.00f, 1183.00f } raw_tot_value : 0 tot_value : 0.0 amplitude : -1.0 baseline : -1.0 peak : -1.0 time_index : -1.0 time_instant : -1.0 time_amplitude : -1.0 first_cell_timestamp : 2238730.78125 === Hit 0 === fe_board_index : 0 channel : 29 hit_number : 0 sampic_index : 1 channel_index : 13 inl_corrected : False adc_corrected : False residual_pedestal_corrected: False cell_info : 0 first_cell_physical_index : 5 corrected_waveform length : 64 first 5 samples : { 1183.00f, 1177.00f, 1202.00f, 1199.00f, 1183.00f } raw_tot_value : 0 tot_value : 0.0 amplitude : -1.0 baseline : -1.0 peak : -1.0 time_index : -1.0 time_instant : -1.0 time_amplitude : -1.0 first_cell_timestamp : 2238730.78125 Also, despite Jihane saying there's a second board in the crate, I only see 1 from the output above. As seen in my code, I give no reference to enabled boards from the ODB in the sampic init settings: #include \"integration/sampic/controller/init_settings_modes/sampic_init_settings_mode_default.h\" #include <spdlog/spdlog.h> #include <cstring> int SampicInitSettingsModeDefault::initialize() { spdlog::info(\"InitSettingsModeDefault: Initializing SAMPIC system...\"); CrateConnectionParamStruct conn{}; conn.ConnectionType = settings_.connection_type; conn.ControlBoardControlType = settings_.control_type; strncpy(conn.CtrlIpAddress, settings_.ip_address.c_str(), sizeof(conn.CtrlIpAddress) - 1); conn.CtrlIpAddress[sizeof(conn.CtrlIpAddress) - 1] = '\\0'; conn.CtrlPort = settings_.port; auto err = SAMPIC256CH_OpenCrateConnection(conn, &info_); if (err != SAMPIC256CH_Success) { spdlog::error(\"InitSettingsModeDefault: Failed to open crate connection (err={})\", static_cast<int>(err)); return err; } spdlog::info(\"InitSettingsModeDefault: Connection opened with {} FE boards.\", info_.NbOfFeBoards); err = SAMPIC256CH_SetDefaultParameters(&info_, &params_); if (err != SAMPIC256CH_Success) { spdlog::error(\"InitSettingsModeDefault: Failed to open crate connection (err={})\", static_cast<int>(err)); return err; } err = SAMPIC256CH_LoadAllCalibValuesFromFiles(&info_, &params_, const_cast<char*>(settings_.calibration_directory.c_str())); if (err != SAMPIC256CH_Success) { spdlog::warn(\"InitSettingsModeDefault: Calibration files missing, continuing anyway...\"); } err = SAMPIC256CH_AllocateEventMemory(&eventBuffer_, &mlFrames_); if (err != SAMPIC256CH_Success) { spdlog::error(\"InitSettingsModeDefault: Failed to allocate event memory (err={})\", static_cast<int>(err)); return err; } spdlog::info(\"InitSettingsModeDefault: Event memory allocated successfully.\"); return SAMPIC256CH_Success; } # include \"integration/sampic/controller/init_settings_modes/sampic_init_settings_mode_default.h\" # include <spdlog/spdlog.h> # include <cstring> int SampicInitSettingsModeDefault::initialize () { spdlog:: info ( \"InitSettingsModeDefault: Initializing SAMPIC system...\" ); CrateConnectionParamStruct conn{}; conn.ConnectionType = settings_.connection_type; conn.ControlBoardControlType = settings_.control_type; strncpy (conn.CtrlIpAddress, settings_.ip_address. c_str (), sizeof (conn.CtrlIpAddress) - 1 ); conn.CtrlIpAddress[ sizeof (conn.CtrlIpAddress) - 1 ] = '\\0' ; conn.CtrlPort = settings_.port; auto err = SAMPIC256CH_OpenCrateConnection (conn, &info_); if (err != SAMPIC256CH_Success) { spdlog:: error ( \"InitSettingsModeDefault: Failed to open crate connection (err={})\" , static_cast < int >(err)); return err; } spdlog:: info ( \"InitSettingsModeDefault: Connection opened with {} FE boards.\" , info_.NbOfFeBoards); err = SAMPIC256CH_SetDefaultParameters (&info_, &params_); if (err != SAMPIC256CH_Success) { spdlog:: error ( \"InitSettingsModeDefault: Failed to open crate connection (err={})\" , static_cast < int >(err)); return err; } err = SAMPIC256CH_LoadAllCalibValuesFromFiles (&info_, &params_, const_cast < char *>(settings_.calibration_directory. c_str ())); if (err != SAMPIC256CH_Success) { spdlog:: warn ( \"InitSettingsModeDefault: Calibration files missing, continuing anyway...\" ); } err = SAMPIC256CH_AllocateEventMemory (&eventBuffer_, &mlFrames_); if (err != SAMPIC256CH_Success) { spdlog:: error ( \"InitSettingsModeDefault: Failed to allocate event memory (err={})\" , static_cast < int >(err)); return err; } spdlog:: info ( \"InitSettingsModeDefault: Event memory allocated successfully.\" ); return SAMPIC256CH_Success; } 10/11/2025 18:09 #include \"integration/sampic/controller/init_settings_modes/sampic_init_settings_mode_default.h\" #include <spdlog/spdlog.h> #include <cstring> int SampicInitSettingsModeDefault::initialize() { spdlog::info(\"InitSettingsModeDefault: Initializing SAMPIC system...\"); CrateConnectionParamStruct conn{}; conn.ConnectionType = settings_.connection_type; conn.ControlBoardControlType = settings_.control_type; strncpy(conn.CtrlIpAddress, settings_.ip_address.c_str(), sizeof(conn.CtrlIpAddress) - 1); conn.CtrlIpAddress[sizeof(conn.CtrlIpAddress) - 1] = '\\0'; conn.CtrlPort = settings_.port; auto err = SAMPIC256CH_OpenCrateConnection(conn, &info_); if (err != SAMPIC256CH_Success) { spdlog::error(\"InitSettingsModeDefault: Failed to open crate connection (err={})\", static_cast<int>(err)); return err; } spdlog::info(\"InitSettingsModeDefault: Connection opened with {} FE boards.\", info_.NbOfFeBoards); err = SAMPIC256CH_CheckCrateFirmwareVersions(&info_); if (err != SAMPIC256CH_Success) { spdlog::error(\"InitSettingsModeDefault: Failed to read crate firmware versions (err={})\", static_cast<int>(err)); return err; } const auto& ctrlFw = info_.CrateBoardsInfo.ControlBoardInfo.FirmwareVersion; spdlog::info(\"InitSettingsModeDefault: Control board firmware v{}.{}.{}\", ctrlFw.BoardVersion, ctrlFw.FPGAVersion, ctrlFw.FPGAEvolution); for (int feIndex = 0; feIndex < info_.NbOfFeBoards; ++feIndex) { const auto& feInfo = info_.CrateBoardsInfo.FeBoardInfo[feIndex]; const auto& ctrlFpgaFw = feInfo.ControlFpgaFirmwareVersion; spdlog::info(\"InitSettingsModeDefault: FE[{}] control FPGA firmware v{}.{}.{}\", feIndex, ctrlFpgaFw.BoardVersion, ctrlFpgaFw.FPGAVersion, ctrlFpgaFw.FPGAEvolution); for (int fpgaIndex = 0; fpgaIndex < NB_OF_FE_FPGAS_IN_FE_BOARD; ++fpgaIndex) { const auto& feFpgaFw = feInfo.FeFpgaFirmwareVersion[fpgaIndex]; spdlog::info(\"InitSettingsModeDefault: FE[{}] FE-FPGA[{}] firmware v{}.{}.{}\", feIndex, fpgaIndex, feFpgaFw.BoardVersion, feFpgaFw.FPGAVersion, feFpgaFw.FPGAEvolution); } } err = SAMPIC256CH_SetDefaultParameters(&info_, &params_); if (err != SAMPIC256CH_Success) { spdlog::error(\"InitSettingsModeDefault: Failed to open crate connection (err={})\", static_cast<int>(err)); return err; } err = SAMPIC256CH_LoadAllCalibValuesFromFiles(&info_, &params_, const_cast<char*>(settings_.calibration_directory.c_str())); if (err != SAMPIC256CH_Success) { spdlog::warn(\"InitSettingsModeDefault: Calibration files missing, continuing anyway...\"); } Boolean adcCorrectionEnabled{}; Boolean timeInlCorrectionEnabled{}; Boolean residualPedestalCorrectionEnabled{}; err = SAMPIC256CH_GetCrateCorrectionLevels(&info_, &params_, &adcCorrectionEnabled, &timeInlCorrectionEnabled, &residualPedestalCorrectionEnabled); if (err != SAMPIC256CH_Success) { spdlog::warn(\"InitSettingsModeDefault: Failed to read crate correction levels (err={})\", static_cast<int>(err)); } else { spdlog::info(\"InitSettingsModeDefault: Correction levels - ADC linearity: {}, Time INL: {}, Residual pedestal: {}\", adcCorrectionEnabled ? \"enabled\" : \"disabled\", timeInlCorrectionEnabled ? \"enabled\" : \"disabled\", residualPedestalCorrectionEnabled ? \"enabled\" : \"disabled\"); } err = SAMPIC256CH_AllocateEventMemory(&eventBuffer_, &mlFrames_); if (err != SAMPIC256CH_Success) { spdlog::error(\"InitSettingsModeDefault: Failed to allocate event memory (err={})\", static_cast<int>(err)); return err; } spdlog::info(\"InitSettingsModeDefault: Event memory allocated successfully.\"); return SAMPIC256CH_Success; } # include \"integration/sampic/controller/init_settings_modes/sampic_init_settings_mode_default.h\" # include <spdlog/spdlog.h> # include <cstring> int SampicInitSettingsModeDefault::initialize () { spdlog:: info ( \"InitSettingsModeDefault: Initializing SAMPIC system...\" ); CrateConnectionParamStruct conn{}; conn.ConnectionType = settings_.connection_type; conn.ControlBoardControlType = settings_.control_type; strncpy (conn.CtrlIpAddress, settings_.ip_address. c_str (), sizeof (conn.CtrlIpAddress) - 1 ); conn.CtrlIpAddress[ sizeof (conn.CtrlIpAddress) - 1 ] = '\\0' ; conn.CtrlPort = settings_.port; auto err = SAMPIC256CH_OpenCrateConnection (conn, &info_); if (err != SAMPIC256CH_Success) { spdlog:: error ( \"InitSettingsModeDefault: Failed to open crate connection (err={})\" , static_cast < int >(err)); return err; } spdlog:: info ( \"InitSettingsModeDefault: Connection opened with {} FE boards.\" , info_.NbOfFeBoards); err = SAMPIC256CH_CheckCrateFirmwareVersions (&info_); if (err != SAMPIC256CH_Success) { spdlog:: error ( \"InitSettingsModeDefault: Failed to read crate firmware versions (err={})\" , static_cast < int >(err)); return err; } const auto & ctrlFw = info_.CrateBoardsInfo.ControlBoardInfo.FirmwareVersion; spdlog:: info ( \"InitSettingsModeDefault: Control board firmware v{}.{}.{}\" , ctrlFw.BoardVersion, ctrlFw.FPGAVersion, ctrlFw.FPGAEvolution); for ( int feIndex = 0 ; feIndex < info_.NbOfFeBoards; ++feIndex) { const auto & feInfo = info_.CrateBoardsInfo.FeBoardInfo[feIndex]; const auto & ctrlFpgaFw = feInfo.ControlFpgaFirmwareVersion; spdlog:: info ( \"InitSettingsModeDefault: FE[{}] control FPGA firmware v{}.{}.{}\" , feIndex, ctrlFpgaFw.BoardVersion, ctrlFpgaFw.FPGAVersion, ctrlFpgaFw.FPGAEvolution); for ( int fpgaIndex = 0 ; fpgaIndex < NB_OF_FE_FPGAS_IN_FE_BOARD; ++fpgaIndex) { const auto & feFpgaFw = feInfo.FeFpgaFirmwareVersion[fpgaIndex]; spdlog:: info ( \"InitSettingsModeDefault: FE[{}] FE-FPGA[{}] firmware v{}.{}.{}\" , feIndex, fpgaIndex, feFpgaFw.BoardVersion, feFpgaFw.FPGAVersion, feFpgaFw.FPGAEvolution); } } err = SAMPIC256CH_SetDefaultParameters (&info_, &params_); if (err != SAMPIC256CH_Success) { spdlog:: error ( \"InitSettingsModeDefault: Failed to open crate connection (err={})\" , static_cast < int >(err)); return err; } err = SAMPIC256CH_LoadAllCalibValuesFromFiles (&info_, &params_, const_cast < char *>(settings_.calibration_directory. c_str ())); if (err != SAMPIC256CH_Success) { spdlog:: warn ( \"InitSettingsModeDefault: Calibration files missing, continuing anyway...\" ); } Boolean adcCorrectionEnabled{}; Boolean timeInlCorrectionEnabled{}; Boolean residualPedestalCorrectionEnabled{}; err = SAMPIC256CH_GetCrateCorrectionLevels (&info_, &params_, &adcCorrectionEnabled, &timeInlCorrectionEnabled, &residualPedestalCorrectionEnabled); if (err != SAMPIC256CH_Success) { spdlog:: warn ( \"InitSettingsModeDefault: Failed to read crate correction levels (err={})\" , static_cast < int >(err)); } else { spdlog:: info ( \"InitSettingsModeDefault: Correction levels - ADC linearity: {}, Time INL: {}, Residual pedestal: {}\" , adcCorrectionEnabled ? \"enabled\" : \"disabled\" , timeInlCorrectionEnabled ? \"enabled\" : \"disabled\" , residualPedestalCorrectionEnabled ? \"enabled\" : \"disabled\" ); } err = SAMPIC256CH_AllocateEventMemory (&eventBuffer_, &mlFrames_); if (err != SAMPIC256CH_Success) { spdlog:: error ( \"InitSettingsModeDefault: Failed to allocate event memory (err={})\" , static_cast < int >(err)); return err; } spdlog:: info ( \"InitSettingsModeDefault: Event memory allocated successfully.\" ); return SAMPIC256CH_Success; } gives output: (sampic_dev) pioneer@localhost:~/jcarlton/projects/midas_sampic/experiments/sampic_daq/scripts$ ./run.sh -i 0 [INFO] Running Sampic Frontend with index 00... Connect to experiment SAMPIC... OK [SAMPIC_Frontend00,INFO] Frontend \"SAMPIC_Frontend00\" started Init hardware... [00:08:10] [info] [SAMPIC_DAQ] Logger 'SAMPIC_DAQ' initialized at level info [00:08:10] [info] [SAMPIC_DAQ] SAMPICCollectorModeDefault initialized: soft_trigger_prepare_interval=100, soft_trigger_max_loops=10000, soft_trigger_retry_sleep_us=100 [00:08:10] [info] [SAMPIC_DAQ] SAMPIC Collector initialized (mode=0, buffer_size=32768) [00:08:10] [info] [SAMPIC_DAQ] InitSettingsModeDefault: Initializing SAMPIC system... ************************************************* New socket (13) with IP address 192.168.0.4 and port 27015. ************************************************* Warning Rd(): only 15 bytes of 17 have actually been read [00:08:10] [info] [SAMPIC_DAQ] InitSettingsModeDefault: Connection opened with 1 FE boards. [00:08:10] [info] [SAMPIC_DAQ] InitSettingsModeDefault: Control board firmware v3.2.19 [00:08:10] [info] [SAMPIC_DAQ] InitSettingsModeDefault: FE[0] control FPGA firmware v2.2.5 [00:08:10] [info] [SAMPIC_DAQ] InitSettingsModeDefault: FE[0] FE-FPGA[0] firmware v4.3.20 [00:08:10] [info] [SAMPIC_DAQ] InitSettingsModeDefault: FE[0] FE-FPGA[1] firmware v4.3.20 [00:08:10] [info] [SAMPIC_DAQ] InitSettingsModeDefault: FE[0] FE-FPGA[2] firmware v4.3.20 [00:08:10] [info] [SAMPIC_DAQ] InitSettingsModeDefault: FE[0] FE-FPGA[3] firmware v4.3.20 [00:08:12] [info] [SAMPIC_DAQ] InitSettingsModeDefault: Correction levels - ADC linearity: enabled, Time INL: enabled, Residual pedestal: disabled [00:08:12] [info] [SAMPIC_DAQ] InitSettingsModeDefault: Event memory allocated successfully. [00:08:12] [info] [SAMPIC_DAQ] FrontendCollectorModeDefault initialized (time_window_ns=5, finalize_after_ms=1, wait_timeout_ms=1000) [00:08:12] [info] [SAMPIC_DAQ] FrontendEventCollector initialized (mode=0, buffer_size=32768) [00:08:12] [info] [SAMPIC_DAQ] FrontendEventCollector created (mode=0, buffer_size=32768) Frontend name : SAMPIC_Frontend00 Event buffer size : 671088640 User max event size : 134217728 User max frag. size : 671088640 # of events per buffer : 5 OK (sampic_dev) pioneer@localhost:~/jcarlton/projects/midas_sampic/experiments/sampic_daq/scripts$ ./run.sh -i 0 [INFO] Running Sampic Frontend with index 00... Connect to experiment SAMPIC... OK [SAMPIC_Frontend00,INFO] Frontend \"SAMPIC_Frontend00\" started Init hardware... [00:08:10] [info] [SAMPIC_DAQ] Logger 'SAMPIC_DAQ' initialized at level info [00:08:10] [info] [SAMPIC_DAQ] SAMPICCollectorModeDefault initialized: soft_trigger_prepare_interval=100, soft_trigger_max_loops=10000, soft_trigger_retry_sleep_us=100 [00:08:10] [info] [SAMPIC_DAQ] SAMPIC Collector initialized (mode=0, buffer_size=32768) [00:08:10] [info] [SAMPIC_DAQ] InitSettingsModeDefault: Initializing SAMPIC system... ************************************************* New socket (13) with IP address 192.168.0.4 and port 27015. ************************************************* Warning Rd(): only 15 bytes of 17 have actually been read [00:08:10] [info] [SAMPIC_DAQ] InitSettingsModeDefault: Connection opened with 1 FE boards. [00:08:10] [info] [SAMPIC_DAQ] InitSettingsModeDefault: Control board firmware v3.2.19 [00:08:10] [info] [SAMPIC_DAQ] InitSettingsModeDefault: FE[0] control FPGA firmware v2.2.5 [00:08:10] [info] [SAMPIC_DAQ] InitSettingsModeDefault: FE[0] FE-FPGA[0] firmware v4.3.20 [00:08:10] [info] [SAMPIC_DAQ] InitSettingsModeDefault: FE[0] FE-FPGA[1] firmware v4.3.20 [00:08:10] [info] [SAMPIC_DAQ] InitSettingsModeDefault: FE[0] FE-FPGA[2] firmware v4.3.20 [00:08:10] [info] [SAMPIC_DAQ] InitSettingsModeDefault: FE[0] FE-FPGA[3] firmware v4.3.20 [00:08:12] [info] [SAMPIC_DAQ] InitSettingsModeDefault: Correction levels - ADC linearity: enabled, Time INL: enabled, Residual pedestal: disabled [00:08:12] [info] [SAMPIC_DAQ] InitSettingsModeDefault: Event memory allocated successfully. [00:08:12] [info] [SAMPIC_DAQ] FrontendCollectorModeDefault initialized (time_window_ns=5, finalize_after_ms=1, wait_timeout_ms=1000) [00:08:12] [info] [SAMPIC_DAQ] FrontendEventCollector initialized (mode=0, buffer_size=32768) [00:08:12] [info] [SAMPIC_DAQ] FrontendEventCollector created (mode=0, buffer_size=32768) Frontend name : SAMPIC_Frontend00 Event buffer size : 671088640 User max event size : 134217728 User max frag. size : 671088640 # of events per buffer : 5 OK 10/11/2025 18:18 I ran the sampic DAQ in pulser mode with periods 640us and 64us. With 1 frontend board = 4 sampics = 64 channels this should correspond to ~100K hits/s and 1M hits/s. Here's a small table of same parameters I varied by hand for some quick (~5 second) tests: Run # Pulser Period (us) Frames per Block 63 640 1 64 64 1 66 640 4 67 64 4 68 640 16 69 64 16 10/11/2025 23:36 Here are some stats from those runs Run Pulser Period (\u00b5s) Frames per Block Average Event Rate (Hz) Event Rate Std (Hz) Event Rate Unc. (Hz) Average Hit Rate (Hz) Hit Rate Std (Hz) Hit Rate Unc. (Hz) Average Data Rate (MB/s) Data Rate Std (MB/s) Data Rate Unc. (MB/s) Hits per Event Hits/Event Std Hits/Event Unc. Avg. Hit Spread (ns) Hit Spread Std (ns) Hit Spread Unc. (ns) Min Pairwise \u0394t (ns) Max Pairwise \u0394t (ns) Expected Hit Rate (Hz) Expected Data Rate (MB/s) 63 640 1 33052.7 20976.7 55.4 57070.9 90673.7 239.48 23.38 32.49 0.09 1.73 1.66 0 1.04 1.7 0 0 6.09 100000 40.96 64 64 1 21181.7 19900.9 63.55 58899.6 291504 930.81 22.64 100.58 0.32 2.78 6.72 0.02 0.86 1.56 0 0 6.25 1e+06 384.36 66 640 4 20277.1 11965.1 36.3 118591 146513 444.49 43.01 51.16 0.16 5.85 4.11 0.01 1.34 1.43 0 0 5 100000 36.27 67 64 4 20119.2 12116.7 38.54 119111 150366 478.3 43.17 52.46 0.17 5.92 5.13 0.02 1.3 1.41 0 0 4.38 1e+06 362.42 68 640 16 9037.83 3693.94 20.75 169524 196831 1105.7 59.19 67.77 0.38 18.76 16.21 0.08 1.54 1.37 0.01 0 4.38 100000 34.91 69 64 16 6865.73 3908.4 22.59 172358 178808 1033.52 59.91 61.59 0.36 25.1 20.14 0.1 1.79 1.49 0.01 0 4.38 1e+06 347.58",
    "textLength": 4404
  },
  {
    "kind": "work-log",
    "title": "10_03_2024 - 16_03_2024.html",
    "fileName": "10_03_2024 - 16_03_2024.html",
    "url": "resources/work_logs/10_03_2024 - 16_03_2024.html",
    "createdDate": "2024-03-10",
    "text": "10/03/2024 - 16/03/2024 10/03/2024 - 16/03/2024 Made some changes to frontend code to fix some issues: common/AMC13.cpp:84 -ss_ip_hardcoded << \"192.168.\" << byte3 << \".\" << (13 + sel); +ss_ip_hardcoded << \"192.168.\" << byte3 << \".\" << (188 + sel); common /AMC13.cpp: 84 -ss_ip_hardcoded << \"192.168.\" << byte3 << \".\" << ( 13 + sel); +ss_ip_hardcoded << \"192.168.\" << byte3 << \".\" << ( 188 + sel); Change the magic number in this function to correspond to our IP. I hate this code the more I read it. MasterGM2/frontend.cpp:595 +strcpy(master_settings_odb.encoder_fe, \"AMC13000\"); MasterGM2/frontend .cpp : 595 + strcpy (master_settings_odb.encoder_fe, \"AMC13000\" ); overwrite this setting that was set to \"AMC1300\" as opposed to \"AMC13000\" I'm not sure where it originally gets set. I think the extra 0 is a result of Lawrence's hijinx to make frontends have 3 digits as opposed to 2. 10/03/2024 21:18 Made some changes: MasterGM2/AMC1300.cpp:127 } else if (ver_read != ver_odb) { std::string error_msg = \"/AMC1300/Settings/AMC13/: Conflict: \\\"T1 Firmware Version Required\\\" - Read version: \" + std::to_string(ver_read) + \", ODB version: \" + std::to_string(ver_odb); cm_msg(MERROR, __FUNCTION__, error_msg.c_str()); return FE_ERR_HW; } MasterGM2/AMC1300.cpp: 127 } else if (ver_read != ver_odb) { std::string error_msg = \"/AMC1300/Settings/AMC13/: Conflict: \\\"T1 Firmware Version Required\\\" - Read version: \" + std::to_string(ver_read) + \", ODB version: \" + std::to_string(ver_odb); cm_msg(MERROR, __FUNCTION__ , error_msg.c_str()); return FE_ERR_HW; } This gives output on how the versions differ, I got: [MasterGM2000,ERROR] [AMC1300.cpp:129:AMC13_init,ERROR] /AMC1300/Settings/AMC13/: Conflict: \"T1 Firmware Version Required\" - Read version: 33063, ODB version: 33087 [MasterGM2000, ERROR ] [AMC1300.cpp:129:AMC13_init, ERROR ] /AMC1300/Settings/AMC13/: Conflict: \"T1 Firmware Version Required\" - Read version: 33063, ODB version: 33087 So I changed the ODB parameter Equipment/AMC13000/Settings/AMC13/T1 Firmware Version Required to be 33063 and got past the error. I did similar for the T2: MasterGM2/AMC1300.cpp:142 else if (ver_read != ver_odb) { std::string error_msg = \"/AMC1300/Settings/AMC13/: Conflict: \\\"T2 Firmware Version Required\\\" - Read version: \" + std::to_string(ver_read) + \", ODB version: \" + std::to_string(ver_odb); cm_msg(MERROR, __FUNCTION__, error_msg.c_str()); return FE_ERR_HW; } MasterGM2/AMC1300.cpp: 142 else if (ver_read != ver_odb) { std::string error_msg = \"/AMC1300/Settings/AMC13/: Conflict: \\\"T2 Firmware Version Required\\\" - Read version: \" + std::to_string(ver_read) + \", ODB version: \" + std::to_string(ver_odb); cm_msg(MERROR, __FUNCTION__ , error_msg.c_str()); return FE_ERR_HW; } Output: [MasterGM2000,ERROR] [AMC1300.cpp:144:AMC13_init,ERROR] /AMC1300/Settings/AMC13/: Conflict: \"T2 Firmware Version Required\" - Read version: 45, ODB version: 46 [MasterGM2000, ERROR ] [AMC1300.cpp:144:AMC13_init, ERROR ] /AMC1300/Settings/AMC13/: Conflict: \"T2 Firmware Version Required\" - Read version: 45, ODB version: 46 changed Equipment/AMC13000/Settings/AMC13/T2 Firmware Version Required to match 45 instead of 46 10/03/2024 21:38 To get around these errors: FC7_init(175): FC7 Board Presence Check [MasterGM2000,ERROR] [AMC1300.cpp:183:FC7_init,ERROR] /AMC1300/Settings/FC7-11/: Board Absent FC7_init ( 175 ) : FC7 Board Presence Check [MasterGM2000,ERROR] [AMC1300.cpp:183:FC7_init,ERROR] /AMC1300/Settings/FC7- 11 /: Board Absent FC7_init(174): FC7 Board Presence Check Unable to send RAW command (channel=0x7 netfn=0x30 lun=0x0 cmd=0x5) getAddress(129): Caught Exception Unable to send RAW command (channel=0x7 netfn=0x30 lun=0x0 cmd=0x5) getAddress(129): Caught Exception Unable to send RAW command (channel=0x7 netfn=0x30 lun=0x0 cmd=0x5) getAddress(129): Caught Exception Unable to send RAW command (channel=0x7 netfn=0x30 lun=0x0 cmd=0x5) getAddress(129): Caught Exception Unable to send RAW command (channel=0x7 netfn=0x30 lun=0x0 cmd=0x5) getAddress(129): Caught Exception FC7_init(190): Slot 11: Read FC7 IP Address: [MasterGM2000,ERROR] [AMC1300.cpp:193:FC7_init,ERROR] AMC13: T1 IP Address Read Failure FC7_init(174): FC7 Board Presence Check Unable to send RAW command ( channel =0x7 netfn =0x30 lun =0x0 cmd =0x5) getAddress(129): Caught Exception Unable to send RAW command ( channel =0x7 netfn =0x30 lun =0x0 cmd =0x5) getAddress(129): Caught Exception Unable to send RAW command ( channel =0x7 netfn =0x30 lun =0x0 cmd =0x5) getAddress(129): Caught Exception Unable to send RAW command ( channel =0x7 netfn =0x30 lun =0x0 cmd =0x5) getAddress(129): Caught Exception Unable to send RAW command ( channel =0x7 netfn =0x30 lun =0x0 cmd =0x5) getAddress(129): Caught Exception FC7_init(190): Slot 11: Read FC7 IP Address: [MasterGM2000, ERROR ] [AMC1300.cpp:193:FC7_init, ERROR ] AMC13: T1 IP Address Read Failure Had to add the -m 0x20 flag to two ipmitool calls: common/FC7.cpp:161 ss_cmd << \"ipmitool -I lan -H \" << ip << \" -U shelf -P shelf -m 0x20 -B 0 -T 0x82 -b 7 -t \" << (0x70 + (2 * slot)) << \" fru print 0x0 | grep 'FC7' &>/dev/null\"; common /FC7.cpp: 161 ss_cmd << \"ipmitool -I lan -H \" << ip << \" -U shelf -P shelf -m 0x20 -B 0 -T 0x82 -b 7 -t \" << ( 0 x70 + ( 2 * slot)) << \" fru print 0x0 | grep 'FC7' &>/dev/null\" ; common/FC7.cpp:87 ss_cmd << \"ipmitool -I lan -H \" << ip << \" -U shelf -P shelf -m 0x20 -B 0 -T 0x82 -b 7 -t \" << (0x70 + (2 * slot)) << \" raw 0x30 0x5\"; common /FC7.cpp: 87 ss_cmd << \"ipmitool -I lan -H \" << ip << \" -U shelf -P shelf -m 0x20 -B 0 -T 0x82 -b 7 -t \" << ( 0 x70 + ( 2 * slot)) << \" raw 0x30 0x5\" ; This worked, though sometimes the equipment \"loses it's mind\" as Lawrence put it. I had to wait a minute then run the frontend again after it failed a couple times. 10/03/2024 21:49 I have this error: [MasterGM2000,ERROR] [AMC1300.cpp:204:FC7_init,ERROR] /AMC1300/Settings/FC7-11/: Invalid \"Address Table Location\" uhal exception: \"Invalid node ID 'BOARD.TYPE' specified (contains dots)\" [MasterGM2000,ERROR] [frontend.cpp:903:frontend_init,ERROR] FC7 Initialization Failed [MasterGM2000, ERROR ] [AMC1300.cpp:204:FC7_init, ERROR ] /AMC1300/Settings/FC7-11/: Invalid \"Address Table Location\" uhal exception: \"Invalid node ID 'BOARD.TYPE' specified (contains dots)\" [MasterGM2000, ERROR ] [frontend.cpp:903:frontend_init, ERROR ] FC7 Initialization Failed which I resolved by changing the address table to the \"correct\" version FC7_CCC.xml in the ODB. I.e. I changed: Equipment/AMC13000/Settings/FC7-11/Common from $GM2DAQ_DIR/address_tables/FC7.xml' to $GM2DAQ_DIR/address_tables/FC7_CCC.xml' 11/03/2024 15:51 I added the jumpers to the FMC. I attempted to do it in a way that was consistent with what Lawrence said in an email: THe firmware is set up to use the \u201cD bank\u201d channels 4-7 for input. As per the instructions, you will need to toggle the micro switch for those for channels for input. For incoming signals that will expect 50 Ohm termination, you\u2019ll want to install the little jumpers I sent along. For the master 40 MHz clock, which will go in on D7, I have seen both synthesizers that expect high impedance but also that expect 50 Ohm termination. The connections: I put jumpers on channels D4, D5, D6, and D7 because those are described as the input channels. 11/03/2024 16:44 I became impatient and decided to haphazardly assemble the FMC module on the FC7. I used the stands and screws from the other FMC module we took out, even though they don't really fit and we don't have enough. See images below: 11/03/2024 16:56 When the crate is power cycled, the IPs we set for the two AMC13 FPGAs get reset as well, causing this errror when trying to run the master frontend: AMC13_init(86): Read AMC13 T2 IP Address: 192.168.1.188 ipbusudp-2.0://192.168.1.189:50001 , file://$GM2DAQ_DIR/address_tables/AMC13XG_T1.xml AMC13_init(120): AMC13 T1 FPGA Firmware Version Check Caught Exception getRegister(207): uHAL Exception: Timeout (1000 milliseconds) occurred for UDP receive from target with URI: ipbusudp-2.0://192.168.1.189:50001 Caught Exception getRegister(207): uHAL Exception: Timeout (1000 milliseconds) occurred for UDP receive from target with URI: ipbusudp-2.0://192.168.1.189:50001 [MasterGM2000,ERROR] [AMC1300.cpp:124:AMC13_init,ERROR] /AMC1300/Settings/AMC13/: Ethernet Communication Failure [MasterGM2000,ERROR] [frontend.cpp:895:frontend_init,ERROR] AMC13 Initialization Failed AMC13_init ( 86 ) : Read AMC13 T2 IP Address: 192.168 . 1.188 ipbusudp- 2.0 : //192.168.1.189:50001 , file://$GM2DAQ_DIR/address_tables/AMC13XG_T1.xml AMC13_init ( 120 ) : AMC13 T1 FPGA Firmware Version Check Caught Exception getRegister ( 207 ) : uHAL Exception: Timeout ( 1000 milliseconds) occurred for UDP receive from target with URI: ipbusudp- 2.0 : //192.168.1.189:50001 Caught Exception getRegister ( 207 ) : uHAL Exception: Timeout ( 1000 milliseconds) occurred for UDP receive from target with URI: ipbusudp- 2.0 : //192.168.1.189:50001 [MasterGM2000,ERROR] [AMC1300.cpp:124:AMC13_init,ERROR] /AMC1300/Settings/AMC13/: Ethernet Communication Failure [MasterGM2000,ERROR] [frontend.cpp:895:frontend_init,ERROR] AMC13 Initialization Failed I found you could ping the two FPGAs (T1 and T2) with their \"default\" addresses: ping 192.168.26.10 ping 192.168.26.11 ping 192.168.26.10 ping 192.168.26.11 To set them back to the \"normal\" addresses: cd /home/installation_testing/packages/experiment/lxedaq/amc13/amc13_v1_2_18/dev_tools/amc13Config ./applyConfig.py -n 33 cd /home/installation_testing/packages/experiment/lxedaq/amc13/amc13_v1_2_18/dev_tools/amc13Config ./applyConfig.py -n 33 Then I could once again ping at the \"normal\" addresses: ping 192.168.1.188 ping 192.168.1.189 ping 192.168.1.188 ping 192.168.1.189 11/03/2024 17:02 After adding the FMC module as detailed above, I still get these errors: The value of code is: 0 [MasterGM2000,ERROR] [AMC1300.cpp:331:FC7_init,ERROR] /AMC1300/Settings/FC7-11/: FMC Startup Failure [MasterGM2000,ERROR] [frontend.cpp:903:frontend_init,ERROR] FC7 Initialization Failed The value of code is: 0 [MasterGM2000, ERROR ] [AMC1300.cpp:331:FC7_init, ERROR ] /AMC1300/Settings/FC7-11/: FMC Startup Failure [MasterGM2000, ERROR ] [frontend.cpp:903:frontend_init, ERROR ] FC7 Initialization Failed Where code is the value: int code = 0; code += getRegister(limit, delay, fc7, \"FMC_READY\"); code += getRegister(limit, delay, fc7, \"FMC_ID_VALID\"); if (code != 2) { return 0; } int code = 0 ; code += getRegister(limit, delay, fc7 , \"FMC_READY\" ); code += getRegister(limit, delay, fc7 , \"FMC_ID_VALID\" ); if ( code != 2 ) { return 0 ; } So the FC7 is not liking the FMC I added. This could be because my bootleg setup. 15/03/2024 00:07 I noticed that the boost installation in /home/installation_testing/packages/boost does not properly link python with boost. However, /home/backup_installation_testing/packages/boost-1.53.0 does, so I just editted /home/installation_testing/packages/experiment/lxedaq/environment_setup/environment_variables.txt to look like: [root@dhcp-10-163-105-238 environment_setup]# cat environment_variables.txt GM2DAQ_DIR=/home/installation_testing/packages/experiment/lxedaq CACTUS_ROOT=/home/installation_testing/packages/cactus BOOST_ROOT=/home/backup_installation_testing/packages/boost-1.53.0 PUGIXML_ROOT=/home/installation_testing/packages/pugixml-1.8 ROOT_ROOT=/usr/include/root MIDASSYS=/home/installation_testing/packages/midas MIDAS_EXPTAB=/home/installation_testing/online/exptab MIDAS_EXPT_NAME=DAQ [root@dhcp-10-163-105-238 environment_setup] # cat environment_variables.txt GM2DAQ_DIR =/home/installation_testing/packages/experiment/lxedaq CACTUS_ROOT =/home/installation_testing/packages/cactus BOOST_ROOT =/home/backup_installation_testing/packages/boost- 1.53 . 0 PUGIXML_ROOT =/home/installation_testing/packages/pugixml- 1.8 ROOT_ROOT =/usr/include/root MIDASSYS =/home/installation_testing/packages/midas MIDAS_EXPTAB =/home/installation_testing/ on line/exptab MIDAS_EXPT_NAME =DAQ This lets me use uHAL in python. 15/03/2024 00:12 Lawrence mentioned that the FC7 firmware needed to be updated. To do this, I follow the steps he gave in an email. cd /home/installation_testing/packages/experiment/lxedaq/environment_setup/environment_variables.txt source setup_environment.sh cd /home/installation_testing/packages/unifiedCCC/software/flash export CPLUS_INCLUDE_PATH=\"$BOOST_ROOT/include:$CPLUS_INCLUDE_PATH\" Added the bottom line to the Makefile LIBRARY_PATH = -Llib \\ -L/opt/cactus/lib \\ -L$(CACTUS_ROOT)/lib \\ -L$(CACTUS_ROOT)/uhal/uhal/lib \\ -L$(CACTUS_ROOT)/uhal/grammars/lib \\ -L$(CACTUS_ROOT)/uhal/log/lib \\ -L$(CACTUS_ROOT)/extern/pugixml/RPMBUILD/SOURCES/lib \\ -L$(CACTUS_ROOT)/extern/boost/RPMBUILD/SOURCES/lib \\ -L$(BOOST_ROOT)/lib LIBRARY_PATH = -Llib \\ -L/opt/cactus/ lib \\ -L $( CACTUS_ROOT)/ lib \\ -L $( CACTUS_ROOT)/uhal/uhal/ lib \\ -L $( CACTUS_ROOT)/uhal/grammars/ lib \\ -L $( CACTUS_ROOT)/uhal/log/ lib \\ -L $( CACTUS_ROOT)/extern/pugixml/RPMBUILD/SOURCES/ lib \\ -L $( CACTUS_ROOT)/extern/boost/RPMBUILD/SOURCES/ lib \\ -L $( BOOST_ROOT)/ lib make cd bin ./programFC7 1 11 /home/installation_testing/packages/unifiedCCC/releases/fc7_unified_0x080107.mcs /home/installation_testing/packages/experiment/lxedaq/address_tables/FC7_CCC.xml (for help on what each parameter is, you can just do ./programFC7 ) Reboot the FC7, you can do this from telnet: telnet 192.168.1.41 ? for list of command show_fru , note the fru ID in the left column for the FC7 shutdown 15 wait a bit fru_start 15 wait a bit Check the FC7 is alive ping 192.168.1.11 After doing all this the firmware should be properly updated, I was able to get past our errors: cd /home/installation_testing/packages/experiment/lxedaq/frontends/MasterGM2 ./frontend -i 0 -e DAQ Output: ... FC7_init(241): FC7 Ethernet Communication Check: 1/1 FC7_init(288): Slot 11: FC7 Firmware Hard Reset FC7_init(298): Waiting 5 s ... FC7_init(410): Slot 11: Write: Enabled Top SFP Ports FC7_init(420): Waiting 15 s ... FC7_init(449): Slot 11: Read: Enabled Top SFP Ports: 0 [MasterGM2000,ERROR] [AMC1300.cpp:450:FC7_init,ERROR] /AMC1300/Settings/FC7-11/: Enabled Top SFP Ports Failure [MasterGM2000,ERROR] [frontend.cpp:903:frontend_init,ERROR] FC7 Initialization Failed ... FC7_init ( 241 ) : FC7 Ethernet Communication Check: 1 / 1 FC7_init ( 288 ) : Slot 11 : FC7 Firmware Hard Reset FC7_init ( 298 ) : Waiting 5 s ... FC7_init ( 410 ) : Slot 11 : Write: Enabled Top SFP Ports FC7_init ( 420 ) : Waiting 15 s ... FC7_init ( 449 ) : Slot 11 : Read: Enabled Top SFP Ports: 0 [MasterGM2000,ERROR] [AMC1300.cpp:450:FC7_init,ERROR] /AMC1300/Settings/FC7- 11 /: Enabled Top SFP Ports Failure [MasterGM2000,ERROR] [frontend.cpp:903:frontend_init,ERROR] FC7 Initialization Failed So now we move onto debugging SFP Port error 15/03/2024 00:50 I noitced the extra SFPs we have are actually loopback SFPs that are used just to test a port. We cannot plug anything into them. They look like the bottom SFP in the image above. I think we have just enough SFPs for the setup, until we get a second crate where we should need 2 more. 15/03/2024 00:58 Now that the CENPA teststand is set back up, I can ssh into it with the old command, for example to see midas on localhost:8081 on my computer: ssh -L 8081:localhost:8080 j.carlton@wombat.npl.washington.edu -p 22001 ssh -L 8081 :localhost: 8080 j.carlton@wombat .npl .washington .edu - p 22001",
    "textLength": 2332
  },
  {
    "kind": "work-log",
    "title": "02_06_2024 - 08_06_2024.html",
    "fileName": "02_06_2024 - 08_06_2024.html",
    "url": "resources/work_logs/02_06_2024 - 08_06_2024.html",
    "createdDate": "2024-06-02",
    "text": "02/06/2024 - 08/06/2024 02/06/2024 - 08/06/2024 04/06/2024 15:02 Following numato's new guide for PCIe DMA: https://numato.com/kb/create-pcie-dma-example-design-for-nereid-2/ The relevant changes are in the constraints file in step 16. I can actually see the device pop up with lspci: [root@fe01 pcimem]# lspci -vv | grep -A 35 \"Xilinx\" pcilib: sysfs_read_vpd: read failed: Input/output error 04:00.0 Serial controller: Xilinx Corporation Device 7024 (prog-if 01 [16450]) Subsystem: Xilinx Corporation Device 0007 Control: I/O+ Mem+ BusMaster+ SpecCycle- MemWINV- VGASnoop- ParErr- Stepping- SERR- FastB2B- DisINTx- Status: Cap+ 66MHz- UDF- FastB2B- ParErr- DEVSEL=fast >TAbort- <TAbort- <MAbort- >SERR- <PERR- INTx- Latency: 0, Cache Line Size: 64 bytes Interrupt: pin A routed to IRQ 37 Region 0: Memory at f5f00000 (32-bit, non-prefetchable) [size=1M] Region 1: Memory at f5ef0000 (32-bit, non-prefetchable) [size=64K] Capabilities: [40] Power Management version 3 Flags: PMEClk- DSI- D1- D2- AuxCurrent=0mA PME(D0+,D1+,D2+,D3hot+,D3cold-) Status: D0 NoSoftRst+ PME-Enable- DSel=0 DScale=0 PME- Capabilities: [48] MSI: Enable+ Count=1/1 Maskable- 64bit+ Address: 00000000fee00000 Data: 4083 Capabilities: [60] Express (v2) Endpoint, MSI 00 DevCap: MaxPayload 512 bytes, PhantFunc 0, Latency L0s <64ns, L1 unlimited ExtTag+ AttnBtn- AttnInd- PwrInd- RBE+ FLReset- SlotPowerLimit 225.000W DevCtl: Report errors: Correctable- Non-Fatal+ Fatal+ Unsupported- RlxdOrd+ ExtTag+ PhantFunc- AuxPwr- NoSnoop+ MaxPayload 256 bytes, MaxReadReq 512 bytes DevSta: CorrErr- UncorrErr- FatalErr- UnsuppReq- AuxPwr- TransPend- LnkCap: Port #0, Speed 5GT/s, Width x4, ASPM L0s, Exit Latency L0s unlimited, L1 unlimited ClockPM- Surprise- LLActRep- BwNot- ASPMOptComp- LnkCtl: ASPM Disabled; RCB 64 bytes Disabled- CommClk+ ExtSynch- ClockPM- AutWidDis- BWInt- AutBWInt- LnkSta: Speed 5GT/s, Width x4, TrErr- Train- SlotClk+ DLActive- BWMgmt- ABWMgmt- DevCap2: Completion Timeout: Range B, TimeoutDis-, LTR-, OBFF Not Supported DevCtl2: Completion Timeout: 50us to 50ms, TimeoutDis-, LTR-, OBFF Disabled LnkCtl2: Target Link Speed: 5GT/s, EnterCompliance- SpeedDis- Transmit Margin: Normal Operating Range, EnterModifiedCompliance- ComplianceSOS- Compliance De-emphasis: -6dB LnkSta2: Current De-emphasis Level: -6dB, EqualizationComplete-, EqualizationPhase1- EqualizationPhase2-, EqualizationPhase3-, LinkEqualizationRequest- Capabilities: [100 v1] Device Serial Number 00-00-00-00-00-00-00-00 Kernel driver in use: xdma Kernel modules: xdma 06:00.0 Ethernet controller: Broadcom Inc. and subsidiaries NetXtreme BCM5761 Gigabit Ethernet PCIe (rev 10) [root@fe01 pcimem]# [root@fe01 pcimem]# lspci -vv | grep -A 35 \"Xilinx\" pcilib: sysfs_read_vpd: read failed: Input/output error 04:00.0 Serial controller: Xilinx Corporation Device 7024 (prog-if 01 [16450]) Subsystem: Xilinx Corporation Device 0007 Control: I/O+ Mem+ BusMaster+ SpecCycle- MemWINV- VGASnoop- ParErr- Stepping- SERR- FastB2B- DisINTx- Status: Cap+ 66MHz- UDF- FastB2B- ParErr- DEVSEL=fast >TAbort- <TAbort- <MAbort- >SERR- <PERR- INTx- Latency: 0, Cache Line Size: 64 bytes Interrupt: pin A routed to IRQ 37 Region 0: Memory at f5f00000 (32-bit, non-prefetchable) [size=1M] Region 1: Memory at f5ef0000 (32-bit, non-prefetchable) [size=64K] Capabilities: [40] Power Management version 3 Flags: PMEClk- DSI- D1- D2- AuxCurrent=0mA PME(D0+,D1+,D2+,D3hot+,D3cold-) Status: D0 NoSoftRst+ PME-Enable- DSel=0 DScale=0 PME- Capabilities: [48] MSI: Enable+ Count=1/1 Maskable- 64bit+ Address: 00000000fee00000 Data: 4083 Capabilities: [60] Express (v2) Endpoint, MSI 00 DevCap: MaxPayload 512 bytes, PhantFunc 0, Latency L0s <64ns, L1 unlimited ExtTag+ AttnBtn- AttnInd- PwrInd- RBE+ FLReset- SlotPowerLimit 225.000W DevCtl: Report errors: Correctable- Non-Fatal+ Fatal+ Unsupported- RlxdOrd+ ExtTag+ PhantFunc- AuxPwr- NoSnoop+ MaxPayload 256 bytes, MaxReadReq 512 bytes DevSta: CorrErr- UncorrErr- FatalErr- UnsuppReq- AuxPwr- TransPend- LnkCap: Port #0, Speed 5GT/s, Width x4, ASPM L0s, Exit Latency L0s unlimited, L1 unlimited ClockPM- Surprise- LLActRep- BwNot- ASPMOptComp- LnkCtl: ASPM Disabled; RCB 64 bytes Disabled- CommClk+ ExtSynch- ClockPM- AutWidDis- BWInt- AutBWInt- LnkSta: Speed 5GT/s, Width x4, TrErr- Train- SlotClk+ DLActive- BWMgmt- ABWMgmt- DevCap2: Completion Timeout: Range B, TimeoutDis-, LTR-, OBFF Not Supported DevCtl2: Completion Timeout: 50us to 50ms, TimeoutDis-, LTR-, OBFF Disabled LnkCtl2: Target Link Speed: 5GT/s, EnterCompliance- SpeedDis- Transmit Margin: Normal Operating Range, EnterModifiedCompliance- ComplianceSOS- Compliance De-emphasis: -6dB LnkSta2: Current De-emphasis Level: -6dB, EqualizationComplete-, EqualizationPhase1- EqualizationPhase2-, EqualizationPhase3-, LinkEqualizationRequest- Capabilities: [100 v1] Device Serial Number 00-00-00-00-00-00-00-00 Kernel driver in use: xdma Kernel modules: xdma 06:00.0 Ethernet controller: Broadcom Inc. and subsidiaries NetXtreme BCM5761 Gigabit Ethernet PCIe (rev 10) [root@fe01 pcimem]# For some reason I can't get the readback to work like in the guide, however: 0xf5f00000 = 4126146560 [root@fe01 pcimem]# ./pcimem /dev/mem 4126146560 w 0xffffff12 /dev/mem opened. Target offset is 0xf5f00000, page size is 4096 mmap(0, 4096, 0x3, 0x1, 3, 0xf5f00000) PCI Memory mapped to address 0x7fdef3330000. Value at offset 0xF5F00000 (0x7fdef3330000): 0xFFFFFFFF Written 0xFFFFFF12; readback 0xFFFFFFFF [root@fe01 pcimem]# [root@fe01 pcimem]# ./pcimem /dev/mem 4126146560 w 0xffffff12 /dev/mem opened. Target offset is 0xf5f00000 , page size is 4096 mmap( 0 , 4096 , 0x3 , 0x1 , 3 , 0xf5f00000 ) PCI Memory mapped to address 0x7fdef3330000 . Value at offset 0xF5F00000 ( 0x7fdef3330000 ): 0xFFFFFFFF Written 0xFFFFFF12 ; readback 0xFFFFFFFF [root@fe01 pcimem]# However, this now works: [root@fe01 tests]# ./load_driver.sh interrupt_selection . xdma 87724 0 Loading driver...insmod xdma.ko interrupt_mode=2 ... The Kernel module installed correctly and the xmda devices were recognized. DONE [root@fe01 tests]# pwd /root/dma_ip_drivers/XDMA/linux-kernel/tests [root@fe01 tests]# [root @fe01 tests] # ./load_driver.sh interrupt_selection . xdma 87724 0 Loading driver...insmod xdma.ko interrupt_mode= 2 ... The Kernel module installed correctly and the xmda devices were recognized . DONE [root @fe01 tests] # pwd /root/dma _ip_drivers/XDMA/linux-kernel/tests [root @fe01 tests] # Somehow trying run_tests.sh caused the system to reboot. [root@fe01 tests]# pwd /root/dma_ip_drivers/XDMA/linux-kernel/tests [root@fe01 tests]# ./run_test.sh Info: Number of enabled h2c channels = 2 Info: Number of enabled c2h channels = 2 Info: The PCIe DMA core is memory mapped. Info: Running PCIe DMA memory mapped write read test transfer size: 1024, count: 1 Info: Writing to h2c channel 0 at address offset 0. Info: Writing to h2c channel 1 at address offset 1024. Info: Wait for current transactions to complete. /dev/xdma0_h2c_0 ** Average BW = 1024, 0.003076 /dev/xdma0_h2c_1, write 0x400 @ 0x400 failed -1. write file: Unknown error 512 Info: Writing to h2c channel 0 at address offset 2048. Info: Writing to h2c channel 1 at address offset 3072. Info: Wait for current transactions to complete. client_loop: send disconnect: Connection reset [root@fe01 tests] # pwd /root/dma_ip_drivers/XDMA/linux-kernel/tests [root@fe01 tests] # ./run_test.sh Info: Number of enabled h2c channels = 2 Info: Number of enabled c2h channels = 2 Info: The PCIe DMA core is memory mapped. Info: Running PCIe DMA memory mapped write read test transfer size: 1024 , count : 1 Info: Writing to h2c channel 0 at address offset 0. Info: Writing to h2c channel 1 at address offset 1024. Info: Wait for current transactions to complete. /dev/xdma0_h2c_0 ** Average BW = 1024 , 0.003076 /dev/xdma0_h2c_1, write 0x400 @ 0x400 failed -1. write file : Unknown error 512 Info: Writing to h2c channel 0 at address offset 2048. Info: Writing to h2c channel 1 at address offset 3072. Info: Wait for current transactions to complete. client_loop: send disconnect: Connection reset I did not try following the exact steps the guide uses to communicate with dma, as they use a different file I have to move onto 'fe01'. I also haven't tried putting the card in the linux mint machine, which may be more promising (though we had trouble with it in the past). 04/06/2024 15:43 Following the second part of the guide (communicating using DMA) seems to work though. I had to clone this repository: https://github.com/Kishore-Numato/XilinxAR65444/blob/master/Linux/build-install-driver-linux.sh Then run the script build-install-driver-linux.sh in {...}/XilinxAR65444/Linux After that I was able to follow all the steps in the guide: [root@fe01 tests]# sudo cp ../etc/udev/rules.d/* /etc/udev/rules.d/ [root@fe01 tests]# sudo ./load_driver.sh xdma 47131 0 Loading driver... The Kernel module installed correctly and the xmda devices were recognized. DONE [root@fe01 tests]# sudo ./run_test.sh Info: Number of enabled h2c channels = 2 Info: Number of enabled c2h channels = 2 Info: The PCIe DMA core is memory mapped. Info: Running PCIe DMA memory mapped write read test transfer size: 1024 transfer count: 1 Info: Writing to h2c channel 0 at address offset 0. Info: Writing to h2c channel 1 at address offset 1024. Info: Wait for current transactions to complete. sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000000 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_h2c_0, address = 0x00000000, size = 0x00000400, offset = 0x00000000, count = 1 host memory buffer = 0x23e3000 CLOCK_MONOTONIC reports 0.000101002 seconds (total) for last transfer of 1024 bytes sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_h2c_1, address = 0x00000400, size = 0x00000400, offset = 0x00000000, count = 1 host memory buffer = 0x24e9000 CLOCK_MONOTONIC reports 0.000033827 seconds (total) for last transfer of 1024 bytes Info: Writing to h2c channel 0 at address offset 2048. Info: Writing to h2c channel 1 at address offset 3072. Info: Wait for current transactions to complete. sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000800 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_h2c_0, address = 0x00000800, size = 0x00000400, offset = 0x00000000, count = 1 host memory buffer = 0xa82000 CLOCK_MONOTONIC reports 0.000077622 seconds (total) for last transfer of 1024 bytes sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000c00 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_h2c_1, address = 0x00000c00, size = 0x00000400, offset = 0x00000000, count = 1 host memory buffer = 0xc16000 CLOCK_MONOTONIC reports 0.000020724 seconds (total) for last transfer of 1024 bytes Info: Reading from c2h channel 0 at address offset 0. sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000000 sscanf() = 1, value = 0x00000001 Info: Reading from c2h channel 1 at address offset 1024. device = /dev/xdma0_c2h_0, address = 0x00000000, size = 0x00000400, offset = 0x00000000, count = 1 host memory buffer = 0x1d61000 Info: Wait for the current transactions to complete. sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_c2h_1, address = 0x00000400, size = 0x00000400, offset = 0x00000000, count = 1 host memory buffer = 0x20ac000 CLOCK_MONOTONIC reports 0.000027775 seconds (total) for last transfer of 1024 bytes CLOCK_MONOTONIC reports 0.000122408 seconds (total) for last transfer of 1024 bytes Info: Reading from c2h channel 0 at address offset 2048. sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000800 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_c2h_0, address = 0x00000800, size = 0x00000400, offset = 0x00000000, count = 1 Info: Reading from c2h channel 1 at address offset 3072. host memory buffer = 0x217a000 Info: Wait for the current transactions to complete. sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000c00 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_c2h_1, address = 0x00000c00, size = 0x00000400, offset = 0x00000000, count = 1 host memory buffer = 0x1eee000 CLOCK_MONOTONIC reports 0.000027601 seconds (total) for last transfer of 1024 bytes CLOCK_MONOTONIC reports 0.000109510 seconds (total) for last transfer of 1024 bytes Info: Checking data integrity. Info: Data check passed for address range 0 - 1024. Info: Data check passed for address range 1024 - 2048. Info: Data check passed for address range 2048 - 3072. Info: Data check passed for address range 3072 - 4096. Info: All PCIe DMA memory mapped tests passed. Info: All tests in run_tests.sh passed. [root@fe01 tests]# [root@fe01 tests]# sudo cp ../etc/udev/rules.d/* /etc/udev/rules.d/ [root@fe01 tests]# sudo ./load_driver.sh xdma 47131 0 Loading driver... The Kernel module installed correctly and the xmda devices were recognized. DONE [root@fe01 tests]# sudo ./run_test.sh Info: Number of enabled h2c channels = 2 Info: Number of enabled c2h channels = 2 Info: The PCIe DMA core is memory mapped. Info: Running PCIe DMA memory mapped write read test transfer size: 1024 transfer count: 1 Info: Writing to h2c channel 0 at address offset 0. Info: Writing to h2c channel 1 at address offset 1024. Info: Wait for current transactions to complete. sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000000 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_h2c_0, address = 0x00000000, size = 0x00000400, offset = 0x00000000, count = 1 host memory buffer = 0x23e3000 CLOCK_MONOTONIC reports 0.000101002 seconds (total) for last transfer of 1024 bytes sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_h2c_1, address = 0x00000400, size = 0x00000400, offset = 0x00000000, count = 1 host memory buffer = 0x24e9000 CLOCK_MONOTONIC reports 0.000033827 seconds (total) for last transfer of 1024 bytes Info: Writing to h2c channel 0 at address offset 2048. Info: Writing to h2c channel 1 at address offset 3072. Info: Wait for current transactions to complete. sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000800 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_h2c_0, address = 0x00000800, size = 0x00000400, offset = 0x00000000, count = 1 host memory buffer = 0xa82000 CLOCK_MONOTONIC reports 0.000077622 seconds (total) for last transfer of 1024 bytes sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000c00 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_h2c_1, address = 0x00000c00, size = 0x00000400, offset = 0x00000000, count = 1 host memory buffer = 0xc16000 CLOCK_MONOTONIC reports 0.000020724 seconds (total) for last transfer of 1024 bytes Info: Reading from c2h channel 0 at address offset 0. sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000000 sscanf() = 1, value = 0x00000001 Info: Reading from c2h channel 1 at address offset 1024. device = /dev/xdma0_c2h_0, address = 0x00000000, size = 0x00000400, offset = 0x00000000, count = 1 host memory buffer = 0x1d61000 Info: Wait for the current transactions to complete. sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_c2h_1, address = 0x00000400, size = 0x00000400, offset = 0x00000000, count = 1 host memory buffer = 0x20ac000 CLOCK_MONOTONIC reports 0.000027775 seconds (total) for last transfer of 1024 bytes CLOCK_MONOTONIC reports 0.000122408 seconds (total) for last transfer of 1024 bytes Info: Reading from c2h channel 0 at address offset 2048. sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000800 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_c2h_0, address = 0x00000800, size = 0x00000400, offset = 0x00000000, count = 1 Info: Reading from c2h channel 1 at address offset 3072. host memory buffer = 0x217a000 Info: Wait for the current transactions to complete. sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000c00 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_c2h_1, address = 0x00000c00, size = 0x00000400, offset = 0x00000000, count = 1 host memory buffer = 0x1eee000 CLOCK_MONOTONIC reports 0.000027601 seconds (total) for last transfer of 1024 bytes CLOCK_MONOTONIC reports 0.000109510 seconds (total) for last transfer of 1024 bytes Info: Checking data integrity. Info: Data check passed for address range 0 - 1024. Info: Data check passed for address range 1024 - 2048. Info: Data check passed for address range 2048 - 3072. Info: Data check passed for address range 3072 - 4096. Info: All PCIe DMA memory mapped tests passed. Info: All tests in run_tests.sh passed. [root@fe01 tests]#",
    "textLength": 2416
  },
  {
    "kind": "work-log",
    "title": "20_07_2025 - 26_07_2025.html",
    "fileName": "20_07_2025 - 26_07_2025.html",
    "url": "resources/work_logs/20_07_2025 - 26_07_2025.html",
    "createdDate": "2025-07-20",
    "text": "20/07/2025 - 26/07/2025 20/07/2025 - 26/07/2025 23/07/2025 14:56 unpacker-stages-core 1. Handle Field Mapping properly a. Forward declared (no ROOT needed) b. Switch cases for variety of member types i. Some way to handle vector types c. Endianness handled efficiently, need: i. Figure out system endianness (system packages?) ii. Flip endianness only if needed (can handle this with conditional build shifts?) 2. ByteStreamProcessorStage a. Gives protected methods to go from config \u21d2 DataProduct unpacker-stages-nalu 1. Provides classes derived from ByteStreamProcessorStage to unpack bytestream a. NaluEventHeaderUnpackerStage (maybe can use below \u201csimple dataproduct core\u201d) i. Forms NaluPacketHeader , NaluPacketPayload , NaluPacketFooter for each packet ii. Uses info in NaluEventHeader to dynamically determine what bytes to use b. NaluEventFooterUnpackerStage (maybe can use below \u201csimple dataproduct\u201d case) i. Forms NaluEventFooter in the event 2. Provides classes derived from BaseStage to create simple data products a. NaluEventFormerStage i. Makes NaluEvent data product containing NaluEventHeader , NaluEvent , NaluEventFooter b. NaluWaveformFormer i. Makes NaluWaveformCollection from NaluEvent Possible Improvements \u201cSimple dataproducts\u201d (i.e. not dynamic, always aligned) can use a special child of ByteStreamProcessorStage a. Takes in dataproduct name and global endianness, that\u2019s it. b. Uses ROOT\u2019s collection meta data to fill in details. Goal-ish: { \"input_product_name\": \"bytestream_bank_AD00\", \"output_product_name\": \"nalu_event_header\", \"field_mappings\": { \"event_header\": { \"offset\": 0, \"size\": 2, \"endianness\": \"little\" }, \"event_info\": { \"offset\": 2, \"size\": 2, \"endianness\": \"little\" }, \"event_index\": { \"offset\": 4, \"size\": 4, \"endianness\": \"little\" }, \"event_reference_time\": { \"offset\": 8, \"size\": 4, \"endianness\": \"little\" }, \"packet_size\": { \"offset\": 12, \"size\": 2, \"endianness\": \"little\" }, \"channel_mask\": { \"offset\": 14, \"size\": 8, \"endianness\": \"little\" }, \"num_windows\": { \"offset\": 22, \"size\": 2, \"endianness\": \"little\" }, \"num_packets\": { \"offset\": 24, \"size\": 2, \"endianness\": \"little\" } } } { \"input_bytestream_product\": \"bytestream_bank_AD00\", \"input_header_product\": \"nalu_event_header\", \"packet_header_mapping\": { \"packet_header\": { \"offset\": 0, \"size\": 2, \"endianness\": \"little\" }, \"packet_info\": { \"offset\": 2, \"size\": 2, \"endianness\": \"little\" }, \"channel\": { \"offset\": 4, \"size\": 2, \"endianness\": \"little\" }, \"trigger_time\": { \"offset\": 6, \"size\": 4, \"endianness\": \"little\" }, \"logical_position\": { \"offset\": 10, \"size\": 2, \"endianness\": \"little\" }, \"window_position\": { \"offset\": 12, \"size\": 2, \"endianness\": \"little\" } }, \"packet_footer_mapping\": { \"parser_index\": { \"offset\": -8, \"size\": 4, \"endianness\": \"little\" }, \"packet_footer\": { \"offset\": -4, \"size\": 4, \"endianness\": \"little\" } }, \"trace_range\": { \"offset\": 14, \"length\": 64 // in shorts, i.e., 2 bytes per sample }, \"output_products\": { \"packet_headers\": \"nalu_packet_headers\", \"packet_footers\": \"nalu_packet_footers\", \"packets\": \"nalu_packets\" } } { \"input_product_name\": \"bytestream_bank_AD00\", \"output_product_name\": \"nalu_event_header\", \"field_mappings\": { \"event_header\": { \"offset\": 0, \"size\": 2, \"endianness\": \"little\" }, \"event_info\": { \"offset\": 2, \"size\": 2, \"endianness\": \"little\" }, \"event_index\": { \"offset\": 4, \"size\": 4, \"endianness\": \"little\" }, \"event_reference_time\": { \"offset\": 8, \"size\": 4, \"endianness\": \"little\" }, \"packet_size\": { \"offset\": 12, \"size\": 2, \"endianness\": \"little\" }, \"channel_mask\": { \"offset\": 14, \"size\": 8, \"endianness\": \"little\" }, \"num_windows\": { \"offset\": 22, \"size\": 2, \"endianness\": \"little\" }, \"num_packets\": { \"offset\": 24, \"size\": 2, \"endianness\": \"little\" } } } { \"input_bytestream_product\": \"bytestream_bank_AD00\", \"input_header_product\": \"nalu_event_header\", \"packet_header_mapping\": { \"packet_header\": { \"offset\": 0, \"size\": 2, \"endianness\": \"little\" }, \"packet_info\": { \"offset\": 2, \"size\": 2, \"endianness\": \"little\" }, \"channel\": { \"offset\": 4, \"size\": 2, \"endianness\": \"little\" }, \"trigger_time\": { \"offset\": 6, \"size\": 4, \"endianness\": \"little\" }, \"logical_position\": { \"offset\": 10, \"size\": 2, \"endianness\": \"little\" }, \"window_position\": { \"offset\": 12, \"size\": 2, \"endianness\": \"little\" } }, \"packet_footer_mapping\": { \"parser_index\": { \"offset\": -8, \"size\": 4, \"endianness\": \"little\" }, \"packet_footer\": { \"offset\": -4, \"size\": 4, \"endianness\": \"little\" } }, \"trace_range\": { \"offset\": 14, \"length\": 64 // in shorts, i.e., 2 bytes per sample }, \"output_products\": { \"packet_headers\": \"nalu_packet_headers\", \"packet_footers\": \"nalu_packet_footers\", \"packets\": \"nalu_packets\" } } 23/07/2025 14:57 Made these new cells/edits Cuts/Event extraction: channel_to_inspect = 1 Pseudotimes_Leading = [] LeadingEdgeSamples = [] Pseudotimes_Rising = [] RisingEdgeSamples = [] N_roll_overs = [] EventTimes = [] EventIndices = [] Nevents = tree.GetEntries() print(\"Number of events:\", Nevents) last_ref_time = -1 N_rollovers = 0 T_rollover = 2**24 for entry in range(Nevents): tree.GetEntry(entry) # --- Rollover detection --- neh_vec = tree.nalu_event_headers if neh_vec.size() == 0: continue neh = neh_vec[0] event_time = neh.event_reference_time if event_time < last_ref_time: N_rollovers += 1 last_ref_time = event_time nw_vec = tree.nalu_waveforms for i_window in range(nw_vec.size()): wf = nw_vec[i_window] if wf.channel_num != channel_to_inspect: continue trace = np.array(wf.trace) if len(trace) < 4: continue diff = np.diff(trace) # Leading edge leading_edge = np.argmin(diff) if leading_edge < 1 or leading_edge + 1 >= len(diff): continue numerator_lead = (-1)*diff[leading_edge] - (-1)*diff[leading_edge - 1] denominator_lead = (-1)*diff[leading_edge] - (-1)*diff[leading_edge + 1] if denominator_lead == 0: continue pt_lead = (2 / np.pi) * np.arctan(numerator_lead / denominator_lead) if not (0 <= pt_lead <= 1): continue # Rising edge rising_edge = np.argmax(diff) if rising_edge < 1 or rising_edge + 1 >= len(diff): continue numerator_rise = diff[rising_edge] - diff[rising_edge - 1] denominator_rise = diff[rising_edge] - diff[rising_edge + 1] if denominator_rise == 0: continue pt_rise = (2 / np.pi) * np.arctan(numerator_rise / denominator_rise) if not (0 <= pt_rise <= 1): continue # Append only if both edges valid Pseudotimes_Leading.append(pt_lead) LeadingEdgeSamples.append(leading_edge) Pseudotimes_Rising.append(pt_rise) RisingEdgeSamples.append(rising_edge) N_roll_overs.append(N_rollovers) EventTimes.append(event_time) EventIndices.append(entry) channel_to_inspect = 1 Pseudotimes_Leading = [] LeadingEdgeSamples = [] Pseudotimes_Rising = [] RisingEdgeSamples = [] N_roll_overs = [] EventTimes = [] EventIndices = [] Nevents = tree.GetEntries() print(\"Number of events:\", Nevents) last_ref_time = -1 N_rollovers = 0 T_rollover = 2**24 for entry in range(Nevents): tree.GetEntry(entry) # --- Rollover detection --- neh_vec = tree.nalu_event_headers if neh_vec.size() == 0: continue neh = neh_vec[0] event_time = neh.event_reference_time if event_time < last_ref_time: N_rollovers += 1 last_ref_time = event_time nw_vec = tree.nalu_waveforms for i_window in range(nw_vec.size()): wf = nw_vec[i_window] if wf.channel_num != channel_to_inspect: continue trace = np.array(wf.trace) if len(trace) < 4: continue diff = np.diff(trace) # Leading edge leading_edge = np.argmin(diff) if leading_edge < 1 or leading_edge + 1 >= len(diff): continue numerator_lead = (-1)*diff[leading_edge] - (-1)*diff[leading_edge - 1] denominator_lead = (-1)*diff[leading_edge] - (-1)*diff[leading_edge + 1] if denominator_lead == 0: continue pt_lead = (2 / np.pi) * np.arctan(numerator_lead / denominator_lead) if not (0 <= pt_lead <= 1): continue # Rising edge rising_edge = np.argmax(diff) if rising_edge < 1 or rising_edge + 1 >= len(diff): continue numerator_rise = diff[rising_edge] - diff[rising_edge - 1] denominator_rise = diff[rising_edge] - diff[rising_edge + 1] if denominator_rise == 0: continue pt_rise = (2 / np.pi) * np.arctan(numerator_rise / denominator_rise) if not (0 <= pt_rise <= 1): continue # Append only if both edges valid Pseudotimes_Leading.append(pt_lead) LeadingEdgeSamples.append(leading_edge) Pseudotimes_Rising.append(pt_rise) RisingEdgeSamples.append(rising_edge) N_roll_overs.append(N_rollovers) EventTimes.append(event_time) EventIndices.append(entry) \"Suspicious\" event detector, marks events a difference of 10ns or more in the correct time lead_diff_thresh = 10 trail_diff_thresh = 10 LeadLargeDiffPairs = [] TrailLargeDiffPairs = [] lead_diff = np.abs(np.diff(corrected_lead_t)) trail_diff = np.abs(np.diff(corrected_trail_t)) for i, d in enumerate(lead_diff): if d > lead_diff_thresh and i+1 < len(EventIndices): LeadLargeDiffPairs.append((EventIndices[i], EventIndices[i+1])) for i, d in enumerate(trail_diff): if d > trail_diff_thresh and i+1 < len(EventIndices): TrailLargeDiffPairs.append((EventIndices[i], EventIndices[i+1])) print(\"# of Lead suspicious event pairs:\", len(LeadLargeDiffPairs)) print(\"# of Trail suspicious event pairs:\", len(TrailLargeDiffPairs)) lead_diff_thresh = 10 trail_diff_thresh = 10 LeadLargeDiffPairs = [] TrailLargeDiffPairs = [] lead_diff = np .abs (np .diff (corrected_lead_t)) trail_diff = np .abs (np .diff (corrected_trail_t)) for i , d in enumerate (lead_diff): if d > lead_diff_thresh and i+ 1 < len (EventIndices): LeadLargeDiffPairs .append ((EventIndices [i] , EventIndices [i+1] )) for i , d in enumerate (trail_diff): if d > trail_diff_thresh and i+ 1 < len (EventIndices): TrailLargeDiffPairs .append ((EventIndices [i] , EventIndices [i+1] )) print ( \"# of Lead suspicious event pairs:\" , len(LeadLargeDiffPairs) ) print ( \"# of Trail suspicious event pairs:\" , len(TrailLargeDiffPairs) ) Plots for leading and trailing cases, (they're probably the same set, I didn't bother checking though) # Pick an index into the suspicious lead pair list i = 1 # change this index to view different pairs if i < len(LeadLargeDiffPairs): entry1, entry2 = LeadLargeDiffPairs[i] fig, axes = plt.subplots(2, 1, figsize=(12, 8), sharex=True) for ax_idx, entry_idx in enumerate([entry1, entry2]): tree.GetEntry(entry_idx) ax = axes[ax_idx] try: corrected_idx = EventIndices.index(entry_idx) corrected_time = corrected_lead_t[corrected_idx] # Build a mapping: channel_num \u2192 list of window_positions chan_to_windows = {} for j in range(tree.nalu_packet_headers.size()): ch = tree.nalu_packet_headers[j].channel wp = tree.nalu_packet_headers[j].window_position if ch not in chan_to_windows: chan_to_windows[ch] = set() chan_to_windows[ch].add(wp) for wf in tree.nalu_waveforms: ax.plot(wf.trace, label=f\"Ch{wf.channel_num}\") ax.set_title(f\"Lead Event {entry_idx} | Corrected Time = {corrected_time:.2f}\") ax.set_ylabel(\"ADC\") ax.legend() ax.grid(True) # Print table of window positions print(f\"\\nEvent {entry_idx} | Corrected Time = {corrected_time:.2f}\") print(f\"{'Channel':<10}Window Positions\") print(\"-\" * 30) for ch in sorted(chan_to_windows.keys()): windows = sorted(chan_to_windows[ch]) print(f\"{ch:<10}{windows}\") except ValueError: ax.set_title(f\"Event {entry_idx} not in EventIndices\") ax.grid(True) axes[-1].set_xlabel(\"Sample Index\") fig.suptitle(f\"Suspicious Lead Pair: Events {entry1}, {entry2}\", fontsize=14) plt.tight_layout() plt.show() else: print(\"Index out of range\") # Pick an index into the suspicious lead pair list i = 1 # change this index to view different pairs if i < len(LeadLargeDiffPairs): entry1, entry2 = LeadLargeDiffPairs[i] fig, axes = plt.subplots(2, 1, figsize=(12, 8), sharex=True) for ax_idx, entry_idx in enumerate([entry1, entry2]): tree.GetEntry(entry_idx) ax = axes[ax_idx] try: corrected_idx = EventIndices.index(entry_idx) corrected_time = corrected_lead_t[corrected_idx] # Build a mapping: channel_num \u2192 list of window_positions chan_to_windows = {} for j in range(tree.nalu_packet_headers.size()): ch = tree.nalu_packet_headers[j].channel wp = tree.nalu_packet_headers[j].window_position if ch not in chan_to_windows: chan_to_windows[ch] = set() chan_to_windows[ch].add(wp) for wf in tree.nalu_waveforms: ax.plot(wf.trace, label=f\"Ch{wf.channel_num}\") ax.set_title(f\"Lead Event {entry_idx} | Corrected Time = {corrected_time:.2f}\") ax.set_ylabel(\"ADC\") ax.legend() ax.grid(True) # Print table of window positions print(f\"\\nEvent {entry_idx} | Corrected Time = {corrected_time:.2f}\") print(f\"{'Channel':<10}Window Positions\") print(\"-\" * 30) for ch in sorted(chan_to_windows.keys()): windows = sorted(chan_to_windows[ch]) print(f\"{ch:<10}{windows}\") except ValueError: ax.set_title(f\"Event {entry_idx} not in EventIndices\") ax.grid(True) axes[-1].set_xlabel(\"Sample Index\") fig.suptitle(f\"Suspicious Lead Pair: Events {entry1}, {entry2}\", fontsize=14) plt.tight_layout() plt.show() else: print(\"Index out of range\") # Pick an index into the suspicious trail pair list i = 1 # change this index to view different pairs if i < len(TrailLargeDiffPairs): entry1, entry2 = TrailLargeDiffPairs[i] fig, axes = plt.subplots(2, 1, figsize=(12, 8), sharex=True) for ax_idx, entry_idx in enumerate([entry1, entry2]): tree.GetEntry(entry_idx) ax = axes[ax_idx] try: corrected_idx = EventIndices.index(entry_idx) corrected_time = corrected_trail_t[corrected_idx] # Build a mapping: channel_num \u2192 set of window_positions chan_to_windows = {} for j in range(tree.nalu_packet_headers.size()): ch = tree.nalu_packet_headers[j].channel wp = tree.nalu_packet_headers[j].window_position if ch not in chan_to_windows: chan_to_windows[ch] = set() chan_to_windows[ch].add(wp) for wf in tree.nalu_waveforms: ax.plot(wf.trace, label=f\"Ch{wf.channel_num}\") ax.set_title(f\"Trail Event {entry_idx} | Corrected Time = {corrected_time:.2f}\") ax.set_ylabel(\"ADC\") ax.legend() ax.grid(True) # Print table of window positions per channel print(f\"\\nEvent {entry_idx} | Corrected Time = {corrected_time:.2f}\") print(f\"{'Channel':<10}Window Positions\") print(\"-\" * 30) for ch in sorted(chan_to_windows.keys()): windows = sorted(chan_to_windows[ch]) print(f\"{ch:<10}{windows}\") except ValueError: ax.set_title(f\"Event {entry_idx} not in EventIndices\") ax.grid(True) axes[-1].set_xlabel(\"Sample Index\") fig.suptitle(f\"Suspicious Trail Pair: Events {entry1}, {entry2}\", fontsize=14) plt.tight_layout() plt.show() else: print(\"Index out of range\") # Pick an index into the suspicious trail pair list i = 1 # change this index to view different pairs if i < len(TrailLargeDiffPairs): entry1, entry2 = TrailLargeDiffPairs[i] fig, axes = plt.subplots(2, 1, figsize=(12, 8), sharex=True) for ax_idx, entry_idx in enumerate([entry1, entry2]): tree.GetEntry(entry_idx) ax = axes[ax_idx] try: corrected_idx = EventIndices.index(entry_idx) corrected_time = corrected_trail_t[corrected_idx] # Build a mapping: channel_num \u2192 set of window_positions chan_to_windows = {} for j in range(tree.nalu_packet_headers.size()): ch = tree.nalu_packet_headers[j].channel wp = tree.nalu_packet_headers[j].window_position if ch not in chan_to_windows: chan_to_windows[ch] = set() chan_to_windows[ch].add(wp) for wf in tree.nalu_waveforms: ax.plot(wf.trace, label=f\"Ch{wf.channel_num}\") ax.set_title(f\"Trail Event {entry_idx} | Corrected Time = {corrected_time:.2f}\") ax.set_ylabel(\"ADC\") ax.legend() ax.grid(True) # Print table of window positions per channel print(f\"\\nEvent {entry_idx} | Corrected Time = {corrected_time:.2f}\") print(f\"{'Channel':<10}Window Positions\") print(\"-\" * 30) for ch in sorted(chan_to_windows.keys()): windows = sorted(chan_to_windows[ch]) print(f\"{ch:<10}{windows}\") except ValueError: ax.set_title(f\"Event {entry_idx} not in EventIndices\") ax.grid(True) axes[-1].set_xlabel(\"Sample Index\") fig.suptitle(f\"Suspicious Trail Pair: Events {entry1}, {entry2}\", fontsize=14) plt.tight_layout() plt.show() else: print(\"Index out of range\") 23/07/2025 15:00 Case 1. HDSoC strangely aligning samples (I don't know what's going on here) Event 10 | Corrected Time = 46.79 Channel Window Positions 0 [41, 42, 43, 44] 1 [41, 42, 43, 44] 2 [41, 42, 43, 44] Event 11 | Corrected Time = 16.48 Channel Window Positions 0 [44, 45, 46, 47] 1 [44, 45, 46, 47] 2 [43, 44, 45, 46] Case 2. Events getting split up (this one is a bug in my collector) Event 19 | Corrected Time = 29.15 Channel Window Positions 0 [58, 59] 1 [58, 59] 2 [58] Event 20 | Corrected Time = 56.21 Channel Window Positions 0 [60, 61] 1 [60, 61] 2 [59, 60, 61] Case 3. Control/Good Event Event 0 | Corrected Time = 29.25 Channel Window Positions 0 [21, 22, 23, 24] 1 [21, 22, 23, 24] 2 [21, 22, 23, 24] Event 1 | Corrected Time = 30.94 Channel Window Positions 0 [23, 24, 25, 26] 1 [23, 24, 25, 26] 2 [23, 24, 25, 26] 23/07/2025 15:07 I added three cuts: Each channel has exactly 4 windows. All channels share the same window positions. Those window positions form a consecutive sequence. And I rewrote the \"extraction\" section to have each cut toggle-able channel_to_inspect = 1 expected_num_windows = 4 T_rollover = 2**24 min_trace_length = 4 # --- Cut switches --- CUT_SKIP_IF_NO_HEADER = True CUT_ENFORCE_WINDOW_COUNT = True CUT_ENFORCE_WINDOW_MATCH = True CUT_ENFORCE_WINDOW_SEQUENTIAL = True CUT_REQUIRE_MIN_TRACE_LENGTH = True CUT_REQUIRE_VALID_EDGES = True CUT_REQUIRE_VALID_PSEUDOTIMES = True # --- Data accumulators --- Pseudotimes_Leading = [] LeadingEdgeSamples = [] Pseudotimes_Rising = [] RisingEdgeSamples = [] N_roll_overs = [] EventTimes = [] EventIndices = [] Nevents = tree.GetEntries() print(\"Number of events:\", Nevents) last_ref_time = -1 N_rollovers = 0 for entry in range(Nevents): tree.GetEntry(entry) # --- Rollover detection --- neh_vec = tree.nalu_event_headers if CUT_SKIP_IF_NO_HEADER and neh_vec.size() == 0: continue neh = neh_vec[0] event_time = neh.event_reference_time if event_time < last_ref_time: N_rollovers += 1 last_ref_time = event_time # --- CUTS: Packet header window structure --- channel_window_map = {} for i in range(tree.nalu_packet_headers.size()): ph = tree.nalu_packet_headers[i] ch = ph.channel wp = ph.window_position if ch not in channel_window_map: channel_window_map[ch] = set() channel_window_map[ch].add(wp) if CUT_ENFORCE_WINDOW_COUNT: if any(len(wps) != expected_num_windows for wps in channel_window_map.values()): continue if CUT_ENFORCE_WINDOW_MATCH: window_sets = list(channel_window_map.values()) if any(wps != window_sets[0] for wps in window_sets[1:]): continue if CUT_ENFORCE_WINDOW_SEQUENTIAL: sorted_wps = sorted(window_sets[0]) if sorted_wps != list(range(sorted_wps[0], sorted_wps[0] + expected_num_windows)): continue # --- Waveform Processing --- nw_vec = tree.nalu_waveforms for i_window in range(nw_vec.size()): wf = nw_vec[i_window] if wf.channel_num != channel_to_inspect: continue trace = np.array(wf.trace) if CUT_REQUIRE_MIN_TRACE_LENGTH and len(trace) < min_trace_length: continue diff = np.diff(trace) # --- Leading Edge --- leading_edge = np.argmin(diff) if CUT_REQUIRE_VALID_EDGES and (leading_edge < 1 or leading_edge + 1 >= len(diff)): continue numerator_lead = diff[leading_edge - 1] - diff[leading_edge] denominator_lead = diff[leading_edge + 1] - diff[leading_edge] if CUT_REQUIRE_VALID_PSEUDOTIMES and denominator_lead == 0: continue pt_lead = (2 / np.pi) * np.arctan(numerator_lead / denominator_lead) if CUT_REQUIRE_VALID_PSEUDOTIMES and not (0 <= pt_lead <= 1): continue # --- Rising Edge --- rising_edge = np.argmax(diff) if CUT_REQUIRE_VALID_EDGES and (rising_edge < 1 or rising_edge + 1 >= len(diff)): continue numerator_rise = diff[rising_edge] - diff[rising_edge - 1] denominator_rise = diff[rising_edge] - diff[rising_edge + 1] if CUT_REQUIRE_VALID_PSEUDOTIMES and denominator_rise == 0: continue pt_rise = (2 / np.pi) * np.arctan(numerator_rise / denominator_rise) if CUT_REQUIRE_VALID_PSEUDOTIMES and not (0 <= pt_rise <= 1): continue # --- Store results --- Pseudotimes_Leading.append(pt_lead) LeadingEdgeSamples.append(leading_edge) Pseudotimes_Rising.append(pt_rise) RisingEdgeSamples.append(rising_edge) N_roll_overs.append(N_rollovers) EventTimes.append(event_time) EventIndices.append(entry) channel_to_inspect = 1 expected_num_windows = 4 T_rollover = 2**24 min_trace_length = 4 # --- Cut switches --- CUT_SKIP_IF_NO_HEADER = True CUT_ENFORCE_WINDOW_COUNT = True CUT_ENFORCE_WINDOW_MATCH = True CUT_ENFORCE_WINDOW_SEQUENTIAL = True CUT_REQUIRE_MIN_TRACE_LENGTH = True CUT_REQUIRE_VALID_EDGES = True CUT_REQUIRE_VALID_PSEUDOTIMES = True # --- Data accumulators --- Pseudotimes_Leading = [] LeadingEdgeSamples = [] Pseudotimes_Rising = [] RisingEdgeSamples = [] N_roll_overs = [] EventTimes = [] EventIndices = [] Nevents = tree.GetEntries() print(\"Number of events:\", Nevents) last_ref_time = -1 N_rollovers = 0 for entry in range(Nevents): tree.GetEntry(entry) # --- Rollover detection --- neh_vec = tree.nalu_event_headers if CUT_SKIP_IF_NO_HEADER and neh_vec.size() == 0: continue neh = neh_vec[0] event_time = neh.event_reference_time if event_time < last_ref_time: N_rollovers += 1 last_ref_time = event_time # --- CUTS: Packet header window structure --- channel_window_map = {} for i in range(tree.nalu_packet_headers.size()): ph = tree.nalu_packet_headers[i] ch = ph.channel wp = ph.window_position if ch not in channel_window_map: channel_window_map[ch] = set() channel_window_map[ch].add(wp) if CUT_ENFORCE_WINDOW_COUNT: if any(len(wps) != expected_num_windows for wps in channel_window_map.values()): continue if CUT_ENFORCE_WINDOW_MATCH: window_sets = list(channel_window_map.values()) if any(wps != window_sets[0] for wps in window_sets[1:]): continue if CUT_ENFORCE_WINDOW_SEQUENTIAL: sorted_wps = sorted(window_sets[0]) if sorted_wps != list(range(sorted_wps[0], sorted_wps[0] + expected_num_windows)): continue # --- Waveform Processing --- nw_vec = tree.nalu_waveforms for i_window in range(nw_vec.size()): wf = nw_vec[i_window] if wf.channel_num != channel_to_inspect: continue trace = np.array(wf.trace) if CUT_REQUIRE_MIN_TRACE_LENGTH and len(trace) < min_trace_length: continue diff = np.diff(trace) # --- Leading Edge --- leading_edge = np.argmin(diff) if CUT_REQUIRE_VALID_EDGES and (leading_edge < 1 or leading_edge + 1 >= len(diff)): continue numerator_lead = diff[leading_edge - 1] - diff[leading_edge] denominator_lead = diff[leading_edge + 1] - diff[leading_edge] if CUT_REQUIRE_VALID_PSEUDOTIMES and denominator_lead == 0: continue pt_lead = (2 / np.pi) * np.arctan(numerator_lead / denominator_lead) if CUT_REQUIRE_VALID_PSEUDOTIMES and not (0 <= pt_lead <= 1): continue # --- Rising Edge --- rising_edge = np.argmax(diff) if CUT_REQUIRE_VALID_EDGES and (rising_edge < 1 or rising_edge + 1 >= len(diff)): continue numerator_rise = diff[rising_edge] - diff[rising_edge - 1] denominator_rise = diff[rising_edge] - diff[rising_edge + 1] if CUT_REQUIRE_VALID_PSEUDOTIMES and denominator_rise == 0: continue pt_rise = (2 / np.pi) * np.arctan(numerator_rise / denominator_rise) if CUT_REQUIRE_VALID_PSEUDOTIMES and not (0 <= pt_rise <= 1): continue # --- Store results --- Pseudotimes_Leading.append(pt_lead) LeadingEdgeSamples.append(leading_edge) Pseudotimes_Rising.append(pt_rise) RisingEdgeSamples.append(rising_edge) N_roll_overs.append(N_rollovers) EventTimes.append(event_time) EventIndices.append(entry) The result seems expected, we shrink the correct time Maybe this plot is misleading/incorrec though(?). The true time still seems to look not good: We also see a large number of suspicious events: # of Lead suspicious event pairs: 7532 # of Trail suspicious event pairs: 7532 # of Lead suspicious event pairs: 7532 # of Trail suspicious event pairs: 7532 This is less than previously though by a factor of ~2: # of Lead suspicious event pairs: 17053 # of Trail suspicious event pairs: 17053 # of Lead suspicious event pairs: 17053 # of Trail suspicious event pairs: 17053 That all look like (from the few I checked): Event 30 | Corrected Time = 47.37 Channel Window Positions ------------------------------ 0 [16, 17, 18, 19] 1 [16, 17, 18, 19] 2 [16, 17, 18, 19] Event 32 | Corrected Time = 18.93 Channel Window Positions ------------------------------ 0 [21, 22, 23, 24] 1 [21, 22, 23, 24] 2 [21, 22, 23, 24] Event 30 | Corrected Time = 47.37 Channel Window Positions ------------------------------ 0 [16, 17, 18, 19] 1 [16, 17, 18, 19] 2 [16, 17, 18, 19] Event 32 | Corrected Time = 18.93 Channel Window Positions ------------------------------ 0 [21, 22, 23, 24] 1 [21, 22, 23, 24] 2 [21, 22, 23, 24] We still end up cutting out a lot of bad events. Though cut \"2. All channels share the same window positions\" doesn't seems to be working as I'd hoped. It seems the HDSoC has some strange decision making on how it decides to place the pulse trigger. 24/07/2025 02:56 TODO \u2013 Nalu Unpacking Pipeline (Next Steps) \u2733\ufe0f Pipeline Stages to Implement 1. NaluEventHeaderUnpackerStage Reads from a ByteStream Parses and constructs a NaluEventHeader struct Publishes: PipelineDataProduct<NaluEventHeader> 2. NaluPacketCollectionUnpackerStage Repeatedly parses triplets of: NaluPacketHeader NaluPacketPayload NaluPacketFooter Constructs NaluPacket objects from triplets Publishes: PipelineDataProduct<NaluPacketCollection> 3. NaluEventFooterUnpackerStage Parses a single NaluEventFooter struct Publishes: PipelineDataProduct<NaluEventFooter> \u2699\ufe0f Endianness Handling Strategy Binary data fields may require per-member endian correction. A global struct-level toggle is insufficient. Design a general helper utility to: Define per-field endianness policies (e.g., via JSON config) Apply byte-swaps in a centralized manner Keep memcpy -based unpacking fast and readable Possible approach: Table-driven field mapping per struct Use helper functions: read_u16_be(...) , etc. \ud83d\udd04 Refactoring Plan Move ByteStreamProcessorStage : From : unpacker_stages_nalu To : unpacker_stages_core Rationale: It is generic infrastructure Avoids polluting NALU-specific logic with general-purpose dependencies \u2705 Notes Avoid ROOT reflection during unpacking. Stick to POD structs with explicit unpackers. Config can drive unpacker behavior (loop count, mapping), but unpacker must be written per struct. 24/07/2025 15:20 I'm noticing my cuts actually seem to clean up basically all the noise: The confusion last time was I was not displaying negative differences on the time difference histogram, these are were all our outlier are However this is not symmetric, which means there MUST be a systematic effect. From our previous plots: we saw skips backwards. From this, I hypothesize we must have some drift where once we reach the end of a window, the HDSoC moves the pulse back to the start of the window. To check that, we can look at a sequence of many events Ignore the poor plot quality and the events that are bugged/don't pass our cuts (15, 19, 20, 21 and 31 all get cut). You can see a noticeable signal drifft. Once the signal drifts too far, it \"jumps back\". This has to do with the digitzation settings. The HDSoC somehow aligns things such that there is a fixed number of windows ahead of and behind the pulse. As a result, if a pulse is drifting it will occassionally \"jump back\" a full window (corresponding to 32 ns). I'm not sure how to account for this, Tim and/or Sean's input mya be helpful here. The spikes in the true time differences correspond to dropped events Each spike is a multiple (1, 2 or 3) of the first spike. This indicates dropped events. This is expected from our cuts before. Sometimes we're taking the time difference between event index 14 and 16 because we cut event 15, for example. We can instead only consider the true time difference of sequential events only to get a better image to determine timing resolution on: You can see the \"back hump,\" I'm not sure what's causing that.Regardless of the hump, the timing resolution seems to be about 0.13 ns from my analysis, which seems reasonable(?). As a side not you can also cut out all the negative time diffs in the corrected time differences to get a better idea of the distribution: Some of the relevant plotting code: corrected_time_l_diff = np.diff(corrected_lead_t) corrected_time_t_diff = np.diff(corrected_trail_t) bins = int(np.sqrt(len(corrected_time_t_diff))) plt.figure(figsize=(10, 5)) plt.hist(corrected_time_l_diff, bins=bins, alpha=0.3, label=\"Leading Edge\", edgecolor='blue') plt.hist(corrected_time_t_diff, bins=bins, alpha=0.3, label=\"Trailing Edge\", edgecolor='orange') plt.xlabel(\"Corrected time difference\") plt.ylabel(\"Frequency\") plt.yscale(\"log\") plt.title(\"Corrected Time Difference Histogram (Log Scale)\") plt.legend(loc='upper right') plt.grid(True) plt.show() corrected_time_l_diff = np.diff(corrected_lead_t) corrected_time_t_diff = np.diff(corrected_trail_t) bins = int(np.sqrt(len(corrected_time_t_diff))) plt.figure(figsize=(10, 5)) plt.hist(corrected_time_l_diff, bins =bins, alpha =0.3, label = \"Leading Edge\" , edgecolor = 'blue' ) plt.hist(corrected_time_t_diff, bins =bins, alpha =0.3, label = \"Trailing Edge\" , edgecolor = 'orange' ) plt.xlabel( \"Corrected time difference\" ) plt.ylabel( \"Frequency\" ) plt.yscale( \"log\" ) plt.title( \"Corrected Time Difference Histogram (Log Scale)\" ) plt.legend( loc = 'upper right' ) plt.grid( True ) plt.show() # --- Cut switch --- CUT_NEGATIVE_CORRECTED_DIFFS = True # Compute diffs corrected_time_l_diff = np.diff(corrected_lead_t) corrected_time_t_diff = np.diff(corrected_trail_t) # Apply post-histogram cuts cut_mask_l = corrected_time_l_diff > 0 if CUT_NEGATIVE_CORRECTED_DIFFS else np.ones_like(corrected_time_l_diff, dtype=bool) cut_mask_t = corrected_time_t_diff > 0 if CUT_NEGATIVE_CORRECTED_DIFFS else np.ones_like(corrected_time_t_diff, dtype=bool) corrected_time_l_diff_cut = corrected_time_l_diff[cut_mask_l] corrected_time_t_diff_cut = corrected_time_t_diff[cut_mask_t] print(f\"Lead diffs kept: {len(corrected_time_l_diff_cut)} / {len(corrected_time_l_diff)}\") print(f\"Trail diffs kept: {len(corrected_time_t_diff_cut)} / {len(corrected_time_t_diff)}\") # --- Plot --- bins = int(np.sqrt(len(corrected_time_l_diff_cut))) plt.figure(figsize=(10, 5)) plt.hist(corrected_time_l_diff_cut, bins=bins, alpha=0.3, label=\"Leading Edge\", edgecolor='blue') plt.hist(corrected_time_t_diff_cut, bins=bins, alpha=0.3, label=\"Trailing Edge\", edgecolor='orange') plt.xlabel(\"Corrected time difference\") plt.ylabel(\"Frequency\") plt.yscale(\"log\") plt.title(\"Corrected Time Difference Histogram (Log Scale)\") plt.legend(loc='upper right') plt.grid(True) plt.show() # --- Cut switch --- CUT_NEGATIVE_CORRECTED_DIFFS = True # Compute diffs corrected_time_l_diff = np.diff(corrected_lead_t) corrected_time_t_diff = np.diff(corrected_trail_t) # Apply post-histogram cuts cut_mask_l = corrected_time_l_diff > 0 if CUT_NEGATIVE_CORRECTED_DIFFS else np.ones_like(corrected_time_l_diff, dtype=bool) cut_mask_t = corrected_time_t_diff > 0 if CUT_NEGATIVE_CORRECTED_DIFFS else np.ones_like(corrected_time_t_diff, dtype=bool) corrected_time_l_diff_cut = corrected_time_l_diff[cut_mask_l] corrected_time_t_diff_cut = corrected_time_t_diff[cut_mask_t] print(f\"Lead diffs kept: {len(corrected_time_l_diff_cut)} / {len(corrected_time_l_diff)}\") print(f\"Trail diffs kept: {len(corrected_time_t_diff_cut)} / {len(corrected_time_t_diff)}\") # --- Plot --- bins = int(np.sqrt(len(corrected_time_l_diff_cut))) plt.figure(figsize=(10, 5)) plt.hist(corrected_time_l_diff_cut, bins=bins, alpha=0.3, label=\"Leading Edge\", edgecolor='blue') plt.hist(corrected_time_t_diff_cut, bins=bins, alpha=0.3, label=\"Trailing Edge\", edgecolor='orange') plt.xlabel(\"Corrected time difference\") plt.ylabel(\"Frequency\") plt.yscale(\"log\") plt.title(\"Corrected Time Difference Histogram (Log Scale)\") plt.legend(loc='upper right') plt.grid(True) plt.show() sample_period_to_ref_period = 32 T_rollover = 2**24 EventTimes = np.array(EventTimes) N_roll_overs = np.array(N_roll_overs) corrected_lead_t = np.array(corrected_time_l_diff_cut) corrected_trail_t = np.array(corrected_time_t_diff_cut) truetime_lead = (EventTimes + N_roll_overs * T_rollover) * sample_period_to_ref_period + corrected_lead_t truetime_trail = (EventTimes + N_roll_overs * T_rollover) * sample_period_to_ref_period + corrected_trail_t print(len(truetime_lead)) print(len(truetime_trail)) sample_period_to_ref_period = 32 T_rollover = 2 ** 24 EventTimes = np. array (EventTimes) N_roll_overs = np. array (N_roll_overs) corrected_lead_t = np. array (corrected_time_l_diff_cut) corrected_trail_t = np. array (corrected_time_t_diff_cut) true time_lead = (EventTimes + N_roll_overs * T_rollover) * sample_period_to_ref_period + corrected_lead_t true time_trail = (EventTimes + N_roll_overs * T_rollover) * sample_period_to_ref_period + corrected_trail_t print(len( true time_lead)) print(len( true time_trail)) # --- Cut switches --- CUT_SEQUENTIAL_ONLY = True # Convert to np arrays EventIndices = np.array(EventIndices) truetime_lead = np.array(truetime_lead) truetime_trail = np.array(truetime_trail) # Compute diffs diff_event_idx = np.diff(EventIndices) diff_true_lead = np.diff(truetime_lead) diff_true_trail = np.diff(truetime_trail) # Initial mask all True mask = np.ones_like(diff_event_idx, dtype=bool) # Apply sequential cut only if CUT_SEQUENTIAL_ONLY: mask &= (diff_event_idx == 1) # Filtered diffs true_t_lead_diff = diff_true_lead[mask] true_t_trail_diff = diff_true_trail[mask] # Report counts total_lead = len(diff_true_lead) kept_lead = len(true_t_lead_diff) cut_lead = total_lead - kept_lead total_trail = len(diff_true_trail) kept_trail = len(true_t_trail_diff) cut_trail = total_trail - kept_trail print(f\"Lead diffs: kept {kept_lead} / total {total_lead} (cut {cut_lead})\") print(f\"Trail diffs: kept {kept_trail} / total {total_trail} (cut {cut_trail})\") # --- Cut switches --- CUT_SEQUENTIAL_ONLY = True # Convert to np arrays EventIndices = np.array(EventIndices) truetime_lead = np.array(truetime_lead) truetime_trail = np.array(truetime_trail) # Compute diffs diff_event_idx = np.diff(EventIndices) diff_true_lead = np.diff(truetime_lead) diff_true_trail = np.diff(truetime_trail) # Initial mask all True mask = np.ones_like(diff_event_idx, dtype=bool) # Apply sequential cut only if CUT_SEQUENTIAL_ONLY: mask &= (diff_event_idx == 1) # Filtered diffs true_t_lead_diff = diff_true_lead[mask] true_t_trail_diff = diff_true_trail[mask] # Report counts total_lead = len(diff_true_lead) kept_lead = len(true_t_lead_diff) cut_lead = total_lead - kept_lead total_trail = len(diff_true_trail) kept_trail = len(true_t_trail_diff) cut_trail = total_trail - kept_trail print(f \"Lead diffs: kept {kept_lead} / total {total_lead} (cut {cut_lead})\" ) print(f \"Trail diffs: kept {kept_trail} / total {total_trail} (cut {cut_trail})\" ) import numpy as np from scipy.stats import norm import matplotlib.pyplot as plt # Compute stats mu_lead = np.mean(true_t_lead_diff) sigma_lead = np.std(true_t_lead_diff) mu_trail = np.mean(true_t_trail_diff) sigma_trail = np.std(true_t_trail_diff) # Plot plt.figure(figsize=(10, 5)) bins = int(np.sqrt(len(true_t_lead_diff))) plt.hist(true_t_lead_diff, bins=bins, alpha=0.8, label=\"Leading Edge\", edgecolor='blue') plt.hist(true_t_trail_diff, bins=bins, alpha=0.8, label=\"Trailing Edge\", edgecolor='orange') plt.xlabel(\"True Time Difference (sequential events only)\") plt.ylabel(\"Count\") plt.title(\"True Time Difference Histogram (Sequential Events, Log Scale)\") plt.yscale(\"log\") plt.ylim(bottom=0.1) plt.grid(True) # Text annotation text_x = 0.10 # axes fraction text_y = 0.15 # axes fraction plt.gca().text( text_x, text_y, f\"Lead \u03bc={mu_lead:.2f}, \u03c3={sigma_lead:.2f}\\nTrail \u03bc={mu_trail:.2f}, \u03c3={sigma_trail:.2f}\", transform=plt.gca().transAxes, fontsize=10, verticalalignment='top', bbox=dict(facecolor='white', edgecolor='gray', alpha=0.7) ) plt.legend(loc='upper right') plt.show() import numpy as np from scipy.stats import norm import matplotlib.pyplot as plt # Compute stats mu_lead = np.mean(true_t_lead_diff) sigma_lead = np.std(true_t_lead_diff) mu_trail = np.mean(true_t_trail_diff) sigma_trail = np.std(true_t_trail_diff) # Plot plt.figure(figsize=(10, 5)) bins = int(np.sqrt(len(true_t_lead_diff))) plt.hist(true_t_lead_diff, bins=bins, alpha=0.8, label=\"Leading Edge\", edgecolor='blue') plt.hist(true_t_trail_diff, bins=bins, alpha=0.8, label=\"Trailing Edge\", edgecolor='orange') plt.xlabel(\"True Time Difference (sequential events only)\") plt.ylabel(\"Count\") plt.title(\"True Time Difference Histogram (Sequential Events, Log Scale)\") plt.yscale(\"log\") plt.ylim(bottom=0.1) plt.grid(True) # Text annotation text_x = 0.10 # axes fraction text_y = 0.15 # axes fraction plt.gca().text( text_x, text_y, f\"Lead \u03bc={mu_lead:.2f}, \u03c3={sigma_lead:.2f}\\nTrail \u03bc={mu_trail:.2f}, \u03c3={sigma_trail:.2f}\", transform=plt.gca().transAxes, fontsize=10, verticalalignment='top', bbox=dict(facecolor='white', edgecolor='gray', alpha=0.7) ) plt.legend(loc='upper right') plt.show() from scipy.stats import norm import numpy as np import matplotlib.pyplot as plt # Fit Gaussian to data mu_lead, sigma_lead = norm.fit(true_t_lead_diff) mu_trail, sigma_trail = norm.fit(true_t_trail_diff) # \u221aN binning num_bins = int(np.sqrt(len(true_t_lead_diff))) plt.figure(figsize=(10, 5)) # --- Leading Edge Histogram and Fit --- counts_lead, bin_edges_lead = np.histogram(true_t_lead_diff, bins=num_bins) bin_centers_lead = 0.5 * (bin_edges_lead[1:] + bin_edges_lead[:-1]) bin_width_lead = bin_edges_lead[1] - bin_edges_lead[0] # Gaussian PDF scaled to histogram pdf_lead = norm.pdf(bin_centers_lead, mu_lead, sigma_lead) * np.sum(counts_lead) * bin_width_lead # Plot histogram with Poisson errors nonzero_mask_lead = counts_lead > 0 plt.errorbar( bin_centers_lead[nonzero_mask_lead], counts_lead[nonzero_mask_lead], yerr=np.sqrt(counts_lead[nonzero_mask_lead]), fmt='o', markersize=3, color='blue', markerfacecolor='blue', ecolor='black', elinewidth=1, capsize=2, capthick=1, label='Leading Edge' ) plt.plot(bin_centers_lead, pdf_lead, 'b--', label=f\"Lead Fit: \u03bc={mu_lead:.2f}, \u03c3={sigma_lead:.2f}\") # --- Trailing Edge Histogram and Fit --- counts_trail, bin_edges_trail = np.histogram(true_t_trail_diff, bins=num_bins) bin_centers_trail = 0.5 * (bin_edges_trail[1:] + bin_edges_trail[:-1]) bin_width_trail = bin_edges_trail[1] - bin_edges_trail[0] pdf_trail = norm.pdf(bin_centers_trail, mu_trail, sigma_trail) * np.sum(counts_trail) * bin_width_trail nonzero_mask_trail = counts_trail > 0 plt.errorbar( bin_centers_trail[nonzero_mask_trail], counts_trail[nonzero_mask_trail], yerr=np.sqrt(counts_trail[nonzero_mask_trail]), fmt='o', markersize=3, color='orange', markerfacecolor='orange', ecolor='black', elinewidth=1, capsize=2, capthick=1, label='Trailing Edge' ) plt.plot(bin_centers_trail, pdf_trail, 'orange', linestyle='--', label=f\"Trail Fit: \u03bc={mu_trail:.2f}, \u03c3={sigma_trail:.2f}\") # Labels and formatting plt.xlabel(\"True Time Difference (sequential events only)\") plt.ylabel(\"Count\") plt.title(\"True Time Difference Histogram with Gaussian Fit + Poisson Errors (Log Scale)\") plt.yscale(\"log\") plt.ylim(bottom=0.1) plt.grid(True) plt.legend(loc='upper right') plt.tight_layout() plt.show() # Optional: print stats print(f\"Leading Edge \u03c3: {sigma_lead:.4f}\") print(f\"Trailing Edge \u03c3: {sigma_trail:.4f}\") from scipy.stats import norm import numpy as np import matplotlib.pyplot as plt # Fit Gaussian to data mu_lead, sigma_lead = norm.fit(true_t_lead_diff) mu_trail, sigma_trail = norm.fit(true_t_trail_diff) # \u221aN binning num_bins = int(np.sqrt(len(true_t_lead_diff))) plt.figure(figsize=(10, 5)) # --- Leading Edge Histogram and Fit --- counts_lead, bin_edges_lead = np.histogram(true_t_lead_diff, bins=num_bins) bin_centers_lead = 0.5 * (bin_edges_lead[1:] + bin_edges_lead[:-1]) bin_width_lead = bin_edges_lead[1] - bin_edges_lead[0] # Gaussian PDF scaled to histogram pdf_lead = norm.pdf(bin_centers_lead, mu_lead, sigma_lead) * np.sum(counts_lead) * bin_width_lead # Plot histogram with Poisson errors nonzero_mask_lead = counts_lead > 0 plt.errorbar( bin_centers_lead[nonzero_mask_lead], counts_lead[nonzero_mask_lead], yerr=np.sqrt(counts_lead[nonzero_mask_lead]), fmt='o', markersize=3, color='blue', markerfacecolor='blue', ecolor='black', elinewidth=1, capsize=2, capthick=1, label='Leading Edge' ) plt.plot(bin_centers_lead, pdf_lead, 'b--', label=f\"Lead Fit: \u03bc={mu_lead:.2f}, \u03c3={sigma_lead:.2f}\") # --- Trailing Edge Histogram and Fit --- counts_trail, bin_edges_trail = np.histogram(true_t_trail_diff, bins=num_bins) bin_centers_trail = 0.5 * (bin_edges_trail[1:] + bin_edges_trail[:-1]) bin_width_trail = bin_edges_trail[1] - bin_edges_trail[0] pdf_trail = norm.pdf(bin_centers_trail, mu_trail, sigma_trail) * np.sum(counts_trail) * bin_width_trail nonzero_mask_trail = counts_trail > 0 plt.errorbar( bin_centers_trail[nonzero_mask_trail], counts_trail[nonzero_mask_trail], yerr=np.sqrt(counts_trail[nonzero_mask_trail]), fmt='o', markersize=3, color='orange', markerfacecolor='orange', ecolor='black', elinewidth=1, capsize=2, capthick=1, label='Trailing Edge' ) plt.plot(bin_centers_trail, pdf_trail, 'orange', linestyle='--', label=f\"Trail Fit: \u03bc={mu_trail:.2f}, \u03c3={sigma_trail:.2f}\") # Labels and formatting plt.xlabel(\"True Time Difference (sequential events only)\") plt.ylabel(\"Count\") plt.title(\"True Time Difference Histogram with Gaussian Fit + Poisson Errors (Log Scale)\") plt.yscale(\"log\") plt.ylim(bottom=0.1) plt.grid(True) plt.legend(loc='upper right') plt.tight_layout() plt.show() # Optional: print stats print(f\"Leading Edge \u03c3: {sigma_lead:.4f}\") print(f\"Trailing Edge \u03c3: {sigma_trail:.4f}\")",
    "textLength": 5114
  },
  {
    "kind": "work-log",
    "title": "09_03_2025 - 15_03_2025.html",
    "fileName": "09_03_2025 - 15_03_2025.html",
    "url": "resources/work_logs/09_03_2025 - 15_03_2025.html",
    "createdDate": "2025-03-09",
    "text": "09/03/2025 - 15/03/2025 09/03/2025 - 15/03/2025 10/03/2025 15:14 I did a \"case study\" on the parameter (external trigger rate, number of channels, number of windows) = (4500, 16, 62) which crashes the midas sequencer. I found it also will crash (with this claiming all the RAM issue) even if I run this case \"by hand\" (i..e no sequencer). However, if I set the time threshold to something absurd ( int time_threshold = 34750 which corresponds to about 1.5ms) I can construct at least some events. Note: this is very volatile. I.e. sometimes I run with this time threshold and we create events that are too big and it errors out. It seems the issue here is the board has no pause between creating packets, meaning we can't group events by time. Instead we have to \"guess\" how long it takes to process the correct number of packets, and this might not even correspond to an event. Event index: 0 Event is complete: 0 Event num packets: 882 Event reference time: 5761574 Event index: 1 Event is complete: 1 Event num packets: 992 Event reference time: 5810185 Event index: 2 Event is complete: 1 Event num packets: 992 Event reference time: 5858796 Event index: 3 Event is complete: 1 Event num packets: 992 Event reference time: 5907407 Event index: 4 Event is complete: 1 Event num packets: 993 Event reference time: 5956019 Event index: 5 Event is complete: 0 Event num packets: 991 Event reference time: 6004630 Event index: 6 Event is complete: 0 Event num packets: 481 Event reference time: 6053241 Event index: 0 Event is complete: 0 Event num packets: 882 Event reference time: 5761574 Event index: 1 Event is complete: 1 Event num packets: 992 Event reference time: 5810185 Event index: 2 Event is complete: 1 Event num packets: 992 Event reference time: 5858796 Event index: 3 Event is complete: 1 Event num packets: 992 Event reference time: 5907407 Event index: 4 Event is complete: 1 Event num packets: 993 Event reference time: 5956019 Event index: 5 Event is complete: 0 Event num packets: 991 Event reference time: 6004630 Event index: 6 Event is complete: 0 Event num packets: 481 Event reference time: 6053241 Some puzzles: This still doesn't explain the issues I saw with (3250, 16, 62), because that worked when I ran it without the sequencer by not with tht sequencer I was able to group events with time seperation of 5000 clock ticks for (28000, 32, 62) with seemingly no problems during my testing",
    "textLength": 430
  },
  {
    "kind": "work-log",
    "title": "12_10_2025 - 18_10_2025.html",
    "fileName": "12_10_2025 - 18_10_2025.html",
    "url": "resources/work_logs/12_10_2025 - 18_10_2025.html",
    "createdDate": "2025-10-12",
    "text": "12/10/2025 - 18/10/2025 12/10/2025 - 18/10/2025 14/10/2025 23:10 In gpu_thread.h:45, I changed #define GPU_BUFFER_SIZE 512 # define GPU_BUFFER_SIZE 512 to #define GPU_BUFFER_SIZE 300 # define GPU_BUFFER_SIZE 300 with the theory being somehow this buffer size relates to the skipping we see in events (which is always a multiple of 512). However, this did not seem to affect the displacement of events: [root@dhcp-10-163-105-238 scripts]# ./run.sh /home/pioneer/data/gm2daq_data/run00193.mid.lz4 --debug [run.sh, INFO] Running unpacker with args: /home/pioneer/data/gm2daq_data/run00193.mid.lz4 --debug [INFO] Debug mode enabled. Printing every 1000 events. [INFO] Processing: \"/home/pioneer/data/gm2daq_data/run00193.mid.lz4\" [DEBUG] Event 1000 \u2014 CR01: 611 | CR02: 611 [DEBUG] Event 2000 \u2014 CR01: 1735 | CR02: 1735 [DEBUG] Event 3000 \u2014 CR01: 2859 | CR02: 2859 [DEBUG] Event 4000 \u2014 CR01: 3683 | CR02: 3683 [DEBUG] Event 5000 \u2014 CR01: 4807 | CR02: 4807 [MISMATCH] Event 5530 \u2014 CR01: 5761 | CR02: 5249 [RESULT] Trigger mismatch found in \"/home/pioneer/data/gm2daq_data/run00193.mid.lz4\" [root@dhcp-10-163-105-238 scripts]# [root@dhcp-10-163-105-238 scripts]# ./run.sh /home/pioneer/data/gm2daq_data/run00193.mid.lz4 --debug [run.sh, INFO] Running unpacker with args: /home/pioneer/data/gm2daq_data/run00193.mid.lz4 --debug [INFO] Debug mode enabled. Printing every 1000 events. [INFO] Processing: \"/home/pioneer/data/gm2daq_data/run00193.mid.lz4\" [DEBUG] Event 1000 \u2014 CR01: 611 | CR02: 611 [DEBUG] Event 2000 \u2014 CR01: 1735 | CR02: 1735 [DEBUG] Event 3000 \u2014 CR01: 2859 | CR02: 2859 [DEBUG] Event 4000 \u2014 CR01: 3683 | CR02: 3683 [DEBUG] Event 5000 \u2014 CR01: 4807 | CR02: 4807 [MISMATCH] Event 5530 \u2014 CR01: 5761 | CR02: 5249 [RESULT] Trigger mismatch found in \"/home/pioneer/data/gm2daq_data/run00193.mid.lz4\" [root@dhcp-10-163-105-238 scripts]# 5761 - 5249 = 512 \\implies 5761 \u2212 5249 = 512 \u27f9 5761 - 5249 = 512 \\implies 5761 \u2212 5249 = 512 \u27f9 same displacement. Tim's code output: AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 513, 300, 512AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 513, 812, 512AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 1025, 812, 1024AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 1025, 1324, 1024AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 1537, 1324, 1536AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 2049, 1836, 2048AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 2049, 2348, 2048AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 2561, 2348, 2560AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 2561, 2860, 2560AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 3073, 2860, 3072AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 3585, 3372, 3584AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 3585, 3884, 3584AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 4097, 3884, 4096AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 4097, 4396, 4096AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 4609, 4396, 4608AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 4609, 4908, 4608AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 5121, 4908, 5120[AMC13001,TALK] Warning: DAQ | AMC13001 GPU Ring buffer close to full (90.039062%) AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 5761, 5248, 5760[AMC13001,TALK] Recovery: DAQ | AMC13001 GPU Ring buffer returns normal (88.281250%) AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 5633, 5932, 5632AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 5633, 5932, 5632AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 6675, 5650, 6674AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 6302, 6813, 6301AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 6657, 6444, 6656AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 6332, 6843, 6331AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 6657, 6444, 6656AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 7239, 6726, 7238AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 7169, 7468, 7168AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 7940, 7427, 7939AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 7681, 7980, 7680AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 7681, 7980, 7680AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 8341, 7828, 8340AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 8705, 8492, 8704AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 8281, 8792, 8280AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 8705, 8492, 8704AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 9254, 8741, 9253AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 8751, 9262, 8750AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 9217, 9004, 9216AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 8774, 9285, 8773AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 9955, 8930, 9954AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 9471, 9982, 9470AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 9729, 9516, 9728AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 9499, 10010, 9498AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 9729, 9516, 9728AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 10519, 10006, 10518AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 10753, 10540, 10752AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 10254, 10765, 10253AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 10753, 10540, 10752AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 10277, 10788, 10276AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 10920, 10407, 10919AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 11265, 11052, 11264AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 10803, 11314, 10802AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 11265, 11052, 11264AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 11833, 11320, 11832AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 11521, 12032, 11520AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 11777, 11564, 11776AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 12534, 12021, 12533AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 12037, 12548, 12036AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 12289, 12076, 12288AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 12061, 12572, 12060AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 12289, 12076, 12288AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 12935, 12422, 12934AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 12801, 13100, 12800AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 13313, 13100, 13312AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 12819, 13330, 12818AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 14011, 12986, 14010AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 13511, 14022, 13510AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 13825, 13612, 13824AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 13534, 14045, 13533AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 13825, 13612, 13824AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 14412, 13899, 14411AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 14001, 14512, 14000AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 14337, 14124, 14336AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 14031, 14542, 14030AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 15113, 14088, 15112AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 14849, 15148, 14848AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 14849, 15148, 14848AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 15514, 15001, 15513AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 15361, 15660, 15360AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 15361, 15660, 15360AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 15915, 15402, 15914AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 16385, 16172, 16384AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 15874, 16385, 15873AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 16385, 16172, 16384AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 15905, 16416, 15904AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 16991, 15966, 16990AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 16605, 17116, 16604AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 16897, 16684, 16896AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 16631, 17142, 16630AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 17180, 16667, 17179AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 17409, 17196, 17408AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 17098, 17609, 17097AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 17409, 17196, 17408AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 18093, 17580, 18092AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 17921, 18220, 17920AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 17921, 18220, 17920AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 18495, 17982, 18494AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 18433, 18732, 18432AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 19196, 18683, 19195AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 19457, 19244, 19456AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 19019, 19530, 19018AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 19457, 19244, 19456AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 19050, 19561, 19049AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 19457, 19244, 19456AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 19972, 19459, 19971AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 19969, 20268, 19968AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 19969, 20268, 19968AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 19969, 20268, 19968AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 19969, 20268, 19968AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 19969, 20268, 19968AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 19969, 20268, 19968AMC13fi AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 513, 300, 512AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 513, 812, 512AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 1025, 812, 1024AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 1025, 1324, 1024AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 1537, 1324, 1536AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 2049, 1836, 2048AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 2049, 2348, 2048AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 2561, 2348, 2560AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 2561, 2860, 2560AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 3073, 2860, 3072AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 3585, 3372, 3584AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 3585, 3884, 3584AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 4097, 3884, 4096AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 4097, 4396, 4096AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 4609, 4396, 4608AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 4609, 4908, 4608AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 5121, 4908, 5120[AMC13001,TALK] Warning: DAQ | AMC13001 GPU Ring buffer close to full (90.039062%) AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 5761, 5248, 5760[AMC13001,TALK] Recovery: DAQ | AMC13001 GPU Ring buffer returns normal (88.281250%) AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 5633, 5932, 5632AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 5633, 5932, 5632AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 6675, 5650, 6674AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 6302, 6813, 6301AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 6657, 6444, 6656AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 6332, 6843, 6331AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 6657, 6444, 6656AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 7239, 6726, 7238AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 7169, 7468, 7168AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 7940, 7427, 7939AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 7681, 7980, 7680AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 7681, 7980, 7680AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 8341, 7828, 8340AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 8705, 8492, 8704AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 8281, 8792, 8280AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 8705, 8492, 8704AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 9254, 8741, 9253AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 8751, 9262, 8750AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 9217, 9004, 9216AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 8774, 9285, 8773AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 9955, 8930, 9954AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 9471, 9982, 9470AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 9729, 9516, 9728AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 9499, 10010, 9498AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 9729, 9516, 9728AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 10519, 10006, 10518AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 10753, 10540, 10752AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 10254, 10765, 10253AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 10753, 10540, 10752AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 10277, 10788, 10276AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 10920, 10407, 10919AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 11265, 11052, 11264AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 10803, 11314, 10802AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 11265, 11052, 11264AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 11833, 11320, 11832AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 11521, 12032, 11520AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 11777, 11564, 11776AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 12534, 12021, 12533AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 12037, 12548, 12036AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 12289, 12076, 12288AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 12061, 12572, 12060AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 12289, 12076, 12288AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 12935, 12422, 12934AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 12801, 13100, 12800AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 13313, 13100, 13312AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 12819, 13330, 12818AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 14011, 12986, 14010AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 13511, 14022, 13510AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 13825, 13612, 13824AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 13534, 14045, 13533AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 13825, 13612, 13824AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 14412, 13899, 14411AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 14001, 14512, 14000AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 14337, 14124, 14336AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 14031, 14542, 14030AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 15113, 14088, 15112AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 14849, 15148, 14848AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 14849, 15148, 14848AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 15514, 15001, 15513AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 15361, 15660, 15360AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 15361, 15660, 15360AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 15915, 15402, 15914AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 16385, 16172, 16384AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 15874, 16385, 15873AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 16385, 16172, 16384AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 15905, 16416, 15904AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 16991, 15966, 16990AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 16605, 17116, 16604AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 16897, 16684, 16896AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 16631, 17142, 16630AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 17180, 16667, 17179AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 17409, 17196, 17408AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 17098, 17609, 17097AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 17409, 17196, 17408AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 18093, 17580, 18092AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 17921, 18220, 17920AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 17921, 18220, 17920AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 18495, 17982, 18494AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 18433, 18732, 18432AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 19196, 18683, 19195AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 19457, 19244, 19456AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 19019, 19530, 19018AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 19457, 19244, 19456AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 19050, 19561, 19049AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 19457, 19244, 19456AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 19972, 19459, 19971AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 19969, 20268, 19968AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 19969, 20268, 19968AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 19969, 20268, 19968AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 19969, 20268, 19968AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 19969, 20268, 19968AMC13fillcounter, lastAMC13fillcounter, GPUmuonfillcounter, 19969, 20268, 19968AMC13fi which tabulated gives: AMC13 lastAMC13 GPUmuon \u0394(A\u2013B) \u0394(A\u2013C) \u0394(C\u2013B) 513 300 512 213 1 212 513 812 512 -299 1 -300 1025 812 1024 213 1 212 1025 1324 1024 -299 1 -300 1537 1324 1536 213 1 212 2049 1836 2048 213 1 212 2049 2348 2048 -299 1 -300 2561 2348 2560 213 1 212 2561 2860 2560 -299 1 -300 3073 2860 3072 213 1 212 3585 3372 3584 213 1 212 3585 3884 3584 -299 1 -300 4097 3884 4096 213 1 212 4097 4396 4096 -299 1 -300 4609 4396 4608 213 1 212 4609 4908 4608 -299 1 -300 5121 4908 5120 213 1 212 5761 5248 5760 513 1 512 5633 5932 5632 -299 1 -300 6675 5650 6674 1025 1 1024 6302 6813 6301 -511 1 -512 6657 6444 6656 213 1 212 6332 6843 6331 -511 1 -512 7239 6726 7238 513 1 512 7169 7468 7168 -299 1 -300 7940 7427 7939 513 1 512 7681 7980 7680 -299 1 -300 8341 7828 8340 513 1 512 8705 8492 8704 213 1 212 8281 8792 8280 -511 1 -512 9254 8741 9253 513 1 512 8751 9262 8750 -511 1 -512 9955 8930 9954 1025 1 1024 9471 9982 9470 -511 1 -512 10519 10006 10518 513 1 512 10753 10540 10752 213 1 212 10254 10765 10253 -511 1 -512 10920 10407 10919 513 1 512 11265 11052 11264 213 1 212 10803 11314 10802 -511 1 -512 11833 11320 11832 513 1 512 11521 12032 11520 -511 1 -512 12534 12021 12533 513 1 512 12037 12548 12036 -511 1 -512 12935 12422 12934 513 1 512 12801 13100 12800 -299 1 -300 13313 13100 13312 213 1 212 12819 13330 12818 -511 1 -512 14011 12986 14010 1025 1 1024 13511 14022 13510 -511 1 -512 13825 13612 13824 213 1 212 13534 14045 13533 -511 1 -512 14412 13899 14411 513 1 512 14001 14512 14000 -511 1 -512 15113 14088 15112 1025 1 1024 14849 15148 14848 -299 1 -300 15514 15001 15513 513 1 512 15361 15660 15360 -299 1 -300 15915 15402 15914 513 1 512 16385 16172 16384 213 1 212 15874 16385 15873 -511 1 -512 16991 15966 16990 1025 1 1024 16605 17116 16604 -511 1 -512 16897 16684 16896 213 1 212 16631 17142 16630 -511 1 -512 17180 16667 17179 513 1 512 17409 17196 17408 213 1 212 17098 17609 17097 -511 1 -512 18093 17580 18092 513 1 512 17921 18220 17920 -299 1 -300 18495 17982 18494 513 1 512 18433 18732 18432 -299 1 -300 19196 18683 19195 513 1 512 19457 19244 19456 213 1 212 19019 19530 19018 -511 1 -512 19972 19459 19971 513 1 512 19969 20268 19968 -299 1 -300 However, the actual recorded data shows desyncs starting at seemingly unrelated indices. always seperated by a multiple of 512 (truncated to only show 100 desyncs) [root@dhcp-10-163-105-238 scripts]# ./run.sh /home/pioneer/data/gm2daq_data/run00193.mid.lz4 --debug --max-desyncs 100 [run.sh, INFO] Running unpacker with args: /home/pioneer/data/gm2daq_data/run00193.mid.lz4 --debug --max-desyncs 100 [INFO] Debug mode enabled. Printing every 1000 events. [INFO] Max desyncs set to 100 [INFO] Processing: \"/home/pioneer/data/gm2daq_data/run00193.mid.lz4\" [DEBUG] Event 1000 \u2014 CR01: 611 | CR02: 611 [DEBUG] Event 2000 \u2014 CR01: 1735 | CR02: 1735 [DEBUG] Event 3000 \u2014 CR01: 2859 | CR02: 2859 [DEBUG] Event 4000 \u2014 CR01: 3683 | CR02: 3683 [DEBUG] Event 5000 \u2014 CR01: 4807 | CR02: 4807 [MISMATCH] Event 5530 \u2014 CR01: 5761 | CR02: 5249 | Difference = 512 | (Desync #1) [MISMATCH] Event 5531 \u2014 CR01: 5762 | CR02: 5250 | Difference = 512 | (Desync #2) [MISMATCH] Event 5532 \u2014 CR01: 5763 | CR02: 5251 | Difference = 512 | (Desync #3) [MISMATCH] Event 5533 \u2014 CR01: 5764 | CR02: 5252 | Difference = 512 | (Desync #4) [MISMATCH] Event 5534 \u2014 CR01: 5765 | CR02: 5253 | Difference = 512 | (Desync #5) [MISMATCH] Event 5535 \u2014 CR01: 5766 | CR02: 5254 | Difference = 512 | (Desync #6) [MISMATCH] Event 5536 \u2014 CR01: 5767 | CR02: 5255 | Difference = 512 | (Desync #7) [MISMATCH] Event 5537 \u2014 CR01: 5768 | CR02: 5256 | Difference = 512 | (Desync #8) [MISMATCH] Event 5538 \u2014 CR01: 5769 | CR02: 5257 | Difference = 512 | (Desync #9) [MISMATCH] Event 5539 \u2014 CR01: 5770 | CR02: 5258 | Difference = 512 | (Desync #10) [MISMATCH] Event 5540 \u2014 CR01: 5771 | CR02: 5259 | Difference = 512 | (Desync #11) [MISMATCH] Event 5541 \u2014 CR01: 5772 | CR02: 5260 | Difference = 512 | (Desync #12) [MISMATCH] Event 5542 \u2014 CR01: 5773 | CR02: 5261 | Difference = 512 | (Desync #13) [MISMATCH] Event 5543 \u2014 CR01: 5774 | CR02: 5262 | Difference = 512 | (Desync #14) [MISMATCH] Event 5544 \u2014 CR01: 5775 | CR02: 5263 | Difference = 512 | (Desync #15) [MISMATCH] Event 5545 \u2014 CR01: 5776 | CR02: 5264 | Difference = 512 | (Desync #16) [MISMATCH] Event 5546 \u2014 CR01: 5777 | CR02: 5265 | Difference = 512 | (Desync #17) [MISMATCH] Event 5547 \u2014 CR01: 5778 | CR02: 5266 | Difference = 512 | (Desync #18) [MISMATCH] Event 5548 \u2014 CR01: 5779 | CR02: 5267 | Difference = 512 | (Desync #19) [MISMATCH] Event 5549 \u2014 CR01: 5780 | CR02: 5268 | Difference = 512 | (Desync #20) [MISMATCH] Event 5550 \u2014 CR01: 5781 | CR02: 5269 | Difference = 512 | (Desync #21) [MISMATCH] Event 5551 \u2014 CR01: 5782 | CR02: 5270 | Difference = 512 | (Desync #22) [MISMATCH] Event 5552 \u2014 CR01: 5783 | CR02: 5271 | Difference = 512 | (Desync #23) [MISMATCH] Event 5553 \u2014 CR01: 5784 | CR02: 5272 | Difference = 512 | (Desync #24) [MISMATCH] Event 5554 \u2014 CR01: 5785 | CR02: 5273 | Difference = 512 | (Desync #25) [MISMATCH] Event 5555 \u2014 CR01: 5786 | CR02: 5274 | Difference = 512 | (Desync #26) [MISMATCH] Event 5556 \u2014 CR01: 5787 | CR02: 5275 | Difference = 512 | (Desync #27) [MISMATCH] Event 5557 \u2014 CR01: 5788 | CR02: 5276 | Difference = 512 | (Desync #28) [MISMATCH] Event 5558 \u2014 CR01: 5789 | CR02: 5277 | Difference = 512 | (Desync #29) [MISMATCH] Event 5559 \u2014 CR01: 5790 | CR02: 5278 | Difference = 512 | (Desync #30) [MISMATCH] Event 5560 \u2014 CR01: 5791 | CR02: 5279 | Difference = 512 | (Desync #31) [MISMATCH] Event 5561 \u2014 CR01: 5792 | CR02: 5280 | Difference = 512 | (Desync #32) [MISMATCH] Event 5562 \u2014 CR01: 5793 | CR02: 5281 | Difference = 512 | (Desync #33) [MISMATCH] Event 5563 \u2014 CR01: 5794 | CR02: 5282 | Difference = 512 | (Desync #34) [MISMATCH] Event 5564 \u2014 CR01: 5795 | CR02: 5283 | Difference = 512 | (Desync #35) [MISMATCH] Event 5565 \u2014 CR01: 5796 | CR02: 5284 | Difference = 512 | (Desync #36) [MISMATCH] Event 5566 \u2014 CR01: 5797 | CR02: 5285 | Difference = 512 | (Desync #37) [MISMATCH] Event 5567 \u2014 CR01: 5798 | CR02: 5286 | Difference = 512 | (Desync #38) [MISMATCH] Event 5568 \u2014 CR01: 5799 | CR02: 5287 | Difference = 512 | (Desync #39) [MISMATCH] Event 5569 \u2014 CR01: 5800 | CR02: 5288 | Difference = 512 | (Desync #40) [MISMATCH] Event 5570 \u2014 CR01: 5801 | CR02: 5289 | Difference = 512 | (Desync #41) [MISMATCH] Event 5571 \u2014 CR01: 5802 | CR02: 5290 | Difference = 512 | (Desync #42) [MISMATCH] Event 5572 \u2014 CR01: 5803 | CR02: 5291 | Difference = 512 | (Desync #43) [MISMATCH] Event 5573 \u2014 CR01: 5804 | CR02: 5292 | Difference = 512 | (Desync #44) [MISMATCH] Event 5574 \u2014 CR01: 5805 | CR02: 5293 | Difference = 512 | (Desync #45) [MISMATCH] Event 5575 \u2014 CR01: 5806 | CR02: 5294 | Difference = 512 | (Desync #46) [MISMATCH] Event 5576 \u2014 CR01: 5807 | CR02: 5295 | Difference = 512 | (Desync #47) [MISMATCH] Event 5577 \u2014 CR01: 5808 | CR02: 5296 | Difference = 512 | (Desync #48) [MISMATCH] Event 5578 \u2014 CR01: 5809 | CR02: 5297 | Difference = 512 | (Desync #49) [MISMATCH] Event 5579 \u2014 CR01: 5810 | CR02: 5298 | Difference = 512 | (Desync #50) [MISMATCH] Event 5580 \u2014 CR01: 5811 | CR02: 5299 | Difference = 512 | (Desync #51) [MISMATCH] Event 5581 \u2014 CR01: 5812 | CR02: 5300 | Difference = 512 | (Desync #52) [MISMATCH] Event 5582 \u2014 CR01: 5813 | CR02: 5301 | Difference = 512 | (Desync #53) [MISMATCH] Event 5583 \u2014 CR01: 5814 | CR02: 5302 | Difference = 512 | (Desync #54) [MISMATCH] Event 5584 \u2014 CR01: 5815 | CR02: 5303 | Difference = 512 | (Desync #55) [MISMATCH] Event 5585 \u2014 CR01: 5816 | CR02: 5304 | Difference = 512 | (Desync #56) [MISMATCH] Event 5586 \u2014 CR01: 5817 | CR02: 5305 | Difference = 512 | (Desync #57) [MISMATCH] Event 5587 \u2014 CR01: 5818 | CR02: 5306 | Difference = 512 | (Desync #58) [MISMATCH] Event 5588 \u2014 CR01: 5819 | CR02: 5307 | Difference = 512 | (Desync #59) [MISMATCH] Event 5589 \u2014 CR01: 5820 | CR02: 5308 | Difference = 512 | (Desync #60) [MISMATCH] Event 5590 \u2014 CR01: 5821 | CR02: 5309 | Difference = 512 | (Desync #61) [MISMATCH] Event 5591 \u2014 CR01: 5822 | CR02: 5310 | Difference = 512 | (Desync #62) [MISMATCH] Event 5592 \u2014 CR01: 5823 | CR02: 5311 | Difference = 512 | (Desync #63) [MISMATCH] Event 5593 \u2014 CR01: 5824 | CR02: 5312 | Difference = 512 | (Desync #64) [MISMATCH] Event 5594 \u2014 CR01: 5825 | CR02: 5313 | Difference = 512 | (Desync #65) [MISMATCH] Event 5595 \u2014 CR01: 5826 | CR02: 5314 | Difference = 512 | (Desync #66) [MISMATCH] Event 5596 \u2014 CR01: 5827 | CR02: 5315 | Difference = 512 | (Desync #67) [MISMATCH] Event 5597 \u2014 CR01: 5828 | CR02: 5316 | Difference = 512 | (Desync #68) [MISMATCH] Event 5598 \u2014 CR01: 5829 | CR02: 5317 | Difference = 512 | (Desync #69) [MISMATCH] Event 5599 \u2014 CR01: 5830 | CR02: 5318 | Difference = 512 | (Desync #70) [MISMATCH] Event 5600 \u2014 CR01: 5831 | CR02: 5319 | Difference = 512 | (Desync #71) [MISMATCH] Event 5601 \u2014 CR01: 5832 | CR02: 5320 | Difference = 512 | (Desync #72) [MISMATCH] Event 5602 \u2014 CR01: 5833 | CR02: 5321 | Difference = 512 | (Desync #73) [MISMATCH] Event 5603 \u2014 CR01: 5834 | CR02: 5322 | Difference = 512 | (Desync #74) [MISMATCH] Event 5604 \u2014 CR01: 5835 | CR02: 5323 | Difference = 512 | (Desync #75) [MISMATCH] Event 5605 \u2014 CR01: 5836 | CR02: 5324 | Difference = 512 | (Desync #76) [MISMATCH] Event 5606 \u2014 CR01: 5837 | CR02: 5325 | Difference = 512 | (Desync #77) [MISMATCH] Event 5607 \u2014 CR01: 5838 | CR02: 5326 | Difference = 512 | (Desync #78) [MISMATCH] Event 5608 \u2014 CR01: 5839 | CR02: 5327 | Difference = 512 | (Desync #79) [MISMATCH] Event 5609 \u2014 CR01: 5840 | CR02: 5328 | Difference = 512 | (Desync #80) [MISMATCH] Event 5610 \u2014 CR01: 5841 | CR02: 5329 | Difference = 512 | (Desync #81) [MISMATCH] Event 5611 \u2014 CR01: 5842 | CR02: 5330 | Difference = 512 | (Desync #82) [MISMATCH] Event 5612 \u2014 CR01: 5843 | CR02: 5331 | Difference = 512 | (Desync #83) [MISMATCH] Event 5613 \u2014 CR01: 5844 | CR02: 5332 | Difference = 512 | (Desync #84) [MISMATCH] Event 5614 \u2014 CR01: 5845 | CR02: 5333 | Difference = 512 | (Desync #85) [MISMATCH] Event 5615 \u2014 CR01: 5846 | CR02: 5334 | Difference = 512 | (Desync #86) [MISMATCH] Event 5616 \u2014 CR01: 5847 | CR02: 5335 | Difference = 512 | (Desync #87) [MISMATCH] Event 5617 \u2014 CR01: 5848 | CR02: 5336 | Difference = 512 | (Desync #88) [MISMATCH] Event 5618 \u2014 CR01: 5849 | CR02: 5337 | Difference = 512 | (Desync #89) [MISMATCH] Event 5619 \u2014 CR01: 5850 | CR02: 5338 | Difference = 512 | (Desync #90) [MISMATCH] Event 5620 \u2014 CR01: 5851 | CR02: 5339 | Difference = 512 | (Desync #91) [MISMATCH] Event 5621 \u2014 CR01: 5852 | CR02: 5340 | Difference = 512 | (Desync #92) [MISMATCH] Event 5622 \u2014 CR01: 5853 | CR02: 5341 | Difference = 512 | (Desync #93) [MISMATCH] Event 5623 \u2014 CR01: 5854 | CR02: 5342 | Difference = 512 | (Desync #94) [MISMATCH] Event 5624 \u2014 CR01: 5855 | CR02: 5343 | Difference = 512 | (Desync #95) [MISMATCH] Event 5625 \u2014 CR01: 5856 | CR02: 5344 | Difference = 512 | (Desync #96) [MISMATCH] Event 5626 \u2014 CR01: 5857 | CR02: 5345 | Difference = 512 | (Desync #97) [MISMATCH] Event 5627 \u2014 CR01: 5858 | CR02: 5346 | Difference = 512 | (Desync #98) [MISMATCH] Event 5628 \u2014 CR01: 5859 | CR02: 5347 | Difference = 512 | (Desync #99) [MISMATCH] Event 5629 \u2014 CR01: 5860 | CR02: 5348 | Difference = 512 | (Desync #100) [INFO] Reached desync limit (100), stopping early. [RESULT] Trigger mismatch found in \"/home/pioneer/data/gm2daq_data/run00193.mid.lz4\" [root@dhcp-10-163-105-238 scripts]# [root@dhcp-10-163-105-238 scripts]# ./run.sh /home/pioneer/data/gm2daq_data/run00193.mid.lz4 --debug --max-desyncs 100 [run.sh, INFO] Running unpacker with args: /home/pioneer/data/gm2daq_data/run00193.mid.lz4 --debug --max-desyncs 100 [INFO] Debug mode enabled. Printing every 1000 events. [INFO] Max desyncs set to 100 [INFO] Processing: \"/home/pioneer/data/gm2daq_data/run00193.mid.lz4\" [DEBUG] Event 1000 \u2014 CR01: 611 | CR02: 611 [DEBUG] Event 2000 \u2014 CR01: 1735 | CR02: 1735 [DEBUG] Event 3000 \u2014 CR01: 2859 | CR02: 2859 [DEBUG] Event 4000 \u2014 CR01: 3683 | CR02: 3683 [DEBUG] Event 5000 \u2014 CR01: 4807 | CR02: 4807 [MISMATCH] Event 5530 \u2014 CR01: 5761 | CR02: 5249 | Difference = 512 | (Desync #1) [MISMATCH] Event 5531 \u2014 CR01: 5762 | CR02: 5250 | Difference = 512 | (Desync #2) [MISMATCH] Event 5532 \u2014 CR01: 5763 | CR02: 5251 | Difference = 512 | (Desync #3) [MISMATCH] Event 5533 \u2014 CR01: 5764 | CR02: 5252 | Difference = 512 | (Desync #4) [MISMATCH] Event 5534 \u2014 CR01: 5765 | CR02: 5253 | Difference = 512 | (Desync #5) [MISMATCH] Event 5535 \u2014 CR01: 5766 | CR02: 5254 | Difference = 512 | (Desync #6) [MISMATCH] Event 5536 \u2014 CR01: 5767 | CR02: 5255 | Difference = 512 | (Desync #7) [MISMATCH] Event 5537 \u2014 CR01: 5768 | CR02: 5256 | Difference = 512 | (Desync #8) [MISMATCH] Event 5538 \u2014 CR01: 5769 | CR02: 5257 | Difference = 512 | (Desync #9) [MISMATCH] Event 5539 \u2014 CR01: 5770 | CR02: 5258 | Difference = 512 | (Desync #10) [MISMATCH] Event 5540 \u2014 CR01: 5771 | CR02: 5259 | Difference = 512 | (Desync #11) [MISMATCH] Event 5541 \u2014 CR01: 5772 | CR02: 5260 | Difference = 512 | (Desync #12) [MISMATCH] Event 5542 \u2014 CR01: 5773 | CR02: 5261 | Difference = 512 | (Desync #13) [MISMATCH] Event 5543 \u2014 CR01: 5774 | CR02: 5262 | Difference = 512 | (Desync #14) [MISMATCH] Event 5544 \u2014 CR01: 5775 | CR02: 5263 | Difference = 512 | (Desync #15) [MISMATCH] Event 5545 \u2014 CR01: 5776 | CR02: 5264 | Difference = 512 | (Desync #16) [MISMATCH] Event 5546 \u2014 CR01: 5777 | CR02: 5265 | Difference = 512 | (Desync #17) [MISMATCH] Event 5547 \u2014 CR01: 5778 | CR02: 5266 | Difference = 512 | (Desync #18) [MISMATCH] Event 5548 \u2014 CR01: 5779 | CR02: 5267 | Difference = 512 | (Desync #19) [MISMATCH] Event 5549 \u2014 CR01: 5780 | CR02: 5268 | Difference = 512 | (Desync #20) [MISMATCH] Event 5550 \u2014 CR01: 5781 | CR02: 5269 | Difference = 512 | (Desync #21) [MISMATCH] Event 5551 \u2014 CR01: 5782 | CR02: 5270 | Difference = 512 | (Desync #22) [MISMATCH] Event 5552 \u2014 CR01: 5783 | CR02: 5271 | Difference = 512 | (Desync #23) [MISMATCH] Event 5553 \u2014 CR01: 5784 | CR02: 5272 | Difference = 512 | (Desync #24) [MISMATCH] Event 5554 \u2014 CR01: 5785 | CR02: 5273 | Difference = 512 | (Desync #25) [MISMATCH] Event 5555 \u2014 CR01: 5786 | CR02: 5274 | Difference = 512 | (Desync #26) [MISMATCH] Event 5556 \u2014 CR01: 5787 | CR02: 5275 | Difference = 512 | (Desync #27) [MISMATCH] Event 5557 \u2014 CR01: 5788 | CR02: 5276 | Difference = 512 | (Desync #28) [MISMATCH] Event 5558 \u2014 CR01: 5789 | CR02: 5277 | Difference = 512 | (Desync #29) [MISMATCH] Event 5559 \u2014 CR01: 5790 | CR02: 5278 | Difference = 512 | (Desync #30) [MISMATCH] Event 5560 \u2014 CR01: 5791 | CR02: 5279 | Difference = 512 | (Desync #31) [MISMATCH] Event 5561 \u2014 CR01: 5792 | CR02: 5280 | Difference = 512 | (Desync #32) [MISMATCH] Event 5562 \u2014 CR01: 5793 | CR02: 5281 | Difference = 512 | (Desync #33) [MISMATCH] Event 5563 \u2014 CR01: 5794 | CR02: 5282 | Difference = 512 | (Desync #34) [MISMATCH] Event 5564 \u2014 CR01: 5795 | CR02: 5283 | Difference = 512 | (Desync #35) [MISMATCH] Event 5565 \u2014 CR01: 5796 | CR02: 5284 | Difference = 512 | (Desync #36) [MISMATCH] Event 5566 \u2014 CR01: 5797 | CR02: 5285 | Difference = 512 | (Desync #37) [MISMATCH] Event 5567 \u2014 CR01: 5798 | CR02: 5286 | Difference = 512 | (Desync #38) [MISMATCH] Event 5568 \u2014 CR01: 5799 | CR02: 5287 | Difference = 512 | (Desync #39) [MISMATCH] Event 5569 \u2014 CR01: 5800 | CR02: 5288 | Difference = 512 | (Desync #40) [MISMATCH] Event 5570 \u2014 CR01: 5801 | CR02: 5289 | Difference = 512 | (Desync #41) [MISMATCH] Event 5571 \u2014 CR01: 5802 | CR02: 5290 | Difference = 512 | (Desync #42) [MISMATCH] Event 5572 \u2014 CR01: 5803 | CR02: 5291 | Difference = 512 | (Desync #43) [MISMATCH] Event 5573 \u2014 CR01: 5804 | CR02: 5292 | Difference = 512 | (Desync #44) [MISMATCH] Event 5574 \u2014 CR01: 5805 | CR02: 5293 | Difference = 512 | (Desync #45) [MISMATCH] Event 5575 \u2014 CR01: 5806 | CR02: 5294 | Difference = 512 | (Desync #46) [MISMATCH] Event 5576 \u2014 CR01: 5807 | CR02: 5295 | Difference = 512 | (Desync #47) [MISMATCH] Event 5577 \u2014 CR01: 5808 | CR02: 5296 | Difference = 512 | (Desync #48) [MISMATCH] Event 5578 \u2014 CR01: 5809 | CR02: 5297 | Difference = 512 | (Desync #49) [MISMATCH] Event 5579 \u2014 CR01: 5810 | CR02: 5298 | Difference = 512 | (Desync #50) [MISMATCH] Event 5580 \u2014 CR01: 5811 | CR02: 5299 | Difference = 512 | (Desync #51) [MISMATCH] Event 5581 \u2014 CR01: 5812 | CR02: 5300 | Difference = 512 | (Desync #52) [MISMATCH] Event 5582 \u2014 CR01: 5813 | CR02: 5301 | Difference = 512 | (Desync #53) [MISMATCH] Event 5583 \u2014 CR01: 5814 | CR02: 5302 | Difference = 512 | (Desync #54) [MISMATCH] Event 5584 \u2014 CR01: 5815 | CR02: 5303 | Difference = 512 | (Desync #55) [MISMATCH] Event 5585 \u2014 CR01: 5816 | CR02: 5304 | Difference = 512 | (Desync #56) [MISMATCH] Event 5586 \u2014 CR01: 5817 | CR02: 5305 | Difference = 512 | (Desync #57) [MISMATCH] Event 5587 \u2014 CR01: 5818 | CR02: 5306 | Difference = 512 | (Desync #58) [MISMATCH] Event 5588 \u2014 CR01: 5819 | CR02: 5307 | Difference = 512 | (Desync #59) [MISMATCH] Event 5589 \u2014 CR01: 5820 | CR02: 5308 | Difference = 512 | (Desync #60) [MISMATCH] Event 5590 \u2014 CR01: 5821 | CR02: 5309 | Difference = 512 | (Desync #61) [MISMATCH] Event 5591 \u2014 CR01: 5822 | CR02: 5310 | Difference = 512 | (Desync #62) [MISMATCH] Event 5592 \u2014 CR01: 5823 | CR02: 5311 | Difference = 512 | (Desync #63) [MISMATCH] Event 5593 \u2014 CR01: 5824 | CR02: 5312 | Difference = 512 | (Desync #64) [MISMATCH] Event 5594 \u2014 CR01: 5825 | CR02: 5313 | Difference = 512 | (Desync #65) [MISMATCH] Event 5595 \u2014 CR01: 5826 | CR02: 5314 | Difference = 512 | (Desync #66) [MISMATCH] Event 5596 \u2014 CR01: 5827 | CR02: 5315 | Difference = 512 | (Desync #67) [MISMATCH] Event 5597 \u2014 CR01: 5828 | CR02: 5316 | Difference = 512 | (Desync #68) [MISMATCH] Event 5598 \u2014 CR01: 5829 | CR02: 5317 | Difference = 512 | (Desync #69) [MISMATCH] Event 5599 \u2014 CR01: 5830 | CR02: 5318 | Difference = 512 | (Desync #70) [MISMATCH] Event 5600 \u2014 CR01: 5831 | CR02: 5319 | Difference = 512 | (Desync #71) [MISMATCH] Event 5601 \u2014 CR01: 5832 | CR02: 5320 | Difference = 512 | (Desync #72) [MISMATCH] Event 5602 \u2014 CR01: 5833 | CR02: 5321 | Difference = 512 | (Desync #73) [MISMATCH] Event 5603 \u2014 CR01: 5834 | CR02: 5322 | Difference = 512 | (Desync #74) [MISMATCH] Event 5604 \u2014 CR01: 5835 | CR02: 5323 | Difference = 512 | (Desync #75) [MISMATCH] Event 5605 \u2014 CR01: 5836 | CR02: 5324 | Difference = 512 | (Desync #76) [MISMATCH] Event 5606 \u2014 CR01: 5837 | CR02: 5325 | Difference = 512 | (Desync #77) [MISMATCH] Event 5607 \u2014 CR01: 5838 | CR02: 5326 | Difference = 512 | (Desync #78) [MISMATCH] Event 5608 \u2014 CR01: 5839 | CR02: 5327 | Difference = 512 | (Desync #79) [MISMATCH] Event 5609 \u2014 CR01: 5840 | CR02: 5328 | Difference = 512 | (Desync #80) [MISMATCH] Event 5610 \u2014 CR01: 5841 | CR02: 5329 | Difference = 512 | (Desync #81) [MISMATCH] Event 5611 \u2014 CR01: 5842 | CR02: 5330 | Difference = 512 | (Desync #82) [MISMATCH] Event 5612 \u2014 CR01: 5843 | CR02: 5331 | Difference = 512 | (Desync #83) [MISMATCH] Event 5613 \u2014 CR01: 5844 | CR02: 5332 | Difference = 512 | (Desync #84) [MISMATCH] Event 5614 \u2014 CR01: 5845 | CR02: 5333 | Difference = 512 | (Desync #85) [MISMATCH] Event 5615 \u2014 CR01: 5846 | CR02: 5334 | Difference = 512 | (Desync #86) [MISMATCH] Event 5616 \u2014 CR01: 5847 | CR02: 5335 | Difference = 512 | (Desync #87) [MISMATCH] Event 5617 \u2014 CR01: 5848 | CR02: 5336 | Difference = 512 | (Desync #88) [MISMATCH] Event 5618 \u2014 CR01: 5849 | CR02: 5337 | Difference = 512 | (Desync #89) [MISMATCH] Event 5619 \u2014 CR01: 5850 | CR02: 5338 | Difference = 512 | (Desync #90) [MISMATCH] Event 5620 \u2014 CR01: 5851 | CR02: 5339 | Difference = 512 | (Desync #91) [MISMATCH] Event 5621 \u2014 CR01: 5852 | CR02: 5340 | Difference = 512 | (Desync #92) [MISMATCH] Event 5622 \u2014 CR01: 5853 | CR02: 5341 | Difference = 512 | (Desync #93) [MISMATCH] Event 5623 \u2014 CR01: 5854 | CR02: 5342 | Difference = 512 | (Desync #94) [MISMATCH] Event 5624 \u2014 CR01: 5855 | CR02: 5343 | Difference = 512 | (Desync #95) [MISMATCH] Event 5625 \u2014 CR01: 5856 | CR02: 5344 | Difference = 512 | (Desync #96) [MISMATCH] Event 5626 \u2014 CR01: 5857 | CR02: 5345 | Difference = 512 | (Desync #97) [MISMATCH] Event 5627 \u2014 CR01: 5858 | CR02: 5346 | Difference = 512 | (Desync #98) [MISMATCH] Event 5628 \u2014 CR01: 5859 | CR02: 5347 | Difference = 512 | (Desync #99) [MISMATCH] Event 5629 \u2014 CR01: 5860 | CR02: 5348 | Difference = 512 | (Desync #100) [INFO] Reached desync limit (100), stopping early. [RESULT] Trigger mismatch found in \"/home/pioneer/data/gm2daq_data/run00193.mid.lz4\" [root@dhcp-10-163-105-238 scripts]# 15/10/2025 00:07 I must have forgotten to save when compiling or something, because this time I see the desyncs spread out by 300 [run.sh, INFO] Running unpacker with args: /home/pioneer/data/gm2daq_data/run00195.mid.lz4 --debug --max-desyncs 100 [INFO] Debug mode enabled. Printing every 1000 events. [INFO] Max desyncs set to 100 [INFO] Processing: \"/home/pioneer/data/gm2daq_data/run00195.mid.lz4\" [DEBUG] Event 1000 \u2014 CR01: 999 | CR02: 999 [DEBUG] Event 2000 \u2014 CR01: 1999 | CR02: 1999 [DEBUG] Event 3000 \u2014 CR01: 2999 | CR02: 2999 [DEBUG] Event 4000 \u2014 CR01: 3999 | CR02: 3999 [DEBUG] Event 5000 \u2014 CR01: 4999 | CR02: 4999 [MISMATCH] Event 5367 \u2014 CR01: 5966 | CR02: 5366 | Difference = 600 | (Desync #1) [MISMATCH] Event 5368 \u2014 CR01: 5967 | CR02: 5367 | Difference = 600 | (Desync #2) [MISMATCH] Event 5369 \u2014 CR01: 5968 | CR02: 5368 | Difference = 600 | (Desync #3) [MISMATCH] Event 5370 \u2014 CR01: 5969 | CR02: 5369 | Difference = 600 | (Desync #4) [MISMATCH] Event 5371 \u2014 CR01: 5970 | CR02: 5370 | Difference = 600 | (Desync #5) [MISMATCH] Event 5372 \u2014 CR01: 5971 | CR02: 5371 | Difference = 600 | (Desync #6) [MISMATCH] Event 5373 \u2014 CR01: 5972 | CR02: 5372 | Difference = 600 | (Desync #7) [MISMATCH] Event 5374 \u2014 CR01: 5973 | CR02: 5373 | Difference = 600 | (Desync #8) [MISMATCH] Event 5375 \u2014 CR01: 5974 | CR02: 5374 | Difference = 600 | (Desync #9) [MISMATCH] Event 5376 \u2014 CR01: 5975 | CR02: 5375 | Difference = 600 | (Desync #10) [MISMATCH] Event 5377 \u2014 CR01: 5976 | CR02: 5376 | Difference = 600 | (Desync #11) [MISMATCH] Event 5378 \u2014 CR01: 5977 | CR02: 5377 | Difference = 600 | (Desync #12) [MISMATCH] Event 5379 \u2014 CR01: 5978 | CR02: 5378 | Difference = 600 | (Desync #13) [MISMATCH] Event 5380 \u2014 CR01: 5979 | CR02: 5379 | Difference = 600 | (Desync #14) [MISMATCH] Event 5381 \u2014 CR01: 5980 | CR02: 5380 | Difference = 600 | (Desync #15) [MISMATCH] Event 5382 \u2014 CR01: 5981 | CR02: 5381 | Difference = 600 | (Desync #16) [MISMATCH] Event 5383 \u2014 CR01: 5682 | CR02: 5382 | Difference = 300 | (Desync #17) [MISMATCH] Event 5384 \u2014 CR01: 5683 | CR02: 5383 | Difference = 300 | (Desync #18) [MISMATCH] Event 5385 \u2014 CR01: 5684 | CR02: 5384 | Difference = 300 | (Desync #19) [MISMATCH] Event 5386 \u2014 CR01: 5685 | CR02: 5385 | Difference = 300 | (Desync #20) [MISMATCH] Event 5387 \u2014 CR01: 5686 | CR02: 5386 | Difference = 300 | (Desync #21) [MISMATCH] Event 5388 \u2014 CR01: 5687 | CR02: 5387 | Difference = 300 | (Desync #22) [MISMATCH] Event 5389 \u2014 CR01: 5688 | CR02: 5388 | Difference = 300 | (Desync #23) [MISMATCH] Event 5390 \u2014 CR01: 5689 | CR02: 5389 | Difference = 300 | (Desync #24) [MISMATCH] Event 5391 \u2014 CR01: 5690 | CR02: 5390 | Difference = 300 | (Desync #25) [MISMATCH] Event 5392 \u2014 CR01: 5691 | CR02: 5391 | Difference = 300 | (Desync #26) [MISMATCH] Event 5393 \u2014 CR01: 5692 | CR02: 5392 | Difference = 300 | (Desync #27) [MISMATCH] Event 5394 \u2014 CR01: 5693 | CR02: 5393 | Difference = 300 | (Desync #28) [MISMATCH] Event 5395 \u2014 CR01: 5694 | CR02: 5394 | Difference = 300 | (Desync #29) [MISMATCH] Event 5396 \u2014 CR01: 5695 | CR02: 5395 | Difference = 300 | (Desync #30) [MISMATCH] Event 5397 \u2014 CR01: 5696 | CR02: 5396 | Difference = 300 | (Desync #31) [MISMATCH] Event 5398 \u2014 CR01: 5697 | CR02: 5397 | Difference = 300 | (Desync #32) [MISMATCH] Event 5399 \u2014 CR01: 5698 | CR02: 5398 | Difference = 300 | (Desync #33) [MISMATCH] Event 5400 \u2014 CR01: 5699 | CR02: 5399 | Difference = 300 | (Desync #34) [MISMATCH] Event 5401 \u2014 CR01: 5700 | CR02: 5400 | Difference = 300 | (Desync #35) [MISMATCH] Event 5402 \u2014 CR01: 5701 | CR02: 5401 | Difference = 300 | (Desync #36) [MISMATCH] Event 5403 \u2014 CR01: 5702 | CR02: 5402 | Difference = 300 | (Desync #37) [MISMATCH] Event 5404 \u2014 CR01: 5703 | CR02: 5403 | Difference = 300 | (Desync #38) [MISMATCH] Event 5405 \u2014 CR01: 5704 | CR02: 5404 | Difference = 300 | (Desync #39) [MISMATCH] Event 5406 \u2014 CR01: 5705 | CR02: 5405 | Difference = 300 | (Desync #40) [MISMATCH] Event 5407 \u2014 CR01: 5706 | CR02: 5406 | Difference = 300 | (Desync #41) [MISMATCH] Event 5408 \u2014 CR01: 5707 | CR02: 5407 | Difference = 300 | (Desync #42) [MISMATCH] Event 5409 \u2014 CR01: 5708 | CR02: 5408 | Difference = 300 | (Desync #43) [MISMATCH] Event 5410 \u2014 CR01: 5709 | CR02: 5409 | Difference = 300 | (Desync #44) [MISMATCH] Event 5411 \u2014 CR01: 5710 | CR02: 5410 | Difference = 300 | (Desync #45) [MISMATCH] Event 5412 \u2014 CR01: 5711 | CR02: 5411 | Difference = 300 | (Desync #46) [MISMATCH] Event 5413 \u2014 CR01: 5712 | CR02: 5412 | Difference = 300 | (Desync #47) [MISMATCH] Event 5414 \u2014 CR01: 5713 | CR02: 5413 | Difference = 300 | (Desync #48) [MISMATCH] Event 5415 \u2014 CR01: 5714 | CR02: 5414 | Difference = 300 | (Desync #49) [MISMATCH] Event 5416 \u2014 CR01: 5715 | CR02: 5415 | Difference = 300 | (Desync #50) [MISMATCH] Event 5417 \u2014 CR01: 5716 | CR02: 5416 | Difference = 300 | (Desync #51) [MISMATCH] Event 5418 \u2014 CR01: 5717 | CR02: 5417 | Difference = 300 | (Desync #52) [MISMATCH] Event 5419 \u2014 CR01: 5718 | CR02: 5418 | Difference = 300 | (Desync #53) [MISMATCH] Event 5420 \u2014 CR01: 5719 | CR02: 5419 | Difference = 300 | (Desync #54) [MISMATCH] Event 5421 \u2014 CR01: 5720 | CR02: 5420 | Difference = 300 | (Desync #55) [MISMATCH] Event 5422 \u2014 CR01: 5721 | CR02: 5421 | Difference = 300 | (Desync #56) [MISMATCH] Event 5423 \u2014 CR01: 5722 | CR02: 5422 | Difference = 300 | (Desync #57) [MISMATCH] Event 5424 \u2014 CR01: 5723 | CR02: 5423 | Difference = 300 | (Desync #58) [MISMATCH] Event 5425 \u2014 CR01: 5724 | CR02: 5424 | Difference = 300 | (Desync #59) [MISMATCH] Event 5426 \u2014 CR01: 5725 | CR02: 5425 | Difference = 300 | (Desync #60) [MISMATCH] Event 5427 \u2014 CR01: 5726 | CR02: 5426 | Difference = 300 | (Desync #61) [MISMATCH] Event 5428 \u2014 CR01: 5727 | CR02: 5427 | Difference = 300 | (Desync #62) [MISMATCH] Event 5429 \u2014 CR01: 5728 | CR02: 5428 | Difference = 300 | (Desync #63) [MISMATCH] Event 5430 \u2014 CR01: 5729 | CR02: 5429 | Difference = 300 | (Desync #64) [MISMATCH] Event 5431 \u2014 CR01: 5730 | CR02: 5430 | Difference = 300 | (Desync #65) [MISMATCH] Event 5432 \u2014 CR01: 5731 | CR02: 5431 | Difference = 300 | (Desync #66) [MISMATCH] Event 5433 \u2014 CR01: 5732 | CR02: 5432 | Difference = 300 | (Desync #67) [MISMATCH] Event 5434 \u2014 CR01: 5733 | CR02: 5433 | Difference = 300 | (Desync #68) [MISMATCH] Event 5435 \u2014 CR01: 5734 | CR02: 5434 | Difference = 300 | (Desync #69) [MISMATCH] Event 5436 \u2014 CR01: 5735 | CR02: 5435 | Difference = 300 | (Desync #70) [MISMATCH] Event 5437 \u2014 CR01: 5736 | CR02: 5436 | Difference = 300 | (Desync #71) [MISMATCH] Event 5438 \u2014 CR01: 5737 | CR02: 5437 | Difference = 300 | (Desync #72) [MISMATCH] Event 5439 \u2014 CR01: 5738 | CR02: 5438 | Difference = 300 | (Desync #73) [MISMATCH] Event 5440 \u2014 CR01: 5739 | CR02: 5439 | Difference = 300 | (Desync #74) [MISMATCH] Event 5441 \u2014 CR01: 5740 | CR02: 5440 | Difference = 300 | (Desync #75) [MISMATCH] Event 5442 \u2014 CR01: 5741 | CR02: 5441 | Difference = 300 | (Desync #76) [MISMATCH] Event 5443 \u2014 CR01: 5742 | CR02: 5442 | Difference = 300 | (Desync #77) [MISMATCH] Event 5444 \u2014 CR01: 5743 | CR02: 5443 | Difference = 300 | (Desync #78) [MISMATCH] Event 5445 \u2014 CR01: 5744 | CR02: 5444 | Difference = 300 | (Desync #79) [MISMATCH] Event 5446 \u2014 CR01: 5745 | CR02: 5445 | Difference = 300 | (Desync #80) [MISMATCH] Event 5447 \u2014 CR01: 5746 | CR02: 5446 | Difference = 300 | (Desync #81) [MISMATCH] Event 5448 \u2014 CR01: 5747 | CR02: 5447 | Difference = 300 | (Desync #82) [MISMATCH] Event 5449 \u2014 CR01: 5748 | CR02: 5448 | Difference = 300 | (Desync #83) [MISMATCH] Event 5450 \u2014 CR01: 5749 | CR02: 5449 | Difference = 300 | (Desync #84) [MISMATCH] Event 5451 \u2014 CR01: 5750 | CR02: 5450 | Difference = 300 | (Desync #85) [MISMATCH] Event 5452 \u2014 CR01: 5751 | CR02: 5451 | Difference = 300 | (Desync #86) [MISMATCH] Event 5453 \u2014 CR01: 5752 | CR02: 5452 | Difference = 300 | (Desync #87) [MISMATCH] Event 5454 \u2014 CR01: 5753 | CR02: 5453 | Difference = 300 | (Desync #88) [MISMATCH] Event 5455 \u2014 CR01: 5754 | CR02: 5454 | Difference = 300 | (Desync #89) [MISMATCH] Event 5456 \u2014 CR01: 5755 | CR02: 5455 | Difference = 300 | (Desync #90) [MISMATCH] Event 5457 \u2014 CR01: 5756 | CR02: 5456 | Difference = 300 | (Desync #91) [MISMATCH] Event 5458 \u2014 CR01: 5757 | CR02: 5457 | Difference = 300 | (Desync #92) [MISMATCH] Event 5459 \u2014 CR01: 5758 | CR02: 5458 | Difference = 300 | (Desync #93) [MISMATCH] Event 5460 \u2014 CR01: 5759 | CR02: 5459 | Difference = 300 | (Desync #94) [MISMATCH] Event 5461 \u2014 CR01: 5760 | CR02: 5460 | Difference = 300 | (Desync #95) [MISMATCH] Event 5462 \u2014 CR01: 5761 | CR02: 5461 | Difference = 300 | (Desync #96) [MISMATCH] Event 5463 \u2014 CR01: 5762 | CR02: 5462 | Difference = 300 | (Desync #97) [MISMATCH] Event 5464 \u2014 CR01: 5763 | CR02: 5463 | Difference = 300 | (Desync #98) [MISMATCH] Event 5465 \u2014 CR01: 5764 | CR02: 5464 | Difference = 300 | (Desync #99) [MISMATCH] Event 5466 \u2014 CR01: 5765 | CR02: 5465 | Difference = 300 | (Desync #100) [INFO] Reached desync limit (100), stopping early. [RESULT] Trigger mismatch found in \"/home/pioneer/data/gm2daq_data/run00195.mid.lz4\" [root@dhcp-10-163-105-238 scripts]# [run.sh, INFO] Running unpacker with args: /home/pioneer/data/gm2daq_data/run00195.mid.lz4 --debug --max-desyncs 100 [INFO] Debug mode enabled. Printing every 1000 events. [INFO] Max desyncs set to 100 [INFO] Processing: \"/home/pioneer/data/gm2daq_data/run00195.mid.lz4\" [DEBUG] Event 1000 \u2014 CR01: 999 | CR02: 999 [DEBUG] Event 2000 \u2014 CR01: 1999 | CR02: 1999 [DEBUG] Event 3000 \u2014 CR01: 2999 | CR02: 2999 [DEBUG] Event 4000 \u2014 CR01: 3999 | CR02: 3999 [DEBUG] Event 5000 \u2014 CR01: 4999 | CR02: 4999 [MISMATCH] Event 5367 \u2014 CR01: 5966 | CR02: 5366 | Difference = 600 | (Desync #1) [MISMATCH] Event 5368 \u2014 CR01: 5967 | CR02: 5367 | Difference = 600 | (Desync #2) [MISMATCH] Event 5369 \u2014 CR01: 5968 | CR02: 5368 | Difference = 600 | (Desync #3) [MISMATCH] Event 5370 \u2014 CR01: 5969 | CR02: 5369 | Difference = 600 | (Desync #4) [MISMATCH] Event 5371 \u2014 CR01: 5970 | CR02: 5370 | Difference = 600 | (Desync #5) [MISMATCH] Event 5372 \u2014 CR01: 5971 | CR02: 5371 | Difference = 600 | (Desync #6) [MISMATCH] Event 5373 \u2014 CR01: 5972 | CR02: 5372 | Difference = 600 | (Desync #7) [MISMATCH] Event 5374 \u2014 CR01: 5973 | CR02: 5373 | Difference = 600 | (Desync #8) [MISMATCH] Event 5375 \u2014 CR01: 5974 | CR02: 5374 | Difference = 600 | (Desync #9) [MISMATCH] Event 5376 \u2014 CR01: 5975 | CR02: 5375 | Difference = 600 | (Desync #10) [MISMATCH] Event 5377 \u2014 CR01: 5976 | CR02: 5376 | Difference = 600 | (Desync #11) [MISMATCH] Event 5378 \u2014 CR01: 5977 | CR02: 5377 | Difference = 600 | (Desync #12) [MISMATCH] Event 5379 \u2014 CR01: 5978 | CR02: 5378 | Difference = 600 | (Desync #13) [MISMATCH] Event 5380 \u2014 CR01: 5979 | CR02: 5379 | Difference = 600 | (Desync #14) [MISMATCH] Event 5381 \u2014 CR01: 5980 | CR02: 5380 | Difference = 600 | (Desync #15) [MISMATCH] Event 5382 \u2014 CR01: 5981 | CR02: 5381 | Difference = 600 | (Desync #16) [MISMATCH] Event 5383 \u2014 CR01: 5682 | CR02: 5382 | Difference = 300 | (Desync #17) [MISMATCH] Event 5384 \u2014 CR01: 5683 | CR02: 5383 | Difference = 300 | (Desync #18) [MISMATCH] Event 5385 \u2014 CR01: 5684 | CR02: 5384 | Difference = 300 | (Desync #19) [MISMATCH] Event 5386 \u2014 CR01: 5685 | CR02: 5385 | Difference = 300 | (Desync #20) [MISMATCH] Event 5387 \u2014 CR01: 5686 | CR02: 5386 | Difference = 300 | (Desync #21) [MISMATCH] Event 5388 \u2014 CR01: 5687 | CR02: 5387 | Difference = 300 | (Desync #22) [MISMATCH] Event 5389 \u2014 CR01: 5688 | CR02: 5388 | Difference = 300 | (Desync #23) [MISMATCH] Event 5390 \u2014 CR01: 5689 | CR02: 5389 | Difference = 300 | (Desync #24) [MISMATCH] Event 5391 \u2014 CR01: 5690 | CR02: 5390 | Difference = 300 | (Desync #25) [MISMATCH] Event 5392 \u2014 CR01: 5691 | CR02: 5391 | Difference = 300 | (Desync #26) [MISMATCH] Event 5393 \u2014 CR01: 5692 | CR02: 5392 | Difference = 300 | (Desync #27) [MISMATCH] Event 5394 \u2014 CR01: 5693 | CR02: 5393 | Difference = 300 | (Desync #28) [MISMATCH] Event 5395 \u2014 CR01: 5694 | CR02: 5394 | Difference = 300 | (Desync #29) [MISMATCH] Event 5396 \u2014 CR01: 5695 | CR02: 5395 | Difference = 300 | (Desync #30) [MISMATCH] Event 5397 \u2014 CR01: 5696 | CR02: 5396 | Difference = 300 | (Desync #31) [MISMATCH] Event 5398 \u2014 CR01: 5697 | CR02: 5397 | Difference = 300 | (Desync #32) [MISMATCH] Event 5399 \u2014 CR01: 5698 | CR02: 5398 | Difference = 300 | (Desync #33) [MISMATCH] Event 5400 \u2014 CR01: 5699 | CR02: 5399 | Difference = 300 | (Desync #34) [MISMATCH] Event 5401 \u2014 CR01: 5700 | CR02: 5400 | Difference = 300 | (Desync #35) [MISMATCH] Event 5402 \u2014 CR01: 5701 | CR02: 5401 | Difference = 300 | (Desync #36) [MISMATCH] Event 5403 \u2014 CR01: 5702 | CR02: 5402 | Difference = 300 | (Desync #37) [MISMATCH] Event 5404 \u2014 CR01: 5703 | CR02: 5403 | Difference = 300 | (Desync #38) [MISMATCH] Event 5405 \u2014 CR01: 5704 | CR02: 5404 | Difference = 300 | (Desync #39) [MISMATCH] Event 5406 \u2014 CR01: 5705 | CR02: 5405 | Difference = 300 | (Desync #40) [MISMATCH] Event 5407 \u2014 CR01: 5706 | CR02: 5406 | Difference = 300 | (Desync #41) [MISMATCH] Event 5408 \u2014 CR01: 5707 | CR02: 5407 | Difference = 300 | (Desync #42) [MISMATCH] Event 5409 \u2014 CR01: 5708 | CR02: 5408 | Difference = 300 | (Desync #43) [MISMATCH] Event 5410 \u2014 CR01: 5709 | CR02: 5409 | Difference = 300 | (Desync #44) [MISMATCH] Event 5411 \u2014 CR01: 5710 | CR02: 5410 | Difference = 300 | (Desync #45) [MISMATCH] Event 5412 \u2014 CR01: 5711 | CR02: 5411 | Difference = 300 | (Desync #46) [MISMATCH] Event 5413 \u2014 CR01: 5712 | CR02: 5412 | Difference = 300 | (Desync #47) [MISMATCH] Event 5414 \u2014 CR01: 5713 | CR02: 5413 | Difference = 300 | (Desync #48) [MISMATCH] Event 5415 \u2014 CR01: 5714 | CR02: 5414 | Difference = 300 | (Desync #49) [MISMATCH] Event 5416 \u2014 CR01: 5715 | CR02: 5415 | Difference = 300 | (Desync #50) [MISMATCH] Event 5417 \u2014 CR01: 5716 | CR02: 5416 | Difference = 300 | (Desync #51) [MISMATCH] Event 5418 \u2014 CR01: 5717 | CR02: 5417 | Difference = 300 | (Desync #52) [MISMATCH] Event 5419 \u2014 CR01: 5718 | CR02: 5418 | Difference = 300 | (Desync #53) [MISMATCH] Event 5420 \u2014 CR01: 5719 | CR02: 5419 | Difference = 300 | (Desync #54) [MISMATCH] Event 5421 \u2014 CR01: 5720 | CR02: 5420 | Difference = 300 | (Desync #55) [MISMATCH] Event 5422 \u2014 CR01: 5721 | CR02: 5421 | Difference = 300 | (Desync #56) [MISMATCH] Event 5423 \u2014 CR01: 5722 | CR02: 5422 | Difference = 300 | (Desync #57) [MISMATCH] Event 5424 \u2014 CR01: 5723 | CR02: 5423 | Difference = 300 | (Desync #58) [MISMATCH] Event 5425 \u2014 CR01: 5724 | CR02: 5424 | Difference = 300 | (Desync #59) [MISMATCH] Event 5426 \u2014 CR01: 5725 | CR02: 5425 | Difference = 300 | (Desync #60) [MISMATCH] Event 5427 \u2014 CR01: 5726 | CR02: 5426 | Difference = 300 | (Desync #61) [MISMATCH] Event 5428 \u2014 CR01: 5727 | CR02: 5427 | Difference = 300 | (Desync #62) [MISMATCH] Event 5429 \u2014 CR01: 5728 | CR02: 5428 | Difference = 300 | (Desync #63) [MISMATCH] Event 5430 \u2014 CR01: 5729 | CR02: 5429 | Difference = 300 | (Desync #64) [MISMATCH] Event 5431 \u2014 CR01: 5730 | CR02: 5430 | Difference = 300 | (Desync #65) [MISMATCH] Event 5432 \u2014 CR01: 5731 | CR02: 5431 | Difference = 300 | (Desync #66) [MISMATCH] Event 5433 \u2014 CR01: 5732 | CR02: 5432 | Difference = 300 | (Desync #67) [MISMATCH] Event 5434 \u2014 CR01: 5733 | CR02: 5433 | Difference = 300 | (Desync #68) [MISMATCH] Event 5435 \u2014 CR01: 5734 | CR02: 5434 | Difference = 300 | (Desync #69) [MISMATCH] Event 5436 \u2014 CR01: 5735 | CR02: 5435 | Difference = 300 | (Desync #70) [MISMATCH] Event 5437 \u2014 CR01: 5736 | CR02: 5436 | Difference = 300 | (Desync #71) [MISMATCH] Event 5438 \u2014 CR01: 5737 | CR02: 5437 | Difference = 300 | (Desync #72) [MISMATCH] Event 5439 \u2014 CR01: 5738 | CR02: 5438 | Difference = 300 | (Desync #73) [MISMATCH] Event 5440 \u2014 CR01: 5739 | CR02: 5439 | Difference = 300 | (Desync #74) [MISMATCH] Event 5441 \u2014 CR01: 5740 | CR02: 5440 | Difference = 300 | (Desync #75) [MISMATCH] Event 5442 \u2014 CR01: 5741 | CR02: 5441 | Difference = 300 | (Desync #76) [MISMATCH] Event 5443 \u2014 CR01: 5742 | CR02: 5442 | Difference = 300 | (Desync #77) [MISMATCH] Event 5444 \u2014 CR01: 5743 | CR02: 5443 | Difference = 300 | (Desync #78) [MISMATCH] Event 5445 \u2014 CR01: 5744 | CR02: 5444 | Difference = 300 | (Desync #79) [MISMATCH] Event 5446 \u2014 CR01: 5745 | CR02: 5445 | Difference = 300 | (Desync #80) [MISMATCH] Event 5447 \u2014 CR01: 5746 | CR02: 5446 | Difference = 300 | (Desync #81) [MISMATCH] Event 5448 \u2014 CR01: 5747 | CR02: 5447 | Difference = 300 | (Desync #82) [MISMATCH] Event 5449 \u2014 CR01: 5748 | CR02: 5448 | Difference = 300 | (Desync #83) [MISMATCH] Event 5450 \u2014 CR01: 5749 | CR02: 5449 | Difference = 300 | (Desync #84) [MISMATCH] Event 5451 \u2014 CR01: 5750 | CR02: 5450 | Difference = 300 | (Desync #85) [MISMATCH] Event 5452 \u2014 CR01: 5751 | CR02: 5451 | Difference = 300 | (Desync #86) [MISMATCH] Event 5453 \u2014 CR01: 5752 | CR02: 5452 | Difference = 300 | (Desync #87) [MISMATCH] Event 5454 \u2014 CR01: 5753 | CR02: 5453 | Difference = 300 | (Desync #88) [MISMATCH] Event 5455 \u2014 CR01: 5754 | CR02: 5454 | Difference = 300 | (Desync #89) [MISMATCH] Event 5456 \u2014 CR01: 5755 | CR02: 5455 | Difference = 300 | (Desync #90) [MISMATCH] Event 5457 \u2014 CR01: 5756 | CR02: 5456 | Difference = 300 | (Desync #91) [MISMATCH] Event 5458 \u2014 CR01: 5757 | CR02: 5457 | Difference = 300 | (Desync #92) [MISMATCH] Event 5459 \u2014 CR01: 5758 | CR02: 5458 | Difference = 300 | (Desync #93) [MISMATCH] Event 5460 \u2014 CR01: 5759 | CR02: 5459 | Difference = 300 | (Desync #94) [MISMATCH] Event 5461 \u2014 CR01: 5760 | CR02: 5460 | Difference = 300 | (Desync #95) [MISMATCH] Event 5462 \u2014 CR01: 5761 | CR02: 5461 | Difference = 300 | (Desync #96) [MISMATCH] Event 5463 \u2014 CR01: 5762 | CR02: 5462 | Difference = 300 | (Desync #97) [MISMATCH] Event 5464 \u2014 CR01: 5763 | CR02: 5463 | Difference = 300 | (Desync #98) [MISMATCH] Event 5465 \u2014 CR01: 5764 | CR02: 5464 | Difference = 300 | (Desync #99) [MISMATCH] Event 5466 \u2014 CR01: 5765 | CR02: 5465 | Difference = 300 | (Desync #100) [INFO] Reached desync limit (100), stopping early. [RESULT] Trigger mismatch found in \"/home/pioneer/data/gm2daq_data/run00195.mid.lz4\" [root@dhcp-10-163-105-238 scripts]# 15/10/2025 00:16 The issue is we need to revive some sort of backpressure. Previously (in g-2) we had the code: if ( (gpu_buffer_filled >= GPU_BUFFER_SIZE - 1) || (tcp_buffer_filled >= TCP_BUF_MAX_FILLS - 1) ) { fc7help->setThrottleTriggers(encoder_fc7, frontend_index, 1); triggersThrottled = true; // Check if at least 10 minutes have passed since the last message, print warning if so. std::time_t current_time = std::time(nullptr); // Get the current time int seconds_between_messages = 600; if (isElapsedTime(current_time, last_msg_time, seconds_between_messages)) { cm_msg(MINFO, __FILE__, \"Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers.\"); last_msg_time = current_time; // Update the last message time } continue; } else if (triggersThrottled) { fc7help->setThrottleTriggers(encoder_fc7, frontend_index, 0); triggersThrottled = false; cm_msg(MINFO, __FILE__, \"Trigger throttling removed\"); } if ( (gpu_buffer_filled >= GPU_BUFFER_SIZE - 1 ) || (tcp_buffer_filled >= TCP_BUF_MAX_FILLS - 1 ) ) { fc7help-> setThrottleTriggers (encoder_fc7, frontend_index, 1 ); triggersThrottled = true ; // Check if at least 10 minutes have passed since the last message, print warning if so. std:: time_t current_time = std:: time ( nullptr ); // Get the current time int seconds_between_messages = 600 ; if ( isElapsedTime (current_time, last_msg_time, seconds_between_messages)) { cm_msg (MINFO, __FILE__, \"Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers.\" ); last_msg_time = current_time; // Update the last message time } continue ; } else if (triggersThrottled) { fc7help-> setThrottleTriggers (encoder_fc7, frontend_index, 0 ); triggersThrottled = false ; cm_msg (MINFO, __FILE__, \"Trigger throttling removed\" ); } But this has sinced not worked for me; perhaps it has something to do with the multicrate setup. 15/10/2025 00:24 FC7 Begin of run success! Retrieve AMC13 status success! AMC13 statuses correct! TCP thread BOR success! GPU thread BOR success! Started run 197 [AMC13001,TALK] Warning: DAQ | AMC13001 GPU Ring buffer close to full (90.333328%) [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. FC7 Begin of run success! Retrieve AMC13 status success! AMC13 statuses correct! TCP thread BOR success! GPU thread BOR success! Started run 197 [AMC13001,TALK] Warning: DAQ | AMC13001 GPU Ring buffer close to full (90.333328%) [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. (this is with 6 second wait between messages for a 1 crate system) The throttling never seems to never unthrottle, causing the run to just remain stagnant. 15/10/2025 00:52 [AMC13001,INFO] Trigger throttling removed [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Trigger throttling removed [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Trigger throttling removed [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Trigger throttling removed [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Trigger throttling removed [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Trigger throttling removed [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Trigger throttling removed [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Trigger throttling removed [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Trigger throttling removed [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Trigger throttling removed [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Trigger throttling removed [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Trigger throttling removed [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Trigger throttling removed [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Trigger throttling removed [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Trigger throttling removed [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Trigger throttling removed [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Trigger throttling removed [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Trigger throttling removed [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Trigger throttling removed index, frontendIndex: 1, 1 id, type, enabled: 2, WFD, 1 id, type, enabled: 3, WFD, 1 id, type, enabled: 4, WFD, 0 id, type, enabled: 5, WFD, 1 id, type, enabled: 6, WFD, 0 id, type, enabled: 7, WFD, 1 id, type, enabled: 10, FC7, 1 --> entering setMasterRegister to write 0 to node CBUF.ACQUIRE <--: success --> entering setMasterRegister to write 0 to node CBUF.ACQUIRE <--: success --> entering setMasterRegister to write 0 to node CBUF.ACQUIRE <--: success --> entering setMasterRegister to write 0 to node CBUF.ACQUIRE <--: success Run stopped [AMC13001,INFO] Trigger throttling removed [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Trigger throttling removed [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Trigger throttling removed [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Trigger throttling removed [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Trigger throttling removed [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Trigger throttling removed [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Trigger throttling removed [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Trigger throttling removed [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Trigger throttling removed [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Trigger throttling removed [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Trigger throttling removed [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Trigger throttling removed [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Trigger throttling removed [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Trigger throttling removed [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Trigger throttling removed [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Trigger throttling removed [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Trigger throttling removed [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Trigger throttling removed [AMC13001,INFO] Requesting Encoder FC7 to throttle TTC triggers to clear TCP/GPU ring buffers. [AMC13001,INFO] Trigger throttling removed index, frontendIndex: 1, 1 id , type , enabled: 2, WFD, 1 id , type , enabled: 3, WFD, 1 id , type , enabled: 4, WFD, 0 id , type , enabled: 5, WFD, 1 id , type , enabled: 6, WFD, 0 id , type , enabled: 7, WFD, 1 id , type , enabled: 10, FC7, 1 --> entering setMasterRegister to write 0 to node CBUF.ACQUIRE <--: success --> entering setMasterRegister to write 0 to node CBUF.ACQUIRE <--: success --> entering setMasterRegister to write 0 to node CBUF.ACQUIRE <--: success --> entering setMasterRegister to write 0 to node CBUF.ACQUIRE <--: success Run stopped throttling seems to work \"well\" with just one crate, not using the event builder.",
    "textLength": 8359
  },
  {
    "kind": "work-log",
    "title": "07_09_2025 - 13_09_2025.html",
    "fileName": "07_09_2025 - 13_09_2025.html",
    "url": "resources/work_logs/07_09_2025 - 13_09_2025.html",
    "createdDate": "2025-09-07",
    "text": "07/09/2025 - 13/09/2025 07/09/2025 - 13/09/2025 10/09/2025 19:14 Process for getting into the french remote system SSH into Tim's Computer (need globalProtect VPN) ssh pioneer@10.164.175.61 ssh pioneer@ 10.164.175.61 Password is the same as our lab passwords 2. SSH into french system ssh pioneer@lpnpioneer.in2p3.fr ssh pioneer @lpnpioneer .in2p3.fr password is \" pioneer4062! \". 12/09/2025 14:30 How to interact with the midas frontend 1. Setup Environment source /home/pioneer/jcarlton/scripts/setup_env.sh source /home/ pioneer /jcarlton/ scripts/setup_env.sh 2. Move to project directory cd $SAMPIC_DAQ_DIR cd $SAMPIC_DAQ_DIR or cd /home/pioneer/jcarlton/projects/midas_sampic/experiments/sampic_daq cd /home/ pioneer /jcarlton/ projects /midas_sampic/ experiments/sampic_daq 3. Checkout your own branch for playing around. I can easily switch off of it later. git checkout -b <branch_name> git checkout - b <branch_name> to check what branch you're currently on: git branch git branch to switch branches git switch <branch_name> git switch < branch_name > 4. Start a frontend If not already started, start the midas webpage with $SAMPIC_DAQ_DIR/scripts/webpage_scripts/start_midas_webpage.sh $SAMPIC_DAQ_DIR /scripts/ webpage_scripts/start_midas_webpage.sh afterwards, you can manually start a frontend $SAMPIC_DAQ_DIR/scripts/start_frontend.sh -i 0 $SAMPIC_DAQ_DIR /scripts/start_frontend .sh - i 0 or start a screen by pushing the button in the midas programs tab to start the frontend. 5. Code edits You can edit $SAMPIC_DAQ_DIR/src/frontend.cpp , right now it's in a fairly simple state. Just use the rebuild script when you make changes: $SAMPIC_DAQ_DIR/scripts/build.sh --overwrite $SAMPIC_DAQ_DIR /scripts/build .sh --overwrite",
    "textLength": 268
  },
  {
    "kind": "work-log",
    "title": "19_05_2024 - 25_05_2024.html",
    "fileName": "19_05_2024 - 25_05_2024.html",
    "url": "resources/work_logs/19_05_2024 - 25_05_2024.html",
    "createdDate": "2024-05-19",
    "text": "19/05/2024 - 25/05/2024 19/05/2024 - 25/05/2024 20/05/2024 09:42 I was able to \"revive\" the event builder by basically just using the correct flags: I was able to simply make it in our normal environment cd $GM2DAQ_DIR/eventbuilder make clean make cd $GM2DAQ_DIR /eventbuilder make clean make After a while of playing around, I figured out I had to run it with these parameters: ./mevb -e DAQ -b BUF ./mevb -e DAQ - b BUF the -b BUF is important. Basically it looks for frontends that write to anything that begin with BUF , so our AMC13001, AMC13002, and MasterGM2 write to BUF001, BUF002, and BUF respectively so they all get compounded into the event builder. I set the ODB programs settings to run this command: screen -dmS event_builder $GM2DAQ_DIR/eventbuilder/mevb -e DAQ -b BUF screen -dmS event_builder $GM2DAQ_DIR /eventbuilder/m evb -e DAQ -b BUF After starting a run, you can then check the output on the SYSTEM buffer (the buffer name can be changed in ebuser.cpp if you'd like): $MIDASSYS/bin/mdump -z SYSTEM $MIDASSYS /bin/m dump -z SYSTEM Now all the data will be logged if the logger is set to log the system buffer. Note: At one point I tried changing the ODB setting /Equipment/EB/Settings/User build to yes. This broke things, keep it at no. 20/05/2024 09:49 I noticed you will get CCC run abort errors if you try to start the 1 crate system with FC7 SFP ports enabled to talk to more than the one crate you have connected. 20/05/2024 10:19 According to this link: https://daq00.triumf.ca/MidasWiki/index.php/MIDAS_Event_Construction Midas bank names can only be 4 characters.We were trying to make them 5, I'm not sure if this is problematic for Lawrence's software. 20/05/2024 10:29 To move files using an SSH tunnel: In one terminal: ssh -L 2222:10.0.0.3:22 pioneer@10.47.95.44 ssh -L 2222 : 10.0.0.3:22 pioneer@ 10.47.95.44 Then: scp -P 2222 root@localhost:{file to copy} {destination} scp -P 2222 root@localhost:{ file to copy } {destination} similarly you can reverse the last command to move files. 20/05/2024 12:35 I was able to get interrupt triggering to \"work\" by adding some things. To CaloReadoutAMC13/frontend.cpp //function pointer to the interrupt routine #define USE_INTERRUPT #ifdef USE_INTERRUPT void (*interrupt_routine)(void); #endif //function pointer to the interrupt routine # define USE_INTERRUPT # ifdef USE_INTERRUPT void (*interrupt_routine)( void ); # endif EQUIPMENT equipment[] = { { \"AMC13%03d\", /* equipment name */ {1, 0xffff, /* event ID, trigger mask */ \"BUF%03d\", /* event buffer */ #ifdef USE_INTERRUPT EQ_INTERRUPT | EQ_EB, /* equipment type */ #else EQ_POLLED | EQ_EB, /* equipment type */ #endif LAM_SOURCE(0, 0xFFFFFF), /* event source crate 0, all stations */ \"MIDAS\", /* format */ TRUE, /* enabled */ RO_RUNNING , /* read only when running and end of run */ 10, /* poll for 1ms */ 0, /* stop run after this event limit */ 0, /* number of sub events */ 0, /* don't log history */ \"\", \"\", \"\", /* frontend host, frontend name, frontend file name */ \"\", \"\", FALSE}, /* status, status color, hidden */ read_trigger_event, /* readout routine */ }, {\"\"} }; EQUIPMENT equipment[] = { { \"AMC13%03d\", /* equipment name */ {1, 0xffff, /* event ID, trigger mask */ \"BUF%03d\", /* event buffer */ #ifdef USE_INTERRUPT EQ_INTERRUPT | EQ_EB, /* equipment type */ #else EQ_POLLED | EQ_EB, /* equipment type */ #endif LAM_SOURCE(0, 0xFFFFFF), /* event source crate 0, all stations */ \"MIDAS\", /* format */ TRUE, /* enabled */ RO_RUNNING , /* read only when running and end of run */ 10, /* poll for 1ms */ 0, /* stop run after this event limit */ 0, /* number of sub events */ 0, /* don't log history */ \"\", \"\", \"\", /* frontend host, frontend name, frontend file name */ \"\", \"\", FALSE}, /* status, status color, hidden */ read_trigger_event, /* readout routine */ }, {\"\"} }; Above is justt a \"switch\" to turn on and off interrupt INT interrupt_configure(INT cmd, INT source __attribute__((unused)), POINTER_T adr __attribute__((unused))) { switch (cmd) { case CMD_INTERRUPT_ENABLE: break; case CMD_INTERRUPT_DISABLE: break; case CMD_INTERRUPT_ATTACH: interrupt_routine = (void (*)())adr; break; case CMD_INTERRUPT_DETACH: break; } INT interrupt_configure ( INT cmd, INT source __attribute__((unused)), POINTER_T adr __attribute__((unused)) ) { switch (cmd) { case CMD_INTERRUPT_ENABLE : break ; case CMD_INTERRUPT_DISABLE : break ; case CMD_INTERRUPT_ATTACH : interrupt_routine = ( void (*)())adr; break ; case CMD_INTERRUPT_DETACH : break ; } I think this is some midas function that somehow links interrupt_routine to read_trigger_event? I'm not sure, I more or less copied it from the master frontend.cpp. BOOL send_interrupt_signal() { //std::cout << \"Received interrupt signal\" << std::endl; #ifdef USE_INTERRUPT (*interrupt_routine)(); #endif return TRUE; } BOOL send_interrupt_signal() { //std::cout << \"Received interrupt signal\" << std::endl; # ifdef USE_INTERRUPT (*interrupt_routine)(); # endif return TRUE ; } The actual \"signal\" used by gpu_thread.cpp frontend.h extern void (*interrupt_routine)(void); // Declare the interrupt routine as extern // Function prototypes BOOL send_interrupt_signal(); extern void ( *interrupt_routine )( void ) ; // Declare the interrupt routine as extern // Function prototypes BOOL send_interrupt_signal () ; Needed to give gpu_thread.cpp a way to send the interupt signal so it just includes this header file. gpu_thread.cpp send_interrupt_signal(); } // while (1) send_interrupt_signal (); } // while (1) If the gpu_thread gets to the end of it's while loop it sends an interrupt signal. This seems to work for low rates (tested 20 Hz and 200 Hz). But the TCP buffer fills up immediately once I try 1000Hz. Somehow it's worse than polling. Here's some additional reading on using interrupts: https://daq00.triumf.ca/MidasWiki/index.php/Frontend_user_code 23/05/2024 02:27 For the parallel port PCIe card. I downlaoded the drivers here: https://www.startech.com/en-us/cards-adapters/pex1s1p950 In there was a pdf \"PEX1P2 DIG.pdf\" that was useful. PEX1P2 DIG.pdf I followed those instructions and noticed I didn't see the card in lscpi -v as described. I swapped the PCIe ports of the meineberg and the parallel port PCIe cards and found that the port was the issue; afterwards I didn't see the meinberg but I saw the parrallel port. I'm not sure why this is. I've taken the meinberg card out to avoid further confusion. 23/05/2024 02:39 The pdf says to look at this information in lspci -v : 02:00.2 Parallel controller: Asix Electronics Corporation Device 9100 (prog-if 03 [IEEE1284]) Subsystem: Device a000:2000 Flags: fast devsel, IRQ 5 I/O ports at e010 [disabled] [size=8] I/O ports at e000 [disabled] [size=8] Memory at fbb01000 (32-bit, non-prefetchable) [disabled] [size=4K] Memory at fbb00000 (32-bit, non-prefetchable) [disabled] [size=4K] Capabilities: [50] MSI: Enable- Count=1/8 Maskable- 64bit+ Capabilities: [78] Power Management version 3 Capabilities: [80] Express Legacy Endpoint, MSI 00 Capabilities: [100] Advanced Error Reporting 02:00.2 Parallel controller: Asix Electronics Corporation Device 9100 (prog-if 03 [IEEE1284] ) Subsystem: Device a000:2000 Flags: fast devsel, IRQ 5 I/O ports at e010 [disabled] [size=8] I/O ports at e000 [disabled] [size=8] Memory at fbb01000 (32-bit, non-prefetchable) [disabled] [size=4K] Memory at fbb00000 (32-bit, non-prefetchable) [disabled] [size=4K] Capabilities: [50] MSI: Enable- Count=1/8 Maskable- 64bit+ Capabilities: [78] Power Management version 3 Capabilities: [80] Express Legacy Endpoint, MSI 00 Capabilities: [100] Advanced Error Reporting I'm pretty confident that the I/O ports should not say \"disabled.\" I'm unsure why this is happening. Specifically: I/O ports at e010 [disabled] [size=8] I/O ports at e000 [disabled] [size=8] I /O ports at e010 [disabled] [size=8] I /O ports at e000 [disabled] [size=8] And then use that information to run this command: sudo modprobe parport_pc io=0xe010 sudo modprobe parport_pc io =0xe010 There are no complaints, but I don't know which of these is the correct lp port (if any) [root@localhost ~]# ls /dev | grep \"lp\" lp0 lp1 lp2 lp3 [root@localhost ~]# [root @localhost ~] # ls /dev | grep \"lp\" lp0 lp1 lp2 lp3 [root @localhost ~] # I tried looking at dmesg, but it's unclear what is going on here (this output occurs rigtht after command sudo modprobe parport_pc io=0xe010 ) [root@localhost ~]# dmesg | grep parport [ 279.843630] parport 0xe010 (WARNING): CTR: wrote 0x0c, read 0xff [ 279.843636] parport 0xe010 (WARNING): DATA: wrote 0xaa, read 0xff [ 279.843638] parport 0xe010: You gave this address, but there is probably no parallel port there! [ 279.843652] parport0: PC-style at 0xe010, irq 0 [PCSPP,TRISTATE] [ 279.843659] genirq: Flags mismatch irq 0. 00000000 (parport0) vs. 00015a20 (timer) [ 279.843692] [<ffffffffc0d7fd90>] ? parport_register_device+0x2d0/0x2d0 [parport] [ 279.843700] [<ffffffffc0d92d1a>] parport_pc_probe_port+0x61a/0xab0 [parport_pc] [ 279.843704] [<ffffffffc0d9a0e7>] ? parport_parse_param.constprop.11+0xe7/0xe7 [parport_pc] [ 279.843707] [<ffffffffc0d9a319>] parport_pc_init+0x232/0xf19 [parport_pc] [ 279.843711] [<ffffffffc0d9a0e7>] ? parport_parse_param.constprop.11+0xe7/0xe7 [parport_pc] [ 279.843734] parport0: irq 0 in use, resorting to polled operation [root@localhost ~] # dmesg | grep parport [ 279.843630] parport 0xe010 (WARNING): CTR: wrote 0x0c, read 0xff [ 279.843636] parport 0xe010 (WARNING): DATA: wrote 0xaa, read 0xff [ 279.843638] parport 0xe010: You gave this address, but there is probably no parallel port there! [ 279.843652] parport0: PC-style at 0xe010, irq 0 [PCSPP,TRISTATE] [ 279.843659] genirq: Flags mismatch irq 0. 00000000 (parport0) vs. 00015a20 (timer) [ 279.843692] [<ffffffffc0d7fd90>] ? parport_register_device+0x2d0/0x2d0 [parport] [ 279.843700] [<ffffffffc0d92d1a>] parport_pc_probe_port+0x61a/0xab0 [parport_pc] [ 279.843704] [<ffffffffc0d9a0e7>] ? parport_parse_param.constprop.11+0xe7/0xe7 [parport_pc] [ 279.843707] [<ffffffffc0d9a319>] parport_pc_init+0x232/0xf19 [parport_pc] [ 279.843711] [<ffffffffc0d9a0e7>] ? parport_parse_param.constprop.11+0xe7/0xe7 [parport_pc] [ 279.843734] parport0: irq 0 in use, resorting to polled operation I also tried checking each 'lp' in /dev, but I'm not really sure what output I should see: [root@localhost ~]# udevadm info -a -p /dev/lp0 syspath not found [root@localhost ~]# udevadm info -a -p /dev/lp1 syspath not found [root@localhost ~]# udevadm info -a -p /dev/lp2 syspath not found [root@localhost ~]# udevadm info -a -p /dev/lp3 syspath not found [root@localhost ~] # udevadm info - a - p /dev/lp0 syspath not found [root@localhost ~] # udevadm info - a - p /dev/lp1 syspath not found [root@localhost ~] # udevadm info - a - p /dev/lp2 syspath not found [root@localhost ~] # udevadm info - a - p /dev/lp3 syspath not found It seems like I have to somehow get the parallel controller I/O ports and memory to not be disabled. 23/05/2024 03:15 The readme ( readme.txt ) mentions Loading the Driver: ------------------- To load the driver use the following command: $ insmod ax99100.ko ** '$' --this symbol represent the shell prompt on linux Unloading the Driver: --------------------- To unload the driver use the following command: $rmmod ax99100 ** '$' --this symbol represent the shell prompt on linux Loading the Driver: ------------------- To load the driver use the following command: $ insmod ax99100.ko ** '$' --this symbol represent the shell prompt on linux Unloading the Driver: --------------------- To unload the driver use the following command: $rmmod ax99100 ** '$' --this symbol represent the shell prompt on linux which was actually the first thing I did. I tried unloading the driver, rebooting, and repeating the steps in the pdf above, but no luck. 23/05/2024 03:19 I additionally found these steps in the readme. Steps for setting parallel port : --------------------------------- 1. rmmod lp 2. rmmod parport_pc 2. insmod parport_pc.ko io=bar0 io_hi=bar1 irq=number. Note: Here, the io, io_hi and irq should be noted from lspci -v. Steps for setting parallel port : --------------------------------- 1. rmmod lp 2. rmmod parport_pc 2. insmod parport_pc.ko io=bar0 io_hi=bar1 irq=number. Note: Here, the io, io_hi and irq should be noted from lspci -v. So I tried using this information: 02:00.2 Parallel controller: Asix Electronics Corporation Device 9100 (prog-if 03 [IEEE1284]) Subsystem: Device a000:2000 Flags: fast devsel, IRQ 5 I/O ports at e010 [disabled] [size=8] I/O ports at e000 [disabled] [size=8] Memory at fbb01000 (32-bit, non-prefetchable) [disabled] [size=4K] Memory at fbb00000 (32-bit, non-prefetchable) [disabled] [size=4K] Capabilities: [50] MSI: Enable- Count=1/8 Maskable- 64bit+ Capabilities: [78] Power Management version 3 Capabilities: [80] Express Legacy Endpoint, MSI 00 Capabilities: [100] Advanced Error Reporting 02:00.2 Parallel controller: Asix Electronics Corporation Device 9100 (prog-if 03 [IEEE1284] ) Subsystem: Device a000:2000 Flags: fast devsel, IRQ 5 I/O ports at e010 [disabled] [size=8] I/O ports at e000 [disabled] [size=8] Memory at fbb01000 (32-bit, non-prefetchable) [disabled] [size=4K] Memory at fbb00000 (32-bit, non-prefetchable) [disabled] [size=4K] Capabilities: [50] MSI: Enable- Count=1/8 Maskable- 64bit+ Capabilities: [78] Power Management version 3 Capabilities: [80] Express Legacy Endpoint, MSI 00 Capabilities: [100] Advanced Error Reporting I'm not sure what io and io_hi should be. I tried both: insmod parport_pc.ko io=0xe010 io_hi=0xe000 irq=5 insmod parport_pc.ko io =0xe010 io_hi =0xe000 irq =5 which takes io_hi to be the second I/O port BAR, and insmod parport_pc.ko io=0xe010 io_hi=0xe050 irq=5 insmod parport_pc.ko io =0xe010 io_hi =0xe050 irq =5 which adds 8 bytes (the size) listed above to the io BAR. All of these (and more dumb ideas I tried) seem to result in: [root@localhost AX99100_SP_PP_SPI_Linux_Driver_v1.8.0_Source]# insmod parport_pc.ko io=0xe010 io_hi=0xe000 irq=5 insmod: ERROR: could not insert module parport_pc.ko: Unknown symbol in module [root@localhost AX99100_SP_PP_SPI_Linux_Driver_v1.8.0_Source]# insmod parport_pc.ko io =0xe010 io_hi =0xe000 irq =5 insmod: ERROR: could not insert module parport_pc.ko: Unknown symbol in module At first I thought it was a kernel version issue, but the readme claims no issue: Kernels: -------- This driver is currently developed and tested on 2.6.13 linux kernel and above Kernels: -------- This driver is currently developed and tested on 2.6.13 linux kernel and above as our kernel version is much higher: [root@localhost AX99100_SP_PP_SPI_Linux_Driver_v1.8.0_Source]# uname -r 3.10.0-1160.99.1.el7.x86_64 [root @localhost AX99100_SP_PP_SPI_Linux_Driver_v1 .8 .0 _Source] # uname -r 3.10 .0 -1160.99 .1 .el7.x86_64 24/05/2024 01:35 This is the procedureI followed after installing the driver (see above pdf) to \"activate\" the card: Enable the PCIe device: echo 1 | sudo tee /sys/bus/pci/devices/0000:02:00.2/enable echo 1 | sudo tee /sys/bus/pci/devices/ 0000 : 02 : 00 . 2 /enable Confirm it's enabled, make note of IRQ: lspci -v | grep -A 10 \"02:00.2\" lspci -v | grep -A 10 \"02:00.2\" output: [root@localhost ~]# lspci -v | grep -A 10 \"02:00.2\" 02:00.2 Parallel controller: Asix Electronics Corporation Device 9100 (prog-if 03 [IEEE1284]) Subsystem: Device a000:2000 Flags: fast devsel, IRQ 48 I/O ports at e010 [size=8] I/O ports at e000 [size=8] Memory at fbb01000 (32-bit, non-prefetchable) [size=4K] Memory at fbb00000 (32-bit, non-prefetchable) [size=4K] Capabilities: [50] MSI: Enable- Count=1/8 Maskable- 64bit+ Capabilities: [78] Power Management version 3 Capabilities: [80] Express Legacy Endpoint, MSI 00 Capabilities: [100] Advanced Error Reporting [root@localhost ~]# lspci -v | grep -A 10 \"02:00.2\" 02:00.2 Parallel controller: Asix Electronics Corporation Device 9100 (prog-if 03 [IEEE1284]) Subsystem: Device a000:2000 Flags: fast devsel, IRQ 48 I/O ports at e010 [ size =8] I/O ports at e000 [ size =8] Memory at fbb01000 (32-bit, non-prefetchable) [ size =4K] Memory at fbb00000 (32-bit, non-prefetchable) [ size =4K] Capabilities: [50] MSI: Enable- Count =1/8 Maskable- 64bit+ Capabilities: [78] Power Management version 3 Capabilities: [80] Express Legacy Endpoint, MSI 00 Capabilities: [100] Advanced Error Reporting Remove old modprobe, load new modprobe: sudo modprobe -r parport_pc sudo modprobe parport_pc io=0xe010 irq=48 sudo modprobe -r parport_pc sudo modprobe parport_pc io =0xe010 irq =48 Make sure dmesg shows no issues: [root@localhost ~]# dmesg | grep parport [ 276.465148] parport0: PC-style at 0xe010, irq 48 [PCSPP,TRISTATE,EPP] [root@localhost ~]# [root @localhost ~] # dmesg | grep parport [ 276.465148 ] parport0: PC-style at 0xe010 , irq 48 [PCSPP,TRISTATE,EPP] [root @localhost ~] # Check for parport0 in devices: [root@localhost ~]# ls /dev/parport0 /dev/parport0 [root @localhost ~] # ls /dev/parport0 /dev/parport 0 Get details abourt parport0 [root@localhost ~]# udevadm info -q path -n /dev/parport0 /devices/platform/parport_pc.57360/ppdev/parport0 [root@localhost ~]# udevadm info -a -p /devices/platform/parport_pc.57360/ppdev/parport0 Udevadm info starts with the device specified by the devpath and then walks up the chain of parent devices. It prints for every device found, all possible attributes in the udev rules key format. A rule to match, can be composed by the attributes of the device and the attributes from one single parent device. looking at device '/devices/platform/parport_pc.57360/ppdev/parport0': KERNEL==\"parport0\" SUBSYSTEM==\"ppdev\" DRIVER==\"\" looking at parent device '/devices/platform/parport_pc.57360': KERNELS==\"parport_pc.57360\" SUBSYSTEMS==\"platform\" DRIVERS==\"parport_pc\" looking at parent device '/devices/platform': KERNELS==\"platform\" SUBSYSTEMS==\"\" DRIVERS==\"\" [root@localhost ~]# [root@localhost ~]# udevadm info -q path -n /dev/parport0 /devices/platform/parport_pc.57360/ppdev/parport0 [root@localhost ~]# udevadm info -a -p /devices/platform/parport_pc.57360/ppdev/parport0 Udevadm info starts with the device specified by the devpath and then walks up the chain of parent devices. It prints for every device found, all possible attributes in the udev rules key format. A rule to match, can be composed by the attributes of the device and the attributes from one single parent device. looking at device '/devices/platform/parport_pc.57360/ppdev/parport0' : KERNEL ==\"parport0\" SUBSYSTEM ==\"ppdev\" DRIVER ==\"\" looking at parent device '/devices/platform/parport_pc.57360' : KERNELS ==\"parport_pc.57360\" SUBSYSTEMS ==\"platform\" DRIVERS ==\"parport_pc\" looking at parent device '/devices/platform' : KERNELS ==\"platform\" SUBSYSTEMS ==\"\" DRIVERS ==\"\" [root@localhost ~]# 24/05/2024 01:56 Apparently doing above was not enough. I tried changinging the code for MasterGM2/frontend.cpp /* configure parallel port */ if (trigger_source == PP) { /* open trigger device */ const char *fd_name = \"/dev/trigger\"; printf(\"Connecting to [%s] ...\", fd_name); fd_pp = open(\"/dev/trigger\", O_RDWR); // for DAQ enable output if (fd_pp < 0) { cm_msg(MERROR, \"frontend_init\", \"Error opening file [%s]\", fd_name); return FE_ERR_HW; } printf(\" done PP configure \\n\"); } /* configure parallel port */ if (trigger_source == PP) { /* open trigger device */ const char *fd_name = \"/dev/trigger\" ; printf ( \"Connecting to [%s] ...\" , fd_name); fd_pp = open ( \"/dev/trigger\" , O_RDWR); // for DAQ enable output if (fd_pp < 0 ) { cm_msg (MERROR, \"frontend_init\" , \"Error opening file [%s]\" , fd_name); return FE_ERR_HW; } printf ( \" done PP configure \\n\" ); } to /* configure parallel port */ if (trigger_source == PP) { /* open trigger device */ const char *fd_name = \"/dev/parport0\"; printf(\"Connecting to [%s] ...\", fd_name); fd_pp = open(\"/dev/parport0\", O_RDWR); // for DAQ enable output if (fd_pp < 0) { cm_msg(MERROR, \"frontend_init\", \"Error opening file [%s]\", fd_name); return FE_ERR_HW; } printf(\" done PP configure \\n\"); } /* configure parallel port */ if (trigger_source == PP) { /* open trigger device */ const char *fd_name = \"/dev/parport0\" ; printf ( \"Connecting to [%s] ...\" , fd_name); fd_pp = open ( \"/dev/parport0\" , O_RDWR); // for DAQ enable output if (fd_pp < 0 ) { cm_msg (MERROR, \"frontend_init\" , \"Error opening file [%s]\" , fd_name); return FE_ERR_HW; } printf ( \" done PP configure \\n\" ); } It didn't complain when initializing (but I'm pretty sure it wouldn't complain as long as you gave it a valid filepath at this point). I was able to start a run but saw no events from the master (and no errors). Ending a run gave this error: 01:55:35.682 2024/05/24 [mhttpd,INFO] Run #230 stopped 01:55:32.464 2024/05/24 [MasterGM2,ERROR] [frontend.cpp:1312:end_of_run,ERROR] Error writing to parallel port 01:55:32.464 2024/05/24 [MasterGM2,INFO] End of Run: fills registered by all frontends match! 01:55:32.464 2024/05/24 [MasterGM2,INFO] End of Run: DC7 Triggers Received 16081 Count triggers 0 01:55:01.711 2024/05/24 [mhttpd,INFO] Run #230 started 01:55:35.682 2024/05/24 [mhttpd, INFO ] Run #230 stopped 01:55:32.464 2024/05/24 [MasterGM2, ERROR ] [frontend.cpp:1312:end_of_run, ERROR ] Error writing to parallel port 01:55:32.464 2024/05/24 [MasterGM2, INFO ] End of Run: fills registered by all frontends match! 01:55:32.464 2024/05/24 [MasterGM2, INFO ] End of Run: DC7 Triggers Received 16081 Count triggers 0 01:55:01.711 2024/05/24 [mhttpd, INFO ] Run #230 started It seems apparent that poll( &pfds, 1, timeout) in this part of the code: if(trigger_source==PP){ pfds.fd = fd_pp; pfds.events = POLLIN; int timeout = 10; int ret = 0; ret = poll( &pfds, 1, timeout); if ( ret > 0 ) { if(trigger_source==PP){ pfds . fd = fd_pp ; pfds . events = POLLIN ; int timeout = 10 ; int ret = 0 ; ret = poll( &pfds, 1 , timeout) ; if ( ret > 0 ) { is returning less than 1 every time. I.e. the polling is probably timing out. 24/05/2024 02:15 To test out the paralllel port, I got chatGPT to write some C code (placed in /home/playground/parallel_port/parallel_port_test) that supposedly reads and writes to it: parallel_port_test.c #include <stdio.h> #include <fcntl.h> #include <unistd.h> #include <sys/ioctl.h> #include <linux/ppdev.h> int main() { int fd = open(\"/dev/parport0\", O_RDWR); if (fd == -1) { perror(\"Cannot open /dev/parport0\"); return 1; } if (ioctl(fd, PPEXCL) < 0) { perror(\"Could not lock port\"); close(fd); return 1; } if (ioctl(fd, PPCLAIM) < 0) { perror(\"Could not claim port\"); close(fd); return 1; } char write_data = 0xFF; // Data to send printf(\"Writing data: 0x%02X\\n\", (unsigned char)write_data); if (ioctl(fd, PPWDATA, &write_data) < 0) { perror(\"Could not write data\"); close(fd); return 1; } else { printf(\"Data written successfully\\n\"); } char read_data; if (ioctl(fd, PPRSTATUS, &read_data) < 0) { perror(\"Could not read data\"); close(fd); return 1; } printf(\"Data read: 0x%02X\\n\", read_data); if (read_data == write_data) { printf(\"Readback matches write operation.\\n\"); } else { printf(\"Readback does not match write operation.\\n\"); } ioctl(fd, PPRELEASE); close(fd); return 0; } #include <stdio.h> #include <fcntl.h> #include <unistd.h> #include <sys/ioctl.h> #include <linux/ppdev.h> int main() { int fd = open(\"/dev/parport0\", O_RDWR); if (fd == -1) { perror(\"Cannot open /dev/parport0\"); return 1; } if (ioctl(fd, PPEXCL) < 0) { perror(\"Could not lock port\"); close(fd); return 1; } if (ioctl(fd, PPCLAIM) < 0) { perror(\"Could not claim port\"); close(fd); return 1; } char write_data = 0xFF; // Data to send printf(\"Writing data: 0x%02X\\n\", (unsigned char)write_data); if (ioctl(fd, PPWDATA, &write_data) < 0) { perror(\"Could not write data\"); close(fd); return 1; } else { printf(\"Data written successfully\\n\"); } char read_data; if (ioctl(fd, PPRSTATUS, &read_data) < 0) { perror(\"Could not read data\"); close(fd); return 1; } printf(\"Data read: 0x%02X\\n\", read_data); if (read_data == write_data) { printf(\"Readback matches write operation.\\n\"); } else { printf(\"Readback does not match write operation.\\n\"); } ioctl(fd, PPRELEASE); close(fd); return 0; } Nothing fails, however, the output indicates that the write wasn't succesfful: [root@localhost parallel_port_test]# ./parallel_port_test Writing data: 0xFF Data written successfully Data read: 0x38 Readback does not match write operation. [ root @ localhost parallel_port_test ] # ./parallel_port_test Writing data : 0 xFF Data written successfully Data read: 0 x38 Readback does not match write operation. 24/05/2024 02:34 I got ChatGPT to make me two other test scripts, both failed similarly: parallel_port_write.c #include <stdio.h> #include <stdlib.h> #include <fcntl.h> #include <unistd.h> #include <sys/ioctl.h> #include <linux/ppdev.h> #include <limits.h> // Include limits.h for UCHAR_MAX #define PORT_ADDRESS \"/dev/parport0\" #define DEFAULT_DATA 0xFF int main(int argc, char *argv[]) { // Data to write to the parallel port (default: 0xFF) unsigned char write_data = DEFAULT_DATA; // Check if a command-line argument is provided if (argc > 1) { // Convert the argument to an integer unsigned long int parsed_data = strtoul(argv[1], NULL, 0); // Check if conversion was successful if (parsed_data <= UCHAR_MAX) { write_data = (unsigned char)parsed_data; } else { fprintf(stderr, \"Error: Invalid data argument. Using default: 0x%02X\\n\", DEFAULT_DATA); } } // Open the parallel port int fd_pp = open(PORT_ADDRESS, O_RDWR); if (fd_pp == -1) { perror(\"Error opening parallel port\"); return 1; } // Write data to the parallel port printf(\"Writing data to parallel port: 0x%02X\\n\", write_data); ssize_t bytes_written = write(fd_pp, &write_data, sizeof(write_data)); if (bytes_written < 0) { perror(\"Error writing data to parallel port\"); close(fd_pp); return 1; } else if (bytes_written != sizeof(write_data)) { fprintf(stderr, \"Error: Incomplete write to parallel port\\n\"); close(fd_pp); return 1; } printf(\"Data written successfully\\n\"); // Close the parallel port close(fd_pp); return 0; } #include <stdio.h> #include <stdlib.h> #include <fcntl.h> #include <unistd.h> #include <sys/ioctl.h> #include <linux/ppdev.h> #include <limits.h> // Include limits.h for UCHAR_MAX #define PORT_ADDRESS \"/dev/parport0\" #define DEFAULT_DATA 0xFF int main(int argc, char *argv[]) { // Data to write to the parallel port (default: 0xFF) unsigned char write_data = DEFAULT_DATA; // Check if a command-line argument is provided if (argc > 1) { // Convert the argument to an integer unsigned long int parsed_data = strtoul(argv[1], NULL, 0); // Check if conversion was successful if (parsed_data <= UCHAR_MAX) { write_data = (unsigned char)parsed_data; } else { fprintf(stderr, \"Error: Invalid data argument. Using default: 0x%02X\\n\", DEFAULT_DATA); } } // Open the parallel port int fd_pp = open(PORT_ADDRESS, O_RDWR); if (fd_pp == -1) { perror(\"Error opening parallel port\"); return 1; } // Write data to the parallel port printf(\"Writing data to parallel port: 0x%02X\\n\", write_data); ssize_t bytes_written = write(fd_pp, &write_data, sizeof(write_data)); if (bytes_written < 0) { perror(\"Error writing data to parallel port\"); close(fd_pp); return 1; } else if (bytes_written != sizeof(write_data)) { fprintf(stderr, \"Error: Incomplete write to parallel port\\n\"); close(fd_pp); return 1; } printf(\"Data written successfully\\n\"); // Close the parallel port close(fd_pp); return 0; } parallel_port_poll.c #include <stdio.h> #include <stdlib.h> #include <fcntl.h> #include <unistd.h> #include <sys/ioctl.h> #include <sys/poll.h> // Include poll header #define PORT_ADDRESS \"/dev/parport0\" // Adjust the port address as per your system int main() { // Open the parallel port int fd_pp = open(PORT_ADDRESS, O_RDONLY); // Open in read-only mode for polling if (fd_pp == -1) { perror(\"Cannot open parallel port\"); return 1; } // Set up the pollfd structure struct pollfd pfds; pfds.fd = fd_pp; // File descriptor to poll pfds.events = POLLIN; // Events to monitor (in this case, POLLIN for input data) int timeout = 10; // Timeout value in milliseconds // Perform polling int ret = poll(&pfds, 1, timeout); if (ret == -1) { perror(\"poll\"); close(fd_pp); return 1; } else if (ret == 0) { printf(\"Timeout occurred\\n\"); } else { // Check if POLLIN event occurred if (pfds.revents & POLLIN) { printf(\"Data available for reading from parallel port\\n\"); // Read data from the parallel port if needed unsigned char data; if (read(fd_pp, &data, sizeof(data)) < 0) { perror(\"Error reading data from parallel port\"); } else { printf(\"Data read from parallel port: 0x%02X\\n\", data); } } else { printf(\"Unexpected event occurred\\n\"); } } // Close the parallel port close(fd_pp); return 0; } #include <stdio.h> #include <stdlib.h> #include <fcntl.h> #include <unistd.h> #include <sys/ioctl.h> #include <sys/poll.h> // Include poll header #define PORT_ADDRESS \"/dev/parport0\" // Adjust the port address as per your system int main() { // Open the parallel port int fd_pp = open(PORT_ADDRESS, O_RDONLY); // Open in read-only mode for polling if (fd_pp == -1) { perror(\"Cannot open parallel port\"); return 1; } // Set up the pollfd structure struct pollfd pfds; pfds.fd = fd_pp; // File descriptor to poll pfds.events = POLLIN; // Events to monitor (in this case, POLLIN for input data) int timeout = 10; // Timeout value in milliseconds // Perform polling int ret = poll(&pfds, 1, timeout); if (ret == -1) { perror(\"poll\"); close(fd_pp); return 1; } else if (ret == 0) { printf(\"Timeout occurred\\n\"); } else { // Check if POLLIN event occurred if (pfds.revents & POLLIN) { printf(\"Data available for reading from parallel port\\n\"); // Read data from the parallel port if needed unsigned char data; if (read(fd_pp, &data, sizeof(data)) < 0) { perror(\"Error reading data from parallel port\"); } else { printf(\"Data read from parallel port: 0x%02X\\n\", data); } } else { printf(\"Unexpected event occurred\\n\"); } } // Close the parallel port close(fd_pp); return 0; } With outputs: [root@localhost parallel_port_test]# ./parallel_port_write 0xAA Writing data to parallel port: 0xAA Error writing data to parallel port: Invalid argument [root@localhost parallel_port_test]# ./parallel_port_poll Timeout occurred [root@localhost parallel_port_test]# [root@localhost parallel_port_test]# ./parallel_port_write 0xAA Writing data to parallel port: 0xAA Error writing data to parallel port: Invalid argument [root@localhost parallel_port_test]# ./parallel_port_poll Timeout occurred [root@localhost parallel_port_test]# These two files try to more closely mimic the function calls present in MasterGM2/frontend.cpp 24/05/2024 02:40 I'm fairly confident /dev/parport0 is the correct path because it dissapears with command: sudo modprobe -r parport_pc sudo modprobe -r parport_pc and reappears with command: sudo modprobe parport_pc io=0xe010 irq=48 sudo modprobe parport_pc io =0xe010 irq =48 Interestingly, I don't need to include irq=48 to make /dev/parport0 appear. I'm not sure if this is meaningful. In any event, the result of the scripts and launching the frontends is no different whether I use sudo modprobe parport_pc io=0xe010 irq=48 sudo modprobe parport_pc io =0xe010 irq =48 or sudo modprobe parport_pc io=0xe010 sudo modprobe parport_pc io =0xe010 to load the module. But I do notice MasterGM2/frontend causes this output when loading the module in the second case: Message from syslogd@localhost at May 24 02:50:47 ... kernel:Disabling IRQ #18 Message from syslogd@localhost at May 24 02 : 50 : 47 ... kernel :Disabling IRQ # 18 it occurs system wide, I saw it occur in another shell session ssh'd into the computer that was not running the frontend. I also notice this error at the beginning of a run: Error: Write to parallel port failed! Data 0x007f [MasterGM2,ERROR] [frontend.cpp:1112:begin_of_runfe_loop,ERROR] Error writing to parallel port begin_of_run: write datum 0x7f Error: Write to parallel port failed! Data 0x007f [MasterGM2, ERROR ] [frontend.cpp:1112:begin_of_runfe_loop, ERROR ] Error writing to parallel port begin_of_run: write datum 0x7f That is not critical to the run starting. It happens whether I do sudo modprobe parport_pc io=0xe010 irq=48 or sudo modprobe parport_pc io=0xe010",
    "textLength": 4863
  },
  {
    "kind": "work-log",
    "title": "04_05_2025 - 10_05_2025.html",
    "fileName": "04_05_2025 - 10_05_2025.html",
    "url": "resources/work_logs/04_05_2025 - 10_05_2025.html",
    "createdDate": "2025-05-04",
    "text": "04/05/2025 - 10/05/2025 04/05/2025 - 10/05/2025 07/05/2025 19:12 THIS NOTE GIVES INCORRECT RESULTS, THE VALIDATION WAS INCORRECT Using the simulation reco results where I rewrote Sean's kmeans algorithm in C++, I was able to directly compare to truth by slightly modifying my python analysis/testing framework . These plots compare the simulation results running the truth tracklet finder --> truth pattern finder compared to reco tracklet finder --> reco pattern finder: \\boldsymbol{\\pi^+ \\rightarrow \\mu^+ + \\nu_\\mu \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 \u03bc + + \u03bd \u03bc \u2192 e + + \u03bd e \\boldsymbol{\\pi^+ \\rightarrow \\mu^+ + \\nu_\\mu \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 \u03bc + + \u03bd \u03bc \u200b \u2192 e + + \u03bd e \u200b : Things appear to perform better than before . This is puzzling, but my guess is that I accidentally debugged some errors in Sean's python code. When I tried to \"plainly copy\" the code over to C++, I noticed patterns weren't forming correctly it. I had to change a few things to get it working, and it's unclear to me whether I made any algorithmic changes or not (i.e. maybe something \"pythonic\" got lost in translation). In other words, there may be an unknown bug in the python code. 07/05/2025 19:30 THIS NOTE GIVES INCORRECT RESULTS, THE VALIDATION WAS INCORRECT Same as above, but now these are the result for \\boldsymbol{\\pi^+ \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 e + + \u03bd e \\boldsymbol{\\pi^+ \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 e + + \u03bd e \u200b : 07/05/2025 19:35 Comparisons using python based algorithm. I.e. here we're comparing truth tracklets --> truth patterns vs. reco tracklets --> reco patterns (but reco patterns constructed in python). \\boldsymbol{\\pi^+ \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 e + + \u03bd e \\boldsymbol{\\pi^+ \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 e + + \u03bd e \u200b : \\boldsymbol{\\pi^+ \\rightarrow \\mu^+ + \\nu_\\mu \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 \u03bc + + \u03bd \u03bc \u2192 e + + \u03bd e \\boldsymbol{\\pi^+ \\rightarrow \\mu^+ + \\nu_\\mu \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 \u03bc + + \u03bd \u03bc \u200b \u2192 e + + \u03bd e \u200b : 08/05/2025 13:54 A VERY IMPORTANT CORRECTION TO THE ABOVE INFO: There was a bad bug in the previous code that caused the validation to only consider tracklets that were in the reco for pattern_idx, pattern in enumerate(truth_source.patternVec): indices = pattern.GetTrackletIndices() pattern_tracklet_ids = [] # For each tracklet in the truth pattern for idx in indices: tid = tracklet_idx_to_id.get(idx) # Find the tracklet ID in the reconstructed tracklet list if tid is not None: pattern_tracklet_ids.append(tid) # Track the count of particles in the event for truth tracklet = tracklets[tid] particle_id = tracklet.particle_id particles_counter[particle_id] += 1 patterns_truth[pattern_idx] = pattern_tracklet_ids for pattern_idx, pattern in enumerate (truth_source.patternVec): indices = pattern.GetTrackletIndices() pattern_tracklet_ids = [] # For each tracklet in the truth pattern for idx in indices: tid = tracklet_idx_to_id.get(idx) # Find the tracklet ID in the reconstructed tracklet list if tid is not None : pattern_tracklet_ids.append(tid) # Track the count of particles in the event for truth tracklet = tracklets[tid] particle_id = tracklet.particle_id particles_counter[particle_id] += 1 patterns_truth[pattern_idx] = pattern_tracklet_ids In particular, these lines were causing the issue: tid = tracklet_idx_to_id.get(idx) # Find the tracklet ID in the reconstructed tracklet list if tid is not None: tid = tracklet_idx_to_id. get (idx) # Find the tracklet ID in the reconstructed tracklet list if tid is not None: Regenerated, the plots for truth tracklet finder --> truth pattern finder compared to reco tracklet finder --> reco pattern show similar results to the python implimentation: \\boldsymbol{\\pi^+ \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 e + + \u03bd e \\boldsymbol{\\pi^+ \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 e + + \u03bd e \u200b : \\boldsymbol{\\pi^+ \\rightarrow \\mu^+ + \\nu_\\mu \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 \u03bc + + \u03bd \u03bc \u2192 e + + \u03bd e \\boldsymbol{\\pi^+ \\rightarrow \\mu^+ + \\nu_\\mu \\rightarrow e^+ + \\nu_e} \u03c0 + \u2192 \u03bc + + \u03bd \u03bc \u200b \u2192 e + + \u03bd e \u200b :",
    "textLength": 607
  },
  {
    "kind": "work-log",
    "title": "10_11_2024 - 16_11_2024.html",
    "fileName": "10_11_2024 - 16_11_2024.html",
    "url": "resources/work_logs/10_11_2024 - 16_11_2024.html",
    "createdDate": "2024-11-10",
    "text": "10/11/2024 - 16/11/2024 10/11/2024 - 16/11/2024 11/11/2024 21:50 Was able to connect to the nalu scientific board using the NaluScope software ( manual , download ). Here are the steps I did on Windows 10: Make Hardware connections Connect Nalu's HDSoCv1 evalr2 board to the FMC of a Nexys Video A7 board (you can follow the quickstart guide for this step) Connect a USB to microUSB cable to the Nexys Video A7 board PROG port. Connect a USB to microUSB cable to the Nexys Video A7 board UART port. Connect the 12V power adapter to the board's power input. Switch the board on. You should see lights on both boards (the Nexsys and HDSoC). Open Vivado to upload bitstream Go to hardware manager Autoconnect to the device, you should see something like xc7a200t_0 . This is the Nexys board. Click program device. Select the bitstream (Firmware) downloaded from the manual page, or this link will download it too . You should see some lights change on both boards, you can see what they mean in the quickstart guide Open the NaluScope software for use Choose a working directory Select model hdsocv1_evalr2 Leave \"Use Hardware Server\" and \"Connect to Board\" checked Under \"Connect to Board\", select FTDI There should be 2 devices listed, one for the programming USB and one for the UART usb. Pick the one that has UART in it's name (mine was named AV0KR3DC or something) Click \"Connect\" wait ~1 minute Once you see \"Startup successful\" click \"Continue\" at the bottom. A new window should appear 11/11/2024 22:14 Well, I'm sure I'm connected to the board because I was able to generate these pedestal plots with in naluscope software They obviously just look like noise centered around some pedestal. I'm currently trying to figure out how to just trigger on some noise so we don't need to input a signal for some testing 11/11/2024 22:22 By setting the trigger source to external, I was able to start a run and activate the autotrigger, which just triggers on a set interval. I generated some events: In short, things are working so far. 11/11/2024 23:21 The linux install was much less straightforward due to needing to install the USB to UART drivers. Here are the steps I followed to reproduce the behavior we had on windows: Make Hardware connections Connect Nalu's HDSoCv1 evalr2 board to the FMC of a Nexys Video A7 board (you can follow the quickstart guide for this step) Connect a USB to microUSB cable to the Nexys Video A7 board PROG port. Connect a USB to microUSB cable to the Nexys Video A7 board UART port. Connect the 12V power adapter to the board's power input. Switch the board on. You should see lights on both boards (the Nexsys and HDSoC). Open Vivado to upload bitstream Go to hardware manager Autoconnect to the device, you should see something like xc7a200t_0 . This is the Nexys board. Click program device. Select the bitstream (Firmware) downloaded from the manual page, or this link will download it too . You should see some lights change on both boards, you can see what they mean in the quickstart guide Install NaluScope for Linux Download latest Linux version off nalu's website Extract naluscope tar -xzvf naluscope*.tar.gz Download dependencies: sudo apt update sudo apt install libxcb-cursor0 libxcb-icccm4 libxcb-keysyms1 libxcb-render-util0 libxkbcommon-x11-0 sudo apt update sudo apt install libxcb-cursor0 libxcb-icccm4 libxcb-keysyms1 libxcb-render-util0 libxkbcommon-x11- 0 Download USB to UART Driver ( D2XX Driver ) I had to follow the video install guide to get it to work The NaluScope Manual suggests installing under home as root, so just mv nalu/ $HOME . Open the NaluScope software for use ./$HOME/nalu/nalu (It may complain about not having D3XX Driver, this driver is for USB3 and isn't supported on linux anyways) Choose a working directory Select model hdsocv1_evalr2 Leave \"Use Hardware Server\" and \"Connect to Board\" checked Under \"Connect to Board\", select FTDI There should be 2 devices listed, one for the programming USB and one for the UART usb. Pick the one that has UART in it's name (mine was named AV0KR3DC or something) Click \"Connect\" wait ~1 minute Once you see \"Startup successful\" click \"Continue\" at the bottom. A new window should appear 12/11/2024 00:03 Was able to connect to the board within python using the naluexamples repository. Here is how one is able to clone the examples, install the repository, then open a jupyter notebook to view it. git clone https://github.com/NaluScientific/naluexamples.git cd naluexamples sudo apt update sudo apt install python3-pip pip3 install jupyter pip3 install naludaq pip3 install . jupyter notebook git clone https://github.com/NaluScientific/naluexamples.git cd naluexamples sudo apt update sudo apt install python3-pip pip3 install jupyter pip3 install naludaq pip3 install . jupyter notebook From there I tried running examples/basic_uart_readout.ipynb . I had to change the following line model, ser_no, baud = 'aodsoc_aods', 'B308B', 2_000_000 # AODS version model, ser_no, baud = 'aodsoc_aods' , 'B308B' , 2 _000_000 # AODS version to model, ser_no, baud = 'hdsocv1_evalr2', 'AV0KR3DC', 2_000_000 # AODS version model, ser_no, baud = 'hdsocv1_evalr2' , 'AV0KR3DC' , 2 _000_000 # AODS version and I was able to initialize the board I ran into an error relating to: ControlRegisters(BOARD).write('testmode', False) ControlRegisters(BOARD). write ( 'testmode' , False ) claiming a key error; I.e. I don't think this board has a \"testmode\" control register. I'll need to do some digging to find the appropriate registers for the board. 15/11/2024 15:01 For some reason connection over UART is very finnicky on Linux. The UART connection will randomly dissapear. To regain it I have to unplug the connectiona and plug it back in. Then do sudo rmmod ftdi-sio sudo rmmod usbserial sudo rmmod ftdi-sio sudo rmmod usbserial After this it will appear as an option when naludaq tries to find it. 15/11/2024 15:16 I modified the readout function in naluexamples basic_uart_readout.ipynb: def readout_buffer(windows=2, lookback=2, amount=2, testmode=True) -> bytearray: \"\"\"Readout data by filling the buffer and then reading it. This means reading out more data that the serailbuffer can hold will be discarded. Args: windows (int): Number of windows to readout. lookback (int): Number of windows to lookback. amount (int): Number of events to readout. testmode (bool): If True, readout will readout ASIC test pattern. Returns: bytearray: Data readout. \"\"\" if amount > 10: print(\"amount too large, setting amount to 10\") amount = 10 _rc = get_readout_controller(BOARD) _bc = get_board_controller(BOARD) with BOARD: print(\"Control Registers:\", ControlRegisters(BOARD).list()) print() print(\"Digital Registers:\", DigitalRegisters(BOARD).list()) print() #ControlRegisters(BOARD).write('testmode', False) #DigitalRegisters(BOARD).write('enabletestpatt', testmode) while BOARD.connection.in_waiting: BOARD.connection.reset_input_buffer() _rc.number_events_to_read(amount) _rc.set_readout_channels(list(range(4))) _rc.set_read_window(windows=windows, lookback=lookback, write_after_trig=16) _bc.start_readout(trig='imm', lb='forced', readoutEn=True, singleEv=True) time.sleep(1*amount) _bc.stop_readout() print(f\"Bytes in buffer: {BOARD.connection.in_waiting}\") _data = BOARD.connection.read_all() return _data def readout_buffer(windows=2, lookback=2, amount=2, testmode=True) -> bytearray: \"\"\"Readout data by filling the buffer and then reading it. This means reading out more data that the serailbuffer can hold will be discarded. Args: windows (int): Number of windows to readout. lookback (int): Number of windows to lookback. amount (int): Number of events to readout. testmode (bool): If True, readout will readout ASIC test pattern. Returns: bytearray: Data readout. \"\"\" if amount > 10: print(\"amount too large, setting amount to 10\") amount = 10 _rc = get_readout_controller(BOARD) _bc = get_board_controller(BOARD) with BOARD: print(\"Control Registers:\", ControlRegisters(BOARD).list()) print() print(\"Digital Registers:\", DigitalRegisters(BOARD).list()) print() #ControlRegisters(BOARD).write('testmode', False) #DigitalRegisters(BOARD).write('enabletestpatt', testmode) while BOARD.connection.in_waiting: BOARD.connection.reset_input_buffer() _rc.number_events_to_read(amount) _rc.set_readout_channels(list(range(4))) _rc.set_read_window(windows=windows, lookback=lookback, write_after_trig=16) _bc.start_readout(trig='imm', lb='forced', readoutEn=True, singleEv=True) time.sleep(1*amount) _bc.stop_readout() print(f\"Bytes in buffer: {BOARD.connection.in_waiting}\") _data = BOARD.connection.read_all() return _data Note that I commented out #ControlRegisters(BOARD).write('testmode', False) #DigitalRegisters(BOARD).write('enabletestpatt', testmode) # ControlRegisters ( BOARD ) .write('testmode', False) # DigitalRegisters ( BOARD ) .write('enabletestpatt', testmode) as no such registers exist for the HDSoC board. Then we call the function like so _data = readout_buffer(windows=2, lookback=2, amount=2, testmode=True) _data = readout_buffer( windows =2, lookback =2, amount =2, testmode = True ) This way it doesn't error out: 2024-11-15 15:14:00,377 naludaq.board [DEBUG ]: Entering board context (\"with\" block); opening connection... 2024-11-15 15:14:00,394 naludaq.FTDI [INFO ]: Success! Connected. 0 2024-11-15 15:14:00,395 naludaq.readout_controller_hdsoc [DEBUG ]: Setting numwinds to 16 2024-11-15 15:14:00,396 naludaq.FTDI [DEBUG ]: Sending: AF080010 in single mode 2024-11-15 15:14:00,417 naludaq.FTDI [DEBUG ]: Sending: B00033E8 in single mode 2024-11-15 15:14:00,438 naludaq.FTDI [DEBUG ]: Sending: B00430FF in single mode 2024-11-15 15:14:00,459 naludaq.FTDI [DEBUG ]: Sending: B00430FF in single mode 2024-11-15 15:14:00,481 naludaq.FTDI [DEBUG ]: Sending: B00073E8 in single mode 2024-11-15 15:14:00,502 naludaq.FTDI [DEBUG ]: Sending: B00430FF in single mode 2024-11-15 15:14:00,523 naludaq.FTDI [DEBUG ]: Sending: B00430FF in single mode 2024-11-15 15:14:00,544 naludaq.FTDI [DEBUG ]: Sending: B000B3E8 in single mode 2024-11-15 15:14:00,566 naludaq.FTDI [DEBUG ]: Sending: B00430FF in single mode 2024-11-15 15:14:00,587 naludaq.FTDI [DEBUG ]: Sending: B00430FF in single mode Control Registers: ['identifier', 'version', 'reg_data0', 'reg_data1', 'mode_sel', 'iomode0', 'regclr', 'pclk', 'nramp', 'iomode1', 'sysrst', 'exttrig', 'nrw', 'sel', 'stopacq', 't_user', 'write_address', 'loadwait', 'pclkwidth', 'numwinds', 'debug_data', 'debug_addr', 'idig_rst', 'wave_fifo_rst', 'clk_sync', 'clk_reset', 'clk_oeb', 'clk_i2c_sel', 'clk1v8_en', 'clk2v5_en', '3v3_i2c_en', '1v2_en', '2v5_en', 'ser_rx_neg_pol', 'ser_rx_crc_en', 'ser_rx_eof_en', 'ser_rx_div', 'ser_tx_neg_pol', 'pedram_addr', 'pedram_data', 'analog_debug_disable', 'auto_numwinds_en', 'timeout15_0', 'timeout31_16', 'eth_addr_sel', 'eth_port_sel', 'tx_mode', 'eth_ar_en', 'eth_dhcp_en', 'eth_dest_addr15_0', 'eth_dest_addr31_16', 'eth_src_addr15_0', 'eth_src_addr31_16', 'eth_dest_port', 'eth_src_port', 'pg_2v5', 'clk_intr_n', 'clk_lol_n', 'fpga_clk_locked', 'asic_clk_locked', 'ser_tx_clk_locked', 'rx_en', 'tx_en', 'idly_cnt_val', 'dhcp_addr15_0', 'ch_en15_0', 'ch_en31_16'] Digital Registers: ['scal0', 'scal1', 'scal2', 'scal3', 'scal4', 'scal5', 'scal6', 'scal7', 'scal8', 'scal9', 'scal10', 'scal11', 'scal12', 'scal13', 'scal14', 'scal15', 'scal16', 'scal17', 'scal18', 'scal19', 'scal20', 'scal21', 'scal22', 'scal23', 'scal24', 'scal25', 'scal26', 'scal27', 'scal28', 'scal29', 'scal30', 'scal31', 'scalmon_left', 'scalmon_right', 'scalhigh', 'idconfig', 'regclr_bk', 'regloadperiod_bk', 'reglatchperiod_bk', 'regwaitread', 'chanmask0', 'chanmask1', 'chanmask2', 'chanmask3', 'streamingpattern0', 'streamingpattern1', 'streamingpattern2', 'streamingpattern3', 'selectchannel', 'wraddrstart', 'wraddrstop', 'wraddrjunk', 'writeaftertrig', 'convertresetwait', 'readoutlookback', 'readoutwindows', 'readoutchannels', 'regclr_chan', 'regloadperiod_chan', 'reglatchperiod_chan', 'regmisc', 'regwaitaddr', 'writedelay', 'regspeed', 'wlcon', 'dig_to_an'] 2024-11-15 15:14:00,608 naludaq.FTDI [DEBUG ]: Sending: B000F3E8 in single mode 2024-11-15 15:14:00,630 naludaq.FTDI [DEBUG ]: Sending: B00430FF in single mode 2024-11-15 15:14:00,651 naludaq.FTDI [DEBUG ]: Sending: B00430FF in single mode 2024-11-15 15:14:00,672 naludaq.FTDI [DEBUG ]: Sending: B0013000 in single mode 2024-11-15 15:14:00,694 naludaq.FTDI [DEBUG ]: Sending: B00430FF in single mode 2024-11-15 15:14:00,715 naludaq.FTDI [DEBUG ]: Sending: B00430FF in single mode 2024-11-15 15:14:00,736 naludaq.FTDI [DEBUG ]: Sending: B0017000 in single mode 2024-11-15 15:14:00,757 naludaq.FTDI [DEBUG ]: Sending: B00430FF in single mode 2024-11-15 15:14:00,778 naludaq.FTDI [DEBUG ]: Sending: B00430FF in single mode 2024-11-15 15:14:00,799 naludaq.FTDI [DEBUG ]: Sending: B001B000 in single mode 2024-11-15 15:14:00,820 naludaq.FTDI [DEBUG ]: Sending: B0042200 in single mode 2024-11-15 15:14:00,842 naludaq.FTDI [DEBUG ]: Sending: B0042200 in single mode 2024-11-15 15:14:00,863 naludaq.FTDI [DEBUG ]: Sending: B001F000 in single mode 2024-11-15 15:14:00,884 naludaq.FTDI [DEBUG ]: Sending: B0042200 in single mode 2024-11-15 15:14:00,905 naludaq.FTDI [DEBUG ]: Sending: B0042200 in single mode 2024-11-15 15:14:00,926 naludaq.FTDI [DEBUG ]: Sending: B0023000 in single mode 2024-11-15 15:14:00,948 naludaq.FTDI [DEBUG ]: Sending: B0042200 in single mode 2024-11-15 15:14:00,969 naludaq.FTDI [DEBUG ]: Sending: B0042200 in single mode 2024-11-15 15:14:00,990 naludaq.FTDI [DEBUG ]: Sending: B0027000 in single mode 2024-11-15 15:14:01,011 naludaq.FTDI [DEBUG ]: Sending: B0042200 in single mode 2024-11-15 15:14:01,032 naludaq.FTDI [DEBUG ]: Sending: B0042200 in single mode 2024-11-15 15:14:01,053 naludaq.FTDI [DEBUG ]: Sending: B002B000 in single mode 2024-11-15 15:14:01,075 naludaq.FTDI [DEBUG ]: Sending: B0044000 in single mode 2024-11-15 15:14:01,096 naludaq.FTDI [DEBUG ]: Sending: B0044000 in single mode 2024-11-15 15:14:01,118 naludaq.FTDI [DEBUG ]: Sending: B002F000 in single mode 2024-11-15 15:14:01,139 naludaq.FTDI [DEBUG ]: Sending: B0044000 in single mode 2024-11-15 15:14:01,160 naludaq.FTDI [DEBUG ]: Sending: B0044000 in single mode 2024-11-15 15:14:01,181 naludaq.FTDI [DEBUG ]: Sending: B0033000 in single mode 2024-11-15 15:14:01,202 naludaq.FTDI [DEBUG ]: Sending: B0044000 in single mode 2024-11-15 15:14:01,223 naludaq.FTDI [DEBUG ]: Sending: B0044000 in single mode 2024-11-15 15:14:01,244 naludaq.FTDI [DEBUG ]: Sending: B0037000 in single mode 2024-11-15 15:14:01,265 naludaq.FTDI [DEBUG ]: Sending: B0044000 in single mode 2024-11-15 15:14:01,286 naludaq.FTDI [DEBUG ]: Sending: B0044000 in single mode 2024-11-15 15:14:01,307 naludaq.FTDI [DEBUG ]: Sending: B003B000 in single mode 2024-11-15 15:14:01,329 naludaq.FTDI [DEBUG ]: Sending: B0044000 in single mode 2024-11-15 15:14:01,350 naludaq.FTDI [DEBUG ]: Sending: B0044000 in single mode 2024-11-15 15:14:01,371 naludaq.FTDI [DEBUG ]: Sending: B003F000 in single mode 2024-11-15 15:14:01,392 naludaq.FTDI [DEBUG ]: Sending: B0044000 in single mode 2024-11-15 15:14:01,413 naludaq.FTDI [DEBUG ]: Sending: B0044000 in single mode 2024-11-15 15:14:01,435 naludaq.FTDI [DEBUG ]: Sending: B0083000 in single mode 2024-11-15 15:14:01,456 naludaq.FTDI [DEBUG ]: Sending: B00C3000 in single mode 2024-11-15 15:14:01,477 naludaq.FTDI [DEBUG ]: Sending: B00C3000 in single mode 2024-11-15 15:14:01,498 naludaq.FTDI [DEBUG ]: Sending: B0087000 in single mode 2024-11-15 15:14:01,519 naludaq.FTDI [DEBUG ]: Sending: B00C3000 in single mode 2024-11-15 15:14:01,540 naludaq.FTDI [DEBUG ]: Sending: B00C3000 in single mode 2024-11-15 15:14:01,561 naludaq.FTDI [DEBUG ]: Sending: B008B000 in single mode 2024-11-15 15:14:01,582 naludaq.FTDI [DEBUG ]: Sending: B00C3000 in single mode 2024-11-15 15:14:01,603 naludaq.FTDI [DEBUG ]: Sending: B00C3000 in single mode 2024-11-15 15:14:01,624 naludaq.FTDI [DEBUG ]: Sending: B008F000 in single mode 2024-11-15 15:14:01,645 naludaq.FTDI [DEBUG ]: Sending: B00C3000 in single mode 2024-11-15 15:14:01,666 naludaq.FTDI [DEBUG ]: Sending: B00C3000 in single mode 2024-11-15 15:14:01,687 naludaq.FTDI [DEBUG ]: Sending: B0093000 in single mode 2024-11-15 15:14:01,708 naludaq.FTDI [DEBUG ]: Sending: B00C3000 in single mode 2024-11-15 15:14:01,729 naludaq.FTDI [DEBUG ]: Sending: B00C3000 in single mode 2024-11-15 15:14:01,750 naludaq.FTDI [DEBUG ]: Sending: B0097000 in single mode 2024-11-15 15:14:01,772 naludaq.FTDI [DEBUG ]: Sending: B00C3000 in single mode 2024-11-15 15:14:01,793 naludaq.FTDI [DEBUG ]: Sending: B00C3000 in single mode 2024-11-15 15:14:01,814 naludaq.FTDI [DEBUG ]: Sending: B009B000 in single mode 2024-11-15 15:14:01,835 naludaq.FTDI [DEBUG ]: Sending: B00C2200 in single mode 2024-11-15 15:14:01,856 naludaq.FTDI [DEBUG ]: Sending: B00C2200 in single mode 2024-11-15 15:14:01,877 naludaq.FTDI [DEBUG ]: Sending: B009F000 in single mode 2024-11-15 15:14:01,898 naludaq.FTDI [DEBUG ]: Sending: B00C2200 in single mode 2024-11-15 15:14:01,919 naludaq.FTDI [DEBUG ]: Sending: B00C2200 in single mode 2024-11-15 15:14:01,941 naludaq.FTDI [DEBUG ]: Sending: B00A3000 in single mode 2024-11-15 15:14:01,962 naludaq.FTDI [DEBUG ]: Sending: B00C2200 in single mode 2024-11-15 15:14:01,983 naludaq.FTDI [DEBUG ]: Sending: B00C2200 in single mode 2024-11-15 15:14:02,005 naludaq.FTDI [DEBUG ]: Sending: B00A7000 in single mode 2024-11-15 15:14:02,026 naludaq.FTDI [DEBUG ]: Sending: B00C2200 in single mode 2024-11-15 15:14:02,047 naludaq.FTDI [DEBUG ]: Sending: B00C2200 in single mode 2024-11-15 15:14:02,069 naludaq.FTDI [DEBUG ]: Sending: B00AB000 in single mode 2024-11-15 15:14:02,090 naludaq.FTDI [DEBUG ]: Sending: B00C4000 in single mode 2024-11-15 15:14:02,111 naludaq.FTDI [DEBUG ]: Sending: B00C4000 in single mode 2024-11-15 15:14:02,132 naludaq.FTDI [DEBUG ]: Sending: B00AF000 in single mode 2024-11-15 15:14:02,154 naludaq.FTDI [DEBUG ]: Sending: B00C4000 in single mode 2024-11-15 15:14:02,175 naludaq.FTDI [DEBUG ]: Sending: B00C4000 in single mode 2024-11-15 15:14:02,196 naludaq.FTDI [DEBUG ]: Sending: B00B3000 in single mode 2024-11-15 15:14:02,218 naludaq.FTDI [DEBUG ]: Sending: B00C4000 in single mode 2024-11-15 15:14:02,239 naludaq.FTDI [DEBUG ]: Sending: B00C4000 in single mode 2024-11-15 15:14:02,260 naludaq.FTDI [DEBUG ]: Sending: B00B7000 in single mode 2024-11-15 15:14:02,281 naludaq.FTDI [DEBUG ]: Sending: B00C4000 in single mode 2024-11-15 15:14:02,302 naludaq.FTDI [DEBUG ]: Sending: B00C4000 in single mode 2024-11-15 15:14:02,324 naludaq.FTDI [DEBUG ]: Sending: B00BB000 in single mode 2024-11-15 15:14:02,345 naludaq.FTDI [DEBUG ]: Sending: B00C4000 in single mode 2024-11-15 15:14:02,366 naludaq.FTDI [DEBUG ]: Sending: B00C4000 in single mode 2024-11-15 15:14:02,387 naludaq.FTDI [DEBUG ]: Sending: B00BF000 in single mode 2024-11-15 15:14:02,408 naludaq.FTDI [DEBUG ]: Sending: B00C4000 in single mode 2024-11-15 15:14:02,429 naludaq.FTDI [DEBUG ]: Sending: B00C4000 in single mode 2024-11-15 15:14:02,450 naludaq.readout_controller_default [DEBUG ]: Set readwindow to: w2, l2, t:16 2024-11-15 15:14:02,450 naludaq.FTDI [DEBUG ]: Sending: B01C6002 in single mode 2024-11-15 15:14:02,471 naludaq.FTDI [DEBUG ]: Sending: B01C5002 in single mode 2024-11-15 15:14:02,491 naludaq.FTDI [DEBUG ]: Sending: B01C3010 in single mode 2024-11-15 15:14:02,512 naludaq.board_controller_default [DEBUG ]: READOUT command: Bc300000 2024-11-15 15:14:02,512 naludaq.FTDI [DEBUG ]: Sending: Bc300000 in single mode 2024-11-15 15:14:04,535 naludaq.FTDI [DEBUG ]: Sending: B0B00000 in single mode 2024-11-15 15:14:04,556 naludaq.FTDI [DEBUG ]: Sending: AF042001 in single mode 2024-11-15 15:14:04,577 naludaq.FTDI [DEBUG ]: Sending: AF040001 in single mode 2024-11-15 15:14:04,598 naludaq.FTDI [DEBUG ]: Sending: AF160400 in single mode 2024-11-15 15:14:04,619 naludaq.FTDI [DEBUG ]: Sending: AF160000 in single mode 2024-11-15 15:14:04,641 naludaq.FTDI [DEBUG ]: Sending: AF160200 in single mode 2024-11-15 15:14:04,661 naludaq.FTDI [DEBUG ]: Sending: AF160000 in single mode 2024-11-15 15:14:04,684 naludaq.board [DEBUG ]: Exiting board context (\"with\" block); closing connection... Bytes in buffer: 0 2024-11-15 15:14:00,377 naludaq.board [DEBUG ]: Entering board context (\"with\" block); opening connection... 2024-11-15 15:14:00,394 naludaq.FTDI [INFO ]: Success! Connected. 0 2024-11-15 15:14:00,395 naludaq.readout_controller_hdsoc [DEBUG ]: Setting numwinds to 16 2024-11-15 15:14:00,396 naludaq.FTDI [DEBUG ]: Sending: AF080010 in single mode 2024-11-15 15:14:00,417 naludaq.FTDI [DEBUG ]: Sending: B00033E8 in single mode 2024-11-15 15:14:00,438 naludaq.FTDI [DEBUG ]: Sending: B00430FF in single mode 2024-11-15 15:14:00,459 naludaq.FTDI [DEBUG ]: Sending: B00430FF in single mode 2024-11-15 15:14:00,481 naludaq.FTDI [DEBUG ]: Sending: B00073E8 in single mode 2024-11-15 15:14:00,502 naludaq.FTDI [DEBUG ]: Sending: B00430FF in single mode 2024-11-15 15:14:00,523 naludaq.FTDI [DEBUG ]: Sending: B00430FF in single mode 2024-11-15 15:14:00,544 naludaq.FTDI [DEBUG ]: Sending: B000B3E8 in single mode 2024-11-15 15:14:00,566 naludaq.FTDI [DEBUG ]: Sending: B00430FF in single mode 2024-11-15 15:14:00,587 naludaq.FTDI [DEBUG ]: Sending: B00430FF in single mode Control Registers: ['identifier', 'version', 'reg_data0', 'reg_data1', 'mode_sel', 'iomode0', 'regclr', 'pclk', 'nramp', 'iomode1', 'sysrst', 'exttrig', 'nrw', 'sel', 'stopacq', 't_user', 'write_address', 'loadwait', 'pclkwidth', 'numwinds', 'debug_data', 'debug_addr', 'idig_rst', 'wave_fifo_rst', 'clk_sync', 'clk_reset', 'clk_oeb', 'clk_i2c_sel', 'clk1v8_en', 'clk2v5_en', '3v3_i2c_en', '1v2_en', '2v5_en', 'ser_rx_neg_pol', 'ser_rx_crc_en', 'ser_rx_eof_en', 'ser_rx_div', 'ser_tx_neg_pol', 'pedram_addr', 'pedram_data', 'analog_debug_disable', 'auto_numwinds_en', 'timeout15_0', 'timeout31_16', 'eth_addr_sel', 'eth_port_sel', 'tx_mode', 'eth_ar_en', 'eth_dhcp_en', 'eth_dest_addr15_0', 'eth_dest_addr31_16', 'eth_src_addr15_0', 'eth_src_addr31_16', 'eth_dest_port', 'eth_src_port', 'pg_2v5', 'clk_intr_n', 'clk_lol_n', 'fpga_clk_locked', 'asic_clk_locked', 'ser_tx_clk_locked', 'rx_en', 'tx_en', 'idly_cnt_val', 'dhcp_addr15_0', 'ch_en15_0', 'ch_en31_16'] Digital Registers: ['scal0', 'scal1', 'scal2', 'scal3', 'scal4', 'scal5', 'scal6', 'scal7', 'scal8', 'scal9', 'scal10', 'scal11', 'scal12', 'scal13', 'scal14', 'scal15', 'scal16', 'scal17', 'scal18', 'scal19', 'scal20', 'scal21', 'scal22', 'scal23', 'scal24', 'scal25', 'scal26', 'scal27', 'scal28', 'scal29', 'scal30', 'scal31', 'scalmon_left', 'scalmon_right', 'scalhigh', 'idconfig', 'regclr_bk', 'regloadperiod_bk', 'reglatchperiod_bk', 'regwaitread', 'chanmask0', 'chanmask1', 'chanmask2', 'chanmask3', 'streamingpattern0', 'streamingpattern1', 'streamingpattern2', 'streamingpattern3', 'selectchannel', 'wraddrstart', 'wraddrstop', 'wraddrjunk', 'writeaftertrig', 'convertresetwait', 'readoutlookback', 'readoutwindows', 'readoutchannels', 'regclr_chan', 'regloadperiod_chan', 'reglatchperiod_chan', 'regmisc', 'regwaitaddr', 'writedelay', 'regspeed', 'wlcon', 'dig_to_an'] 2024-11-15 15:14:00,608 naludaq.FTDI [DEBUG ]: Sending: B000F3E8 in single mode 2024-11-15 15:14:00,630 naludaq.FTDI [DEBUG ]: Sending: B00430FF in single mode 2024-11-15 15:14:00,651 naludaq.FTDI [DEBUG ]: Sending: B00430FF in single mode 2024-11-15 15:14:00,672 naludaq.FTDI [DEBUG ]: Sending: B0013000 in single mode 2024-11-15 15:14:00,694 naludaq.FTDI [DEBUG ]: Sending: B00430FF in single mode 2024-11-15 15:14:00,715 naludaq.FTDI [DEBUG ]: Sending: B00430FF in single mode 2024-11-15 15:14:00,736 naludaq.FTDI [DEBUG ]: Sending: B0017000 in single mode 2024-11-15 15:14:00,757 naludaq.FTDI [DEBUG ]: Sending: B00430FF in single mode 2024-11-15 15:14:00,778 naludaq.FTDI [DEBUG ]: Sending: B00430FF in single mode 2024-11-15 15:14:00,799 naludaq.FTDI [DEBUG ]: Sending: B001B000 in single mode 2024-11-15 15:14:00,820 naludaq.FTDI [DEBUG ]: Sending: B0042200 in single mode 2024-11-15 15:14:00,842 naludaq.FTDI [DEBUG ]: Sending: B0042200 in single mode 2024-11-15 15:14:00,863 naludaq.FTDI [DEBUG ]: Sending: B001F000 in single mode 2024-11-15 15:14:00,884 naludaq.FTDI [DEBUG ]: Sending: B0042200 in single mode 2024-11-15 15:14:00,905 naludaq.FTDI [DEBUG ]: Sending: B0042200 in single mode 2024-11-15 15:14:00,926 naludaq.FTDI [DEBUG ]: Sending: B0023000 in single mode 2024-11-15 15:14:00,948 naludaq.FTDI [DEBUG ]: Sending: B0042200 in single mode 2024-11-15 15:14:00,969 naludaq.FTDI [DEBUG ]: Sending: B0042200 in single mode 2024-11-15 15:14:00,990 naludaq.FTDI [DEBUG ]: Sending: B0027000 in single mode 2024-11-15 15:14:01,011 naludaq.FTDI [DEBUG ]: Sending: B0042200 in single mode 2024-11-15 15:14:01,032 naludaq.FTDI [DEBUG ]: Sending: B0042200 in single mode 2024-11-15 15:14:01,053 naludaq.FTDI [DEBUG ]: Sending: B002B000 in single mode 2024-11-15 15:14:01,075 naludaq.FTDI [DEBUG ]: Sending: B0044000 in single mode 2024-11-15 15:14:01,096 naludaq.FTDI [DEBUG ]: Sending: B0044000 in single mode 2024-11-15 15:14:01,118 naludaq.FTDI [DEBUG ]: Sending: B002F000 in single mode 2024-11-15 15:14:01,139 naludaq.FTDI [DEBUG ]: Sending: B0044000 in single mode 2024-11-15 15:14:01,160 naludaq.FTDI [DEBUG ]: Sending: B0044000 in single mode 2024-11-15 15:14:01,181 naludaq.FTDI [DEBUG ]: Sending: B0033000 in single mode 2024-11-15 15:14:01,202 naludaq.FTDI [DEBUG ]: Sending: B0044000 in single mode 2024-11-15 15:14:01,223 naludaq.FTDI [DEBUG ]: Sending: B0044000 in single mode 2024-11-15 15:14:01,244 naludaq.FTDI [DEBUG ]: Sending: B0037000 in single mode 2024-11-15 15:14:01,265 naludaq.FTDI [DEBUG ]: Sending: B0044000 in single mode 2024-11-15 15:14:01,286 naludaq.FTDI [DEBUG ]: Sending: B0044000 in single mode 2024-11-15 15:14:01,307 naludaq.FTDI [DEBUG ]: Sending: B003B000 in single mode 2024-11-15 15:14:01,329 naludaq.FTDI [DEBUG ]: Sending: B0044000 in single mode 2024-11-15 15:14:01,350 naludaq.FTDI [DEBUG ]: Sending: B0044000 in single mode 2024-11-15 15:14:01,371 naludaq.FTDI [DEBUG ]: Sending: B003F000 in single mode 2024-11-15 15:14:01,392 naludaq.FTDI [DEBUG ]: Sending: B0044000 in single mode 2024-11-15 15:14:01,413 naludaq.FTDI [DEBUG ]: Sending: B0044000 in single mode 2024-11-15 15:14:01,435 naludaq.FTDI [DEBUG ]: Sending: B0083000 in single mode 2024-11-15 15:14:01,456 naludaq.FTDI [DEBUG ]: Sending: B00C3000 in single mode 2024-11-15 15:14:01,477 naludaq.FTDI [DEBUG ]: Sending: B00C3000 in single mode 2024-11-15 15:14:01,498 naludaq.FTDI [DEBUG ]: Sending: B0087000 in single mode 2024-11-15 15:14:01,519 naludaq.FTDI [DEBUG ]: Sending: B00C3000 in single mode 2024-11-15 15:14:01,540 naludaq.FTDI [DEBUG ]: Sending: B00C3000 in single mode 2024-11-15 15:14:01,561 naludaq.FTDI [DEBUG ]: Sending: B008B000 in single mode 2024-11-15 15:14:01,582 naludaq.FTDI [DEBUG ]: Sending: B00C3000 in single mode 2024-11-15 15:14:01,603 naludaq.FTDI [DEBUG ]: Sending: B00C3000 in single mode 2024-11-15 15:14:01,624 naludaq.FTDI [DEBUG ]: Sending: B008F000 in single mode 2024-11-15 15:14:01,645 naludaq.FTDI [DEBUG ]: Sending: B00C3000 in single mode 2024-11-15 15:14:01,666 naludaq.FTDI [DEBUG ]: Sending: B00C3000 in single mode 2024-11-15 15:14:01,687 naludaq.FTDI [DEBUG ]: Sending: B0093000 in single mode 2024-11-15 15:14:01,708 naludaq.FTDI [DEBUG ]: Sending: B00C3000 in single mode 2024-11-15 15:14:01,729 naludaq.FTDI [DEBUG ]: Sending: B00C3000 in single mode 2024-11-15 15:14:01,750 naludaq.FTDI [DEBUG ]: Sending: B0097000 in single mode 2024-11-15 15:14:01,772 naludaq.FTDI [DEBUG ]: Sending: B00C3000 in single mode 2024-11-15 15:14:01,793 naludaq.FTDI [DEBUG ]: Sending: B00C3000 in single mode 2024-11-15 15:14:01,814 naludaq.FTDI [DEBUG ]: Sending: B009B000 in single mode 2024-11-15 15:14:01,835 naludaq.FTDI [DEBUG ]: Sending: B00C2200 in single mode 2024-11-15 15:14:01,856 naludaq.FTDI [DEBUG ]: Sending: B00C2200 in single mode 2024-11-15 15:14:01,877 naludaq.FTDI [DEBUG ]: Sending: B009F000 in single mode 2024-11-15 15:14:01,898 naludaq.FTDI [DEBUG ]: Sending: B00C2200 in single mode 2024-11-15 15:14:01,919 naludaq.FTDI [DEBUG ]: Sending: B00C2200 in single mode 2024-11-15 15:14:01,941 naludaq.FTDI [DEBUG ]: Sending: B00A3000 in single mode 2024-11-15 15:14:01,962 naludaq.FTDI [DEBUG ]: Sending: B00C2200 in single mode 2024-11-15 15:14:01,983 naludaq.FTDI [DEBUG ]: Sending: B00C2200 in single mode 2024-11-15 15:14:02,005 naludaq.FTDI [DEBUG ]: Sending: B00A7000 in single mode 2024-11-15 15:14:02,026 naludaq.FTDI [DEBUG ]: Sending: B00C2200 in single mode 2024-11-15 15:14:02,047 naludaq.FTDI [DEBUG ]: Sending: B00C2200 in single mode 2024-11-15 15:14:02,069 naludaq.FTDI [DEBUG ]: Sending: B00AB000 in single mode 2024-11-15 15:14:02,090 naludaq.FTDI [DEBUG ]: Sending: B00C4000 in single mode 2024-11-15 15:14:02,111 naludaq.FTDI [DEBUG ]: Sending: B00C4000 in single mode 2024-11-15 15:14:02,132 naludaq.FTDI [DEBUG ]: Sending: B00AF000 in single mode 2024-11-15 15:14:02,154 naludaq.FTDI [DEBUG ]: Sending: B00C4000 in single mode 2024-11-15 15:14:02,175 naludaq.FTDI [DEBUG ]: Sending: B00C4000 in single mode 2024-11-15 15:14:02,196 naludaq.FTDI [DEBUG ]: Sending: B00B3000 in single mode 2024-11-15 15:14:02,218 naludaq.FTDI [DEBUG ]: Sending: B00C4000 in single mode 2024-11-15 15:14:02,239 naludaq.FTDI [DEBUG ]: Sending: B00C4000 in single mode 2024-11-15 15:14:02,260 naludaq.FTDI [DEBUG ]: Sending: B00B7000 in single mode 2024-11-15 15:14:02,281 naludaq.FTDI [DEBUG ]: Sending: B00C4000 in single mode 2024-11-15 15:14:02,302 naludaq.FTDI [DEBUG ]: Sending: B00C4000 in single mode 2024-11-15 15:14:02,324 naludaq.FTDI [DEBUG ]: Sending: B00BB000 in single mode 2024-11-15 15:14:02,345 naludaq.FTDI [DEBUG ]: Sending: B00C4000 in single mode 2024-11-15 15:14:02,366 naludaq.FTDI [DEBUG ]: Sending: B00C4000 in single mode 2024-11-15 15:14:02,387 naludaq.FTDI [DEBUG ]: Sending: B00BF000 in single mode 2024-11-15 15:14:02,408 naludaq.FTDI [DEBUG ]: Sending: B00C4000 in single mode 2024-11-15 15:14:02,429 naludaq.FTDI [DEBUG ]: Sending: B00C4000 in single mode 2024-11-15 15:14:02,450 naludaq.readout_controller_default [DEBUG ]: Set readwindow to: w2, l2, t:16 2024-11-15 15:14:02,450 naludaq.FTDI [DEBUG ]: Sending: B01C6002 in single mode 2024-11-15 15:14:02,471 naludaq.FTDI [DEBUG ]: Sending: B01C5002 in single mode 2024-11-15 15:14:02,491 naludaq.FTDI [DEBUG ]: Sending: B01C3010 in single mode 2024-11-15 15:14:02,512 naludaq.board_controller_default [DEBUG ]: READOUT command: Bc300000 2024-11-15 15:14:02,512 naludaq.FTDI [DEBUG ]: Sending: Bc300000 in single mode 2024-11-15 15:14:04,535 naludaq.FTDI [DEBUG ]: Sending: B0B00000 in single mode 2024-11-15 15:14:04,556 naludaq.FTDI [DEBUG ]: Sending: AF042001 in single mode 2024-11-15 15:14:04,577 naludaq.FTDI [DEBUG ]: Sending: AF040001 in single mode 2024-11-15 15:14:04,598 naludaq.FTDI [DEBUG ]: Sending: AF160400 in single mode 2024-11-15 15:14:04,619 naludaq.FTDI [DEBUG ]: Sending: AF160000 in single mode 2024-11-15 15:14:04,641 naludaq.FTDI [DEBUG ]: Sending: AF160200 in single mode 2024-11-15 15:14:04,661 naludaq.FTDI [DEBUG ]: Sending: AF160000 in single mode 2024-11-15 15:14:04,684 naludaq.board [DEBUG ]: Exiting board context (\"with\" block); closing connection... Bytes in buffer: 0 But I end up readout 0 bytes. The line _bc.start_readout(trig='imm', lb='forced', readoutEn=True, singleEv=True) _bc.start_readout( trig = 'imm' , lb = 'forced' , readoutEn = True , singleEv = True ) is supposed to force a trigger, but it doesn't seem to be working(?). I think sending some message to nalu would be useful.",
    "textLength": 5189
  },
  {
    "kind": "work-log",
    "title": "18_08_2024 - 24_08_2024.html",
    "fileName": "18_08_2024 - 24_08_2024.html",
    "url": "resources/work_logs/18_08_2024 - 24_08_2024.html",
    "createdDate": "2024-08-18",
    "text": "18/08/2024 - 24/08/2024 18/08/2024 - 24/08/2024 19/08/2024 16:03 The entry here: 13/08/2024 23:29 Tried making a new midas install on the SSD and linking it to dependencies already on the HDD. The idea was to somehow remove any knowledge of the HDD from midas. It didn't seem to work, supporting the theory that the bottlneck lies in mlogger instead. 5kHz with waveform size 4800 5kHz with waveform size 7200: The conclusion is will still max at around 240 MB/s was actually using an installation of midas on the HDD, so I'm retrying with an installation of midas on the SSD. 19/08/2024 17:24 After ensuring it now uses a midas version on the SSD, I find the same results. 19/08/2024 18:16 After playing with the Data Simulator, it appears midas has some problems when the bank size gets too large: INT read_periodic_event(char *pevent, INT off) { short *pdata; // Change the data type to short // Init bank structure bk_init32(pevent); // Create a bank named \"CR00\" and specify the data type as TID_SHORT bk_create(pevent, \"CR00\", TID_SHORT, (void **)&pdata); // Repeat the loop to scale the data for (int repeat = 0; repeat < 400; repeat++) { for (int i = 0; i < data.size(); i++) { *pdata++ = data[i]; } } // Close the bank bk_close(pevent, pdata); return bk_size(pevent); } INT read_periodic_event( char *pevent, INT off) { short *pdata; // Change the data type to short // Init bank structure bk_init32(pevent); // Create a bank named \"CR00\" and specify the data type as TID_SHORT bk_create(pevent, \"CR00\" , TID_SHORT, (void **)&pdata); // Repeat the loop to scale the data for ( int repeat = 0 ; repeat < 400 ; repeat ++) { for ( int i = 0 ; i < data . size (); i++) { *pdata++ = data [i]; } } // Close the bank bk_close(pevent, pdata); return bk_size(pevent); } Each data vector here is about 1kB. Midas complains about null pointers when I try scaling by 1000 for each event (so ~1MB/event) at 100Hz. When I try scaling by 500 for each event at 100Hz I get the following error messages: 18:11:17.086 2024/08/19 [Logger,ERROR] [odb.cxx:5497:db_get_data_locked,ERROR] odb entry \"/Equipment/Data Simulator/Variables/CR00\" data truncated, size is 113600 (56800*2), buffer size is only 0 18:11:16.987 2024/08/19 [DataSimulator,ERROR] [midas.cxx:17635:cm_write_event_to_odb,ERROR] cannot write bank \"CR00\" to ODB, db_set_data1() status 310 18:11:16.986 2024/08/19 [DataSimulator,ERROR] [odb.cxx:6999:db_set_data1,ERROR] Cannot reallocate \"/Equipment/Data Simulator/Variables/CR00\" with new size 568000 bytes, online database full 18:11:16.986 2024/08/19 [DataSimulator,ERROR] [odb.cxx:559:realloc_data,ERROR] cannot malloc_data(568000), called from db_set_data1 18:11:17.086 2024/08/19 [Logger, ERROR ] [odb.cxx:5497:db_get_data_locked, ERROR ] odb entry \"/Equipment/Data Simulator/Variables/CR00\" data truncated, size is 113600 (56800 *2 ), buffer size is only 0 18:11:16.987 2024/08/19 [DataSimulator, ERROR ] [midas.cxx:17635:cm_write_event_to_odb, ERROR ] cannot write bank \"CR00\" to ODB, db_set_data1() status 310 18:11:16.986 2024/08/19 [DataSimulator, ERROR ] [odb.cxx:6999:db_set_data1, ERROR ] Cannot reallocate \"/Equipment/Data Simulator/Variables/CR00\" with new size 568000 bytes, online database full 18:11:16.986 2024/08/19 [DataSimulator, ERROR ] [odb.cxx:559:realloc_data, ERROR ] cannot malloc_data(568000), called from db_set_data1 19/08/2024 18:59 I made some adjustments and was able to write at 1GB/s on the SSD. In particular I added the features: Use a polling system to trigger events at a given rate Each event is a scalable vector of zeros Events are memcpy ed into the data bank This indicates mlogger (or otherwise midas) is NOT the bottleneck. Interestingly enough, this also is faster than the tested write speed for the drive using: /********************************************************************\\ Name: wdfe.cxx Created by: Stefan Ritt Contents: Example front-end for standalone WaveDREAM board \\********************************************************************/ #include <stdio.h> #include <stdlib.h> #include <math.h> #include <string.h> #include <iostream> #include <fstream> #include <sstream> #include <vector> #include \"midas.h\" #include \"mfe.h\" #include <stdlib.h> // Include the header for rand() #include <random> // Include for random number generation void trigger_update(INT, INT, void*); /*-- Globals -------------------------------------------------------*/ /* The frontend name (client name) as seen by other MIDAS clients */ const char *frontend_name = \"DataSimulator\"; /* The frontend file name, don't change it */ const char *frontend_file_name = __FILE__; /* frontend_loop is called periodically if this variable is TRUE */ BOOL frontend_call_loop = FALSE; /* a frontend status page is displayed with this frequency in ms */ INT display_period = 1000; /* maximum event size produced by this frontend */ INT max_event_size = 1024 * 1014; /* maximum event size for fragmented events (EQ_FRAGMENTED) */ INT max_event_size_frag = 5 * max_event_size; /* buffer size to hold events */ INT event_buffer_size = 5 * max_event_size; // Define a vector to store 16-bit words std::vector<int16_t> data; // Define a global vector to store 16-bit signed integers // Global variable to keep track of the last poll time std::chrono::steady_clock::time_point last_poll_time; const std::chrono::microseconds polling_interval(100); // Poll every 100 microsecond // Random number generator for generating data std::mt19937 generator; std::uniform_int_distribution<short> distribution(-32768, 32767); // Define the range of random values (short range) // Global variable to hold the zero buffer std::vector<short> zero_buffer; /*-- Function declarations -----------------------------------------*/ INT frontend_init(void); INT frontend_exit(void); INT begin_of_run(INT run_number, char *error); INT end_of_run(INT run_number, char *error); INT pause_run(INT run_number, char *error); INT resume_run(INT run_number, char *error); INT frontend_loop(void); INT read_trigger_event(char *pevent, INT off); INT read_periodic_event(char *pevent, INT off); INT poll_event(INT source, INT count, BOOL test); INT interrupt_configure(INT cmd, INT source, POINTER_T adr); /*-- Equipment list ------------------------------------------------*/ BOOL equipment_common_overwrite = TRUE; EQUIPMENT equipment[] = { {\"Data Simulator\", /* equipment name */ {2, 0, /* event ID, trigger mask */ \"SYSTEM\", /* event buffer */ EQ_POLLED, /* equipment type */ 0, /* event source */ \"MIDAS\", /* format */ TRUE, /* enabled */ RO_RUNNING | RO_TRANSITIONS | /* read when running and on transitions */ RO_ODB, /* and update ODB */ 10, /* read every sec */ 0, /* stop run after this event limit */ 0, /* number of sub events */ TRUE, /* log history */ \"\", \"\", \"\",}, read_trigger_event /* readout routine */ }, {\"\"} }; /*-- Trigger Update ------------------------------------------------*/ void trigger_update(INT hDB, INT hkey,void*) { } /*-- Frontend Init -------------------------------------------------*/ int frontend_init() { // Open the file for reading std::ifstream inputFile(\"fake_data.txt\"); if (!inputFile) { std::cerr << \"Error opening the file.\" << std::endl; return 1; } std::cout << \"Reading and converting data:\" << std::endl; std::string line; while (std::getline(inputFile, line)) { std::istringstream iss(line); std::string token; while (std::getline(iss, token, ',')) { int16_t value; std::istringstream(token) >> value; data.push_back(value); } } // Print the converted data for (int i = 0; i < data.size(); i++) { std::cout << \" \" << data[i]; } // Close the file inputFile.close(); if (data.empty()) { std::cerr << \"No data was converted.\" << std::endl; } else { std::cout << std::endl << \"Conversion completed.\" << std::endl; } // Initialize random number generator std::random_device rd; // Obtain a random number from hardware generator = std::mt19937(rd()); // Seed the generator // Define the total number of zero data points const int total_data_size = 50000; // Adjust size as needed // Create and initialize the buffer of zeros zero_buffer.resize(total_data_size, 0); return SUCCESS; } /*-- Frontend Exit -------------------------------------------------*/ INT frontend_exit() { return SUCCESS; } /*-- Begin of Run --------------------------------------------------*/ INT begin_of_run(INT run_number, char *error) { return SUCCESS; } /*-- End of Run ----------------------------------------------------*/ INT end_of_run(INT run_number, char *error) { return SUCCESS; } /*-- Pause Run -----------------------------------------------------*/ INT pause_run(INT run_number, char *error) { return SUCCESS; } /*-- Resume Run ----------------------------------------------------*/ INT resume_run(INT run_number, char *error) { return SUCCESS; } /*-- Frontend Loop -------------------------------------------------*/ INT frontend_loop() { /* if frontend_call_loop is true, this routine gets called when the frontend is idle or once between every event */ return SUCCESS; } /*------------------------------------------------------------------*/ /********************************************************************\\ Readout routines for different events \\********************************************************************/ /*-- Trigger event routines ----------------------------------------*/ INT poll_event(INT source, INT count, BOOL test) { // Get the current time auto now = std::chrono::steady_clock::now(); // Check if enough time has passed since the last poll if (now - last_poll_time >= polling_interval) { // Update the last poll time last_poll_time = now; // Return TRUE to indicate that an event is available return TRUE; } // If test is TRUE, don't return anything if (test) { return FALSE; } // Otherwise, return FALSE to indicate no event available return FALSE; } /*-- Interrupt configuration ---------------------------------------*/ INT interrupt_configure(INT cmd, INT source, POINTER_T adr) { switch (cmd) { case CMD_INTERRUPT_ENABLE: break; case CMD_INTERRUPT_DISABLE: break; case CMD_INTERRUPT_ATTACH: break; case CMD_INTERRUPT_DETACH: break; } return SUCCESS; } /*-- Event readout -------------------------------------------------*/ INT read_trigger_event(char *pevent, INT off) { short *pdata; // Init bank structure bk_init32(pevent); // Create a bank named \"CR00\" and specify the data type as TID_SHORT bk_create(pevent, \"CR00\", TID_SHORT, (void **)&pdata); // Use memcpy to copy the buffer of zeros into the MIDAS bank memcpy(pdata, zero_buffer.data(), zero_buffer.size() * sizeof(short)); // Adjust pdata pointer pdata += zero_buffer.size(); // Move the pointer past the copied data // Close the bank bk_close(pevent, pdata); return bk_size(pevent); } /*-- Periodic event ------------------------------------------------*/ INT read_periodic_event(char *pevent, INT off) { short *pdata; // Change the data type to short // Init bank structure bk_init32(pevent); // Create a bank named \"CR00\" and specify the data type as TID_SHORT bk_create(pevent, \"CR00\", TID_SHORT, (void **)&pdata); // Repeat the loop 5000 times for (int repeat = 0; repeat < 400; repeat++) { for (int i = 0; i < data.size(); i++) { *pdata++ = data[i]; } } // Close the bank bk_close(pevent, pdata); return bk_size(pevent); } /********************************************************************\\ Name: wdfe.cxx Created by: Stefan Ritt Contents: Example front-end for standalone WaveDREAM board \\********************************************************************/ #include <stdio.h> #include <stdlib.h> #include <math.h> #include <string.h> #include <iostream> #include <fstream> #include <sstream> #include <vector> #include \"midas.h\" #include \"mfe.h\" #include <stdlib.h> // Include the header for rand() #include <random> // Include for random number generation void trigger_update(INT, INT, void*); /*-- Globals -------------------------------------------------------*/ /* The frontend name (client name) as seen by other MIDAS clients */ const char *frontend_name = \"DataSimulator\"; /* The frontend file name, don't change it */ const char *frontend_file_name = __FILE__; /* frontend_loop is called periodically if this variable is TRUE */ BOOL frontend_call_loop = FALSE; /* a frontend status page is displayed with this frequency in ms */ INT display_period = 1000; /* maximum event size produced by this frontend */ INT max_event_size = 1024 * 1014; /* maximum event size for fragmented events (EQ_FRAGMENTED) */ INT max_event_size_frag = 5 * max_event_size; /* buffer size to hold events */ INT event_buffer_size = 5 * max_event_size; // Define a vector to store 16-bit words std::vector<int16_t> data; // Define a global vector to store 16-bit signed integers // Global variable to keep track of the last poll time std::chrono::steady_clock::time_point last_poll_time; const std::chrono::microseconds polling_interval(100); // Poll every 100 microsecond // Random number generator for generating data std::mt19937 generator; std::uniform_int_distribution<short> distribution(-32768, 32767); // Define the range of random values (short range) // Global variable to hold the zero buffer std::vector<short> zero_buffer; /*-- Function declarations -----------------------------------------*/ INT frontend_init(void); INT frontend_exit(void); INT begin_of_run(INT run_number, char *error); INT end_of_run(INT run_number, char *error); INT pause_run(INT run_number, char *error); INT resume_run(INT run_number, char *error); INT frontend_loop(void); INT read_trigger_event(char *pevent, INT off); INT read_periodic_event(char *pevent, INT off); INT poll_event(INT source, INT count, BOOL test); INT interrupt_configure(INT cmd, INT source, POINTER_T adr); /*-- Equipment list ------------------------------------------------*/ BOOL equipment_common_overwrite = TRUE; EQUIPMENT equipment[] = { {\"Data Simulator\", /* equipment name */ {2, 0, /* event ID, trigger mask */ \"SYSTEM\", /* event buffer */ EQ_POLLED, /* equipment type */ 0, /* event source */ \"MIDAS\", /* format */ TRUE, /* enabled */ RO_RUNNING | RO_TRANSITIONS | /* read when running and on transitions */ RO_ODB, /* and update ODB */ 10, /* read every sec */ 0, /* stop run after this event limit */ 0, /* number of sub events */ TRUE, /* log history */ \"\", \"\", \"\",}, read_trigger_event /* readout routine */ }, {\"\"} }; /*-- Trigger Update ------------------------------------------------*/ void trigger_update(INT hDB, INT hkey,void*) { } /*-- Frontend Init -------------------------------------------------*/ int frontend_init() { // Open the file for reading std::ifstream inputFile(\"fake_data.txt\"); if (!inputFile) { std::cerr << \"Error opening the file.\" << std::endl; return 1; } std::cout << \"Reading and converting data:\" << std::endl; std::string line; while (std::getline(inputFile, line)) { std::istringstream iss(line); std::string token; while (std::getline(iss, token, ',')) { int16_t value; std::istringstream(token) >> value; data.push_back(value); } } // Print the converted data for (int i = 0; i < data.size(); i++) { std::cout << \" \" << data[i]; } // Close the file inputFile.close(); if (data.empty()) { std::cerr << \"No data was converted.\" << std::endl; } else { std::cout << std::endl << \"Conversion completed.\" << std::endl; } // Initialize random number generator std::random_device rd; // Obtain a random number from hardware generator = std::mt19937(rd()); // Seed the generator // Define the total number of zero data points const int total_data_size = 50000; // Adjust size as needed // Create and initialize the buffer of zeros zero_buffer.resize(total_data_size, 0); return SUCCESS; } /*-- Frontend Exit -------------------------------------------------*/ INT frontend_exit() { return SUCCESS; } /*-- Begin of Run --------------------------------------------------*/ INT begin_of_run(INT run_number, char *error) { return SUCCESS; } /*-- End of Run ----------------------------------------------------*/ INT end_of_run(INT run_number, char *error) { return SUCCESS; } /*-- Pause Run -----------------------------------------------------*/ INT pause_run(INT run_number, char *error) { return SUCCESS; } /*-- Resume Run ----------------------------------------------------*/ INT resume_run(INT run_number, char *error) { return SUCCESS; } /*-- Frontend Loop -------------------------------------------------*/ INT frontend_loop() { /* if frontend_call_loop is true, this routine gets called when the frontend is idle or once between every event */ return SUCCESS; } /*------------------------------------------------------------------*/ /********************************************************************\\ Readout routines for different events \\********************************************************************/ /*-- Trigger event routines ----------------------------------------*/ INT poll_event(INT source, INT count, BOOL test) { // Get the current time auto now = std::chrono::steady_clock::now(); // Check if enough time has passed since the last poll if (now - last_poll_time >= polling_interval) { // Update the last poll time last_poll_time = now; // Return TRUE to indicate that an event is available return TRUE; } // If test is TRUE, don't return anything if (test) { return FALSE; } // Otherwise, return FALSE to indicate no event available return FALSE; } /*-- Interrupt configuration ---------------------------------------*/ INT interrupt_configure(INT cmd, INT source, POINTER_T adr) { switch (cmd) { case CMD_INTERRUPT_ENABLE: break; case CMD_INTERRUPT_DISABLE: break; case CMD_INTERRUPT_ATTACH: break; case CMD_INTERRUPT_DETACH: break; } return SUCCESS; } /*-- Event readout -------------------------------------------------*/ INT read_trigger_event(char *pevent, INT off) { short *pdata; // Init bank structure bk_init32(pevent); // Create a bank named \"CR00\" and specify the data type as TID_SHORT bk_create(pevent, \"CR00\", TID_SHORT, (void **)&pdata); // Use memcpy to copy the buffer of zeros into the MIDAS bank memcpy(pdata, zero_buffer.data(), zero_buffer.size() * sizeof(short)); // Adjust pdata pointer pdata += zero_buffer.size(); // Move the pointer past the copied data // Close the bank bk_close(pevent, pdata); return bk_size(pevent); } /*-- Periodic event ------------------------------------------------*/ INT read_periodic_event(char *pevent, INT off) { short *pdata; // Change the data type to short // Init bank structure bk_init32(pevent); // Create a bank named \"CR00\" and specify the data type as TID_SHORT bk_create(pevent, \"CR00\", TID_SHORT, (void **)&pdata); // Repeat the loop 5000 times for (int repeat = 0; repeat < 400; repeat++) { for (int i = 0; i < data.size(); i++) { *pdata++ = data[i]; } } // Close the bank bk_close(pevent, pdata); return bk_size(pevent); } Interestingly, this is faster than what dd reports for the write speed of the drive [root@dhcp-10-163-105-238 ~]# dd if=/dev/zero of=/data/ssd/testfile bs=1G count=1 oflag=dsync HDD dd if=/dev/zero of=/home/testfile bs=1G count=1 oflag=dsync 1+0 records in 1+0 records out 1073741824 bytes (1.1 GB) copied, 1.45859 s, 736 MB/s [root@dhcp-10-163-105-238 ~]# dd if =/dev/zero of =/data/ssd/testfile bs =1G count =1 oflag =dsync HDD dd if =/dev/zero of =/home/testfile bs =1G count =1 oflag =dsync 1+0 records in 1+0 records out 1073741824 bytes (1.1 GB) copied, 1.45859 s, 736 MB/s In both cases, we are just writing zeros to the drive. I don't know why this is (and don't care to investigate). 19/08/2024 19:09 By changing the logging directory from /data/ssd/simdaq_data (SSD) to /home/installation_testing/online/ (HDD) I saw the data rate go down to ~110 MB/s from ~1GB/s (did not test past 1GB/s). This is evidence that yes, the drive does matter. We were able to achieve 240MB/s (with 50% compression rate so 120MB/s) a with the HDD with the gm2daq which seems consistent with the 110MB/s I'm seeing here. I tested lower event rates (~3kHz) and saw the same results. Anyways, the overall conclusion is the bottleneck in the gm2daq is not the logger as it can handle 1GB/s. I'm still skeptical that somehow the HDD is causing a bottleneck in the gm2daq, even when we write to SSD.",
    "textLength": 2593
  },
  {
    "kind": "work-log",
    "title": "28_01_2024-03_02_2024.html",
    "fileName": "28_01_2024-03_02_2024.html",
    "url": "resources/work_logs/28_01_2024-03_02_2024.html",
    "createdDate": "2024-01-28",
    "text": "28/01/2024-03/02/2024 28/01/2024-03/02/2024 29/01/2024 23:35 Was able to install the meinberg card following the readme, which boils down to: git clone https://git.meinbergglobal.com/drivers/mbgtools-lx.git cd mbgtools-lx git pull sudo yum install kernel-devel-$(uname -r) gcc make make clean make make install sudo /sbin/modprobe mbgclock make install_svc git clone https://git.meinbergglobal. com /drivers/mbgtools-lx.git cd mbgtools-lx git pull sudo yum install kernel-devel-$(uname -r) gcc make make clean make make install sudo /sbin/modprobe mbgclock make install_svc And I was able to get some example output: [root@dhcp-10-163-105-238 mbgtools-lx-4.2.24]# mbgstatus mbgstatus v4.2.24 copyright Meinberg 2001-2023 TCR180PEX 039212025430 (FW 1.21, ASIC 9.00) at port 0xE000, irq 47 Date/time: Tu, 2024-01-30 04:36:10.33 UTC Signal: 0% (IRIG B122/B123, ** UTC offs not configured **) Status info: *** NO INPUT SIGNAL Status info: *** Ref. Time is Invalid Last sync: We, 2023-10-04 11:36:55.00 UTC ** Warning: The IRIG receiver has not yet been configured! Please make sure the correct IRIG Code Format has been selected, and enter the correct IRIG Time Offset from UTC according to the settings of the IRIG generator. The command \"mbgirigcfg\" can be used to change the settings. [root@dhcp-10-163-105-238 mbgtools-lx-4.2.24]# [root@dhcp -10 -163 -105 -238 mbgtools-lx -4 .2.24]# mbgstatus mbgstatus v4.2.24 copyright Meinberg 2001 -2023 TCR180PEX 039212025430 (FW 1.21, ASIC 9.00) at port 0xE000, irq 47 Date/time: Tu, 2024 -01 -30 04:36:10.33 UTC Signal: 0% (IRIG B122/B123, ** UTC offs not configured **) Status info: *** NO INPUT SIGNAL Status info: *** Ref. Time is Invalid Last sync: We, 2023 -10 -04 11:36:55.00 UTC ** Warning: The IRIG receiver has not yet been configured! Please make sure the correct IRIG Code Format has been selected, and enter the correct IRIG Time Offset from UTC according to the settings of the IRIG generator. The command \"mbgirigcfg\" can be used to change the settings. [root@dhcp -10 -163 -105 -238 mbgtools-lx -4 .2.24]# 02/02/2024 19:21 I've been mixing and matching this guide: https://numato.com/kb/vivado-design-suite-create-microblaze-based-design-using-ip-integrator-with-nereid-kintex-7-pci-express-development-board/ and this video: https://www.youtube.com/watch?v=C-RtLnagFuQ To try to program the board with vitis. Once I get to the vitis part of the numato guide linked above, I'm able to program the board in Vitis with the following steps: In Vivado In the tools dropdown in the top left, Select Launch Vitis IDE Choose any folder for a workspace, click Launch Click 'Create Application Project' Hit Next In the top bar, click Create a new platform from hardware (XSA), click browse and select the .xsa file we made earlier (mine is in C:\\Users\\custo\\nereid_microblazer\\nereid_design_wrapper.xsa). click 'Next'. For application Project name, type \"hello_world\", click 'Next' twice. Select \"Hello World\" from the emebdded software developtment templates. Click 'Finish' Power on the board with 12V power supply. Have only the 12pin JTAG connected otherwise (not the microUSB). From the XIlinx dropdown in the top left sleect program device. Select the bitstream generated earlier. Mine is at C:\\Users\\custo\\nereid_microblazer\\nereid_microblazer.runs\\impl_1\\nereid_design_wrapper.bit. Leave everything else default. Click 'Program' (note: I had to autoconnect in the hardware manager in Vivado beforehand or else it complains it can't find the board) This is as far as I got. I have two issues. One, I don't know how to connect to the serial COM port with PuTTY, I get this error when trying: I also think somehow the microblazer is not getting recongized, because when I try to launch hardware by right clicking \"hello_world\" and 'Debug as->Launch Hardware (Single Application Debug)' I get the following warning: Launching anyway gives me some weird output (what looks like a bunch of register values?) but I have no idea what's happening or if it's even working.",
    "textLength": 706
  },
  {
    "kind": "work-log",
    "title": "14_12_2025 - 19_12_2025.html",
    "fileName": "14_12_2025 - 19_12_2025.html",
    "url": "resources/work_logs/14_12_2025 - 19_12_2025.html",
    "createdDate": "2025-12-14",
    "text": "14/12/2025 - 19/12/2025 14/12/2025 - 19/12/2025 15/12/2025 13:19 RP Pico W State Machine Here is a link to some micropython documentation https://docs.micropython.org/en/latest/library/rp2.StateMachine.html Here's an AI generated explanation: Each PIO state machine is a small deterministic processor with four core registers and a fixed execution model optimized for cycle-accurate I/O. Registers OSR \u2014 Output Shift Register 32-bit register. Source for OUT instructions. Shifts left or right (configurable). Loaded via PULL from TX FIFO or MOV . Bits are consumed as they shift out; shifted bits are lost. ISR \u2014 Input Shift Register 32-bit register. Destination for IN instructions. Shifts left or right (configurable). Can be transferred to RX FIFO via PUSH . Bits accumulate via shifting until pushed or overwritten. X Register 32-bit general-purpose register. Used for counters and state. Supports decrement and conditional jumps ( JMP X-- , comparisons). No shifting; contents persist until overwritten. Y Register Same behavior as X. Independent storage for counters or state. Register Transfers MOV copies data between OSR, ISR, X, and Y. Only OSR and ISR can shift. X and Y cannot shift and do not interact with FIFOs directly. FIFO Interface TX FIFO feeds OSR via PULL . RX FIFO receives ISR via PUSH . FIFO depth is 4 words (shared or per-state-machine configurable). FIFO operations can block or be non-blocking. Execution Model One instruction per cycle (unless delayed). Deterministic timing. No stack, no RAM access. Control flow via JMP , WAIT , and IRQ . Constraints Shifting OSR/ISR is destructive. No random access or bit slicing of registers. X and Y are the only stable scratch registers. Complex logic requires host interaction or careful register reuse. Instruction Memory Limit Each PIO block has a fixed instruction memory of 32 instructions total. This memory is shared by all 4 state machines in that PIO block. A single PIO program can be at most 32 instructions , and often less if multiple programs are loaded simultaneously. In short, if you want to write a \"general\" program operating on the scale of the pico's 125MHz clock, you have to use the state machine. This is a great feature, with glaring limitations though. The 4 registers means at best* you can have 3 parameters. In our cases for our multi pulse tests, I chose these 3 parameters to be pulse width pulse seperation frequency *There's fancy things you can do to get around this in special cases. Here's an example of how this works with a double pulse (it works a lot like assembly): @asm_pio(set_init=PIO.OUT_LOW) def double_pulse_program(): \"\"\" PIO program that emits a repeating pair of pulses with configurable delays. Three values must be queued before the state machine starts: pulse width cycles, low cycles between the pulses, and idle cycles between pairs. \"\"\" pull(block) # pull in queued data into OSR register (placed in FIFO by main micropython program) mov(y, osr) # move pulled data from OSR to y, this stores our pulse width variable in clock ticks pull(block) # pull next queued data into OSR register mov(isr, osr) # move pulled data from OSR to y, this stores the gap between pulses in clock ticks pull(block) # pull next queued data into OSR register # we leave this data in OSR, it represents the wait time between pulse bursts in clock ticks (i.e our period) wrap_target() #define top of indefinite loop # Below we use X as our scratch register, we \"copy\" data into it # and decriment it as our counter each time we need to loop #Create pulse 1: mov(x, y) # Copy pulse width into x (operation takes 1 clock tick) set(pins, 1) # Set output pin to high (operation takes 1 clock tick) label(\"pulse_one\") # Set \"GOTO\" point for jump statement below (op takes 0 clock ticks) jmp(x_dec, \"pulse_one\") # Decriment x by 1, if x > 0 jump to label \"pulse_one\", otherwise continue (op takes 1 clock tock) set(pins, 0) # Set output pin to low (op takes 0 clock ticks) # Create gap between pulse 1 and 2: mov(x, isr) # Copy gap width into x (op takes 1 clock tick) label(\"gap_wait\") # Set \"GOTO\" point for jump statement below (op takes 0 clock ticks) jmp(x_dec, \"gap_wait\") # Decriment x by 1, if x > 0 jump to label \"gap_wait\", otherwise continue (op takes 1 clock tock) # Create pulse 2: # Repeat everything we did for pulse 1 for our second pulse mov(x, y) set(pins, 1) label(\"pulse_two\") jmp(x_dec, \"pulse_two\") set(pins, 0) # Create wait time before next burst (period)\"\" mov(x, osr) # Copy wait time into x (op takes 1 clock tick) label(\"idle_wait\") # Set \"GOTO\" point for jump statement below (op takes 0 clock ticks) jmp(x_dec, \"idle_wait\") # Decriment x by 1, if x > 0 jump to label \"idle_wait\", otherwise continue (op takes 1 clock tock) wrap() #define bottom of indefinite loop @asm_pio( set_init=PIO.OUT_LOW ) def double_pulse_program (): \"\"\" PIO program that emits a repeating pair of pulses with configurable delays. Three values must be queued before the state machine starts: pulse width cycles, low cycles between the pulses, and idle cycles between pairs. \"\"\" pull(block) # pull in queued data into OSR register (placed in FIFO by main micropython program) mov(y, osr) # move pulled data from OSR to y, this stores our pulse width variable in clock ticks pull(block) # pull next queued data into OSR register mov(isr, osr) # move pulled data from OSR to y, this stores the gap between pulses in clock ticks pull(block) # pull next queued data into OSR register # we leave this data in OSR, it represents the wait time between pulse bursts in clock ticks (i.e our period) wrap_target() #define top of indefinite loop # Below we use X as our scratch register, we \"copy\" data into it # and decriment it as our counter each time we need to loop #Create pulse 1: mov(x, y) # Copy pulse width into x (operation takes 1 clock tick) set (pins, 1 ) # Set output pin to high (operation takes 1 clock tick) label( \"pulse_one\" ) # Set \"GOTO\" point for jump statement below (op takes 0 clock ticks) jmp(x_dec, \"pulse_one\" ) # Decriment x by 1, if x > 0 jump to label \"pulse_one\", otherwise continue (op takes 1 clock tock) set (pins, 0 ) # Set output pin to low (op takes 0 clock ticks) # Create gap between pulse 1 and 2: mov(x, isr) # Copy gap width into x (op takes 1 clock tick) label( \"gap_wait\" ) # Set \"GOTO\" point for jump statement below (op takes 0 clock ticks) jmp(x_dec, \"gap_wait\" ) # Decriment x by 1, if x > 0 jump to label \"gap_wait\", otherwise continue (op takes 1 clock tock) # Create pulse 2: # Repeat everything we did for pulse 1 for our second pulse mov(x, y) set (pins, 1 ) label( \"pulse_two\" ) jmp(x_dec, \"pulse_two\" ) set (pins, 0 ) # Create wait time before next burst (period)\"\" mov(x, osr) # Copy wait time into x (op takes 1 clock tick) label( \"idle_wait\" ) # Set \"GOTO\" point for jump statement below (op takes 0 clock ticks) jmp(x_dec, \"idle_wait\" ) # Decriment x by 1, if x > 0 jump to label \"idle_wait\", otherwise continue (op takes 1 clock tock) wrap() #define bottom of indefinite loop This gives you a double pulse. You can create triple and quadrouple pulse by just adding more blocks to create pulses and gap waits. I accomplish this by generating instructions in python like so: def _build_uniform_pulse_program(pulse_count): \"\"\"Return a PIO program that emits `pulse_count` identical pulses per period.\"\"\" if asm_pio is None: return None @asm_pio(set_init=PIO.OUT_LOW) def program(): pull(block) mov(y, osr) # Pulse width cycles pull(block) mov(isr, osr) # Gap cycles pull(block) # Tail/idle cycles wrap_target() for idx in range(pulse_count): mov(x, y) set(pins, 1) label(f\"pulse_{idx}_high\") jmp(x_dec, f\"pulse_{idx}_high\") set(pins, 0) if idx < pulse_count - 1: mov(x, isr) label(f\"gap_{idx}_wait\") jmp(x_dec, f\"gap_{idx}_wait\") mov(x, osr) label(\"tail_wait\") jmp(x_dec, \"tail_wait\") wrap() return program def _build_uniform_pulse_program ( pulse_count ): \"\"\"Return a PIO program that emits `pulse_count` identical pulses per period.\"\"\" if asm_pio is None : return None @asm_pio( set_init=PIO.OUT_LOW ) def program (): pull(block) mov(y, osr) # Pulse width cycles pull(block) mov(isr, osr) # Gap cycles pull(block) # Tail/idle cycles wrap_target() for idx in range (pulse_count): mov(x, y) set (pins, 1 ) label( f\"pulse_ {idx} _high\" ) jmp(x_dec, f\"pulse_ {idx} _high\" ) set (pins, 0 ) if idx < pulse_count - 1 : mov(x, isr) label( f\"gap_ {idx} _wait\" ) jmp(x_dec, f\"gap_ {idx} _wait\" ) mov(x, osr) label( \"tail_wait\" ) jmp(x_dec, \"tail_wait\" ) wrap() return program HOWEVER this is not a great way to do this. We are limited to each program containing at most 64 instructions. As it turns out, this limits you to 4 pulses using this method. This was enough for our tests, so I said \"good enough\" and stopped here. ASIDE: If you fix any of these variables, you can write a general n pulser. I didn't bother to do this because I didn't find it necessary, and the other solution ended up being quicker to adapt for our purposes. Here's an example AI generated pulser (UNTESTED) where you fix each pulse to be 500ns, which gains you the ability to specify an arbitrary number of pulses from machine import Pin import rp2 import time # 500 ns pulse width is FIXED by SM frequency + instruction delay. # With SM_FREQ = 8 MHz, one cycle = 125 ns, and [3] makes HIGH = 4 cycles = 500 ns. SM_FREQ = 8_000_000 # Hz @rp2.asm_pio(set_init=rp2.PIO.OUT_LOW) def burst_pulser(): wrap_target() # Host provides 3 words per burst: # N (number of pulses in the burst) # sep_cycles (wait between pulses, in PIO cycles) # gap_cycles (wait after burst, in PIO cycles) pull() # N mov(y, osr) # Y = pulse counter pull() # sep_cycles mov(isr, osr) # ISR = sep_cycles (constant for this burst) pull() # gap_cycles # OSR now holds gap_cycles (constant for this burst) label(\"pulse_loop\") set(pins, 1) [3] # HIGH for 4 cycles total -> 500 ns at 8 MHz set(pins, 0) # LOW # wait sep_cycles (loop uses X as countdown) mov(x, isr) label(\"sep_wait\") jmp(x_dec, \"sep_wait\") # decrement pulse counter and continue if not done jmp(y_dec, \"pulse_loop\") # after burst: wait gap_cycles mov(x, osr) label(\"gap_wait\") jmp(x_dec, \"gap_wait\") wrap() def ns_to_cycles(ns, sm_freq=SM_FREQ): # cycles = round(t * f). This is raw cycles; loop overhead is separate. return max(0, int(round((ns * 1e-9) * sm_freq))) def us_to_cycles(us, sm_freq=SM_FREQ): return max(0, int(round((us * 1e-6) * sm_freq))) # --- setup --- OUT_PIN = 15 sm = rp2.StateMachine(0, burst_pulser, freq=SM_FREQ, set_base=Pin(OUT_PIN)) sm.active(1) def queue_burst(N, sep_ns, gap_us): # sep_ns is time between pulses (approx). gap_us is time between bursts (approx). # # Note: sep_wait and gap_wait are 1-cycle-per-iteration countdown loops. # The exact timing includes some fixed instruction overhead (set/mov/jmp). # Treat sep_ns and gap_us as \"close to\" requested; calibrate if you need exact edges. sep_cycles = ns_to_cycles(sep_ns) gap_cycles = us_to_cycles(gap_us) sm.put(N) sm.put(sep_cycles) sm.put(gap_cycles) # Example: 20 pulses per burst, ~2 us between pulses, ~1000 us between bursts while True: queue_burst(N=20, sep_ns=2_000, gap_us=1_000) # Optional: if you don't want FIFO to fill ahead, wait roughly one burst duration. # Otherwise you can also stream continuously. time.sleep_ms(2) from machine import Pin import rp2 import time # 500 ns pulse width is FIXED by SM frequency + instruction delay. # With SM_FREQ = 8 MHz, one cycle = 125 ns, and [3] makes HIGH = 4 cycles = 500 ns. SM_FREQ = 8_000_000 # Hz @rp2.asm_pio( set_init=rp2.PIO.OUT_LOW ) def burst_pulser (): wrap_target() # Host provides 3 words per burst: # N (number of pulses in the burst) # sep_cycles (wait between pulses, in PIO cycles) # gap_cycles (wait after burst, in PIO cycles) pull() # N mov(y, osr) # Y = pulse counter pull() # sep_cycles mov(isr, osr) # ISR = sep_cycles (constant for this burst) pull() # gap_cycles # OSR now holds gap_cycles (constant for this burst) label( \"pulse_loop\" ) set (pins, 1 ) [ 3 ] # HIGH for 4 cycles total -> 500 ns at 8 MHz set (pins, 0 ) # LOW # wait sep_cycles (loop uses X as countdown) mov(x, isr) label( \"sep_wait\" ) jmp(x_dec, \"sep_wait\" ) # decrement pulse counter and continue if not done jmp(y_dec, \"pulse_loop\" ) # after burst: wait gap_cycles mov(x, osr) label( \"gap_wait\" ) jmp(x_dec, \"gap_wait\" ) wrap() def ns_to_cycles ( ns, sm_freq=SM_FREQ ): # cycles = round(t * f). This is raw cycles; loop overhead is separate. return max ( 0 , int ( round ((ns * 1e-9 ) * sm_freq))) def us_to_cycles ( us, sm_freq=SM_FREQ ): return max ( 0 , int ( round ((us * 1e-6 ) * sm_freq))) # --- setup --- OUT_PIN = 15 sm = rp2.StateMachine( 0 , burst_pulser, freq=SM_FREQ, set_base=Pin(OUT_PIN)) sm.active( 1 ) def queue_burst ( N, sep_ns, gap_us ): # sep_ns is time between pulses (approx). gap_us is time between bursts (approx). # # Note: sep_wait and gap_wait are 1-cycle-per-iteration countdown loops. # The exact timing includes some fixed instruction overhead (set/mov/jmp). # Treat sep_ns and gap_us as \"close to\" requested; calibrate if you need exact edges. sep_cycles = ns_to_cycles(sep_ns) gap_cycles = us_to_cycles(gap_us) sm.put(N) sm.put(sep_cycles) sm.put(gap_cycles) # Example: 20 pulses per burst, ~2 us between pulses, ~1000 us between bursts while True : queue_burst(N= 20 , sep_ns= 2_000 , gap_us= 1_000 ) # Optional: if you don't want FIFO to fill ahead, wait roughly one burst duration. # Otherwise you can also stream continuously. time.sleep_ms( 2 ) 15/12/2025 13:53 I created some notebooks testing the deadtime of the HDSoC as we vary the number of pulses parameter described above. They are available here: https://github.com/jaca230/nalu_deadtime_tests The conclusion I came to was the the number of pulses doesn't really seem to affect the deadtime: There are some \"hiccups\" in this data, for example you can look at how the deadtime scales with windows for each number of channels: Note that the results seem to be unaffected by pulser rate, so we'll ignore it from here on on out. Things seem \"normal\" for 2 and 3 pulses. But for 4 pulses things get strange, looking into it you can kind of see why: In particular we want to look at: n = 4 pulses pulser = 100Hz windows = 2,4,8 channels = 2 It's hard to say exactly what's happening, but the data point at 500Hz seems to indicate that events are getting split bewteen the 2 channels somehow. The frontend was configured to time_threshold: 100 which means packets seperated by 100 or fewer clock ticks are considered to be the same event (should correspond to ~3200 ns). This was purposefully set low so we could resolve as small of seperations bewteen consecutive pulses as possible. However if you set it too low, it's possible two channels could get \"out of sync\" and the delay could be long enough that the frontend treats them as two events. We can look at specific data points on this plot by unpacking the midas files and looking at the data, but there's two problems with that: It takes a bit more code to unpack all the files and sort through them properly I didn't log the data for the 3 and 4 pulse deadtime scans (we can always go back and retake specific data points, which I found a more efficient solution at the time) A more rigourous test we'd write a new mode for the frontend where packets are no longer collected into events; i.e. each event is just a single packet. We know exactly how many packets to expect for any given setting. This method would remove the unnecessary event collecting step. The reason this wasn't done to begin with was just in interest of time; it would take longer to rewrite this mode and there did not seem to be any problems in the double pulse test. Regardless of all these details, the triple pulse data seems fine, which may be all we need. The triple pulse data seems to suggest there is no meaningful difference between the deadtime of digitizing 2 pulses vs 3 pulses: View of how windows affects deadtime for each number of pulses View of how channels affects deadtime for each number of pulses: 15/12/2025 14:36 An important note: If you look at some of these plots you may naively think \"why are we resolving 2 pulses earlier when we feed in 4 pulses compared to 2\". The reason is because when we feed in 4 pulses, you can do something like this: digitize the first Ignore the next 2 digitize the last So you'll see 2 pulses, but the effective deadtime here is actually about 3x longer than what is recorded (because I just record whatever I set spacing between pulses on the pico to), which is about where you'd expect to resolve 2 pulses. For this reason, some of the error bars are much larger than you'd expect, because you get situations like this: The error bar algorithm takes the error range as Max: The minimum seperation where you see n pulses Min: The maximum seperation where you see n-1 pulses. As seen above, this algorithm can fail and probably needs to be rethought. 19/12/2025 00:36 FEB Detection Issue Problem: library auto-discovery reports 1 FEB even when 2 are present. Broadcast mask ( 0xff ) returns only one path, but slot-by-slot probing finds both. The library then latches the partial result as truth, so all downstream code only sees one board. Fix (application-side): force a slot sweep, union all responding paths, then patch the crate info and presence mask. This makes both FEBs visible to normal readout. Comparison to current library logic: the library uses a broadcast presence mask and trusts the first response; my version forces a sweep and unions all responses. // Library (current, from Check_FeBoardsInSystem): broadcast mask + one read. // Problem: if multiple FEBs respond, the returned frames may not encode all paths. sub_address = ad_control_board_FeBoardPresence; data = 0xFF; SAMPIC256CH_BusWriteWords(crateInfoParams, CTRL_ACCESS, CB_CTRL_FPGA, dummy, dummy, sub_address, &data, 1); Purge_ControlBufferChain(deviceHandle); crateInfoParams->NbOfFeBoards = 0; SAMPIC256CH_BusCommandReadWords(crateInfoParams, CTRL_ACCESS, FEB_CTRL_FPGA, ALL_FE_BOARDs, dummy, 0, 1); SAMPIC256CH_BusReadExtended(deviceHandle, tempBuff, my_MLFrames, MAX_BYTES_TO_READ, &nframes); for (n = 0; n < nframes; n++) { feBoardIndex = my_MLFrames[n].path[0]; if (feBoardIndex >= 0) { crateInfoParams->NbOfFeBoards++; feBoardIsPresent[feBoardIndex] = TRUE; } } for (feBoardIndex = 0; feBoardIndex < MAX_NB_OF_FE_BOARDS; feBoardIndex++) { if (feBoardIsPresent[feBoardIndex] == TRUE) { crateInfoParams->FrontEndBoardsPathIndex[n] = feBoardIndex; n++; } } // Library (current, from Check_FeBoardsInSystem): broadcast mask + one read. // Problem: if multiple FEBs respond, the returned frames may not encode all paths. sub_address = ad_control_board_FeBoardPresence; data = 0xFF ; SAMPIC256CH_BusWriteWords (crateInfoParams, CTRL_ACCESS, CB_CTRL_FPGA, dummy, dummy, sub_address, &data, 1 ); Purge_ControlBufferChain (deviceHandle); crateInfoParams->NbOfFeBoards = 0 ; SAMPIC256CH_BusCommandReadWords (crateInfoParams, CTRL_ACCESS, FEB_CTRL_FPGA, ALL_FE_BOARDs, dummy, 0 , 1 ); SAMPIC256CH_BusReadExtended (deviceHandle, tempBuff, my_MLFrames, MAX_BYTES_TO_READ, &nframes); for (n = 0 ; n < nframes; n++) { feBoardIndex = my_MLFrames[n].path[ 0 ]; if (feBoardIndex >= 0 ) { crateInfoParams->NbOfFeBoards++; feBoardIsPresent[feBoardIndex] = TRUE; } } for (feBoardIndex = 0 ; feBoardIndex < MAX_NB_OF_FE_BOARDS; feBoardIndex++) { if (feBoardIsPresent[feBoardIndex] == TRUE) { crateInfoParams->FrontEndBoardsPathIndex[n] = feBoardIndex; n++; } } // Application side fix: PresenceProbeResult probe_feb_paths(CrateInfoStruct& info) { PresenceProbeResult result; std::set<int> unique_paths; for (int slot = 0; slot < MAX_NB_OF_FE_BOARDS; ++slot) { const uint8_t mask = static_cast<uint8_t>(1u << slot); uint8_t mask_value = mask; auto err = SAMPIC256CH_BusWriteWords(&info, CTRL_ACCESS, CB_CTRL_FPGA, 0, 0, ad_control_board_FeBoardPresence, &mask_value, 1); if (err != SAMPIC256CH_Success) { throw std::runtime_error(\"Failed to write presence mask for slot \" + std::to_string(slot) + \" (err=\" + std::to_string(err) + \")\"); } std::this_thread::sleep_for(std::chrono::milliseconds(2)); err = SAMPIC256CH_BusCommandReadWords(&info, CTRL_ACCESS, FEB_CTRL_FPGA, ALL_FE_BOARDs, 0, 0, 1); if (err != SAMPIC256CH_Success) { continue; } char temp_buffer[MAX_BYTES_TO_READ]{}; ML_Frame frames[MAX_EXPECTED_FRAMES]; int nframes = 0; err = SAMPIC256CH_BusReadExtended(info.ConnectionInfo.CtrlDeviceHandle, temp_buffer, frames, MAX_BYTES_TO_READ, &nframes); if (err != SAMPIC256CH_Success) { continue; } for (int idx = 0; idx < nframes; ++idx) { const int path = frames[idx].path[0]; if (path >= 0 && path < MAX_NB_OF_FE_BOARDS) { unique_paths.insert(path); result.bitmask |= static_cast<uint8_t>(1u << path); } } } result.paths.assign(unique_paths.begin(), unique_paths.end()); if (result.paths.empty()) { throw std::runtime_error(\"Presence probe found no responding FEBs\"); } uint8_t latched_mask = result.bitmask; auto err = SAMPIC256CH_BusWriteWords(&info, CTRL_ACCESS, CB_CTRL_FPGA, 0, 0, ad_control_board_FeBoardPresence, &latched_mask, 1); if (err != SAMPIC256CH_Success) { throw std::runtime_error(\"Failed to latch aggregated presence mask (err=\" + std::to_string(err) + \")\"); } info.CrateBoardsInfo.ControlBoardInfo.FeBoardsPresence = latched_mask; info.NbOfFeBoards = static_cast<int>(result.paths.size()); for (int i = 0; i < info.NbOfFeBoards; ++i) { info.FrontEndBoardsPathIndex[i] = result.paths[i]; } return result; } // Application side fix: PresenceProbeResult probe_feb_paths (CrateInfoStruct& info) { PresenceProbeResult result; std::set< int > unique_paths; for ( int slot = 0 ; slot < MAX_NB_OF_FE_BOARDS; ++slot) { const uint8_t mask = static_cast < uint8_t >( 1u << slot); uint8_t mask_value = mask; auto err = SAMPIC256CH_BusWriteWords (&info, CTRL_ACCESS, CB_CTRL_FPGA, 0 , 0 , ad_control_board_FeBoardPresence, &mask_value, 1 ); if (err != SAMPIC256CH_Success) { throw std:: runtime_error ( \"Failed to write presence mask for slot \" + std:: to_string (slot) + \" (err=\" + std:: to_string (err) + \")\" ); } std::this_thread:: sleep_for (std::chrono:: milliseconds ( 2 )); err = SAMPIC256CH_BusCommandReadWords (&info, CTRL_ACCESS, FEB_CTRL_FPGA, ALL_FE_BOARDs, 0 , 0 , 1 ); if (err != SAMPIC256CH_Success) { continue ; } char temp_buffer[MAX_BYTES_TO_READ]{}; ML_Frame frames[MAX_EXPECTED_FRAMES]; int nframes = 0 ; err = SAMPIC256CH_BusReadExtended (info.ConnectionInfo.CtrlDeviceHandle, temp_buffer, frames, MAX_BYTES_TO_READ, &nframes); if (err != SAMPIC256CH_Success) { continue ; } for ( int idx = 0 ; idx < nframes; ++idx) { const int path = frames[idx].path[ 0 ]; if (path >= 0 && path < MAX_NB_OF_FE_BOARDS) { unique_paths. insert (path); result.bitmask |= static_cast < uint8_t >( 1u << path); } } } result.paths. assign (unique_paths. begin (), unique_paths. end ()); if (result.paths. empty ()) { throw std:: runtime_error ( \"Presence probe found no responding FEBs\" ); } uint8_t latched_mask = result.bitmask; auto err = SAMPIC256CH_BusWriteWords (&info, CTRL_ACCESS, CB_CTRL_FPGA, 0 , 0 , ad_control_board_FeBoardPresence, &latched_mask, 1 ); if (err != SAMPIC256CH_Success) { throw std:: runtime_error ( \"Failed to latch aggregated presence mask (err=\" + std:: to_string (err) + \")\" ); } info.CrateBoardsInfo.ControlBoardInfo.FeBoardsPresence = latched_mask; info.NbOfFeBoards = static_cast < int >(result.paths. size ()); for ( int i = 0 ; i < info.NbOfFeBoards; ++i) { info.FrontEndBoardsPathIndex[i] = result.paths[i]; } return result; } Workaround location: /home/pioneer/jcarlton/projects/midas_sampic/experiments/sampic_daq/scripts/tools/sampic_tests/src/modes/occupancy/occupancy_mode.cpp ( probe_feb_paths() ).",
    "textLength": 3586
  },
  {
    "kind": "work-log",
    "title": "24_03_2024 -30_03_2024.html",
    "fileName": "24_03_2024 -30_03_2024.html",
    "url": "resources/work_logs/24_03_2024 -30_03_2024.html",
    "createdDate": "2024-03-24",
    "text": "24/03/2024 -30/03/2024 24/03/2024 -30/03/2024 26/03/2024 05:38 It seems putting in the new SFPs fixed our error with the master frontend, I can now get it to start up successfully: [root@dhcp-10-163-105-238 MasterGM2]# ./frontend -e DAQ Frontend name : MasterGM2 Event buffer size : 1000000 User max event size : 10000 # of events per buffer : 100 Connect to experiment DAQ... OK Init hardware... print(155): /Equipment/MasterGM2/Settings/Globals Trigger source GPS print(156): /Equipment/MasterGM2/Settings/Globals Socket trigger IP address 127.0.0.1 print(157): /Equipment/MasterGM2/Settings/Globals Socket trigger port 55000 print(158): /Equipment/MasterGM2/Settings/Globals Rate 12.000000 print(159): /Equipment/MasterGM2/Settings/Globals Fills per bunch 8 print(160): /Equipment/MasterGM2/Settings/Globals Readout name AMC13 print(161): /Equipment/MasterGM2/Settings/Globals Front End Offset 1 print(162): /Equipment/MasterGM2/Settings/Globals Simulator name CaloSimulatorAMC13 print(163): /Equipment/MasterGM2/Settings/Globals Encoder Front End AMC13001 print(164): /Equipment/MasterGM2/Settings/Globals Send to event builder 1 print(165): /Equipment/MasterGM2/Settings/Globals Verbose 0 print(166): /Equipment/MasterGM2/Settings/Globals CCC 1 print(167): /Equipment/MasterGM2/Settings/Globals Post MTCA Abort State to ECL 1 print(168): /Equipment/MasterGM2/Settings/Globals Preserve TTC Trigger Config 0 print(169): /Equipment/MasterGM2/Settings/Globals Preserve Analog Trigger Config 0 print(170): /Equipment/MasterGM2/Settings/Globals Enable Trigger DB 1 print(171): /Equipment/MasterGM2/Settings/Globals Trigger DB Analog A6 ID 1 print(172): /Equipment/MasterGM2/Settings/Globals Trigger DB Analog T9 ID 1 print(173): /Equipment/MasterGM2/Settings/Globals Trigger DB TTC ID 1 print(174): /Equipment/MasterGM2/Settings/Globals Trigger DB TTC Analog Pulse ID 1 print(175): /Equipment/MasterGM2/Settings/Globals Trigger DB Fanout Delays ID 1 print(176): /Equipment/MasterGM2/Settings/Globals Database Connection pgsql://g2db-priv:5433/gm2_online_prod gm2_writer gm2_4_writer print(177): /Equipment/MasterGM2/Settings/Globals Internal Trig Alarm Thresh (s) 30 print(178): /Equipment/MasterGM2/Settings/Globals T9A6Gap (ns) 8654175 get_slave_info : 1 enabled slave frontends: FE [AMC13001] : slave index = 0 : sync = 0 Key: /Equipment/AMC13001/Common/Enabled Looking for encoder in crate 1 Found encoder FC7 in slot 11 /AMC13XX/Settings/: ODB Verifcation Looking for encoder in crate 1 MCH IPMI Communication Check AMC13 Initialization Started AMC13_init(78): Read AMC13 T1 IP Address: 192.168.1.189 AMC13_init(86): Read AMC13 T2 IP Address: 192.168.1.188 ipbusudp-2.0://192.168.1.189:50001 , file://$GM2DAQ_DIR/address_tables/AMC13XG_T1.xml AMC13_init(120): AMC13 T1 FPGA Firmware Version Check AMC13_init(135): AMC13 T2 FPGA Firmware Version Check AMC13_init(159): AMC13 Backplane Enables FC7 Initialization Started FC7_init(174): FC7 Board Presence Check FC7_init(190): Slot 11: Read FC7 IP Address: 192.168.1.11 FC7_init(241): FC7 Ethernet Communication Check: 1/1 FC7_init(288): Slot 11: FC7 Firmware Hard Reset FC7_init(298): Waiting 5 s ... FC7_init(410): Slot 11: Write: Enabled Top SFP Ports top: 1, enable: 1 FC7_init(420): Waiting 15 s ... FC7_init(454): Slot 11: Read: Enabled Top SFP Ports: 1 FC7_init(473): Slot 11: Write: Top TTS Receiver Reset MicroTCA initialization duration: 21.866452 s frontend_init: Trigger source is GPS trigger source 3 GPS 3 Name of Device Found: TCR180PEX Buffers Used: 0, Buffers Capacity: 584 Frontend Initialization Complete OK [root@dhcp-10-163-105-238 MasterGM2]# ./frontend -e DAQ Frontend name : MasterGM2 Event buffer size : 1000000 User max event size : 10000 # of events per buffer : 100 Connect to experiment DAQ... OK Init hardware... print(155): /Equipment/MasterGM2/Settings/Globals Trigger source GPS print(156): /Equipment/MasterGM2/Settings/Globals Socket trigger IP address 127.0.0.1 print(157): /Equipment/MasterGM2/Settings/Globals Socket trigger port 55000 print(158): /Equipment/MasterGM2/Settings/Globals Rate 12.000000 print(159): /Equipment/MasterGM2/Settings/Globals Fills per bunch 8 print(160): /Equipment/MasterGM2/Settings/Globals Readout name AMC13 print(161): /Equipment/MasterGM2/Settings/Globals Front End Offset 1 print(162): /Equipment/MasterGM2/Settings/Globals Simulator name CaloSimulatorAMC13 print(163): /Equipment/MasterGM2/Settings/Globals Encoder Front End AMC13001 print(164): /Equipment/MasterGM2/Settings/Globals Send to event builder 1 print(165): /Equipment/MasterGM2/Settings/Globals Verbose 0 print(166): /Equipment/MasterGM2/Settings/Globals CCC 1 print(167): /Equipment/MasterGM2/Settings/Globals Post MTCA Abort State to ECL 1 print(168): /Equipment/MasterGM2/Settings/Globals Preserve TTC Trigger Config 0 print(169): /Equipment/MasterGM2/Settings/Globals Preserve Analog Trigger Config 0 print(170): /Equipment/MasterGM2/Settings/Globals Enable Trigger DB 1 print(171): /Equipment/MasterGM2/Settings/Globals Trigger DB Analog A6 ID 1 print(172): /Equipment/MasterGM2/Settings/Globals Trigger DB Analog T9 ID 1 print(173): /Equipment/MasterGM2/Settings/Globals Trigger DB TTC ID 1 print(174): /Equipment/MasterGM2/Settings/Globals Trigger DB TTC Analog Pulse ID 1 print(175): /Equipment/MasterGM2/Settings/Globals Trigger DB Fanout Delays ID 1 print(176): /Equipment/MasterGM2/Settings/Globals Database Connection pgsql://g2db-priv:5433/gm2_online_prod gm2_writer gm2_4_writer print(177): /Equipment/MasterGM2/Settings/Globals Internal Trig Alarm Thresh (s) 30 print(178): /Equipment/MasterGM2/Settings/Globals T9A6Gap (ns) 8654175 get_slave_info : 1 enabled slave frontends: FE [AMC13001] : slave index = 0 : sync = 0 Key: /Equipment/AMC13001/Common/Enabled Looking for encoder in crate 1 Found encoder FC7 in slot 11 /AMC13XX/Settings/: ODB Verifcation Looking for encoder in crate 1 MCH IPMI Communication Check AMC13 Initialization Started AMC13_init(78): Read AMC13 T1 IP Address: 192.168.1.189 AMC13_init(86): Read AMC13 T2 IP Address: 192.168.1.188 ipbusudp-2.0://192.168.1.189:50001 , file://$GM2DAQ_DIR/address_tables/AMC13XG_T1.xml AMC13_init(120): AMC13 T1 FPGA Firmware Version Check AMC13_init(135): AMC13 T2 FPGA Firmware Version Check AMC13_init(159): AMC13 Backplane Enables FC7 Initialization Started FC7_init(174): FC7 Board Presence Check FC7_init(190): Slot 11: Read FC7 IP Address: 192.168.1.11 FC7_init(241): FC7 Ethernet Communication Check: 1/1 FC7_init(288): Slot 11: FC7 Firmware Hard Reset FC7_init(298): Waiting 5 s ... FC7_init(410): Slot 11: Write: Enabled Top SFP Ports top: 1, enable: 1 FC7_init(420): Waiting 15 s ... FC7_init(454): Slot 11: Read: Enabled Top SFP Ports: 1 FC7_init(473): Slot 11: Write: Top TTS Receiver Reset MicroTCA initialization duration: 21.866452 s frontend_init: Trigger source is GPS trigger source 3 GPS 3 Name of Device Found: TCR180PEX Buffers Used: 0, Buffers Capacity: 584 Frontend Initialization Complete OK 26/03/2024 05:43 I changed the IP of the WFD5 so it \"matches\" it's slot number now instead: [root@dhcp-10-163-105-238 software]# python store_ip.py 1 5 192.168.1.5 ipmitool -I lan -H 192.168.1.41 -U '' -P '' -m 0x20 -B 0x0 -T 0x82 -b 7 -t 0x7a raw 0x32 0x51 0x05 0x01 0xa8 0xc0 [root@dhcp- 10-163-105-238 software]# python store_ip.py 1 5 192.168 . 1 . 5 ipmitool -I lan -H 192.168.1.41 -U '' -P '' -m 0 x20 -B 0 x0 -T 0 x82 -b 7 -t 0 x7a raw 0x32 0x51 0x05 0x01 0 xa8 0 xc0 physically pull black hotswap switch on the WFD5 wait for \"mgmt\" light to be the only green line physicall push black hotswap switch ojn the WFD5 back in [root@dhcp-10-163-105-238 software]# ping 192.168.1.5 PING 192.168.1.5 (192.168.1.5) 56(84) bytes of data. 64 bytes from 192.168.1.5: icmp_seq=1 ttl=64 time=0.135 ms 64 bytes from 192.168.1.5: icmp_seq=2 ttl=64 time=0.060 ms ^C --- 192.168.1.5 ping statistics --- 2 packets transmitted, 2 received, 0% packet loss, time 999ms rtt min/avg/max/mdev = 0.060/0.097/0.135/0.038 ms [root@dhcp-10-163-105-238 software]# [root@dhcp-10-163-105-238 software]# ping 192.168.1.5 PING 192.168.1.5 (192.168.1.5) 56(84) bytes of data. 64 bytes from 192.168.1.5: icmp_seq =1 ttl =64 time =0.135 ms 64 bytes from 192.168.1.5: icmp_seq =2 ttl =64 time =0.060 ms ^C --- 192.168.1.5 ping statistics --- 2 packets transmitted, 2 received, 0% packet loss, time 999ms rtt min/avg/max/mdev = 0.060/0.097/0.135/0.038 ms [root@dhcp-10-163-105-238 software]# 26/03/2024 06:06 Just a \"note to self\" when 'fe01' is plugged into LAN, it has IP: 10.163.102.46 10.163.102.46 So you can connect with ssh root@10.163.102.46 ssh root@ 10.163.102.46 26/03/2024 06:08 Just as a sanity check, I made just the page size of 'fe01' is 4KB as it is on most machine: [root@fe01 ~]# getconf PAGE_SIZE 4096 [root @fe01 ~] # getconf PAGE_SIZE 4096 So this 512 4-byte \"periodic\" structure of the data I read is still a mystery to me. 26/03/2024 06:18 This is as far as I get with the CaloReadoutAMC13 frontend: [root@dhcp-10-163-105-238 CaloReadoutAMC13]# ./frontend -i 1 -e DAQ Frontend name : AMC13001 Event buffer size : 4194304 User max event size : 2097152 # of events per buffer : 2 Connect to experiment DAQ... OK Init hardware... Frontend Index = 1, IP Offset = 1 totalSlots = 2 Enabled Mask (Binary): 010000010000 frontend_init(1754): AMC13 ODB Verifcation frontend_init(1762): WFD5 ODB Verifcation frontend_init(1768): FC7 ODB Verifcation frontend_init(1778): MCH IPMI Communication Check frontend_init(1803): Read AMC13 T1 IP Address: 192.168.1.189 frontend_init(1811): Read AMC13 T2 IP Address: 192.168.1.188 frontend_init(1840): AMC13 T1 FPGA Firmware Version Check frontend_init(1851): AMC13 T2 FPGA Firmware Version Check frontend_init(1862): AMC13 TTC Signal Presence Check [AMC13001,ERROR] [frontend.cpp:1866:frontend_init,ERROR] AMC13: TTC Signal Absent [root@dhcp-10-163-105-238 CaloReadoutAMC13]# ./frontend -i 1 -e DAQ Frontend name : AMC13001 Event buffer size : 4194304 User max event size : 2097152 # of events per buffer : 2 Connect to experiment DAQ... OK Init hardware... Frontend Index = 1, IP Offset = 1 totalSlots = 2 Enabled Mask (Binary) : 010000010000 frontend_init(1754) : AMC13 ODB Verifcation frontend_init(1762) : WFD5 ODB Verifcation frontend_init(1768) : FC7 ODB Verifcation frontend_init(1778) : MCH IPMI Communication Check frontend_init(1803) : Read AMC13 T1 IP Address: 192.168.1.189 frontend_init(1811) : Read AMC13 T2 IP Address: 192.168.1.188 frontend_init(1840) : AMC13 T1 FPGA Firmware Version Check frontend_init(1851) : AMC13 T2 FPGA Firmware Version Check frontend_init(1862) : AMC13 TTC Signal Presence Check [AMC13001,ERROR] [frontend.cpp:1866:frontend_init,ERROR] AMC13: TTC Signal Absent We have the TTC signal input, my guess is we need to update the firmware. 26/03/2024 16:46 I changed the priority for the 10GbE port so it stops stealing traffic from our 1GbE port: # # Connect to AMC # TYPE=Ethernet BOOTPROTO=static IPADDR=192.168.1.20 NETMASK=255.255.255.0 IPV4_FAILURE_FATAL=no IPV6INIT=no IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_PEERDNS=yes IPV6_PEERROUTES=yes IPV6_FAILURE_FATAL=no NAME=enp1s0f1 DEVICE=enp1s0f1 ONBOOT=yes AUTOCONNECT_PRIORITY=-999 MTU=9600 # # Connect to AMC # TYPE =Ethernet BOOTPROTO =static IPADDR = 192.168 . 1.20 NETMASK = 255.255 . 255.0 IPV4_FAILURE_FATAL = no IPV6INIT = no IPV6_AUTOCONF = yes IPV6_DEFROUTE = yes IPV6_PEERDNS = yes IPV6_PEERROUTES = yes IPV6_FAILURE_FATAL = no NAME =enp1s0f1 DEVICE =enp1s0f1 ONBOOT = yes AUTOCONNECT_PRIORITY =- 999 MTU = 9600 And similar for enp1s0f0 # # Connect to AMC # TYPE=Ethernet BOOTPROTO=static IPADDR=192.168.1.21 NETMASK=255.255.255.0 IPV4_FAILURE_FATAL=no IPV6INIT=no IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_PEERDNS=yes IPV6_PEERROUTES=yes IPV6_FAILURE_FATAL=no NAME=enp1s0f0 DEVICE=enp1s0f0 ONBOOT=yes AUTOCONNECT_PRIORITY=-999 MTU=9600 # # Connect to AMC # TYPE =Ethernet BOOTPROTO =static IPADDR = 192.168 . 1.21 NETMASK = 255.255 . 255.0 IPV4_FAILURE_FATAL = no IPV6INIT = no IPV6_AUTOCONF = yes IPV6_DEFROUTE = yes IPV6_PEERDNS = yes IPV6_PEERROUTES = yes IPV6_FAILURE_FATAL = no NAME =enp1s0f0 DEVICE =enp1s0f0 ONBOOT = yes AUTOCONNECT_PRIORITY =- 999 MTU = 9600 I tried to ping 192.168.1.25 as mentioned in Tim's notes: 4) CONFIGURE THE AMC13 bin/AMC13Tool -u do amc13_scripts/ky_init.amc # check the 10 GbE link is up ping 192.168.1.32 PING 192.168.1.32 (192.168.1.32) 56(84) bytes of data. 64 bytes from 192.168.1.32: icmp_seq=1 ttl=64 time=0.038 ms 64 bytes from 192.168.1.32: icmp_seq=2 ttl=64 time=0.021 ms 4b) if 4) doesnt work if ping doesn't work try # reset of AMC13 bin/AMC13Tool -u ws 0x0 0x10 then repeat 3) and 4) - this worked for me on 4/22/15 5) RUN SIMPLE CLIENT cd /home/daq/DAQ/amc13/old_version/examples/SimpleClient ./client 192.168.1.32 Starting run dt = 0 s 0 us 4) CONFIGURE THE AMC13 bin/AMC13Tool -u do amc13_scripts/ky_init.amc # check the 10 GbE link is up ping 192.168.1.32 PING 192.168.1.32 (192.168.1.32) 56(84) bytes of data. 64 bytes from 192.168.1.32: icmp_seq =1 ttl =64 time =0.038 ms 64 bytes from 192.168.1.32: icmp_seq =2 ttl =64 time =0.021 ms 4b) if 4) doesnt work if ping doesn 't work try # reset of AMC13 bin/AMC13Tool -u ws 0x0 0x10 then repeat 3) and 4) - this worked for me on 4/22/15 5) RUN SIMPLE CLIENT cd /home/daq/DAQ/amc13/old_version/examples/SimpleClient ./client 192.168.1.32 Starting run dt = 0 s 0 us but was unable to. I disabled every port on the network with ifdown enp5s0 and enp1s0f0 to make sure they aren't stealing traffic. Then I tried pinging 192.168.1.32 but was unable to. I feel like this port needs to be \"configured\" somehow. 26/03/2024 16:55 The priority thing is a bit finnicky. If I ifdown enp5s0 then ifup enp5s0 I find that somehow enp1s0f1 takes priority. So I have to ifdown enp1s0f1 then ifup enp1s0f1 to make the priority order \"correct\" again. You can check priority order with this command: [root@dhcp-10-163-105-238 network-scripts]# ip route show default via 10.163.105.1 dev eno1 proto dhcp metric 101 10.163.105.0/24 dev eno1 proto kernel scope link src 10.163.105.238 metric 101 192.168.1.0/24 dev enp5s0 proto kernel scope link src 192.168.1.100 metric 103 192.168.1.0/24 dev enp1s0f1 proto kernel scope link src 192.168.1.20 metric 104 192.168.122.0/24 dev virbr0 proto kernel scope link src 192.168.122.1 [root@dhcp-10-163-105-238 network-scripts] # ip route show default via 10 . 163 . 105 . 1 dev eno1 proto dhcp metric 101 10.163.105.0 / 24 dev eno1 proto kernel scope link src 10 . 163 . 105 . 238 metric 101 192.168.1.0 / 24 dev enp5s0 proto kernel scope link src 192 . 168 . 1 . 100 metric 103 192.168.1.0 / 24 dev enp1s0f1 proto kernel scope link src 192 . 168 . 1 . 20 metric 104 192.168.122.0 / 24 dev virbr0 proto kernel scope link src 192 . 168 . 122 . 1 Higher metric number corresponds to worse priority. 26/03/2024 17:16 It looks like there was port configuration in ky_init.amc [root@dhcp-10-163-105-238 amc13_scripts]# cat ky_init.amc # # This AMC13Tool script initializes the AMC13 from all AMC inputs and # prepares the module to send local L1As and build fake events # # Reset the AMC13 (not usually necessary, but never a bad idea) rg # Enable the AMC13 from all twelve of its AMC inputs, # enable run mode, and prepare to take fake data en 0-11 f # Display AMC13 status st # setup # run control, only uses bits 0-14 wv 0x1 0x0 # enables amc slots and SFP outputs wv 0x3 0x1fff # run control, 0x187 means # bit 0 '1' run mode, bit 1 '1' enables DAQLSC, bit 2 \"1\" use LIA # bit 7 \"1\" generate fake event on receiving L1A, bit 8 \"1\" TTs=TTC wv 0x1 0x187 # controls the rate in free running mode using lower 16 bits # 0x8000 is period of L1As so decreasing 0x8000 increases rate wv 0x1c 0x80008000 # 0x550 makes 32kB events, 13 May 2014 changed to 17 bit payload #wv 0x18 0x550 # 0x550 makes 25MB events, 13 May 2014 changed to 17 bit max payload wv 0x18 0x3fff0 # bit 5 '1' reset ddr3 memory controller wv 0x0 0x10 # wv 0x0 0x1 # (exit this script file) #q [root@dhcp-10-163-105-238 amc13_scripts]# cat ky_init.amc # # This AMC13Tool script initializes the AMC13 from all AMC inputs and # prepares the module to send local L1As and build fake events # # Reset the AMC13 (not usually necessary, but never a bad idea) rg # Enable the AMC13 from all twelve of its AMC inputs, # enable run mode, and prepare to take fake data en 0-11 f # Display AMC13 status st # setup # run control, only uses bits 0-14 wv 0x1 0x0 # enables amc slots and SFP outputs wv 0x3 0x1fff # run control, 0x187 means # bit 0 '1' run mode, bit 1 '1' enables DAQLSC, bit 2 \"1\" use LIA # bit 7 \"1\" generate fake event on receiving L1A, bit 8 \"1\" TTs=TTC wv 0x1 0x187 # controls the rate in free running mode using lower 16 bits # 0x8000 is period of L1As so decreasing 0x8000 increases rate wv 0x1c 0x80008000 # 0x550 makes 32kB events, 13 May 2014 changed to 17 bit payload #wv 0x18 0x550 # 0x550 makes 25MB events, 13 May 2014 changed to 17 bit max payload wv 0x18 0x3fff0 # bit 5 '1' reset ddr3 memory controller wv 0x0 0x10 # wv 0x0 0x1 # (exit this script file) #q particularly this line: # enables amc slots and SFP outputs wv 0x3 0x1fff # enables amc slots and SFP outputs wv 0 x3 0 x1fff 27/03/2024 20:30 From the mysterious Mr. Wu's notes we have: Note from Mr Wu MSS applies only to TCP, ping is ICMP so is irrelevant. amc13 does not accept any TCP data, so its receiving buffer has a limited size, if the buffer is full, packet will be dropped. We noticed that NIC has a tendency of exaggerating its receiving window, this leads to dropping the packets and repeated resending on the amc13 side. amc13 can set an upper limit on its sending window by writing to reg 0x1c1f e.g. 0x20000 which limits the number of packets in the tube to 32. Depending on the RTT, this may limit the bandwidth of the TCP, so try to use a smaller number if it can meet the 2.7Gb/s requirement list of TCP registers in AMC13. 0x1c00-0x1fff TCPIP interface general registers 0x1c0d event cmsCRC error counter for event builder 0 0x1c0e event cmsCRC error counter for event builder 1 0x1c0f event cmsCRC error counter for event builder 2 0x1c19 word count output of event builder 0 0x1c1a word count output of event builder 1 0x1c1b word count output of event builder 2 0x1c1c SFP0 IP address register R/W (default 192.168.1.32) 0x1c1d SFP1 IP address register R/W (default 192.168.1.33) 0x1c1e SFP2 IP address register R/W (default 192.168.1.34) 0x1c1f congistion window upper limit register R/W (default 0x3fffffff) 0x1c20 stop monitor buffer overwrite on error register(default is stop on any error) bit 31-5 not used bit 4 if 1, stop on AMC CRC error bit 3 if 1, stop on AMC evn, orn or bcn mismatch bit 2 if 1, stop on AMC length error bit 1 if 1, stop on CMS event length error bit 0 if 1, stop on CMS CRC error In particular, I'm interested in 0x1c1c SFP0 IP address register R/W (default 192.168.1.32) So I fired up the help table for the amc13 [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# bin/AMC13Tool -u Connecting to AMC13... T2 ip 192.168.1.188 T2 ip 192.168.1.188 T1 ip 192.168.1.189 Serial Number 33 T2 URI: ipbusudp-2.0://192.168.1.188:50001 T2 Address Table: file://map/AMC13_AddressTable_S6.xml T1 URI: ipbusudp-2.0://192.168.1.189:50001 T1 Address Table: file://map/AMC13_AddressTable_K7.xml Pick an action (h for menu): h ... ------- AMC13 Read/Write Commands ------- rs(v) <add> [count] single read from spartan (virtex) <add> to <add>+[count] brs(v) <add> [count] block read [count] words from spartan (virtex) <add> frs(v) <add> [count] fifo read spartan (virtex) <add> [count] times ws(v) <add> <data> [count] single write <data> from spartan (virtex) <add> to <add>+[count] bws(v) <add> [<data_list>] block write [<data_list>] from spartan (virtex) <add> fws(v) <add> [<data_list>] fifo write [<data_list>] to spartan (virtex) <add> ... [root@dhcp- 10 - 163 - 105 - 238 amc13StandaloneMAN_2014- 05 - 12 ]# bin/AMC13Tool - u Connecting to AMC13... T2 ip 192.168 . 1.188 T2 ip 192.168 . 1.188 T1 ip 192.168 . 1.189 Serial Number 33 T2 URI: ipbusudp- 2.0 :// 192.168 . 1.188 : 50001 T2 Address Table: file :// map /AMC13_AddressTable_S6.xml T1 URI: ipbusudp- 2.0 :// 192.168 . 1.189 : 50001 T1 Address Table: file :// map /AMC13_AddressTable_K7.xml Pick an action (h for menu ): h ... ------- AMC13 Read/Write Commands ------- rs(v) <add> [ count ] single read from spartan (virtex) <add> to <add> +[ count ] brs(v) <add> [ count ] block read [ count ] words from spartan (virtex) <add> frs(v) <add> [ count ] fifo read spartan (virtex) <add> [ count ] times ws (v) <add> <data> [ count ] single write <data> from spartan (virtex) <add> to <add> +[ count ] bws(v) <add> [ <data_list> ] block write [ <data_list> ] from spartan (virtex) <add> fws(v) <add> [ <data_list> ] fifo write [ <data_list> ] to spartan (virtex) <add> ... Low and behold, if I read 0x1c1c on the virtex: Pick an action (h for menu): rv 0x1c1c Reading T1: 00001c1c: c0a80120 Pick an action (h for menu): rv 0x1c1c Reading T 1 : 00001 c 1 c : c 0 a 80120 Which corresponds to: c0 = 192 a8 = 168 01 = 1 20 = 32 c0 = 192 a8 = 168 01 = 1 20 = 32 which is our IP. 27/03/2024 20:38 I am trying to change the IP to 192.168.10.1 Pick an action (h for menu): wv 0x1c1c 0xc0a80a01 Writing to T1: 00001c1c: c0a80a01 Pick an action (h for menu): rv 0x1c1c Reading T1: 00001c1c: c0a80a01 Pick an action (h for menu): wv 0x1c1c 0xc0a80a01 Writing to T 1 : 00001 c 1 c : c 0 a 80 a 01 Pick an action (h for menu): rv 0x1c1c Reading T 1 : 00001 c 1 c : c 0 a 80 a 01 since 192 = c0 168 = a8 10 = 0a 1 = 01 192 = c0 168 = a8 10 = 0 a 1 = 01 I then changed enp1s0f1 to be on the 192.168.10.xxx subnet with IP 192.168.1.2. It didn't really seem to work: [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# ping 192.168.10.1 PING 192.168.10.1 (192.168.10.1) 56(84) bytes of data. ^C --- 192.168.10.1 ping statistics --- 2 packets transmitted, 0 received, 100% packet loss, time 999ms [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# ifdown enp5s0 Device 'enp5s0' successfully disconnected. [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# ping 192.168.10.1 PING 192.168.10.1 (192.168.10.1) 56(84) bytes of data. ^C --- 192.168.10.1 ping statistics --- 1 packets transmitted, 0 received, 100% packet loss, time 0ms [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# [root@dhcp -10 -163 -105 -238 amc13StandaloneMAN_2014 -05 -12 ]# ping 192.168.10.1 PING 192.168.10.1 (192.168.10.1) 56(84) bytes of data. ^C --- 192.168.10.1 ping statistics --- 2 packets transmitted, 0 received, 100% packet loss, time 999ms [root@dhcp -10 -163 -105 -238 amc13StandaloneMAN_2014 -05 -12 ]# ifdown enp5s0 Device 'enp5s0' successfully disconnected. [root@dhcp -10 -163 -105 -238 amc13StandaloneMAN_2014 -05 -12 ]# ping 192.168.10.1 PING 192.168.10.1 (192.168.10.1) 56(84) bytes of data. ^C --- 192.168.10.1 ping statistics --- 1 packets transmitted, 0 received, 100% packet loss, time 0ms [root@dhcp -10 -163 -105 -238 amc13StandaloneMAN_2014 -05 -12 ]# I can successfully change the IP to something else on the 192.168.1.xxx subnet though: [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# bin/AMC13Tool -u Connecting to AMC13... T2 ip 192.168.1.188 T2 ip 192.168.1.188 T1 ip 192.168.1.189 Serial Number 33 T2 URI: ipbusudp-2.0://192.168.1.188:50001 T2 Address Table: file://map/AMC13_AddressTable_S6.xml T1 URI: ipbusudp-2.0://192.168.1.189:50001 T1 Address Table: file://map/AMC13_AddressTable_K7.xml Pick an action (h for menu): wv 0x1c1c 0xc0a8011e Writing to T1: 00001c1c: c0a8011e Pick an action (h for menu): exit Invalid command Pick an action (h for menu): ^C [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# ifdown enp5s0 Device 'enp5s0' successfully disconnected. [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# ping 192.168.1.30 PING 192.168.1.30 (192.168.1.30) 56(84) bytes of data. 64 bytes from 192.168.1.30: icmp_seq=1 ttl=64 time=0.155 ms 64 bytes from 192.168.1.30: icmp_seq=2 ttl=64 time=0.089 ms [root@dhcp -10 -163 -105 -238 amc13StandaloneMAN_2014 -05 -12 ]# bin/AMC13Tool -u Connecting to AMC13... T2 ip 192.168.1.188 T2 ip 192.168.1.188 T1 ip 192.168.1.189 Serial Number 33 T2 URI: ipbusudp -2 .0://192.168.1.188:50001 T2 Address Table: file://map/AMC13_AddressTable_S6.xml T1 URI: ipbusudp -2 .0://192.168.1.189:50001 T1 Address Table: file://map/AMC13_AddressTable_K7.xml Pick an action (h for menu): wv 0x1c1c 0xc0a8011e Writing to T1: 00001c1c: c0a8011e Pick an action (h for menu): exit Invalid command Pick an action (h for menu): ^C [root@dhcp -10 -163 -105 -238 amc13StandaloneMAN_2014 -05 -12 ]# ifdown enp5s0 Device 'enp5s0' successfully disconnected. [root@dhcp -10 -163 -105 -238 amc13StandaloneMAN_2014 -05 -12 ]# ping 192.168.1.30 PING 192.168.1.30 (192.168.1.30) 56(84) bytes of data. 64 bytes from 192.168.1.30: icmp_seq=1 ttl=64 time=0.155 ms 64 bytes from 192.168.1.30: icmp_seq=2 ttl=64 time=0.089 ms 27/03/2024 20:53 My theory was that the changing the IP to 192.168.10.1 did not work because the 10GbE NIC needs to be on the same subnet as the virtex (which is 192.168.1.188 (or 189, I forgot)). But it looks like on the UW DAQ, they have the 10GbE NIC on 192.168.27.1 while the MCH is on 192.168.7.1. My only idea of how they accomplished this is they changed the IPs of T1 and T2 to be on the 192.168.27.xxx subet, so I tried that: First, while I was still able to talk to T1 and T2 through the 1GbE NIC, I changed the IP of the 10GbE NIC on the AMC13 [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# bin/AMC13Tool -u Connecting to AMC13... T2 ip 192.168.1.188 T2 ip 192.168.1.188 T1 ip 192.168.1.189 Serial Number 33 T2 URI: ipbusudp-2.0://192.168.1.188:50001 T2 Address Table: file://map/AMC13_AddressTable_S6.xml T1 URI: ipbusudp-2.0://192.168.1.189:50001 T1 Address Table: file://map/AMC13_AddressTable_K7.xml Pick an action (h for menu): wv 0x1c1c 0xc0a81b01 Writing to T1: 00001c1c: c0a81b01 [root@dhcp- 10 - 163 - 105 - 238 amc13StandaloneMAN_2014- 05 - 12 ] # bin/AMC13Tool -u Connecting to AMC13... T2 ip 192.168 . 1.188 T2 ip 192.168 . 1.188 T1 ip 192.168 . 1.189 Serial Number 33 T2 URI: ipbusudp- 2.0 :// 192.168 . 1.188 : 50001 T2 Address Table: file://map/AMC13_AddressTable_S6. xml T1 URI: ipbusudp- 2.0 :// 192.168 . 1.189 : 50001 T1 Address Table: file://map/AMC13_AddressTable_K7. xml Pick an action (h for menu): wv 0 x1c1c 0 xc0a81b01 Writing to T1: 00001 c1c: c0a81b01 This corresponds to 192 = c0 168 = a8 27 = 1b 1 = 01 192 = c0 168 = a8 27 = 1 b 1 = 01 Then I changed systemVars.py to change the network base: [root@dhcp-10-163-105-238 amc13Config]# cat systemVars.py #File to specify what the default varaibles addresses are used in your system #Default IP address for commercial MCH module # our NAT MCH address DEFAULT_HOST_IP=\"192.168.1.41\" # our Vadatech MCH address # DEFAULT_HOST_IP=\"192.168.1.2\" #Default AMC13 slot number DEFAULT_AMC13_SLOT=13 #Location of 'config_tools'. This should never need to be changed DEFAULT_CONFIG_DIR=\"./config_tools\" #Network base for your uTCA crate's AMC modules NETWORK_BASE=\"192.168.27\" [root@dhcp-10-163-105-238 amc13Config] # cat systemVars.py #File to specify what the default varaibles addresses are used in your system #Default IP address for commercial MCH module # our NAT MCH address DEFAULT_HOST_IP = \"192.168.1.41\" # our Vadatech MCH address # DEFAULT_HOST_IP=\"192.168.1.2\" #Default AMC13 slot number DEFAULT_AMC13_SLOT = 13 #Location of 'config_tools'. This should never need to be changed DEFAULT_CONFIG_DIR = \"./config_tools\" #Network base for your uTCA crate's AMC modules NETWORK_BASE = \"192.168.27\" I then ran ./applyConfig -n 33 [root@dhcp-10-163-105-238 amc13Config]# ./applyConfig.py -n 33 Applying IP addresses to board in slot 13 from host 192.168.1.41 Setting IP addresses using SN 33 ipmitool -H 192.168.1.41 -U '' -P '' -m 0x20 -T 0x82 -b 7 -t 0xa4 raw 0x32 0x33 0 0 0 11 0x0d 0xff 0xff 0xff 0x00 0xc0 0xa8 0x1b 0xbc 0x00 0x00 ipmitool -H 192.168.1.41 -U '' -P '' -m 0x20 -T 0x82 -b 7 -t 0xa4 raw 0x32 0x33 1 0 0 11 0x0d 0xff 0xff 0xff 0x00 0xc0 0xa8 0x1b 0xbd 0x00 0x00 [root@dhcp- 10-163-105-238 amc13Config]# ./applyConfig.py -n 33 Applying IP addresses to board in slot 13 from host 192.168.1.41 Setting IP addresses using SN 33 ipmitool -H 192.168.1.41 -U '' -P '' -m 0 x20 -T 0 x82 -b 7 -t 0 xa4 raw 0x32 0x33 0 0 0 11 0 x0d 0 xff 0 xff 0 xff 0 x00 0 xc0 0 xa8 0 x1b 0 xbc 0x00 0x00 ipmitool -H 192.168.1.41 -U '' -P '' -m 0 x20 -T 0 x82 -b 7 -t 0 xa4 raw 0x32 0x33 1 0 0 11 0 x0d 0 xff 0 xff 0 xff 0 x00 0 xc0 0 xa8 0 x1b 0 xbd 0x00 0x00 We see the new IPs are set to: 0xc0 0xa8 0x1b 0xbc --> 192.168.27.188 0xc0 0xa8 0x1b 0xbd --> 102.168.27.189 Then I check that I can no longer ping T1 and T2 (I shouldn't be able to) [root@dhcp-10-163-105-238 amc13Config]# ping 192.168.1.188 PING 192.168.1.188 (192.168.1.188) 56(84) bytes of data. ^C --- 192.168.1.188 ping statistics --- 2 packets transmitted, 0 received, 100% packet loss, time 999ms [root@dhcp-10-163-105-238 amc13Config]# ping 192.168.1.189 PING 192.168.1.189 (192.168.1.189) 56(84) bytes of data. ^C --- 192.168.1.189 ping statistics --- 1 packets transmitted, 0 received, 100% packet loss, time 0ms [root@dhcp- 10-163-105-238 amc13Config]# ping 192.168.1.188 PING 192.168.1.188 ( 192.168.1.188 ) 56 ( 84 ) bytes of data. ^C --- 192.168.1.188 ping statistics --- 2 packets transmitted, 0 received, 100 % packet loss, time 999m s [root@dhcp- 10-163-105-238 amc13Config]# ping 192.168.1.189 PING 192.168.1.189 ( 192.168.1.189 ) 56 ( 84 ) bytes of data. ^C --- 192.168.1.189 ping statistics --- 1 packets transmitted, 0 received, 100 % packet loss, time 0m s I then change enp1s0f1 to be on the 192.168.27.xxx subnet: enp1s0f1: flags=4163<UP,BROADCAST,RUNNING,MULTICAST> mtu 9000 inet 192.168.27.21 netmask 255.255.255.0 broadcast 192.168.27.255 inet6 fe80::232a:6445:25a6:4e16 prefixlen 64 scopeid 0x20<link> ether b4:b5:2f:a4:e7:fc txqueuelen 1000 (Ethernet) RX packets 37 bytes 2790 (2.7 KiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 841 bytes 102979 (100.5 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 enp1s0f1 : flags= 4163 <UP,BROADCAST,RUNNING,MULTICAST> mtu 9000 inet 192.168.27.21 netmask 255.255.255.0 broadcast 192.168.27.255 inet6 fe80:: 232 a: 6445 : 25 a6: 4 e16 prefixlen 64 scopeid 0 x20<link> ether b4:b5: 2 f:a4:e7:fc txqueuelen 1000 (Ethernet) RX packets 37 bytes 2790 ( 2 . 7 KiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 841 bytes 102979 ( 100 . 5 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 And try to ping: [root@dhcp-10-163-105-238 network-scripts]# ping 192.168.27.1 PING 192.168.27.1 (192.168.27.1) 56(84) bytes of data. From 192.168.27.21 icmp_seq=1 Destination Host Unreachable From 192.168.27.21 icmp_seq=2 Destination Host Unreachable From 192.168.27.21 icmp_seq=3 Destination Host Unreachable From 192.168.27.21 icmp_seq=4 Destination Host Unreachable [root@dhcp-10-163-105-238 network-scripts]# ping 192.168.27.1 PING 192.168.27.1 (192.168.27.1) 56(84) bytes of data. From 192.168.27.21 icmp_seq =1 Destination Host Unreachable From 192.168.27.21 icmp_seq =2 Destination Host Unreachable From 192.168.27.21 icmp_seq =3 Destination Host Unreachable From 192.168.27.21 icmp_seq =4 Destination Host Unreachable But no luck. On second though, this procedure makes no sense anyway. The frontend needs to see T1 and T2, which means they need to be on the same subnet as the 1GbE NIC. I think UW accomplishes this by putting the 1GbE NIC on the 192.168.xxx.xxx subnet. I can't see exactly what they did right now because it's in use, but this doesn't seem right because I can't ping what I think T1 and T2 should be: [root@cenpa-pioneer j.carlton]# ping 192.168.27.188 PING 192.168.27.188 (192.168.27.188) 56(84) bytes of data. ^C --- 192.168.27.188 ping statistics --- 2 packets transmitted, 0 received, 100% packet loss, time 999ms [root@cenpa-pioneer j.carlton]# ping 192.168.27.189 PING 192.168.27.189 (192.168.27.189) 56(84) bytes of data. ^C --- 192.168.27.189 ping statistics --- 1 packets transmitted, 0 received, 100% packet loss, time 0ms [root @cenpa -pioneer j.carlton] # ping 192.168.27.188 PING 192.168 .27 .188 ( 192.168 .27 .188 ) 56 ( 84 ) bytes of data. ^C --- 192.168 .27 .188 ping statistics --- 2 packets transmitted, 0 received, 100 % packet loss, time 999 ms [root @cenpa -pioneer j.carlton] # ping 192.168.27.189 PING 192.168 .27 .189 ( 192.168 .27 .189 ) 56 ( 84 ) bytes of data. ^C --- 192.168 .27 .189 ping statistics --- 1 packets transmitted, 0 received, 100 % packet loss, time 0 ms But it's possible they have different IPs (not 188 and 189) 25/03/2024 06:12 Hi Tim, the easiest way I think is to install it from CERN repository. See details below: Name : cactus-amc13 Arch : noarch Version : 1.2.2 Release : 20170214 Size : 0.0 Repo : installed From repo : cactus_amc13_noarch Summary : Wrapper meta RPM for cactus-amc13 YUM group URL : https://git.cern.ch/web/cms-daq-sysadmins-public.git License : UNKNOWN Description : Meta RPM that pulls all the cactus-amc13 Yum group required RPMs This is a printout from one of my machines in CERN that has amc13 tools installed. The command that generated this printout is: sudo yum info cactus-amc13 I did not install it myself though, so don't have step-by-step instructions. Let me know if you need further help with this. Alex. Unsurprisngly, just trying to see if we have the RPM shows we don't: [root@dhcp-10-163-105-238 tools]# sudo yum info cactus-amc13 Loaded plugins: fastestmirror, langpacks Loading mirror speeds from cached hostfile * base: mirror.us-midwest-1.nexcess.net * centos-sclo-rh: mirror.us.oneandone.net * centos-sclo-sclo: mirror.team-cymru.com * epel: mirrors.lug.mtu.edu * extras: coresite.mm.fcix.net * updates: mirror.pit.teraswitch.com Error: No matching Packages to list [root@dhcp-10-163-105-238 tools]# sudo yum install cactus-amc13 Loaded plugins: fastestmirror, langpacks Loading mirror speeds from cached hostfile * base: mirror.us-midwest-1.nexcess.net * centos-sclo-rh: mirror.us.oneandone.net * centos-sclo-sclo: mirror.team-cymru.com * epel: mirrors.lug.mtu.edu * extras: coresite.mm.fcix.net * updates: mirror.pit.teraswitch.com No package cactus-amc13 available. Error: Nothing to do [root@dhcp-10-163-105-238 tools]# [root@dhcp -10 -163 -105 -238 tools]# sudo yum info cactus-amc13 Loaded plugins: fastestmirror, langpacks Loading mirror speeds from cached hostfile * base: mirror.us-midwest -1 .nexcess.net * centos-sclo-rh: mirror.us.oneandone.net * centos-sclo-sclo: mirror.team-cymru.com * epel: mirrors.lug.mtu.edu * extras: coresite.mm.fcix.net * updates: mirror.pit.teraswitch.com Error: No matching Packages to list [root@dhcp -10 -163 -105 -238 tools]# sudo yum install cactus-amc13 Loaded plugins: fastestmirror, langpacks Loading mirror speeds from cached hostfile * base: mirror.us-midwest -1 .nexcess.net * centos-sclo-rh: mirror.us.oneandone.net * centos-sclo-sclo: mirror.team-cymru.com * epel: mirrors.lug.mtu.edu * extras: coresite.mm.fcix.net * updates: mirror.pit.teraswitch.com No package cactus-amc13 available. Error: Nothing to do [root@dhcp -10 -163 -105 -238 tools]# I tried checking out the link Alex gave from when he ran sudo yum info cactus-amc13 on his machine: https://git.cern.ch/web/cms-daq-sysadmins-public.git But I'm blocked by a CERN login page. 25/03/2024 06:20 I found this on a google search: https://gitlab.cern.ch/cms-cactus/boards/amc13 But I can't seem to clone it, I'm suspecting similar permission issues. [root@dhcp-10-163-105-238 tools]# git clone --recurse-submodules https://gitlab.cern.ch/cms-cactus/boards/amc13 Cloning into 'amc13'... error: RPC failed; result=22, HTTP code = 422 fatal: The remote end hung up unexpectedly [root@dhcp-10-163-105-238 tools]# [root@dhcp -10 -163 -105 -238 tools]# git clone --recurse-submodules https://gitlab.cern.ch/cms-cactus/boards/amc13 Cloning into 'amc13'... error: RPC failed; result=22, HTTP code = 422 fatal: The remote end hung up unexpectedly [root@dhcp -10 -163 -105 -238 tools]# Trying the ssh variant of the clone, the command hangs: [root@dhcp-10-163-105-238 tools]# git clone --recurse-submodules git@gitlab.cern.ch:cms-cactus/boards/amc13 Cloning into 'amc13'... [root@dhcp-10-163-105-238 tools] # git clone --recurse-submodules git @gitlab .cern. ch :cms-cactus/boards/amc13 Cloning into 'amc13' ... 25/03/2024 06:22 By just looking at the file structure on https://gitlab.cern.ch/cms-cactus/boards/amc13 , I noticed it look similar to what we have in /home/installation_testing/packages/experiment/lxedaq/amc13/amc13_v1_2_18 . And it turns out AMC13Tool2 is indeed in here: [root@dhcp-10-163-105-238 common]# ls AMC13BenchTest.cxx AMC13ToolFlash.cxx CLIHelper.cc Launcher.cc Launcher_commands_control.cc Launcher_commands_io.cc Module.cc AMC13Tool2.cxx CLI.cc LaTeXprint.cxx Launcher_commands.cc Launcher_commands_flash.cc Launcher_commands_status.cc [root@dhcp-10-163-105-238 common]# pwd /home/installation_testing/packages/experiment/lxedaq/amc13/amc13_v1_2_18/tools/src/common [root@dhcp-10-163-105-238 common]# [root @dhcp-10-163-105-238 common ]# ls AMC 13 BenchTest.cxx AMC 13 ToolFlash.cxx CLIHelper. cc Launcher. cc Launcher_commands_control. cc Launcher_commands_io. cc Module. cc AMC 13 Tool 2 .cxx CLI. cc LaTeXprint.cxx Launcher_commands. cc Launcher_commands_flash. cc Launcher_commands_status. cc [root @dhcp-10-163-105-238 common ]# pwd /home/installation_testing/packages/experiment/lxedaq/amc 13 /amc 13 _v 1 _ 2 _ 18 /tools/src/ common [root @dhcp-10-163-105-238 common ]# So I tried making it (first I have to setup the environment): cd /home/installation_testing/packages/experiment/lxedaq/environment_setup/ source ./setup_environment.sh export CPLUS_INCLUDE_PATH=$CPLUS_INCLUDE_PATH:/home/backup_installation_testing/packages/boost-1.53.0/include (adds boost to C++ include path) After doing that, I try making: cd /home/installation_testing/packages/experiment/lxedaq/amc13/amc13_v1_2_18/tools make But get these errors: [root@dhcp-10-163-105-238 tools]# make Using AMC13_ROOT=/home/installation_testing/packages/experiment/lxedaq/amc13/amc13_v1_2_18/tools/../ Using BUILD_HOME=/home/installation_testing/packages/experiment/lxedaq/amc13/amc13_v1_2_18/tools/../ OS Detected: centos7 mkdir -p {lib,obj} g++ -g -O3 -rdynamic -Wall -MMD -MP -fPIC -std=c++11 -Iinclude -I../amc13//include -I/opt/cactus/include -c src/common/Launcher_commands.cc -o obj/Launcher_commands.o In file included from ../amc13//include/amc13/AMC13.hh:9, from include/amc13/Launcher.hh:11, from src/common/Launcher_commands.cc:1: ../amc13//include/amc13/Status.hh:100:31: error: \u2018std::unordered_map\u2019 has not been declared std::string ParseRow(std::unordered_map<std::string,std::string> & parameters, ^~~~~~~~~~~~~ ../amc13//include/amc13/Status.hh:100:44: error: expected \u2018,\u2019 or \u2018...\u2019 before \u2018<\u2019 token std::string ParseRow(std::unordered_map<std::string,std::string> & parameters, ^ ../amc13//include/amc13/Status.hh:102:31: error: \u2018std::unordered_map\u2019 has not been declared std::string ParseCol(std::unordered_map<std::string,std::string> & parameters, ^~~~~~~~~~~~~ ../amc13//include/amc13/Status.hh:102:44: error: expected \u2018,\u2019 or \u2018...\u2019 before \u2018<\u2019 token std::string ParseCol(std::unordered_map<std::string,std::string> & parameters, ^ make: *** [Makefile:100: obj/Launcher_commands.o] Error 1 [root@dhcp-10-163-105-238 tools]# [root@dhcp-10-163-105-238 tools]# make Using AMC13_ROOT=/home/installation_testing/packages/experiment/lxedaq/amc13/amc13_v1_2_18/tools/../ Using BUILD_HOME=/home/installation_testing/packages/experiment/lxedaq/amc13/amc13_v1_2_18/tools/../ OS Detected: centos7 mkdir -p {lib,obj} g++ -g -O3 -rdynamic -Wall -MMD -MP -fPIC -std=c++11 -Iinclude -I../amc13//include -I/opt/cactus/include -c src/common/Launcher_commands.cc -o obj/Launcher_commands.o In file included from ../amc13//include/amc13/AMC13.hh:9, from include/amc13/Launcher.hh:11, from src/common/Launcher_commands.cc:1: ../amc13//include/amc13/Status.hh:100:31: error: \u2018std::unordered_map\u2019 has not been declared std::string ParseRow(std::unordered_map<std::string,std::string> & parameters, ^~~~~~~~~~~~~ ../amc13//include/amc13/Status.hh:100:44: error: expected \u2018,\u2019 or \u2018...\u2019 before \u2018<\u2019 token std::string ParseRow(std::unordered_map<std::string,std::string> & parameters, ^ ../amc13//include/amc13/Status.hh:102:31: error: \u2018std::unordered_map\u2019 has not been declared std::string ParseCol(std::unordered_map<std::string,std::string> & parameters, ^~~~~~~~~~~~~ ../amc13//include/amc13/Status.hh:102:44: error: expected \u2018,\u2019 or \u2018...\u2019 before \u2018<\u2019 token std::string ParseCol(std::unordered_map<std::string,std::string> & parameters, ^ make: *** [Makefile:100: obj/Launcher_commands.o] Error 1 [root@dhcp-10-163-105-238 tools]# This error seems very dumb to me. The project includes boost unordered maps, but uses standard c++ library unordered maps here (???). Unless there's some hidden C++ magic here, this just seems like faulty code. The \"newer\" code (see here: https://gitlab.cern.ch/cms-cactus/boards/amc13/-/blob/master/amc13/include/amc13/Status.hh?ref_type=heads ) doesn't even used unordered maps. Anyways, I tried fixing it by adding #include <unordered_map> # include <unordered_map> to Status.hh . That got past this error but we quickly reached another: [root@dhcp-10-163-105-238 tools]# make clean Using AMC13_ROOT=/home/installation_testing/packages/experiment/lxedaq/amc13/amc13_v1_2_18/tools/../ Using BUILD_HOME=/home/installation_testing/packages/experiment/lxedaq/amc13/amc13_v1_2_18/tools/../ OS Detected: centos7 rm -rf obj rm -rf bin rm -rf lib [root@dhcp-10-163-105-238 tools]# make Using AMC13_ROOT=/home/installation_testing/packages/experiment/lxedaq/amc13/amc13_v1_2_18/tools/../ Using BUILD_HOME=/home/installation_testing/packages/experiment/lxedaq/amc13/amc13_v1_2_18/tools/../ OS Detected: centos7 mkdir -p {lib,obj} g++ -g -O3 -rdynamic -Wall -MMD -MP -fPIC -std=c++11 -Iinclude -I../amc13//include -I/home/installation_testing/packages/cactus/include -c src/common/Launcher_commands.cc -o obj/Launcher_commands.o mkdir -p {lib,obj} g++ -g -O3 -rdynamic -Wall -MMD -MP -fPIC -std=c++11 -Iinclude -I../amc13//include -I/home/installation_testing/packages/cactus/include -c src/common/CLI.cc -o obj/CLI.o mkdir -p {lib,obj} g++ -g -O3 -rdynamic -Wall -MMD -MP -fPIC -std=c++11 -Iinclude -I../amc13//include -I/home/installation_testing/packages/cactus/include -c src/common/Module.cc -o obj/Module.o mkdir -p {lib,obj} g++ -g -O3 -rdynamic -Wall -MMD -MP -fPIC -std=c++11 -Iinclude -I../amc13//include -I/home/installation_testing/packages/cactus/include -c src/common/Launcher_commands_io.cc -o obj/Launcher_commands_io.o mkdir -p {lib,obj} g++ -g -O3 -rdynamic -Wall -MMD -MP -fPIC -std=c++11 -Iinclude -I../amc13//include -I/home/installation_testing/packages/cactus/include -c src/common/Launcher_commands_status.cc -o obj/Launcher_commands_status.o src/common/Launcher_commands_status.cc: In function \u2018void amc13::statusTableAutoCompleteHelper(const uhal::Node&, std::vector<std::basic_string<char> >&, const string&)\u2019: src/common/Launcher_commands_status.cc:242:85: error: conversion from \u2018const boost::unordered::unordered_map<std::basic_string<char>, std::basic_string<char> >\u2019 to non-scalar type \u2018std::unordered_map<std::basic_string<char>, std::basic_string<char> >\u2019 requested std::unordered_map<std::string,std::string> parameters = itNode->getParameters(); ~~~~~~~~~~~~~~~~~~~~~^~ make: *** [Makefile:100: obj/Launcher_commands_status.o] Error 1 [root@dhcp-10-163-105-238 tools]# make clean Using AMC13_ROOT=/home/installation_testing/packages/experiment/lxedaq/amc13/amc13_v1_2_18/tools/../ Using BUILD_HOME=/home/installation_testing/packages/experiment/lxedaq/amc13/amc13_v1_2_18/tools/../ OS Detected: centos7 rm -rf obj rm -rf bin rm -rf lib [root@dhcp-10-163-105-238 tools]# make Using AMC13_ROOT=/home/installation_testing/packages/experiment/lxedaq/amc13/amc13_v1_2_18/tools/../ Using BUILD_HOME=/home/installation_testing/packages/experiment/lxedaq/amc13/amc13_v1_2_18/tools/../ OS Detected: centos7 mkdir -p {lib,obj} g++ -g -O3 -rdynamic -Wall -MMD -MP -fPIC -std=c++11 -Iinclude -I../amc13//include -I/home/installation_testing/packages/cactus/include -c src/common/Launcher_commands.cc -o obj/Launcher_commands.o mkdir -p {lib,obj} g++ -g -O3 -rdynamic -Wall -MMD -MP -fPIC -std=c++11 -Iinclude -I../amc13//include -I/home/installation_testing/packages/cactus/include -c src/common/CLI.cc -o obj/CLI.o mkdir -p {lib,obj} g++ -g -O3 -rdynamic -Wall -MMD -MP -fPIC -std=c++11 -Iinclude -I../amc13//include -I/home/installation_testing/packages/cactus/include -c src/common/Module.cc -o obj/Module.o mkdir -p {lib,obj} g++ -g -O3 -rdynamic -Wall -MMD -MP -fPIC -std=c++11 -Iinclude -I../amc13//include -I/home/installation_testing/packages/cactus/include -c src/common/Launcher_commands_io.cc -o obj/Launcher_commands_io.o mkdir -p {lib,obj} g++ -g -O3 -rdynamic -Wall -MMD -MP -fPIC -std=c++11 -Iinclude -I../amc13//include -I/home/installation_testing/packages/cactus/include -c src/common/Launcher_commands_status.cc -o obj/Launcher_commands_status.o src/common/Launcher_commands_status.cc: In function \u2018void amc13::statusTableAutoCompleteHelper(const uhal::Node&, std::vector<std::basic_string<char> >&, const string&)\u2019: src/common/Launcher_commands_status.cc:242:85: error: conversion from \u2018const boost::unordered::unordered_map<std::basic_string<char>, std::basic_string<char> >\u2019 to non-scalar type \u2018std::unordered_map<std::basic_string<char>, std::basic_string<char> >\u2019 requested std::unordered_map<std::string,std::string> parameters = itNode->getParameters(); ~~~~~~~~~~~~~~~~~~~~~^~ make: *** [Makefile:100: obj/Launcher_commands_status.o] Error 1 This error has to do with the fact that itNode is returning a boost unordered map and C++ doesn't know how to convert that to a standard C++ library unordered map. So I tried changing the relevant to line to use boost's unordered map: boost::unordered_map<std::string,std::string> parameters = itNode->getParameters(); boost::unordered_map<std::string,std::string> parameters = itNode -> getParameters (); That seemed to cause a lot more trouble \"down the road\" in the code by the errors after: root@dhcp-10-163-105-238 tools]# make Using AMC13_ROOT=/home/installation_testing/packages/experiment/lxedaq/amc13/amc13_v1_2_18/tools/../ Using BUILD_HOME=/home/installation_testing/packages/experiment/lxedaq/amc13/amc13_v1_2_18/tools/../ OS Detected: centos7 mkdir -p {lib,obj} g++ -g -O3 -rdynamic -Wall -MMD -MP -fPIC -std=c++11 -Iinclude -I../amc13//include -I/home/installation_testing/packages/cactus/include -c src/common/Launcher_commands_status.cc -o obj/Launcher_commands_status.o src/common/Launcher_commands_status.cc: In function \u2018void amc13::statusTableAutoCompleteHelper(const uhal::Node&, std::vector<std::basic_string<char> >&, const string&)\u2019: src/common/Launcher_commands_status.cc:244:40: error: no match for \u2018operator=\u2019 (operand types are \u2018std::unordered_map<std::basic_string<char>, std::basic_string<char> >::iterator\u2019 {aka \u2018std::__detail::_Node_iterator<std::pair<const std::basic_string<char>, std::basic_string<char> >, false, true>\u2019} and \u2018boost::unordered::unordered_map<std::basic_string<char>, std::basic_string<char> >::iterator\u2019 {aka \u2018boost::unordered::iterator_detail::iterator<boost::unordered::detail::ptr_node<std::pair<const std::basic_string<char>, std::basic_string<char> > > >\u2019}) itTable = parameters.find(\"Table\"); ^ In file included from /opt/rh/devtoolset-8/root/usr/include/c++/8/bits/hashtable.h:35, from /opt/rh/devtoolset-8/root/usr/include/c++/8/unordered_map:46, from ../amc13//include/amc13/Status.hh:14, from ../amc13//include/amc13/AMC13.hh:9, from include/amc13/Launcher.hh:11, from src/common/Launcher_commands_status.cc:1: /opt/rh/devtoolset-8/root/usr/include/c++/8/bits/hashtable_policy.h:319:12: note: candidate: \u2018std::__detail::_Node_iterator<std::pair<const std::basic_string<char>, std::basic_string<char> >, false, true>& std::__detail::_Node_iterator<std::pair<const std::basic_string<char>, std::basic_string<char> >, false, true>::operator=(const std::__detail::_Node_iterator<std::pair<const std::basic_string<char>, std::basic_string<char> >, false, true>&)\u2019 struct _Node_iterator ... root@dhcp-10-163-105-238 tools]# make Using AMC13_ROOT=/home/installation_testing/packages/experiment/lxedaq/amc13/amc13_v1_2_18/tools/../ Using BUILD_HOME=/home/installation_testing/packages/experiment/lxedaq/amc13/amc13_v1_2_18/tools/../ OS Detected: centos7 mkdir -p {lib,obj} g++ -g -O3 -rdynamic -Wall -MMD -MP -fPIC -std=c++11 -Iinclude -I../amc13//include -I/home/installation_testing/packages/cactus/include -c src/common/Launcher_commands_status.cc -o obj/Launcher_commands_status.o src/common/Launcher_commands_status.cc: In function \u2018void amc13::statusTableAutoCompleteHelper(const uhal::Node&, std::vector<std::basic_string<char> >&, const string&)\u2019: src/common/Launcher_commands_status.cc:244:40: error: no match for \u2018operator=\u2019 (operand types are \u2018std::unordered_map<std::basic_string<char>, std::basic_string<char> >::iterator\u2019 {aka \u2018std::__detail::_Node_iterator<std::pair<const std::basic_string<char>, std::basic_string<char> >, false, true>\u2019} and \u2018boost::unordered::unordered_map<std::basic_string<char>, std::basic_string<char> >::iterator\u2019 {aka \u2018boost::unordered::iterator_detail::iterator<boost::unordered::detail::ptr_node<std::pair<const std::basic_string<char>, std::basic_string<char> > > >\u2019}) itTable = parameters.find(\"Table\"); ^ In file included from /opt/rh/devtoolset-8/root/usr/include/c++/8/bits/hashtable.h:35, from /opt/rh/devtoolset-8/root/usr/include/c++/8/unordered_map:46, from ../amc13//include/amc13/Status.hh:14, from ../amc13//include/amc13/AMC13.hh:9, from include/amc13/Launcher.hh:11, from src/common/Launcher_commands_status.cc:1: /opt/rh/devtoolset-8/root/usr/include/c++/8/bits/hashtable_policy.h:319:12: note: candidate: \u2018std::__detail::_Node_iterator<std::pair<const std::basic_string<char>, std::basic_string<char> >, false, true>& std::__detail::_Node_iterator<std::pair<const std::basic_string<char>, std::basic_string<char> >, false, true>::operator=(const std::__detail::_Node_iterator<std::pair<const std::basic_string<char>, std::basic_string<char> >, false, true>&)\u2019 struct _Node_iterator ... I'm not quite sure why the code is so broken. For one it's old. But it seems we have it in some intermediate state where the code was still being developed. Or maybe uHAL updated to use boost unordered maps for efficiency purposes. 25/03/2024 07:27 You can check the page size on a computer like this: [root@dhcp-10-163-105-238 tools]# getconf PAGE_SIZE 4096 [root@dhcp -10 -163 -105 -238 tools]# getconf PAGE_SIZE 4096 (this is on the 'be' computer) I want to check this on 'fe01'. If it reads back 2048 for some reason, that can explain the cyclic nature of our 512 4-byte words. 27/03/2024 18:42 I'm currently able to talk to the AMC through 10GbE now. However, only if enp5s0 is off: [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# ping 192.168.1.32 PING 192.168.1.32 (192.168.1.32) 56(84) bytes of data. ^C --- 192.168.1.32 ping statistics --- 2 packets transmitted, 0 received, 100% packet loss, time 999ms [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# ifdown enp5s0 Device 'enp5s0' successfully disconnected. [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# ping 192.168.1.32 PING 192.168.1.32 (192.168.1.32) 56(84) bytes of data. 64 bytes from 192.168.1.32: icmp_seq=1 ttl=64 time=0.161 ms 64 bytes from 192.168.1.32: icmp_seq=2 ttl=64 time=0.093 ms 64 bytes from 192.168.1.32: icmp_seq=3 ttl=64 time=0.058 ms ^C --- 192.168.1.32 ping statistics --- 3 packets transmitted, 3 received, 0% packet loss, time 2000ms rtt min/avg/max/mdev = 0.058/0.104/0.161/0.042 ms [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# ping 192.168.1.32 PING 192.168.1.32 (192.168.1.32) 56(84) bytes of data. ^C --- 192.168.1.32 ping statistics --- 2 packets transmitted, 0 received, 100% packet loss, time 999ms [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# ifdown enp5s0 Device 'enp5s0' successfully disconnected. [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# ping 192.168.1.32 PING 192.168.1.32 (192.168.1.32) 56(84) bytes of data. 64 bytes from 192.168.1.32: icmp_seq =1 ttl =64 time =0.161 ms 64 bytes from 192.168.1.32: icmp_seq =2 ttl =64 time =0.093 ms 64 bytes from 192.168.1.32: icmp_seq =3 ttl =64 time =0.058 ms ^C --- 192.168.1.32 ping statistics --- 3 packets transmitted, 3 received, 0% packet loss, time 2000ms rtt min/avg/max/mdev = 0.058/0.104/0.161/0.042 ms [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# To accomplish this I did a few things: Set up enp1s0f1 port: vi ifcfg-enp1s0f1 Change active lines to below # # Connect to AMC # HWADDR=b4:b5:2f:a4:e7:fc TYPE=Ethernet PROXY_METHOD=none BROWSER_ONLY=no BOOTPROTO=none IPADDR=192.168.1.21 PREFIX=24 DEFROUTE=yes IPV4_FAILURE_FATAL=no IPV6INIT=yes IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_FAILURE_FATAL=no IPV6_ADDR_GEN_MODE=stable-privacy UUID=f1d52da3-687b-3215-a2c0-60c11d0fd3bf ONBOOT=yes AUTOCONNECT_PRIORITY=-999 MTU=9000 DEVICE=enp1s0f1 NAME=enp1s0f1 # # Connect to AMC # HWADDR =b4:b5: 2 f:a4:e7:fc TYPE =Ethernet PROXY_METHOD =none BROWSER_ONLY = no BOOTPROTO =none IPADDR = 192.168 . 1.21 PREFIX = 24 DEFROUTE = yes IPV4_FAILURE_FATAL = no IPV6INIT = yes IPV6_AUTOCONF = yes IPV6_DEFROUTE = yes IPV6_FAILURE_FATAL = no IPV6_ADDR_GEN_MODE =stable-privacy UUID =f1d52da3- 687 b- 3215 -a2c0- 60 c11d0fd3bf ONBOOT = yes AUTOCONNECT_PRIORITY =- 999 MTU = 9000 DEVICE =enp1s0f1 NAME =enp1s0f1 This is more or less copied from the UW setup. I had to change MTU to 9000, anything higher seemed to default the port back to an MTU of 1500. Run AMC13Tool: Previously in my notes we built AMC13Tool. To run it, some minor changes need to be made: replace all \".\" characters in /home/installation_testing/packages/experiment/lxedaq/amc13/amc13StandaloneMAN_2014-05-12/map/AMC13_AddressTable_V6.xml with something else. Tim chose \"dot\" so that's what I went with. I just used VSC select all tool and made sure to chang ehte xml version at the top back to \"1.0\". Apply environment variables: cd /home/installation_testing/packages/experiment/gm2daq/environment_setup/ source ./setup_environment.sh export LD_LIBRARY_PATH=/home/installation_testing/packages/experiment/lxedaq/amc13/amc13StandaloneMAN_2014-05-12/lib:$LD_LIBRARY_PATH cd /home/installation_testing/packages/experiment/lxedaq/amc13/amc13StandaloneMAN_2014-05-12 source uhalEnv.sh Run the AMC13Tool from directory /home/installation_testing/packages/experiment/lxedaq/amc13/amc13StandaloneMAN_2014-05-12 bin/AMC13Tool -u should see output like this: [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# bin/AMC13Tool - u Connecting to AMC13... T2 ip 192.168.1.188 T2 ip 192.168.1.188 T1 ip 192.168.1.189 Serial Number 33 T2 URI: ipbusudp-2.0://192.168.1.188:50001 T2 Address Table: file://map/AMC13_AddressTable_S6.xml T1 URI: ipbusudp-2.0://192.168.1.189:50001 T1 Address Table: file://map/AMC13_AddressTable_K7.xml Pick an action (h for menu): [root@dhcp- 10 - 163 - 105 - 238 amc13StandaloneMAN_2014- 05 - 12 ] # bin/AMC13Tool - u Connecting to AMC13... T2 ip 192.168 . 1.188 T2 ip 192.168 . 1.188 T1 ip 192.168 . 1.189 Serial Number 33 T2 URI: ipbusudp- 2.0 :// 192.168 . 1.188 : 50001 T2 Address Table: file://map/AMC13_AddressTable_S6. xml T1 URI: ipbusudp- 2.0 :// 192.168 . 1.189 : 50001 T1 Address Table: file://map/AMC13_AddressTable_K7. xml Pick an action (h for menu): Note: at first it complained it couldn't find AMC13 like below: [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# bin/AMC13Tool -u Connecting to AMC13... T2 ip 192.168.1.188 T2 ip 192.168.1.188 T2 ip 192.168.1.188 T2 ip 192.168.1.188 T1 ip 192.168.1.189 T1 ip 192.168.1.189 Serial Number 33 T2 URI: ipbusudp-1.3://192.168.1.188:50001 T2 Address Table: file://map/AMC13_AddressTable_S6.xml T1 URI: ipbusudp-1.3://192.168.1.189:50001 T1 Address Table: file://map/AMC13_AddressTable_V6.xml ***WARNING! AMC13 NOT FOUND AT THIS LOCATION!*** [root @dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# bin/AMC13Tool -u Connecting to AMC13... T2 ip 192 . 168 . 1 . 188 T2 ip 192 . 168 . 1 . 188 T2 ip 192 . 168 . 1 . 188 T2 ip 192 . 168 . 1 . 188 T1 ip 192 . 168 . 1 . 189 T1 ip 192 . 168 . 1 . 189 Serial Number 33 T2 URI: ipbusudp- 1 . 3 : //192.168.1.188:50001 T2 Address Table: file: //map/AMC13_AddressTable_S6.xml T1 URI: ipbusudp- 1 . 3 : //192.168.1.189:50001 T1 Address Table: file: //map/AMC13_AddressTable_V6.xml ***WARNING! AMC13 NOT FOUND AT THIS LOCATION!*** I had to make sure port enp5s0 (our MCH 1GbE connection) was up and had priority over enp1s0f1 (our AMC13 10GbE connection) on our network: [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# ip route show default via 10.163.105.1 dev eno1 proto dhcp metric 101 10.163.105.0/24 dev eno1 proto kernel scope link src 10.163.105.238 metric 101 192.168.1.0/24 dev enp5s0 proto kernel scope link src 192.168.1.100 metric 105 192.168.1.0/24 dev enp1s0f1 proto kernel scope link src 192.168.1.21 metric 106 192.168.122.0/24 dev virbr0 proto kernel scope link src 192.168.122.1 [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12] # ip route show default via 10 . 163 . 105 . 1 dev eno1 proto dhcp metric 101 10.163.105.0 / 24 dev eno1 proto kernel scope link src 10 . 163 . 105 . 238 metric 101 192.168.1.0 / 24 dev enp5s0 proto kernel scope link src 192 . 168 . 1 . 100 metric 105 192.168.1.0 / 24 dev enp1s0f1 proto kernel scope link src 192 . 168 . 1 . 21 metric 106 192.168.122.0 / 24 dev virbr0 proto kernel scope link src 192 . 168 . 122 . 1 A higher metric means worse priority. Then, it complained that it couldn't find T1: [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# bin/AMC13Tool -u Connecting to AMC13... T2 ip 192.168.1.188 T2 ip 192.168.1.188 T1 ip 192.168.1.189 T1 ip 192.168.1.189 Serial Number 33 T2 URI: ipbusudp-2.0://192.168.1.188:50001 T2 Address Table: file://map/AMC13_AddressTable_S6.xml T1 URI: ipbusudp-1.3://192.168.1.189:50001 T1 Address Table: file://map/AMC13_AddressTable_K7.xml ***WARNING! T1 NOT FOUND AT THIS LOCATION!*** [root @dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# bin/AMC13Tool -u Connecting to AMC13... T2 ip 192 . 168 . 1 . 188 T2 ip 192 . 168 . 1 . 188 T1 ip 192 . 168 . 1 . 189 T1 ip 192 . 168 . 1 . 189 Serial Number 33 T2 URI: ipbusudp- 2 . 0 : //192.168.1.188:50001 T2 Address Table: file: //map/AMC13_AddressTable_S6.xml T1 URI: ipbusudp- 1 . 3 : //192.168.1.189:50001 T1 Address Table: file: //map/AMC13_AddressTable_K7.xml ***WARNING! T1 NOT FOUND AT THIS LOCATION!*** To fix that, I had to just \"re-apply\" the config that set the ports cd /home/installation_testing/packages/experiment/lxedaq/amc13/amc13_v1_2_18/dev_tools/amc13Config/ ./applyConfig -n 33 cd /home/i nstallation_testing /packages/ experiment /lxedaq/ amc13 /amc13_v1_2_18/ dev_tools /amc13Config/ ./applyConfig -n 33 Run amc13_scripts/ky_init.amc from inside AMC13Tool [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# bin/AMC13Tool -u Connecting to AMC13... T2 ip 192.168.1.188 T2 ip 192.168.1.188 T1 ip 192.168.1.189 Serial Number 33 T2 URI: ipbusudp-2.0://192.168.1.188:50001 T2 Address Table: file://map/AMC13_AddressTable_S6.xml T1 URI: ipbusudp-2.0://192.168.1.189:50001 T1 Address Table: file://map/AMC13_AddressTable_K7.xml Pick an action (h for menu): fv Virtex Firmware Version: 0x8127 Spartan Firmware Version: 0x2d Pick an action (h for menu): do amc13_scripts/ky_init.amc Entering script file amc13_scripts/ky_init.amc *** Both chips have been issued a reset *** Enabling AMC inputs from list: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11 Link status: 04100fff Enable Fake Event Generator 'CONTROL1': 81270081 *****AMC13 Status***** Status display detail level: 1 Control 0: 4b000048 Monitor Buffer Empty TTC BCNT Error Control 1: 81270081 Create fake event at L1A Run Mode AMC Link Status: 0fff0fff AMC13 Enabled Inputs: 00, 01, 02, 03, 04, 05, 06, 07, 08, 09, 10, 11 AMC Input links locked: 00, 01, 02, 03, 04, 05, 06, 07, 08, 09, 10, 11 AMC Port Status: 0fff0fff AMC Link Versions incorrect: 00, 01, 02, 03, 04, 05, 06, 07, 08, 09, 10, 11 Unsynced AMC Ports: 00, 01, 02, 03, 04, 05, 06, 07, 08, 09, 10, 11 AMC Bc0 Status: 00000000 --No BC0s locked-- EVB Counters: (All 32-bit counters read 0x0) TTC BC0 err [0044]: 00000000 00000371 Run time [0048]: 00000000 00314f8f Ready time [004a]: 00000000 00222012 Busy time [004c]: 00000000 000fff01 L1A ovfl warn time [0050]: 00000000 00000001 AMC Counters: <---Link 00-----> <---Link 01-----> <---Link 02-----> <---Link 03-----> <---Link 04-----> <---Link 05-----> *******************************************All counters read 0x0******************************************* <---Link 06-----> <---Link 07-----> <---Link 08-----> <---Link 09-----> <---Link 10-----> <---Link 11-----> *******************************************All counters read 0x0******************************************* Writing to T1: 00000001: 00000000 Writing to T1: 00000003: 00001fff Writing to T1: 00000001: 00000187 Writing to T1: 0000001c: 80008000 Writing to T1: 00000018: 0003fff0 Writing to T1: 00000000: 00000010 Pick an action (h for menu): ^C [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# bin/AMC13Tool -u Connecting to AMC13... T2 ip 192.168.1.188 T2 ip 192.168.1.188 T1 ip 192.168.1.189 Serial Number 33 T2 URI: ipbusudp-2.0://192.168.1.188:50001 T2 Address Table: file://map/AMC13_AddressTable_S6.xml T1 URI: ipbusudp-2.0://192.168.1.189:50001 T1 Address Table: file://map/AMC13_AddressTable_K7.xml Pick an action (h for menu): fv Virtex Firmware Version: 0x8127 Spartan Firmware Version: 0x2d Pick an action (h for menu): do amc13_scripts/ky_init.amc Entering script file amc13_scripts/ky_init.amc *** Both chips have been issued a reset *** Enabling AMC inputs from list: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11 Link status: 04100fff Enable Fake Event Generator 'CONTROL1': 81270081 *****AMC13 Status***** Status display detail level: 1 Control 0: 4b000048 Monitor Buffer Empty TTC BCNT Error Control 1: 81270081 Create fake event at L1A Run Mode AMC Link Status: 0fff0fff AMC13 Enabled Inputs: 00, 01, 02, 03, 04, 05, 06, 07, 08, 09, 10, 11 AMC Input links locked: 00, 01, 02, 03, 04, 05, 06, 07, 08, 09, 10, 11 AMC Port Status: 0fff0fff AMC Link Versions incorrect: 00, 01, 02, 03, 04, 05, 06, 07, 08, 09, 10, 11 Unsynced AMC Ports: 00, 01, 02, 03, 04, 05, 06, 07, 08, 09, 10, 11 AMC Bc0 Status: 00000000 --No BC0s locked-- EVB Counters: (All 32-bit counters read 0x0) TTC BC0 err [0044]: 00000000 00000371 Run time [0048]: 00000000 00314f8f Ready time [004a]: 00000000 00222012 Busy time [004c]: 00000000 000fff01 L1A ovfl warn time [0050]: 00000000 00000001 AMC Counters: <---Link 00-----> <---Link 01-----> <---Link 02-----> <---Link 03-----> <---Link 04-----> <---Link 05-----> *******************************************All counters read 0x0******************************************* <---Link 06-----> <---Link 07-----> <---Link 08-----> <---Link 09-----> <---Link 10-----> <---Link 11-----> *******************************************All counters read 0x0******************************************* Writing to T1: 00000001: 00000000 Writing to T1: 00000003: 00001fff Writing to T1: 00000001: 00000187 Writing to T1: 0000001c: 80008000 Writing to T1: 00000018: 0003fff0 Writing to T1: 00000000: 00000010 Pick an action (h for menu): ^C Test Connection: Turn off enp5s0 as it will steal traffic from the 10GbE port on the same network ifdown enp5s0 ifdown enp5s0 Make sure enp1s0f1 is up, try pinging ifup enp1s0f1 [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# ping 192.168.1.32 PING 192.168.1.32 (192.168.1.32) 56(84) bytes of data. 64 bytes from 192.168.1.32: icmp_seq=1 ttl=64 time=0.161 ms 64 bytes from 192.168.1.32: icmp_seq=2 ttl=64 time=0.093 ms 64 bytes from 192.168.1.32: icmp_seq=3 ttl=64 time=0.058 ms ifup enp1s0f1 [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# ping 192.168.1.32 PING 192.168.1.32 (192.168.1.32) 56(84) bytes of data. 64 bytes from 192.168.1.32: icmp_seq =1 ttl =64 time =0.161 ms 64 bytes from 192.168.1.32: icmp_seq =2 ttl =64 time =0.093 ms 64 bytes from 192.168.1.32: icmp_seq =3 ttl =64 time =0.058 ms",
    "textLength": 10916
  },
  {
    "kind": "work-log",
    "title": "01_11_2026 - 01_17_2026.html",
    "fileName": "01_11_2026 - 01_17_2026.html",
    "url": "resources/work_logs/01_11_2026 - 01_17_2026.html",
    "createdDate": "2026-11-01",
    "text": "01/11/2026 - 01/17/2026 01/11/2026 - 01/17/2026 14/01/2026 13:53 I ran two deadtime estimate schemes. The later I thought would be more accurate, but that may not be the case. They both have this strange behavior for 1 and 2 channel cases. Scheme #1: Vary seperation between pulses and binary search on the condition: observed_rate >= 1.95 * pico_double_pulse_rate AND observed_num_channels_per_event >= 0.99 * num_channels_activate The idea behind this is we get the smallest pulse seperation such that we resolve both pulses and every channel is present. However, it does not guarentee the event builder does not stitch the same pulse into one event (i.e not splitting 2 events); though I don't think this happens because the event_builder's grouping threshold was set very low for these tests (~500ns). In these plots you can see the 1 channel and 2 channel cases break the pattern. their deadtime scales more aggressively as we increae the number of windows Scheme #2: Vary seperation between pulses and binary search on the condition: observed_number_of_packets_per_second >= 1.99*expected_number_of_packets_per_second where the expected number of packets per second is given by expected_number_of_packets_per_second = channels*windows*pico_double_pulse_rate and we compute the observed number of packets by computing the average number of packets in each midas event and multiplying by the event rate supplied by midas observed_number_of_packets_per_second = observed_event_rate*average_number_of_packets_per_event The idea is that now our scan is agnostic to if events are properly split or not. Let's say the event collector collected 2 digitized pulses into one midas event. Then we'd measure an event rate of our input rate (say 100 Hz) but we'd see twice as many packets per event. In other words observed_number_of_packets_per_second is agnostic to how the collector decides to group the packets We still see the same exact effect, meaning it was not a grouping artifact.",
    "textLength": 311
  },
  {
    "kind": "work-log",
    "title": "01_06_2025 - 07_06_2025.html",
    "fileName": "01_06_2025 - 07_06_2025.html",
    "url": "resources/work_logs/01_06_2025 - 07_06_2025.html",
    "createdDate": "2025-06-01",
    "text": "01/06/2025 - 07/06/2025 01/06/2025 - 07/06/2025 02/06/2025 21:54 I got the internal trigger working following the example nalu made for us. We put 3 copies of a square wave firing at the same rate as the external trigger into channels 0,1, and 2 on the board. If I set the trigger value for one of channel 0, 1, or 2 (and confusingly 4 and some other channels as well?) to an appropriate value (~40), I see triggers at the rate the pico is set to. Furthermore, trying to set set more than one trigger value (example, both channel 1 and 2 to trigger_value = 40) produces unexpected results, there are triggers but they are \"strange,\" they don't include the pulse in the digitized window. To determine the appropraite trigger value, I played with the threshold scan in Nalu Scope 0.20.2. I had to set the signal rate fairly high (~20kHz) before I saw obvious peaks. This can be controlled with the pico; most easily by using the script I have on the newest machine: pioneer@pioneer-MS-7D41:~/packages/software/pico_scripts$ pwd /home/pioneer/packages/software/pico_scripts pioneer@pioneer-MS-7D41:~/packages/software/pico_scripts$ ./change_trigger_rate.py --help usage: change_trigger_rate.py [-h] [--serial_port SERIAL_PORT] [--frequency FREQUENCY] [--pulse_width_ns PULSE_WIDTH_NS] [--hardware_name HARDWARE_NAME] [--pin_number PIN_NUMBER] Create and control a PWM hardware on the device. options: -h, --help show this help message and exit --serial_port SERIAL_PORT The serial port to which the device is connected. Default is /dev/ttyACM0. --frequency FREQUENCY Frequency for the PWM signal in Hz. Default is 10 Hz. --pulse_width_ns PULSE_WIDTH_NS Pulse width in nanoseconds (alternative to duty cycle). --hardware_name HARDWARE_NAME Name for the PWM hardware. Default is 'nalu_trigger_pwm'. --pin_number PIN_NUMBER Pin number for the PWM signal. Default is 15. pioneer@pioneer-MS-7D41:~/packages/software/pico_scripts$ pioneer@pioneer-MS-7D41:~/packages/software/pico_scripts$ pwd /home/pioneer/packages/software/pico_scripts pioneer@pioneer-MS-7D41:~/packages/software/pico_scripts$ ./change_trigger_rate.py --help usage: change_trigger_rate.py [-h] [--serial_port SERIAL_PORT] [--frequency FREQUENCY] [--pulse_width_ns PULSE_WIDTH_NS] [--hardware_name HARDWARE_NAME] [--pin_number PIN_NUMBER] Create and control a PWM hardware on the device. options: -h, --help show this help message and exit --serial_port SERIAL_PORT The serial port to which the device is connected. Default is /dev/ttyACM0. --frequency FREQUENCY Frequency for the PWM signal in Hz. Default is 10 Hz. --pulse_width_ns PULSE_WIDTH_NS Pulse width in nanoseconds (alternative to duty cycle). --hardware_name HARDWARE_NAME Name for the PWM hardware. Default is 'nalu_trigger_pwm'. --pin_number PIN_NUMBER Pin number for the PWM signal. Default is 15. pioneer@pioneer-MS-7D41:~/packages/software/pico_scripts$ The internal trigger behaves not as I'd expect. Instead of creating 3 UDP seperate packets for each channel's internal trigger, they're all put in one UDP packet. This may just be because they're very coincident in time(?). The event collector groups them in time Here's an example of raw UDP readout, with the 3 channel packets highlighted: 21:49:57.369438 IP 192.168.1.59.4660 > pioneer-MS-7D41.12345: UDP, length 238 0x0000: 4500 010a 588b 4000 4011 5dcb c0a8 013b E...X.@.@.]....; 0x0010: c0a8 0101 1234 3039 00f6 a963 00de 0000 .....409...c.... 0x0020: 0000 0000 0000 0000 0000 0000 0e01 0a3a 0x0030: 0594 001f 028e 02b4 02b0 02b8 02b3 02b2 0x0040: 02bd 02b9 02bb 02c1 0296 02b7 029e 02b8 0x0050: 0296 02bd 02ba 02a6 02af 02c4 02d4 02cb 0x0060: 02b0 02b2 02c5 02c6 02bc 02a8 027a 02ba 0x0070: 02ba 02d0 fa5a 0e02 0a3a 0594 001f 03c5 0x0080: 03c2 03d8 040c 03fa 03d8 03d9 03ec 03e2 0x0090: 03d1 03d1 03f0 03d8 03bc 03d8 03f5 03fe 0x00a0: 03f0 03f8 03e4 03d8 03da 03ca 03d3 03e0 0x00b0: 03de 0408 03e1 03dc 03e4 03c7 03d4 fa5a 0x00c0: 0e00 0a3a 0594 001f 0392 0380 03a2 03b9 0x00d0: 036e 038f 0382 037f 0389 0384 039d 0378 0x00e0: 037c 037d 0386 039c 0396 03a1 03af 03ad 0x00f0: 0397 03ad 038c 037e 0394 039e 03ab 038a 0x0100: 03a4 03a1 0399 03b2 fa5a The bytes corresponding to the timestamp are: First packet: 0a3a 0594 Second Packet: 0a3a 0594 Third Packet: 0a3a 0594 Meaning there is no way to split these packets in time. The result of this is I don't think there is a way to pre-determine the number of packets expected in an \"event\" when using the internal trigger . In this way, we cannot tell when an \"event\" is complete. This gives two options: Say every event is \"complete\" when the trigger type is \"self\". I don't like this for this reason: It gives a chance to split one event into multiple if it's taken from the buffer \"mid formation.\" Events are marked as complete if a certain amount of time (the time threshold) has passed since they were created. I don't like this for these reasons: Every event is now delayed by the time_threshold parameter We need either: a) a conversion from clocks ticks to second or b) a way to access the current clock tick of the board. The former is likely board dependant will be imprecise to some degree. The latter destroys the philosophy that the collector does not talk to the board at all. I thnk option 2 is best. We just need to add an ODB parameter for board_clock_frequency . A more user friendly approach would be to just get that from the model parameter (i.e. hardcode the specs for each model), but I don't know the specs for each nalu board model so I can't easily do that. The caveat of this is that the time_threshold paramteter should be \"minimized\" to minimize waiting times for getting events out of the buffer. This issue could be solved if nalu had some sort of \"event_id\" stamp on their packets. 02/06/2025 23:47 I have the internal trigger working \"as expected\", there are some specific ODB parameters to look out for: Enabled Channels : in my tests, adding more enabled channels to the self trigger has no affect unless those channels have a signal that triggers on threshold. So enable whichever ones you want: 0, 1, and 2 have signals in them as of now. /Equipment/HDSoC-00/Settings/nalu_board_controller/nalu_capture/high_reference and /Equipment/HDSoC-00/Settings/nalu_board_controller/nalu_capture/low_reference should be set to 15 and 10 respectively, though I did see triggers when they were set to other values; maybe you can see what data is spit out in that case. /Equipment/HDSoC-00/Settings/nalu_event_collector/nalu_event_builder/time_threshold should be a small number (for example, 500 corresponds to a max rate of ~50kHz). This is how long an event must exist before the collector says it's \"ready\". See why I did this above. /Equipment/HDSoC-00/Settings/nalu_event_collector/nalu_event_builder/clock_frequency is a new setting whichis the clock frequency in Hz (I'm not sure what clock it actually is, but it's each \"tick\" in the nalu timestamp). It's used to convert the time threshold (clock ticks) to seconds; this is how the collector determines when an event is ready (again, see above). I haven't tested, but the midas file event output should have the same structure; I.e. one can use Sean's unpacker on the files for external or internal triggering. At some point I do want to add the time_threshold parameter to the event information because it may be useful in analysis for the internal trigger if triggers that \"belong together\" start to get seperated.",
    "textLength": 1242
  },
  {
    "kind": "work-log",
    "title": "05_01_2025 - 11_01_2025.html",
    "fileName": "05_01_2025 - 11_01_2025.html",
    "url": "resources/work_logs/05_01_2025 - 11_01_2025.html",
    "createdDate": "2025-01-05",
    "text": "05/01/2025 - 11/01/2025 05/01/2025 - 11/01/2025 06/01/2025 15:03 By changing this line iov --> __iov in the 2017 driver (Xilinx Answer 65444), I was able to get it to compile on ALMA9 #if LINUX_VERSION_CODE >= KERNEL_VERSION(3,15,0) static ssize_t sg_read_iter (struct kiocb *iocb, struct iov_iter *from) { dbg_sg(\"%s()\\n\", __func__); return sg_aio_read_write(iocb, from->__iov, from->nr_segs, iocb->ki_pos, 0); } static ssize_t sg_write_iter (struct kiocb *iocb, struct iov_iter *iter) { dbg_sg(\"%s()\\n\", __func__); return sg_aio_read_write(iocb, iter->__iov, iter->nr_segs, iocb->ki_pos, 1); } # if LINUX_VERSION_CODE >= KERNEL_VERSION(3,15,0) static ssize_t sg_read_iter ( struct kiocb *iocb, struct iov_iter * from ) { dbg_sg( \"%s()\\n\" , __func__); return sg_aio_read_write(iocb, from ->__iov, from ->nr_segs, iocb->ki_pos, 0 ); } static ssize_t sg_write_iter ( struct kiocb *iocb, struct iov_iter *iter ) { dbg_sg( \"%s()\\n\" , __func__); return sg_aio_read_write(iocb, iter->__iov, iter->nr_segs, iocb->ki_pos, 1 ); } This restored the rates I was seeing using this driver on CentOS7, even when using my C++ library: I was also able to get about a 20% rate boost when using 2 channnels in midas (from ~1GB/s --> 1.2GB/s)",
    "textLength": 185
  },
  {
    "kind": "work-log",
    "title": "18_02_2024 - 24_02_2024.html",
    "fileName": "18_02_2024 - 24_02_2024.html",
    "url": "resources/work_logs/18_02_2024 - 24_02_2024.html",
    "createdDate": "2024-02-18",
    "text": "18/02/2024 - 24/02/2024 18/02/2024 - 24/02/2024 20/02/2024 00:02 I'm currently trying to ping the MCH. I got rid of the ethernet splitter (network box, or whatever it's called) and directly connected the MCH to 'be'. Both ports are blinking, but not data is being transferred to the MCH as far as I'm aware. These are the network settings I tried to use: [root@dhcp-10-163-105-238 network-scripts]# cat ifcfg-enp5s0 # # Connect to WaveDream Board # #TYPE=Ethernet #BOOTPROTO=static #IPADDR=192.168.248.251 #NETMASK=255.255.0.0 #IPV4_FAILURE_FATAL=no #IPV6INIT=no #IPV6_AUTOCONF=yes #IPV6_DEFROUTE=yes #IPV6_PEERDNS=yes #IPV6_PEERROUTES=yes #IPV6_FAILURE_FATAL=no #NAME=enp5s0 #DEVICE=enp5s0 #ONBOOT=yes # # Connect to FE01 # #DEVICE=\"enp5s0\" #NM_CONTROLLED=\"no\" #ONBOOT=yes #TYPE=Ethernet #BOOTPROTO=static #IPADDR=10.0.0.2 #NETMASK=255.255.255.0 # # Default Configuration # TYPE=Ethernet PROXY_METHOD=none BROWSER_ONLY=no BOOTPROTO=dhcp DEFROUTE=yes IPV4_FAILURE_FATAL=no IPV6INIT=yes IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_FAILURE_FATAL=no IPV6_ADDR_GEN_MODE=stable-privacy NAME=enp5s0 UUID=c7e67db0-b884-4b86-935e-483b1bbf52dc DEVICE=enp5s0 ONBOOT=no [root@dhcp-10-163-105-238 network-scripts] # cat ifcfg-enp5s0 # # Connect to WaveDream Board # #TYPE=Ethernet #BOOTPROTO=static #IPADDR=192.168.248.251 #NETMASK=255.255.0.0 #IPV4_FAILURE_FATAL=no #IPV6INIT=no #IPV6_AUTOCONF=yes #IPV6_DEFROUTE=yes #IPV6_PEERDNS=yes #IPV6_PEERROUTES=yes #IPV6_FAILURE_FATAL=no #NAME=enp5s0 #DEVICE=enp5s0 #ONBOOT=yes # # Connect to FE01 # #DEVICE=\"enp5s0\" #NM_CONTROLLED=\"no\" #ONBOOT=yes #TYPE=Ethernet #BOOTPROTO=static #IPADDR=10.0.0.2 #NETMASK=255.255.255.0 # # Default Configuration # TYPE =Ethernet PROXY_METHOD =none BROWSER_ONLY = no BOOTPROTO =dhcp DEFROUTE = yes IPV4_FAILURE_FATAL = no IPV6INIT = yes IPV6_AUTOCONF = yes IPV6_DEFROUTE = yes IPV6_FAILURE_FATAL = no IPV6_ADDR_GEN_MODE =stable-privacy NAME =enp5s0 UUID =c7e67db0-b884- 4 b86- 935 e- 483 b1bbf52dc DEVICE =enp5s0 ONBOOT = no I tired pinging the MCH at it's factory default adresses but no luck: ping 192.168.1.230 ping 192.168.1.231 ping 192.168.16.17 ping 192.168.1.41 ping 192.168.1.230 ping 192.168.1.231 ping 192.168.16.17 ping 192.168.1.41 The last one is just he address from Tim's notes. Here is the relevant part of ifconfig: enp5s0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST> mtu 1500 inet 10.0.0.1 netmask 255.255.255.0 broadcast 10.0.0.255 inet6 fe80::f0f4:a75c:c399:9a9a prefixlen 64 scopeid 0x20<link> ether 00:1b:21:59:59:a5 txqueuelen 1000 (Ethernet) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 49 bytes 7659 (7.4 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 device interrupt 16 memory 0xfbac0000-fbae0000 enp5s0 : flags= 4163 <UP,BROADCAST,RUNNING,MULTICAST> mtu 1500 inet 10.0.0.1 netmask 255.255.255.0 broadcast 10.0.0.255 inet6 fe80::f0f4:a75c:c399: 9 a9a prefixlen 64 scopeid 0 x20<link> ether 00 : 1 b: 21 : 59 : 59 :a5 txqueuelen 1000 (Ethernet) RX packets 0 bytes 0 ( 0 . 0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 49 bytes 7659 ( 7 . 4 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 device interrupt 16 memory 0 xfbac0000-fbae0000 20/02/2024 00:36 I also tried connecting the ethernet ports of the MCH to our newest desktop, hoping it would automatically lease and IP from the MCH. This did not work even after restarting both the crate and the computer. 20/02/2024 00:57 I looked at the way we connected to the wavedream, and basically copy and pasted those network script settings into /etc/sysconfig/networkscripts/ifcfg-enp5s0 so that it looked like this (effectively, more comments that are excluded here): # # Connect to MCH # TYPE=Ethernet BOOTPROTO=static IPADDR=192.168.1.1 NETMASK=255.255.0.0 IPV4_FAILURE_FATAL=no IPV6INIT=no IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_PEERDNS=yes IPV6_PEERROUTES=yes IPV6_FAILURE_FATAL=no NAME=enp5s0 DEVICE=enp5s0 ONBOOT=yes # # Connect to MCH # TYPE =Ethernet BOOTPROTO =static IPADDR = 192.168 . 1.1 NETMASK = 255.255 . 0.0 IPV4_FAILURE_FATAL = no IPV6INIT = no IPV6_AUTOCONF = yes IPV6_DEFROUTE = yes IPV6_PEERDNS = yes IPV6_PEERROUTES = yes IPV6_FAILURE_FATAL = no NAME =enp5s0 DEVICE =enp5s0 ONBOOT = yes Then I was able to ping the MCH as in Tim's notes: [root@dhcp-10-163-105-238 network-scripts]# ping 192.168.1.41 PING 192.168.1.41 (192.168.1.41) 56(84) bytes of data. 64 bytes from 192.168.1.41: icmp_seq=1 ttl=255 time=0.280 ms 64 bytes from 192.168.1.41: icmp_seq=2 ttl=255 time=0.331 ms 64 bytes from 192.168.1.41: icmp_seq=3 ttl=255 time=0.315 ms ... [root@dhcp-10-163-105-238 network-scripts]# ping 192.168.1.41 PING 192.168.1.41 (192.168.1.41) 56(84) bytes of data. 64 bytes from 192.168.1.41: icmp_seq =1 ttl =255 time =0.280 ms 64 bytes from 192.168.1.41: icmp_seq =2 ttl =255 time =0.331 ms 64 bytes from 192.168.1.41: icmp_seq =3 ttl =255 time =0.315 ms .. . Though, I cannot ping any of the adresses in the MCH \"getting started\" guide: [root@dhcp-10-163-105-238 network-scripts]# ping 192.168.1.230 PING 192.168.1.230 (192.168.1.230) 56(84) bytes of data. ^C --- 192.168.1.230 ping statistics --- 2 packets transmitted, 0 received, 100% packet loss, time 999ms [root@dhcp-10-163-105-238 network-scripts]# ping 192.168.1.231 PING 192.168.1.231 (192.168.1.231) 56(84) bytes of data. ^C --- 192.168.1.231 ping statistics --- 3 packets transmitted, 0 received, 100% packet loss, time 1999ms [root@dhcp-10-163-105-238 network-scripts]# ping 192.168.16.17 PING 192.168.16.17 (192.168.16.17) 56(84) bytes of data. ^C --- 192.168.16.17 ping statistics --- 1 packets transmitted, 0 received, 100% packet loss, time 0ms [root@dhcp-10-163-105-238 network-scripts]# [root@dhcp- 10-163-105-238 network-scripts]# ping 192.168.1.230 PING 192.168.1.230 ( 192.168.1.230 ) 56 ( 84 ) bytes of data. ^C --- 192.168.1.230 ping statistics --- 2 packets transmitted, 0 received, 100 % packet loss, time 999m s [root@dhcp- 10-163-105-238 network-scripts]# ping 192.168.1.231 PING 192.168.1.231 ( 192.168.1.231 ) 56 ( 84 ) bytes of data. ^C --- 192.168.1.231 ping statistics --- 3 packets transmitted, 0 received, 100 % packet loss, time 1999m s [root@dhcp- 10-163-105-238 network-scripts]# ping 192.168.16.17 PING 192.168.16.17 ( 192.168.16.17 ) 56 ( 84 ) bytes of data. ^C --- 192.168.16.17 ping statistics --- 1 packets transmitted, 0 received, 100 % packet loss, time 0m s [root@dhcp- 10-163-105-238 network-scripts]# 20/02/2024 01:34 I tried following further steps in Tim's notes: particularly 3) SET LINK TO AMC13 cd /home/daq/DAQ/amc13/amc13StandaloneMAN_2014-05-12 source uhalEnv.sh #set ip addresses in amc13 amc13Config/applyConfig.py -n 33 Applying IP addresses to board in slot 13 from host 192.168.1.41 #initially got message below - problem was amc13 not seated properly Unable to send RAW commaQnd (channel=0x7 netfn=0x32 lun=0x0 cmd=0x33 rsp=0xc3): Timeout 3) SET LINK TO AMC13 cd /home/daq/DAQ/amc13/amc13StandaloneMAN_2014-05-12 source uhalEnv.sh #set ip addresses in amc13 amc13Config/applyConfig.py -n 33 Applying IP addresses to board in slot 13 from host 192.168.1.41 #initially got message below - problem was amc13 not seated properly Unable to send RAW commaQnd ( channel =0x7 netfn =0x32 lun =0x0 cmd =0x33 rsp =0xc3): Timeout I had to hardcode these lines: #host = options.host host = \"192.168.1.41\" #host = options.host host = \"192.168.1.41\" Because it was detector the \"wrong\" IP: [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# amc13Config/applyConfig.py -n 33 Applying IP addresses to board in slot 13 from host 192.168.1.230 Setting IP addresses using SN 33 Error: Unable to establish LAN session Error: Unable to establish IPMI v1.5 / RMCP session Error: Unable to establish LAN session Error: Unable to establish IPMI v1.5 / RMCP session [root@dhcp -10 -163 -105 -238 amc13StandaloneMAN_2014 -05 -12 ]# amc13Config/applyConfig.py -n 33 Applying IP addresses to board in slot 13 from host 192.168.1.230 Setting IP addresses using SN 33 Error: Unable to establish LAN session Error: Unable to establish IPMI v1.5 / RMCP session Error: Unable to establish LAN session Error: Unable to establish IPMI v1.5 / RMCP session (Curiously enough, this is the \"correct\" IP in the \"MCH getting started\" guide. I don't know how this IP was picked, somehow an imported class has the information). That got me further, but I have the same issue as Tim described: [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# amc13Config/applyConfig.py -n 33 Applying IP addresses to board in slot 13 from host 192.168.1.41 Setting IP addresses using SN 33 Unable to send RAW command (channel=0x7 netfn=0x32 lun=0x0 cmd=0x33) Unable to send RAW command (channel=0x7 netfn=0x32 lun=0x0 cmd=0x33) [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# amc13Config/applyConfig.py -n 33 Applying IP addresses to board in slot 13 from host 192.168.1.41 Setting IP addresses using SN 33 Unable to send RAW command ( channel =0x7 netfn =0x32 lun =0x0 cmd =0x33) Unable to send RAW command ( channel =0x7 netfn =0x32 lun =0x0 cmd =0x33) So I tried reseating both the AMC and MCH, with no luck. 20/02/2024 01:38 Really what I want to do is ssh into the MCH so I can follow the steps Lawrence gave. However, because we have a different module, I'm unsure how to do that. sshing into the one address I can ping gives: [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# ssh root@192.168.1.41 ssh: connect to host 192.168.1.41 port 22: Connection refused [root@dhcp -10 -163 -105 -238 amc13StandaloneMAN_2014 -05 -12 ]# ssh root@192.168.1.41 ssh: connect to host 192.168.1.41 port 22: Connection refused I'm not sure there is a version of linux running on our MCH because the model is different. 20/02/2024 15:43 Tried following this manual https://nateurope.com/wp-content/uploads/2022/09/NAT-MCH_UsersManual.pdf to enable sshing into the MCH. In particular page 37-38 claims I should be able to edit this in the global settings. However, I am never prompted with the option: [root@dhcp-10-163-105-238 ~]# telnet 192.168.1.41 Trying 192.168.1.41... Connected to 192.168.1.41. Escape character is '^]'. Welcome to NAT-MCH nat> mchcfg MCH_CFG: ERR - unknown configuration mode 1312904301 MCH CFG: configuration modes [ 0] no action [ 1] print complete configuration [ 2] reset to defaults [ 3] modify MCH global configuration [ 4] modify ShM configuration [ 5] modify CM configuration [ 6] modify SEL configuration [ 7] modify GbE switch configuration [10] modify NTP configuration [11] modify DHCP configuration [ ?] print menu [ h] print menu [ q] quit and save configuration Enter configuration mode (RET=0/0x0): 3 MCH global parameter: --------------------- remote interfaces: RMCP access: enabled telnet access: enabled WEB access: enabled IP address source Mgmt: board configuration RMCP session activity timeout minutes: 0 min RMCP session activity timeout seconds: 60 sec default fan level: 30 percent MCH configuration flags: Enable backward compatibility V2.4: no Enable alternative cooling scheme: no Control rear transition module fans: no MCH remote interfaces Enable RMCP access (y/n) (RET=y): y Enable telnet access (y/n) (RET=y): y Enable WEB access (y/n) (RET=y): y MCH IP address source: no IP address: 0 board configuration: 1 DHCP: 2 ShM IP link record: 3 CM IP link record: 4 Enter IP address source Mgmt (dec) (RET=1/0x1): 1 Enter session activity timeout (dec, minutes) (RET=0/0x0): 0 Enter session activity timeout (dec, seconds) (RET=60/0x3c): 60 Enter default fan level (dec, percent) (RET=30/0x1e): 30 MCH configuration flags: Enable backward compatibility V2.4 (y/n) (RET=n): n Enable alternative cooling scheme (y/n) (RET=n): n Control rear transition module fans (y/n) (RET=n): n Enter configuration mode (RET=0/0x0): [root@dhcp-10-163-105-238 ~]# telnet 192.168.1.41 Trying 192.168.1.41... Connected to 192.168.1.41. Escape character is '^]'. Welcome to NAT-MCH nat> mchcfg MCH_CFG: ERR - unknown configuration mode 1312904301 MCH CFG: configuration modes [ 0] no action [ 1] print complete configuration [ 2] reset to defaults [ 3] modify MCH global configuration [ 4] modify ShM configuration [ 5] modify CM configuration [ 6] modify SEL configuration [ 7] modify GbE switch configuration [10] modify NTP configuration [11] modify DHCP configuration [ ?] print menu [ h] print menu [ q] quit and save configuration Enter configuration mode (RET=0/0x0): 3 MCH global parameter: --------------------- remote interfaces: RMCP access: enabled telnet access: enabled WEB access: enabled IP address source Mgmt: board configuration RMCP session activity timeout minutes: 0 min RMCP session activity timeout seconds: 60 sec default fan level: 30 percent MCH configuration flags: Enable backward compatibility V2.4: no Enable alternative cooling scheme: no Control rear transition module fans: no MCH remote interfaces Enable RMCP access (y/n) (RET=y): y Enable telnet access (y/n) (RET=y): y Enable WEB access (y/n) (RET=y): y MCH IP address source: no IP address: 0 board configuration: 1 DHCP: 2 ShM IP link record: 3 CM IP link record: 4 Enter IP address source Mgmt (dec) (RET=1/0x1): 1 Enter session activity timeout (dec, minutes) (RET=0/0x0): 0 Enter session activity timeout (dec, seconds) (RET=60/0x3c): 60 Enter default fan level (dec, percent) (RET=30/0x1e): 30 MCH configuration flags: Enable backward compatibility V2.4 (y/n) (RET=n): n Enable alternative cooling scheme (y/n) (RET=n): n Control rear transition module fans (y/n) (RET=n): n Enter configuration mode (RET=0/0x0): The guide has this written a few times: 2.2.5 Console Port \u2013 USB / Telnet / SSH The console port provides an interface to the Command Line Interface (CLI) of the onboard CPU. The console interface can be used to set the operational and configuration parameters of the NAT-MCH. Once the IP configuration has been set, the console interface can be switched to a Telnet or SSH session by connecting via Telnet/SSH. In case a password had been configured for a Telnet session, a check of this password is done when starting the Telnet session. For SSH sessions this password check is mandatory. For details regarding configuration of a Telnet/SSH password, please refer to chapter 8 \u201cCommand line interface\u201d. So I checked Chapter 8 and tried running this commnad: ip IP configuration: Configures IP addresses, net mask, broadcast address, and gateway. But it doesn't appear to do anything: nat> ip MCH_CFG: ERR - unknown configuration mode 1312904297 MCH CFG: configuration modes [ 0] no action [ 1] print complete configuration [ 2] reset to defaults [ 3] modify MCH global configuration [ 4] modify ShM configuration [ 5] modify CM configuration [ 6] modify SEL configuration [ 7] modify GbE switch configuration [10] modify NTP configuration [11] modify DHCP configuration [ ?] print menu [ h] print menu [ q] quit and save configuration Enter configuration mode (RET=0/0x0): nat> ip MCH_CFG: ERR - unknown configuration mode 1312904297 MCH CFG: configuration modes [ 0] no action [ 1] print complete configuration [ 2] reset to defaults [ 3] modify MCH global configuration [ 4] modify ShM configuration [ 5] modify CM configuration [ 6] modify SEL configuration [ 7] modify GbE switch configuration [10] modify NTP configuration [11] modify DHCP configuration [ ?] print menu [ h] print menu [ q] quit and save configuration Enter configuration mode (RET= 0 / 0 x0): 20/02/2024 16:21 Tried changing network script for the 10GbE ports to look more like the one we used to connect to the MCH Port 1: # # Connect to AMC # TYPE=Ethernet BOOTPROTO=static IPADDR=192.168.1.2 NETMASK=255.255.0.0 IPV4_FAILURE_FATAL=no IPV6INIT=no IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_PEERDNS=yes IPV6_PEERROUTES=yes IPV6_FAILURE_FATAL=no NAME=enp1s0f0 DEVICE=enp1s0f0 ONBOOT=yes # # Connect to AMC # TYPE =Ethernet BOOTPROTO =static IPADDR = 192.168 . 1.2 NETMASK = 255.255 . 0.0 IPV4_FAILURE_FATAL = no IPV6INIT = no IPV6_AUTOCONF = yes IPV6_DEFROUTE = yes IPV6_PEERDNS = yes IPV6_PEERROUTES = yes IPV6_FAILURE_FATAL = no NAME =enp1s0f0 DEVICE =enp1s0f0 ONBOOT = yes Port 2: # # Connect to AMC # TYPE=Ethernet BOOTPROTO=static IPADDR=192.168.1.3 NETMASK=255.255.0.0 IPV4_FAILURE_FATAL=no IPV6INIT=no IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_PEERDNS=yes IPV6_PEERROUTES=yes IPV6_FAILURE_FATAL=no NAME=enp1s0f1 DEVICE=enp1s0f1 ONBOOT=yes # # Connect to AMC # TYPE =Ethernet BOOTPROTO =static IPADDR = 192.168 . 1.3 NETMASK = 255.255 . 0.0 IPV4_FAILURE_FATAL = no IPV6INIT = no IPV6_AUTOCONF = yes IPV6_DEFROUTE = yes IPV6_PEERDNS = yes IPV6_PEERROUTES = yes IPV6_FAILURE_FATAL = no NAME =enp1s0f1 DEVICE =enp1s0f1 ONBOOT = yes did ifdown enp1s0f0 ifdown enp1s0f1 ifup enp1s0f0 ifup enp1s0f1 ifdown enp1s0f0 ifdown enp1s0f1 ifup enp1s0f0 ifup enp1s0f1 But got no further, still get the same error: [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# amc13Config/applyConfig.py -n 33 Applying IP addresses to board in slot 13 from host 192.168.1.41 Setting IP addresses using SN 33 Unable to send RAW command (channel=0x7 netfn=0x32 lun=0x0 cmd=0x33) Unable to send RAW command (channel=0x7 netfn=0x32 lun=0x0 cmd=0x33) [root@dhcp-10-163-105-238 amc13StandaloneMAN_2014-05-12]# amc13Config/applyConfig.py -n 33 Applying IP addresses to board in slot 13 from host 192.168.1.41 Setting IP addresses using SN 33 Unable to send RAW command ( channel =0x7 netfn =0x32 lun =0x0 cmd =0x33) Unable to send RAW command ( channel =0x7 netfn =0x32 lun =0x0 cmd =0x33) 20/02/2024 16:24 I realized that this curiosity I had (Curiously enough, this is the \"correct\" IP in the \"MCH getting started\" guide. I don't know how this IP was picked, somehow an imported class has the information). Is picked in the file amc13Config/systemVars.py . So I wrote the correct IP in this file and undid my edits to amc13Config/applyConfig.py . 22/02/2024 01:12 I noticed whenever I use the development board \"PCI Express\" IP block (really a PCIe block with AXI interface for DDR3) I get the following warning: WARNING: [IP_Flow 19-3374] An attempt to modify the value of disabled parameter 'Xlnx_Ref_Board' from 'None' to 'NEREID' has been ignored for IP 'design_1_xdma_0_0/design_1_xdma_0_0_pcie2_ip It doesn't stop validation, bitstream generation, or anything else. 22/02/2024 01:40 Tried a design that is just the development boards \"PCI Express\" block. I ran block automation and there was no option for connection automation (everything was connected). I had 2 warnings I ignored: \"WARNING: [BD 41-2670] Found an incomplete address path from address space '/xdma_0/M_AXI' to master interface '/xdma_0/M_AXI'. Please either complete or remove this path to resolve.\" WARNING: [IP_Flow 19-3374] An attempt to modify the value of disabled parameter 'Xlnx_Ref_Board' from 'None' to 'NEREID' has been ignored for IP 'design_1_xdma_0_0/design_1_xdma_0_0_pcie2_ip But I was still able to generate a bitstream and program the board's flash memory with the generated .bin file. I was unable to see the board with lspci or lspci -vv on the 'fe01' computer. 22/02/2024 01:47 I tried making a block design using Vivado's \"7 Series Integrated Block for PCI Express.\" I couldn't even get a valid design. I tried running connection automation after configuring the block as described in https://numato.com/kb/getting-started-with-pci-express-on-nereid/ . Instead of generating an example project, I just tried to run the connection automation instead. I don't know how to resolve this critical warning CRITICAL WARNING: [BD 41-759] The input pins (listed below) are either not connected or do not have a source port, and they don't have a tie-off specified. These pins are tied-off to all 0's to avoid error in Implementation flow. Please check your design and connect them as needed: /pcie_7x_0/s_axis_tx_tvalid /pcie_7x_0/sys_rst_n CRITICAL WARNING: [BD 41-759] The input pins (listed below) are either not connected or do not have a source port, and they don't have a tie-off specified. These pins are tied-off to all 0's to avoid error in Implementation flow. Please check your design and connect them as needed: /pcie_7x_0/s_axis_tx_tvalid /pcie_7x_0/sys_rst_n I.e. I don't know what to put into the input pins. I especially don't know what to put into the output pins. I have the same problem trying to insert the block into our working microblazer design. 22/02/2024 02:21 In the product guide for the 7 Series Integrated Block for PCI Express Product Guide (PG054) ( https://docs.xilinx.com/r/en-US/pg054-7series-pcie/Minimum-Device-Requirements ) I noticed this line: Kintex-7 FBG484 package supports only x1, x2, and x4 operation; x8 is not supported. This seems to suggest this block will NOT work for out HTGK700 board, at least not utilzing all 8 lanes. 22/02/2024 02:39 After skipping through 7 Series Integrated Block for PCI Express Product Guide (PG054) ( https://docs.xilinx.com/r/en-US/pg054-7series-pcie ), I realized there's not much in there that can help us with this block. My goal was to figure out how to 'wire up' the block becuase I know what the \"names\" of the \"pcie invovled\" pins are from the board configuration files ( you can find that here https://github.com/numato/vivadoBSP/blob/main/NereidDevBoard7K160T/3.0/part0_pins.xml , below is a snippet): <pin index=\"181\" name =\"pcie_mgt_clkn\" loc=\"K5\"/> <pin index=\"182\" name =\"pcie_mgt_clkp\" loc=\"K6\"/> <pin index=\"183\" name =\"pcie_perstn_rst\" iostandard=\"LVCMOS33\" loc=\"E21\"/> <pin index=\"184\" name =\"pcie_rx0_n\" loc=\"J4\"/> <pin index=\"185\" name =\"pcie_rx1_n\" loc=\"L4\"/> <pin index=\"186\" name =\"pcie_rx2_n\" loc=\"N4\"/> <pin index=\"187\" name =\"pcie_rx3_n\" loc=\"R4\"/> <pin index=\"188\" name =\"pcie_rx0_p\" loc=\"J3\"/> <pin index=\"189\" name =\"pcie_rx1_p\" loc=\"L3\"/> <pin index=\"190\" name =\"pcie_rx2_p\" loc=\"N3\"/> <pin index=\"191\" name =\"pcie_rx3_p\" loc=\"R3\"/> <pin index=\"192\" name =\"pcie_tx0_n\" loc=\"H2\"/> <pin index=\"193\" name =\"pcie_tx1_n\" loc=\"K2\"/> <pin index=\"194\" name =\"pcie_tx2_n\" loc=\"M2\"/> <pin index=\"195\" name =\"pcie_tx3_n\" loc=\"P2\"/> <pin index=\"196\" name =\"pcie_tx0_p\" loc=\"H1\"/> <pin index=\"197\" name =\"pcie_tx1_p\" loc=\"K1\"/> <pin index=\"198\" name =\"pcie_tx2_p\" loc=\"M1\"/> <pin index=\"199\" name =\"pcie_tx3_p\" loc=\"P1\"/> <pin index=\"181\" name =\"pcie_mgt_clkn\" loc=\"K5\"/> <pin index=\"182\" name =\"pcie_mgt_clkp\" loc=\"K6\"/> <pin index=\"183\" name =\"pcie_perstn_rst\" iostandard=\"LVCMOS33\" loc=\"E21\"/> <pin index=\"184\" name =\"pcie_rx0_n\" loc=\"J4\"/> <pin index=\"185\" name =\"pcie_rx1_n\" loc=\"L4\"/> <pin index=\"186\" name =\"pcie_rx2_n\" loc=\"N4\"/> <pin index=\"187\" name =\"pcie_rx3_n\" loc=\"R4\"/> <pin index=\"188\" name =\"pcie_rx0_p\" loc=\"J3\"/> <pin index=\"189\" name =\"pcie_rx1_p\" loc=\"L3\"/> <pin index=\"190\" name =\"pcie_rx2_p\" loc=\"N3\"/> <pin index=\"191\" name =\"pcie_rx3_p\" loc=\"R3\"/> <pin index=\"192\" name =\"pcie_tx0_n\" loc=\"H2\"/> <pin index=\"193\" name =\"pcie_tx1_n\" loc=\"K2\"/> <pin index=\"194\" name =\"pcie_tx2_n\" loc=\"M2\"/> <pin index=\"195\" name =\"pcie_tx3_n\" loc=\"P2\"/> <pin index=\"196\" name =\"pcie_tx0_p\" loc=\"H1\"/> <pin index=\"197\" name =\"pcie_tx1_p\" loc=\"K1\"/> <pin index=\"198\" name =\"pcie_tx2_p\" loc=\"M1\"/> <pin index=\"199\" name =\"pcie_tx3_p\" loc=\"P1\"/> But I didn't see anything that helped me in that regard 22/02/2024 16:23 Plugging in an FC7 and WFD5 I am able to see the components appear over telnet in the crate IDB: print found devices ---------------------------------------------- FRU type i2c state sensors name ---------------------------------------------- 0 MCH1 20 M4 64 NMCH-CM 3 MCH1 10 M4 12 NAT-MCH-MCMC 13 AMC9 82 M4 31 ICL-CERN FC7 15 AMC11 86 M4 11 CU WFD5 30 AMC26 a4 M4 9 BU AMC13 40 CU1 a8 M4 22 VT VT095 41 CU2 aa M4 19 VT VT095 50 PM1 c2 M4 39 VT UTC010 128 ShMC1 00 M0 0 <none> 253 ShFRU1 f4 M0 0 <Carrier FRU> 254 ShFRU1 f4 M0 0 <Shelf FRU> ---------------------------------------------- found 11 devices IDB: print found devices ---------------------------------------------- FRU type i2c state sensors name ---------------------------------------------- 0 MCH1 20 M4 64 NMCH-CM 3 MCH1 10 M4 12 NAT-MCH-MCMC 13 AMC9 82 M4 31 ICL-CERN FC7 15 AMC11 86 M4 11 CU WFD5 30 AMC26 a4 M4 9 BU AMC13 40 CU1 a8 M4 22 VT VT095 41 CU2 aa M4 19 VT VT095 50 PM1 c2 M4 39 VT UTC010 128 ShMC1 00 M0 0 <none> 253 ShFRU1 f4 M0 0 <Carrier FRU> 254 ShFRU1 f4 M0 0 <Shelf FRU> ---------------------------------------------- found 11 devices 22/02/2024 16:54 After installing the lxedaq branch and using the \"updated\" software as Lawrence suggested in his email, I'm still unable to read any IPs of the modules: Hi Tim, I never see that light on the AMC13 working. THere\u2019s probably some bug with that version of the MMC firmware. THere are python scripts that use IPMI to read / set the IP addresses. I finally figured out how to get the amc13_v1_2_18 files to appear properly in git. I\u2019ve done this in the lxedaq branch. Do a pull, check that one out, and then have a look in gm2daq-modified/amc13/amc13_v1_2_18/dev_tools/amc13Config/ You will want readIPs.py to read the current IP addresses, and storeConfig.py to get those addresses into the PROM. I believe you want to use the -v options with the 192.168.xx.13 address, and it will automatically add 1 for the 2nd IP address. You will either want to power cycle the AMC13 payload power or use the applyConfig.py script to make the IP addresses current. -Lawrence First I checked systemVars.py: [root@dhcp-10-163-105-238 amc13Config]# cat systemVars.py #File to specify what the default varaibles addresses are used in your system #Default IP address for commercial MCH module # our NAT MCH address DEFAULT_HOST_IP=\"192.168.1.41\" # our Vadatech MCH address # DEFAULT_HOST_IP=\"192.168.1.2\" #Default AMC13 slot number DEFAULT_AMC13_SLOT=9 #Location of 'config_tools'. This should never need to be changed DEFAULT_CONFIG_DIR=\"./config_tools\" #Network base for your uTCA crate's AMC modules NETWORK_BASE=\"192.168.1\" [root@dhcp-10-163-105-238 amc13Config] # cat systemVars.py #File to specify what the default varaibles addresses are used in your system #Default IP address for commercial MCH module # our NAT MCH address DEFAULT_HOST_IP = \"192.168.1.41\" # our Vadatech MCH address # DEFAULT_HOST_IP=\"192.168.1.2\" #Default AMC13 slot number DEFAULT_AMC13_SLOT = 9 #Location of 'config_tools'. This should never need to be changed DEFAULT_CONFIG_DIR = \"./config_tools\" #Network base for your uTCA crate's AMC modules NETWORK_BASE = \"192.168.1\" Everything look reasonable here, so then I sourced this script to set the environment: [root@dhcp-10-163-105-238 amc13_v1_2_18]# cat env.sh if [[ $_ == $0 ]]; then echo \"$0 is meant to be sourced:\" echo \" source $0\" exit 0 fi AMC13_STANDALONE_ROOT=$( readlink -f $(dirname $BASH_SOURCE)/ ) CACTUS_ROOT=/opt/cactus PATH=\"${AMC13_STANDALONE_ROOT}/tools/bin:${PATH}\" PYTHONPATH=\"${AMC13_STANDALONE_ROOT}/python/pkg:${PYTHONPATH}\" LD_LIBRARY_PATH=\"${CACTUS_ROOT}/lib/:${LD_LIBRARY_PATH}\" LD_LIBRARY_PATH=\"${AMC13_STANDALONE_ROOT}/amc13/lib/:${LD_LIBRARY_PATH}\" LD_LIBRARY_PATH=\"${AMC13_STANDALONE_ROOT}/tools/lib/:${LD_LIBRARY_PATH}\" export AMC13_STANDALONE_ROOT CACTUS_ROOT PATH LD_LIBRARY_PATH PYTHONPATH [root@dhcp-10-163-105-238 amc13_v1_2_18]# cat env.sh if [[ $_ == $0 ]]; then echo \" $0 is meant to be sourced:\" echo \" source $0 \" exit 0 fi AMC13_STANDALONE_ROOT =$( readlink -f $(dirname $BASH_SOURCE )/ ) CACTUS_ROOT =/opt/cactus PATH = \" ${AMC13_STANDALONE_ROOT} /tools/bin: ${PATH} \" PYTHONPATH = \" ${AMC13_STANDALONE_ROOT} /python/pkg: ${PYTHONPATH} \" LD_LIBRARY_PATH = \" ${CACTUS_ROOT} /lib/: ${LD_LIBRARY_PATH} \" LD_LIBRARY_PATH = \" ${AMC13_STANDALONE_ROOT} /amc13/lib/: ${LD_LIBRARY_PATH} \" LD_LIBRARY_PATH = \" ${AMC13_STANDALONE_ROOT} /tools/lib/: ${LD_LIBRARY_PATH} \" export AMC13_STANDALONE_ROOT CACTUS_ROOT PATH LD_LIBRARY_PATH PYTHONPATH For good luck I also ran: export AMC13_SERIAL_NO=33 export AMC13_SERIAL_NO =33 The output of trying to read IPs of the modules in the crate is the same as before: [root@dhcp-10-163-105-238 amc13Config]# ./readIPs.py --slot=13 Reading IP addresses of board in slot 13 from host 192.168.1.41 T2 IP Bytes: ipmitool -H 192.168.1.41 -U '' -P '' -T 0x82 -b 7 -t 0xa4 raw 0x32 0x34 0 11 0 4 Unable to send RAW command (channel=0x7 netfn=0x32 lun=0x0 cmd=0x34) [] [] T1 IP Bytes: ipmitool -H 192.168.1.41 -U '' -P '' -T 0x82 -b 7 -t 0xa4 raw 0x32 0x34 1 11 0 4 Unable to send RAW command (channel=0x7 netfn=0x32 lun=0x0 cmd=0x34) [] [] [root@dhcp-10-163-105-238 amc13Config]# ./readIPs.py --slot=11 Reading IP addresses of board in slot 11 from host 192.168.1.41 T2 IP Bytes: ipmitool -H 192.168.1.41 -U '' -P '' -T 0x82 -b 7 -t 0x86 raw 0x32 0x34 0 11 0 4 Unable to send RAW command (channel=0x7 netfn=0x32 lun=0x0 cmd=0x34) [] [] T1 IP Bytes: ipmitool -H 192.168.1.41 -U '' -P '' -T 0x82 -b 7 -t 0x86 raw 0x32 0x34 1 11 0 4 Unable to send RAW command (channel=0x7 netfn=0x32 lun=0x0 cmd=0x34) [] [] [root@dhcp-10-163-105-238 amc13Config]# ./readIPs.py --slot=9 Reading IP addresses of board in slot 9 from host 192.168.1.41 T2 IP Bytes: ipmitool -H 192.168.1.41 -U '' -P '' -T 0x82 -b 7 -t 0x82 raw 0x32 0x34 0 11 0 4 Unable to send RAW command (channel=0x7 netfn=0x32 lun=0x0 cmd=0x34) [] [] T1 IP Bytes: ipmitool -H 192.168.1.41 -U '' -P '' -T 0x82 -b 7 -t 0x82 raw 0x32 0x34 1 11 0 4 Unable to send RAW command (channel=0x7 netfn=0x32 lun=0x0 cmd=0x34) [] [] [root@dhcp-10-163-105-238 amc13Config]# ./readIPs.py --slot=13 Reading IP addresses of board in slot 13 from host 192.168.1.41 T2 IP Bytes: ipmitool -H 192.168.1.41 -U '' -P '' -T 0x82 -b 7 -t 0xa4 raw 0x32 0x34 0 11 0 4 Unable to send RAW command (channel=0x7 netfn=0x32 lun=0x0 cmd=0x34) [] [] T1 IP Bytes: ipmitool -H 192.168.1.41 -U '' -P '' -T 0x82 -b 7 -t 0xa4 raw 0x32 0x34 1 11 0 4 Unable to send RAW command (channel=0x7 netfn=0x32 lun=0x0 cmd=0x34) [] [] [root@dhcp-10-163-105-238 amc13Config]# ./readIPs.py --slot=11 Reading IP addresses of board in slot 11 from host 192.168.1.41 T2 IP Bytes: ipmitool -H 192.168.1.41 -U '' -P '' -T 0x82 -b 7 -t 0x86 raw 0x32 0x34 0 11 0 4 Unable to send RAW command (channel=0x7 netfn=0x32 lun=0x0 cmd=0x34) [] [] T1 IP Bytes: ipmitool -H 192.168.1.41 -U '' -P '' -T 0x82 -b 7 -t 0x86 raw 0x32 0x34 1 11 0 4 Unable to send RAW command (channel=0x7 netfn=0x32 lun=0x0 cmd=0x34) [] [] [root@dhcp-10-163-105-238 amc13Config]# ./readIPs.py --slot=9 Reading IP addresses of board in slot 9 from host 192.168.1.41 T2 IP Bytes: ipmitool -H 192.168.1.41 -U '' -P '' -T 0x82 -b 7 -t 0x82 raw 0x32 0x34 0 11 0 4 Unable to send RAW command (channel=0x7 netfn=0x32 lun=0x0 cmd=0x34) [] [] T1 IP Bytes: ipmitool -H 192.168.1.41 -U '' -P '' -T 0x82 -b 7 -t 0x82 raw 0x32 0x34 1 11 0 4 Unable to send RAW command (channel=0x7 netfn=0x32 lun=0x0 cmd=0x34) [] [] 22/02/2024 17:08 I ran a brute force check where I ping every IP on the network I expect the modules to live (192.162.1.xxx) [root@dhcp-10-163-105-238 shell_scripts]# cat brute_force_ping_check.sh #!/bin/bash # Define colors GREEN='\\033[0;32m' NC='\\033[0m' # No Color # Define the IP range IP_PREFIX=\"192.168.1.\" # Loop through each IP address and ping it with a 1 second timeout for ((i=1; i<=255; i++)) do IP=\"${IP_PREFIX}${i}\" if ping -c 1 -W 1 $IP &> /dev/null; then echo -e \"${GREEN}Host $IP is up${NC}\" else echo \"Host $IP is down\" fi done [root@dhcp-10-163-105-238 shell_scripts]# cat brute_force_ping_check.sh #!/bin/bash # Define colors GREEN = '\\033[0;32m' NC = '\\033[0m' # No Color # Define the IP range IP_PREFIX = \"192.168.1.\" # Loop through each IP address and ping it with a 1 second timeout for (( i =1; i<=255; i++)) do IP = \" ${IP_PREFIX} ${i} \" if ping -c 1 -W 1 $IP &> /dev/ null ; then echo -e \" ${GREEN} Host $IP is up ${NC} \" else echo \"Host $IP is down\" fi done The results are that I can only ping the computer itself and the MCH, not other modules were found. [root@dhcp-10-163-105-238 shell_scripts]# ./brute_force_ping_check.sh Host 192.168.1.1 is up Host 192.168.1.2 is down Host 192.168.1.3 is down Host 192.168.1.4 is down Host 192.168.1.5 is down Host 192.168.1.6 is down Host 192.168.1.7 is down Host 192.168.1.8 is down Host 192.168.1.9 is down Host 192.168.1.10 is down Host 192.168.1.11 is down Host 192.168.1.12 is down Host 192.168.1.13 is down Host 192.168.1.14 is down Host 192.168.1.15 is down Host 192.168.1.16 is down Host 192.168.1.17 is down Host 192.168.1.18 is down Host 192.168.1.19 is down Host 192.168.1.20 is down Host 192.168.1.21 is down Host 192.168.1.22 is down Host 192.168.1.23 is down Host 192.168.1.24 is down Host 192.168.1.25 is down Host 192.168.1.26 is down Host 192.168.1.27 is down Host 192.168.1.28 is down Host 192.168.1.29 is down Host 192.168.1.30 is down Host 192.168.1.31 is down Host 192.168.1.32 is down Host 192.168.1.33 is down Host 192.168.1.34 is down Host 192.168.1.35 is down Host 192.168.1.36 is down Host 192.168.1.37 is down Host 192.168.1.38 is down Host 192.168.1.39 is down Host 192.168.1.40 is down Host 192.168.1.41 is up Host 192.168.1.42 is down Host 192.168.1.43 is down Host 192.168.1.44 is down Host 192.168.1.45 is down Host 192.168.1.46 is down Host 192.168.1.47 is down Host 192.168.1.48 is down Host 192.168.1.49 is down Host 192.168.1.50 is down Host 192.168.1.51 is down Host 192.168.1.52 is down Host 192.168.1.53 is down Host 192.168.1.54 is down Host 192.168.1.55 is down Host 192.168.1.56 is down Host 192.168.1.57 is down Host 192.168.1.58 is down Host 192.168.1.59 is down Host 192.168.1.60 is down Host 192.168.1.61 is down Host 192.168.1.62 is down Host 192.168.1.63 is down Host 192.168.1.64 is down Host 192.168.1.65 is down Host 192.168.1.66 is down Host 192.168.1.67 is down Host 192.168.1.68 is down Host 192.168.1.69 is down Host 192.168.1.70 is down Host 192.168.1.71 is down Host 192.168.1.72 is down Host 192.168.1.73 is down Host 192.168.1.74 is down Host 192.168.1.75 is down Host 192.168.1.76 is down Host 192.168.1.77 is down Host 192.168.1.78 is down Host 192.168.1.79 is down Host 192.168.1.80 is down Host 192.168.1.81 is down Host 192.168.1.82 is down Host 192.168.1.83 is down Host 192.168.1.84 is down Host 192.168.1.85 is down Host 192.168.1.86 is down Host 192.168.1.87 is down Host 192.168.1.88 is down Host 192.168.1.89 is down Host 192.168.1.90 is down Host 192.168.1.91 is down Host 192.168.1.92 is down Host 192.168.1.93 is down Host 192.168.1.94 is down Host 192.168.1.95 is down Host 192.168.1.96 is down Host 192.168.1.97 is down Host 192.168.1.98 is down Host 192.168.1.99 is down Host 192.168.1.100 is down Host 192.168.1.101 is down Host 192.168.1.102 is down Host 192.168.1.103 is down Host 192.168.1.104 is down Host 192.168.1.105 is down Host 192.168.1.106 is down Host 192.168.1.107 is down Host 192.168.1.108 is down Host 192.168.1.109 is down Host 192.168.1.110 is down Host 192.168.1.111 is down Host 192.168.1.112 is down Host 192.168.1.113 is down Host 192.168.1.114 is down Host 192.168.1.115 is down Host 192.168.1.116 is down Host 192.168.1.117 is down Host 192.168.1.118 is down Host 192.168.1.119 is down Host 192.168.1.120 is down Host 192.168.1.121 is down Host 192.168.1.122 is down Host 192.168.1.123 is down Host 192.168.1.124 is down Host 192.168.1.125 is down Host 192.168.1.126 is down Host 192.168.1.127 is down Host 192.168.1.128 is down Host 192.168.1.129 is down Host 192.168.1.130 is down Host 192.168.1.131 is down Host 192.168.1.132 is down Host 192.168.1.133 is down Host 192.168.1.134 is down Host 192.168.1.135 is down Host 192.168.1.136 is down Host 192.168.1.137 is down Host 192.168.1.138 is down Host 192.168.1.139 is down Host 192.168.1.140 is down Host 192.168.1.141 is down Host 192.168.1.142 is down Host 192.168.1.143 is down Host 192.168.1.144 is down Host 192.168.1.145 is down Host 192.168.1.146 is down Host 192.168.1.147 is down Host 192.168.1.148 is down Host 192.168.1.149 is down Host 192.168.1.150 is down Host 192.168.1.151 is down Host 192.168.1.152 is down Host 192.168.1.153 is down Host 192.168.1.154 is down Host 192.168.1.155 is down Host 192.168.1.156 is down Host 192.168.1.157 is down Host 192.168.1.158 is down Host 192.168.1.159 is down Host 192.168.1.160 is down Host 192.168.1.161 is down Host 192.168.1.162 is down Host 192.168.1.163 is down Host 192.168.1.164 is down Host 192.168.1.165 is down Host 192.168.1.166 is down Host 192.168.1.167 is down Host 192.168.1.168 is down Host 192.168.1.169 is down Host 192.168.1.170 is down Host 192.168.1.171 is down Host 192.168.1.172 is down Host 192.168.1.173 is down Host 192.168.1.174 is down Host 192.168.1.175 is down Host 192.168.1.176 is down Host 192.168.1.177 is down Host 192.168.1.178 is down Host 192.168.1.179 is down Host 192.168.1.180 is down Host 192.168.1.181 is down Host 192.168.1.182 is down Host 192.168.1.183 is down Host 192.168.1.184 is down Host 192.168.1.185 is down Host 192.168.1.186 is down Host 192.168.1.187 is down Host 192.168.1.188 is down Host 192.168.1.189 is down Host 192.168.1.190 is down Host 192.168.1.191 is down Host 192.168.1.192 is down Host 192.168.1.193 is down Host 192.168.1.194 is down Host 192.168.1.195 is down Host 192.168.1.196 is down Host 192.168.1.197 is down Host 192.168.1.198 is down Host 192.168.1.199 is down Host 192.168.1.200 is down Host 192.168.1.201 is down Host 192.168.1.202 is down Host 192.168.1.203 is down Host 192.168.1.204 is down Host 192.168.1.205 is down Host 192.168.1.206 is down Host 192.168.1.207 is down Host 192.168.1.208 is down Host 192.168.1.209 is down Host 192.168.1.210 is down Host 192.168.1.211 is down Host 192.168.1.212 is down Host 192.168.1.213 is down Host 192.168.1.214 is down Host 192.168.1.215 is down Host 192.168.1.216 is down Host 192.168.1.217 is down Host 192.168.1.218 is down Host 192.168.1.219 is down Host 192.168.1.220 is down Host 192.168.1.221 is down Host 192.168.1.222 is down Host 192.168.1.223 is down Host 192.168.1.224 is down Host 192.168.1.225 is down Host 192.168.1.226 is down Host 192.168.1.227 is down Host 192.168.1.228 is down Host 192.168.1.229 is down Host 192.168.1.230 is down Host 192.168.1.231 is down Host 192.168.1.232 is down Host 192.168.1.233 is down Host 192.168.1.234 is down Host 192.168.1.235 is down Host 192.168.1.236 is down Host 192.168.1.237 is down Host 192.168.1.238 is down Host 192.168.1.239 is down Host 192.168.1.240 is down Host 192.168.1.241 is down Host 192.168.1.242 is down Host 192.168.1.243 is down Host 192.168.1.244 is down Host 192.168.1.245 is down Host 192.168.1.246 is down Host 192.168.1.247 is down Host 192.168.1.248 is down Host 192.168.1.249 is down Host 192.168.1.250 is down Host 192.168.1.251 is down Host 192.168.1.252 is down Host 192.168.1.253 is down Host 192.168.1.254 is down Host 192.168.1.255 is down [root@dhcp-10-163-105-238 shell_scripts]# ./brute_force_ping_check.sh Host 192.168.1.1 is up Host 192.168.1.2 is down Host 192.168.1.3 is down Host 192.168.1.4 is down Host 192.168.1.5 is down Host 192.168.1.6 is down Host 192.168.1.7 is down Host 192.168.1.8 is down Host 192.168.1.9 is down Host 192.168.1.10 is down Host 192.168.1.11 is down Host 192.168.1.12 is down Host 192.168.1.13 is down Host 192.168.1.14 is down Host 192.168.1.15 is down Host 192.168.1.16 is down Host 192.168.1.17 is down Host 192.168.1.18 is down Host 192.168.1.19 is down Host 192.168.1.20 is down Host 192.168.1.21 is down Host 192.168.1.22 is down Host 192.168.1.23 is down Host 192.168.1.24 is down Host 192.168.1.25 is down Host 192.168.1.26 is down Host 192.168.1.27 is down Host 192.168.1.28 is down Host 192.168.1.29 is down Host 192.168.1.30 is down Host 192.168.1.31 is down Host 192.168.1.32 is down Host 192.168.1.33 is down Host 192.168.1.34 is down Host 192.168.1.35 is down Host 192.168.1.36 is down Host 192.168.1.37 is down Host 192.168.1.38 is down Host 192.168.1.39 is down Host 192.168.1.40 is down Host 192.168.1.41 is up Host 192.168.1.42 is down Host 192.168.1.43 is down Host 192.168.1.44 is down Host 192.168.1.45 is down Host 192.168.1.46 is down Host 192.168.1.47 is down Host 192.168.1.48 is down Host 192.168.1.49 is down Host 192.168.1.50 is down Host 192.168.1.51 is down Host 192.168.1.52 is down Host 192.168.1.53 is down Host 192.168.1.54 is down Host 192.168.1.55 is down Host 192.168.1.56 is down Host 192.168.1.57 is down Host 192.168.1.58 is down Host 192.168.1.59 is down Host 192.168.1.60 is down Host 192.168.1.61 is down Host 192.168.1.62 is down Host 192.168.1.63 is down Host 192.168.1.64 is down Host 192.168.1.65 is down Host 192.168.1.66 is down Host 192.168.1.67 is down Host 192.168.1.68 is down Host 192.168.1.69 is down Host 192.168.1.70 is down Host 192.168.1.71 is down Host 192.168.1.72 is down Host 192.168.1.73 is down Host 192.168.1.74 is down Host 192.168.1.75 is down Host 192.168.1.76 is down Host 192.168.1.77 is down Host 192.168.1.78 is down Host 192.168.1.79 is down Host 192.168.1.80 is down Host 192.168.1.81 is down Host 192.168.1.82 is down Host 192.168.1.83 is down Host 192.168.1.84 is down Host 192.168.1.85 is down Host 192.168.1.86 is down Host 192.168.1.87 is down Host 192.168.1.88 is down Host 192.168.1.89 is down Host 192.168.1.90 is down Host 192.168.1.91 is down Host 192.168.1.92 is down Host 192.168.1.93 is down Host 192.168.1.94 is down Host 192.168.1.95 is down Host 192.168.1.96 is down Host 192.168.1.97 is down Host 192.168.1.98 is down Host 192.168.1.99 is down Host 192.168.1.100 is down Host 192.168.1.101 is down Host 192.168.1.102 is down Host 192.168.1.103 is down Host 192.168.1.104 is down Host 192.168.1.105 is down Host 192.168.1.106 is down Host 192.168.1.107 is down Host 192.168.1.108 is down Host 192.168.1.109 is down Host 192.168.1.110 is down Host 192.168.1.111 is down Host 192.168.1.112 is down Host 192.168.1.113 is down Host 192.168.1.114 is down Host 192.168.1.115 is down Host 192.168.1.116 is down Host 192.168.1.117 is down Host 192.168.1.118 is down Host 192.168.1.119 is down Host 192.168.1.120 is down Host 192.168.1.121 is down Host 192.168.1.122 is down Host 192.168.1.123 is down Host 192.168.1.124 is down Host 192.168.1.125 is down Host 192.168.1.126 is down Host 192.168.1.127 is down Host 192.168.1.128 is down Host 192.168.1.129 is down Host 192.168.1.130 is down Host 192.168.1.131 is down Host 192.168.1.132 is down Host 192.168.1.133 is down Host 192.168.1.134 is down Host 192.168.1.135 is down Host 192.168.1.136 is down Host 192.168.1.137 is down Host 192.168.1.138 is down Host 192.168.1.139 is down Host 192.168.1.140 is down Host 192.168.1.141 is down Host 192.168.1.142 is down Host 192.168.1.143 is down Host 192.168.1.144 is down Host 192.168.1.145 is down Host 192.168.1.146 is down Host 192.168.1.147 is down Host 192.168.1.148 is down Host 192.168.1.149 is down Host 192.168.1.150 is down Host 192.168.1.151 is down Host 192.168.1.152 is down Host 192.168.1.153 is down Host 192.168.1.154 is down Host 192.168.1.155 is down Host 192.168.1.156 is down Host 192.168.1.157 is down Host 192.168.1.158 is down Host 192.168.1.159 is down Host 192.168.1.160 is down Host 192.168.1.161 is down Host 192.168.1.162 is down Host 192.168.1.163 is down Host 192.168.1.164 is down Host 192.168.1.165 is down Host 192.168.1.166 is down Host 192.168.1.167 is down Host 192.168.1.168 is down Host 192.168.1.169 is down Host 192.168.1.170 is down Host 192.168.1.171 is down Host 192.168.1.172 is down Host 192.168.1.173 is down Host 192.168.1.174 is down Host 192.168.1.175 is down Host 192.168.1.176 is down Host 192.168.1.177 is down Host 192.168.1.178 is down Host 192.168.1.179 is down Host 192.168.1.180 is down Host 192.168.1.181 is down Host 192.168.1.182 is down Host 192.168.1.183 is down Host 192.168.1.184 is down Host 192.168.1.185 is down Host 192.168.1.186 is down Host 192.168.1.187 is down Host 192.168.1.188 is down Host 192.168.1.189 is down Host 192.168.1.190 is down Host 192.168.1.191 is down Host 192.168.1.192 is down Host 192.168.1.193 is down Host 192.168.1.194 is down Host 192.168.1.195 is down Host 192.168.1.196 is down Host 192.168.1.197 is down Host 192.168.1.198 is down Host 192.168.1.199 is down Host 192.168.1.200 is down Host 192.168.1.201 is down Host 192.168.1.202 is down Host 192.168.1.203 is down Host 192.168.1.204 is down Host 192.168.1.205 is down Host 192.168.1.206 is down Host 192.168.1.207 is down Host 192.168.1.208 is down Host 192.168.1.209 is down Host 192.168.1.210 is down Host 192.168.1.211 is down Host 192.168.1.212 is down Host 192.168.1.213 is down Host 192.168.1.214 is down Host 192.168.1.215 is down Host 192.168.1.216 is down Host 192.168.1.217 is down Host 192.168.1.218 is down Host 192.168.1.219 is down Host 192.168.1.220 is down Host 192.168.1.221 is down Host 192.168.1.222 is down Host 192.168.1.223 is down Host 192.168.1.224 is down Host 192.168.1.225 is down Host 192.168.1.226 is down Host 192.168.1.227 is down Host 192.168.1.228 is down Host 192.168.1.229 is down Host 192.168.1.230 is down Host 192.168.1.231 is down Host 192.168.1.232 is down Host 192.168.1.233 is down Host 192.168.1.234 is down Host 192.168.1.235 is down Host 192.168.1.236 is down Host 192.168.1.237 is down Host 192.168.1.238 is down Host 192.168.1.239 is down Host 192.168.1.240 is down Host 192.168.1.241 is down Host 192.168.1.242 is down Host 192.168.1.243 is down Host 192.168.1.244 is down Host 192.168.1.245 is down Host 192.168.1.246 is down Host 192.168.1.247 is down Host 192.168.1.248 is down Host 192.168.1.249 is down Host 192.168.1.250 is down Host 192.168.1.251 is down Host 192.168.1.252 is down Host 192.168.1.253 is down Host 192.168.1.254 is down Host 192.168.1.255 is down",
    "textLength": 9049
  },
  {
    "kind": "work-log",
    "title": "07_01_2024 - 13_01_2024.html",
    "fileName": "07_01_2024 - 13_01_2024.html",
    "url": "resources/work_logs/07_01_2024 - 13_01_2024.html",
    "createdDate": "2024-01-07",
    "text": "07/01/2024 - 13/01/2024 07/01/2024 - 13/01/2024 07/01/2024 22:43 Tried booting a clean install of Rocky Linux 9.3 (no other OSes) on the newest computer in in CP263. I could not get it to boot with a GUI, only command line. The issue is unclear, going to try using Linux Mint instead... 07/01/2024 22:46 Linux Mint seems to not have the same GUI issues. Maybe its' a GNOME vs Cinnamon issue? For now, I'm going to leave the system in Linux Mint. 08/01/2024 19:04 Vivado 2023.2 install on linux mint failed near the end due to a checksum error (4 hours down the drain). Will try installing version 2017.3 before I leave tonight 08/01/2024 19:39 \"Also - just checking - the switch S1 for downloading the bitstream via the jtag is slid to off after programming - right?\" This switch seems to be covered and very small. The tutorial makes no mention of it. \"A soft-reset after the host is powered up helps the host detect FPGA-based PCIe devices\" The part abouts saying the host detects the FPGA really makes me think they mean reset your computer (or your server, in more sophisticated cases). As our computer is our host here. In any event, hitting that restart swtich on the board doesn't appear to do anything. \"Nereid features a Push-button S2 normally meant to be used as a \u201cReset\u201d signal for designs running on FPGA. Push-button S2 is connected to FPGA pin C26. Push-button S2 is active-high, and users need to enable FPGA\u2019s internal Pulldown on the pin C26 to use the pushbutton correctly. This pushbutton can also be used for any other input and is not just limited to be used as a Reset signal.\" ( https://numato.com/docs/nereid-kintex-7-pci-express-development-board/ ) This paragraph seems to suggest the reset button needs to be programmed first. It's unclear to me whether that programming is doing in the tutorial. 08/01/2024 20:41 Entropy Calculation Because our endoing is lossless, we can look at the distribution fo our residuals and apply the first order entropy calculation in this link: https://faculty.uml.edu/jweitzen/16.548/classnotes/Theory of Data Compression.htm#:~:text=When the compression is lossless,rate is the entropy rate . See section III, B 09/01/2024 23:01 Vivado failed to install one again \"Generating installed device list\". I have downloaded some packages with sudo apt install or whatever libncurses5-dev libncursesw5-dev libncurses5 libtinfo5 libtinfo-dev python3-pip Supposedly after restarting the computer, the installation will no longer break here. It's a painful error because it takes several hours to even get to the point where it breaks. 09/01/2024 23:30 With a jewler's screwdriver I can flip teh switch S1. Whether it's in the \"ON\" or \"OFF\" state doesn't seem to affect anything, including whether I can program it or not. I've tried Switching while the computer is on with platform cable connected Switching while the computer is off then rebooting with the platform cable connected Switching while the computer is on with the platform cable disconnected Siwtching while the computer is off then rebooting with the platform cable disconnected 09/01/2024 23:47 lspci no longer shows 05:00.0 Memory Controller: Xilinx Corporation Device 7024 when I reboot with teh Platform cable disconnected, which is unexpected (an potentially bad?) I got lspci to once again show 05:00.0 Memory Controller: Xilinx Corporation Device 7024 return by unplugging the xilinx connector cable after a shutdown, making sure S1 is in the \"OFF\" position. I'm unsure what I did differently in this case. I think somehow the act of autoconnecting to the hardware with vivado reset it, the resetting the computer helps register it as a pci device. 09/01/2024 23:56 By spamming lspci while configuring the memory device in vivado, I notice that 05:00.0 Memory Controller: Xilinx Corporation DEvice 7024 --> 05:00.0 Memory Controller: Xilinx Corporation DEvice 7024 (rev ff) which makes me think some specific bits were changed 10/01/2024 00:09 Before uploading bistream lspci -vv yields: 05:00.0 Memory controller: Xilinx Corporation Device 7024 Subsystem: Xilinx Corporation Device 0007 Control: I/O- Mem- BusMaster- SpecCycle- MemWINV- VGASnoop- ParErr- Stepping- SERR- FastB2B- DisINTx- Status: Cap+ 66MHz- UDF- FastB2B- ParErr- DEVSEL=fast >TAbort- <TAbort- <MAbort- >SERR- <PERR- INTx- Interrupt: pin A routed to IRQ 255 Region 0: Memory at 51100000 (32-bit, non-prefetchable) [disabled] [size=512K] Capabilities: [40] Power Management version 3 Flags: PMEClk- DSI- D1- D2- AuxCurrent=0mA PME(D0+,D1+,D2+,D3hot+,D3cold-) Status: D0 NoSoftRst+ PME-Enable- DSel=0 DScale=0 PME- Capabilities: [48] MSI: Enable- Count=1/1 Maskable- 64bit+ Address: 0000000000000000 Data: 0000 Capabilities: [60] Express (v2) Endpoint, MSI 00 DevCap: MaxPayload 512 bytes, PhantFunc 0, Latency L0s <64ns, L1 unlimited ExtTag- AttnBtn- AttnInd- PwrInd- RBE+ FLReset- SlotPowerLimit 25.000W DevCtl: CorrErr- NonFatalErr- FatalErr- UnsupReq- RlxdOrd+ ExtTag- PhantFunc- AuxPwr- NoSnoop+ MaxPayload 256 bytes, MaxReadReq 512 bytes DevSta: CorrErr- NonFatalErr- FatalErr- UnsupReq- AuxPwr- TransPend- LnkCap: Port #0, Speed 5GT/s, Width x4, ASPM L0s, Exit Latency L0s unlimited ClockPM- Surprise- LLActRep- BwNot- ASPMOptComp- LnkCtl: ASPM Disabled; RCB 64 bytes, Disabled- CommClk+ ExtSynch- ClockPM- AutWidDis- BWInt- AutBWInt- LnkSta: Speed 5GT/s (ok), Width x1 (downgraded) TrErr- Train- SlotClk+ DLActive- BWMgmt- ABWMgmt- DevCap2: Completion Timeout: Range B, TimeoutDis- NROPrPrP- LTR- 10BitTagComp- 10BitTagReq- OBFF Not Supported, ExtFmt- EETLPPrefix- EmergencyPowerReduction Not Supported, EmergencyPowerReductionInit- FRS- TPHComp- ExtTPHComp- AtomicOpsCap: 32bit- 64bit- 128bitCAS- DevCtl2: Completion Timeout: 50us to 50ms, TimeoutDis- LTR- OBFF Disabled, AtomicOpsCtl: ReqEn- LnkCtl2: Target Link Speed: 5GT/s, EnterCompliance- SpeedDis- Transmit Margin: Normal Operating Range, EnterModifiedCompliance- ComplianceSOS- Compliance De-emphasis: -6dB LnkSta2: Current De-emphasis Level: -6dB, EqualizationComplete- EqualizationPhase1- EqualizationPhase2- EqualizationPhase3- LinkEqualizationRequest- Retimer- 2Retimers- CrosslinkRes: unsupported Capabilities: [100 v1] Device Serial Number 00-00-00-01-01-00-0a-35 05:00.0 Memory controller: Xilinx Corporation Device 7024 Subsystem: Xilinx Corporation Device 0007 Control: I/O- Mem- BusMaster- SpecCycle- MemWINV- VGASnoop- ParErr- Stepping- SERR- FastB2B- DisINTx- Status: Cap+ 66MHz- UDF- FastB2B- ParErr- DEVSEL=fast >TAbort- <TAbort- <MAbort- >SERR- <PERR- INTx- Interrupt: pin A routed to IRQ 255 Region 0: Memory at 51100000 (32-bit, non-prefetchable) [disabled] [size=512K] Capabilities: [40] Power Management version 3 Flags: PMEClk- DSI- D1- D2- AuxCurrent=0mA PME(D0+,D1+,D2+,D3hot+,D3cold-) Status: D0 NoSoftRst+ PME-Enable- DSel=0 DScale=0 PME- Capabilities: [48] MSI: Enable- Count=1/1 Maskable- 64bit+ Address: 0000000000000000 Data: 0000 Capabilities: [60] Express (v2) Endpoint, MSI 00 DevCap: MaxPayload 512 bytes, PhantFunc 0, Latency L0s <64ns, L1 unlimited ExtTag- AttnBtn- AttnInd- PwrInd- RBE+ FLReset- SlotPowerLimit 25.000W DevCtl: CorrErr- NonFatalErr- FatalErr- UnsupReq- RlxdOrd+ ExtTag- PhantFunc- AuxPwr- NoSnoop+ MaxPayload 256 bytes, MaxReadReq 512 bytes DevSta: CorrErr- NonFatalErr- FatalErr- UnsupReq- AuxPwr- TransPend- LnkCap: Port #0, Speed 5GT/s, Width x4, ASPM L0s, Exit Latency L0s unlimited ClockPM- Surprise- LLActRep- BwNot- ASPMOptComp- LnkCtl: ASPM Disabled; RCB 64 bytes, Disabled- CommClk+ ExtSynch- ClockPM- AutWidDis- BWInt- AutBWInt- LnkSta: Speed 5GT/s (ok), Width x1 (downgraded) TrErr- Train- SlotClk+ DLActive- BWMgmt- ABWMgmt- DevCap2: Completion Timeout: Range B, TimeoutDis- NROPrPrP- LTR- 10BitTagComp- 10BitTagReq- OBFF Not Supported, ExtFmt- EETLPPrefix- EmergencyPowerReduction Not Supported, EmergencyPowerReductionInit- FRS- TPHComp- ExtTPHComp- AtomicOpsCap: 32bit- 64bit- 128bitCAS- DevCtl2: Completion Timeout: 50us to 50ms, TimeoutDis- LTR- OBFF Disabled, AtomicOpsCtl: ReqEn- LnkCtl2: Target Link Speed: 5GT/s, EnterCompliance- SpeedDis- Transmit Margin: Normal Operating Range, EnterModifiedCompliance- ComplianceSOS- Compliance De-emphasis: -6dB LnkSta2: Current De-emphasis Level: -6dB, EqualizationComplete- EqualizationPhase1- EqualizationPhase2- EqualizationPhase3- LinkEqualizationRequest- Retimer- 2Retimers- CrosslinkRes: unsupported Capabilities: [100 v1] Device Serial Number 00-00-00-01-01-00-0a-35 and root@pioneer-MS-7D41:/home/pioneer# echo 1 > /sys/bus/pci/devices/0000:05:00.0/reset root@pioneer-MS-7D41:/home/pioneer# root @pioneer-MS- 7 D41:/home/pioneer# echo 1 > /sys/bus/pci/devices/ 0000 : 05 : 00 . 0 /reset root @pioneer-MS- 7 D41:/home/pioneer# After uploading bitstream: lspci -vv yields: 05:00.0 Memory controller: Xilinx Corporation Device 7024 (rev ff) (prog-if ff) !!! Unknown header type 7f 05 : 00.0 Memory controller: Xilinx Corporation Device 7024 (rev ff) (prog-if ff) !!! Unknown header type 7 f and root@pioneer-MS-7D41:/home/pioneer# echo 1 > /sys/bus/pci/devices/0000:05:00.0/reset bash: echo: write error: Inappropriate ioctl for device root @pioneer-MS- 7 D41:/home/pioneer# echo 1 > /sys/bus/pci/devices/ 0000 : 05 : 00 . 0 /reset bash : echo: write error: Inappropriate ioctl for device 10/01/2024 21:04 Vivado 2023.2 successfully installed this time. 10/01/2024 21:13 I noticed there are three different FPGA versions for this board And each corresponds to it's own board layout in Vivado I've been selecting the red option (which looks like it corresponds to 160T).I noticed a checkmark on the packaging for 160T, so I believe I have been selecting the correct board. 10/01/2024 21:57 I can't really make any sense of the readback, but I was able to generate a readback file. First 10 lines: root@pioneer-MS-7D41:/tools/Xilinx/Vivado/2023.2/pcie_7x_0_ex/pcie_7x_0_ex.runs/impl_1# cat xilinx_pcie_2_1_ep_7x_readback | head -n 10 :020000040000FA :10000000FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF00 :10001000FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF0 :10002000000000BB11220044FFFFFFFFFFFFFFFFA6 :10003000AA9955662000000030022001000000004F :1000400030020001000000003000800100000000CC :1000500020000000300080010000000720000000A8 :10006000200000003002600100000000300120018B :1000700002223FE53001C001000000003001800194 :100080000364C093300080010000000920000000DC root@pioneer-MS-7D41:/tools/Xilinx/Vivado/2023.2/pcie_7x_0_ex/pcie_7x_0_ex.runs/impl_1 # cat xilinx_pcie_2_1_ep_7x_readback | head -n 10 :020000040000FA :10000000FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF00 :10001000FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF0 :10002000000000BB11220044FFFFFFFFFFFFFFFFA6 :10003000AA9955662000000030022001000000004F :1000400030020001000000003000800100000000CC :1000500020000000300080010000000720000000A8 :10006000200000003002600100000000300120018B :1000700002223FE53001C001000000003001800194 :100080000364C093300080010000000920000000DC last 10 lines: root@pioneer-MS-7D41:/tools/Xilinx/Vivado/2023.2/pcie_7x_0_ex/pcie_7x_0_ex.runs/impl_1# cat xilinx_pcie_2_1_ep_7x_readback | tail -n 10 :10FF7000FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF91 :10FF8000FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF81 :10FF9000FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF71 :10FFA000FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF61 :10FFB000FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF51 :10FFC000FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF41 :10FFD000FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF31 :10FFE000FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF21 :10FFF000FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF11 :00000001FF root@pioneer-MS-7D41:/tools/Xilinx/Vivado/2023.2/pcie_7x_0_ex/pcie_7x_0_ex.runs/impl_1 # cat xilinx_pcie_2_1_ep_7x_readback | tail -n 10 :10FF7000FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF91 :10FF8000FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF81 :10FF9000FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF71 :10FFA000FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF61 :10FFB000FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF51 :10FFC000FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF41 :10FFD000FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF31 :10FFE000FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF21 :10FFF000FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF11 :00000001FF",
    "textLength": 1649
  },
  {
    "kind": "work-log",
    "title": "16_02_2025 - 22_02_2025.html",
    "fileName": "16_02_2025 - 22_02_2025.html",
    "url": "resources/work_logs/16_02_2025 - 22_02_2025.html",
    "createdDate": "2025-02-16",
    "text": "16/02/2025 - 22/02/2025 16/02/2025 - 22/02/2025 17/02/2025 15:52 First draft of a mermaid chart for Nalu Readout System graph TD; A[\"<b>Nalu MIDAS Frontend</b><br> Coordinates MIDAS event construction\"] style A fill:#ff4d4d subgraph Libraries B[\"<b><a href='https://github.com/jaca230/nalu_board_controller'>Nalu Board Controller</a></b><br>C++ Wrapper around some naludaq methods for configuring the board and starting readout\"] style B fill:#66cc66 C[\"<b>Nalu Event Collector</b><br>C++ API for launching collector threads. Handles receiving data over UDP, processing packets, and collecting into NaluEvents\"] style C fill:#cc9900 D[\"<b>RP Pico W Controller (C++)</b><br>C++ API to remotely control the RP Pico over serial or WiFi\"] style D fill:#ff4d4d end subgraph MicroPython RPBoard[\"<b><a href='https://github.com/jaca230/RP_pico_W_board_interface'>RP Pico W Board Interface</a></b><br>Handles low-level communication with the RP Pico W board over serial or WiFi.\"] style RPBoard fill:#66cc66 end subgraph Python Packages P3[\"<b><a href='https://github.com/jaca230/RP_pico_W_board_remote_controller'>RP Pico W Controller</a></b><br>Provides python methods to remotely control RP Pico \"] style P3 fill:#66cc66 P2[\"<b>naludaq</b><br>Python interface for Naludaq\"] end subgraph Classes Z[\"<b>PicoBoardManager</b><br>Provides methods for remotely controlling RP Pico W\"] style Z fill:#ff4d4d X[\"<b>NaluBoardManager</b><br>Provides methods for configuring board and starting readout\"] style X fill:#66cc66 Y[\"<b>NaluEventCollector</b><br>Provides methods for starting collector threads and polling for events\"] style Y fill:#cc9900 ODB[\"<b>ODB Manager</b><br>Handles initializing and managing ODB structure for Nalu Equipment\"] style ODB fill:#ff4d4d MEC[\"<b>Midas Event Constructor</b><br>Builds Midas Events from NaluEvents\"] style MEC fill:#ff4d4d end A -->|Uses| B A -->|Uses| C A -.->|Optional| D B -->|Provides| X C -->|Provides| Y A --> ODB A --> MEC %% Connect libraries to the PythonPackages layer B -->|Pybind| P2 %% Connect RP Pico W Controller to the MicroPython layer D -->|Interfaces with| RPBoard D -->|Pybind| P3 D -->|Provides| Z graph TD; A[\"<b>Nalu MIDAS Frontend</b><br> Coordinates MIDAS event construction\"] style A fill:#ff4d4d subgraph Libraries B[\"<b><a href='https://github.com/jaca230/nalu_board_controller'>Nalu Board Controller</a></b><br>C++ Wrapper around some naludaq methods for configuring the board and starting readout\"] style B fill:#66cc66 C[\"<b>Nalu Event Collector</b><br>C++ API for launching collector threads. Handles receiving data over UDP, processing packets, and collecting into NaluEvents\"] style C fill:#cc9900 D[\"<b>RP Pico W Controller (C++)</b><br>C++ API to remotely control the RP Pico over serial or WiFi\"] style D fill:#ff4d4d end subgraph MicroPython RPBoard[\"<b><a href='https://github.com/jaca230/RP_pico_W_board_interface'>RP Pico W Board Interface</a></b><br>Handles low-level communication with the RP Pico W board over serial or WiFi.\"] style RPBoard fill:#66cc66 end subgraph Python Packages P3[\"<b><a href='https://github.com/jaca230/RP_pico_W_board_remote_controller'>RP Pico W Controller</a></b><br>Provides python methods to remotely control RP Pico \"] style P3 fill:#66cc66 P2[\"<b>naludaq</b><br>Python interface for Naludaq\"] end subgraph Classes Z[\"<b>PicoBoardManager</b><br>Provides methods for remotely controlling RP Pico W\"] style Z fill:#ff4d4d X[\"<b>NaluBoardManager</b><br>Provides methods for configuring board and starting readout\"] style X fill:#66cc66 Y[\"<b>NaluEventCollector</b><br>Provides methods for starting collector threads and polling for events\"] style Y fill:#cc9900 ODB[\"<b>ODB Manager</b><br>Handles initializing and managing ODB structure for Nalu Equipment\"] style ODB fill:#ff4d4d MEC[\"<b>Midas Event Constructor</b><br>Builds Midas Events from NaluEvents\"] style MEC fill:#ff4d4d end A -->|Uses| B A -->|Uses| C A -.->|Optional| D B -->|Provides| X C -->|Provides| Y A --> ODB A --> MEC %% Connect libraries to the PythonPackages layer B -->|Pybind| P2 %% Connect RP Pico W Controller to the MicroPython layer D -->|Interfaces with| RPBoard D -->|Pybind| P3 D -->|Provides| Z 17/02/2025 16:45 Here's the \"simplified version\", i.e. the branch withouth the RP Pico graph TD; A[\"<b>Nalu MIDAS Frontend</b><br> Coordinates MIDAS event construction\"] style A fill:#ff4d4d subgraph Libraries B[\"<b><a href='https://github.com/jaca230/nalu_board_controller'>Nalu Board Controller</a></b><br>C++ Wrapper around some naludaq methods for configuring the board and starting readout\"] style B fill:#66cc66 C[\"<b>Nalu Event Collector</b><br>C++ API for launching collector threads. Handles receiving data over UDP, processing packets, and collecting into NaluEvents\"] style C fill:#cc9900 end subgraph Python Packages P2[\"<b>naludaq</b><br>Python interface for Naludaq\"] end subgraph Classes X[\"<b>NaluBoardManager</b><br>Provides methods for configuring board and starting readout\"] style X fill:#66cc66 Y[\"<b>NaluEventCollector</b><br>Provides methods for starting collector threads and polling for events\"] style Y fill:#cc9900 ODB[\"<b>ODB Manager</b><br>Handles initializing and managing ODB structure for Nalu Equipment\"] style ODB fill:#ff4d4d MEC[\"<b>Midas Event Constructor</b><br>Builds Midas Events from NaluEvents\"] style MEC fill:#ff4d4d end A -->|Uses| B A -->|Uses| C B -->|Provides| X C -->|Provides| Y A --> ODB A --> MEC %% Connect libraries to the PythonPackages layer B -->|Pybind| P2 graph TD; A[\"<b>Nalu MIDAS Frontend</b><br> Coordinates MIDAS event construction\"] style A fill:#ff4d4d subgraph Libraries B[\"<b><a href='https://github.com/jaca230/nalu_board_controller'>Nalu Board Controller</a></b><br>C++ Wrapper around some naludaq methods for configuring the board and starting readout\"] style B fill:#66cc66 C[\"<b>Nalu Event Collector</b><br>C++ API for launching collector threads. Handles receiving data over UDP, processing packets, and collecting into NaluEvents\"] style C fill:#cc9900 end subgraph Python Packages P2[\"<b>naludaq</b><br>Python interface for Naludaq\"] end subgraph Classes X[\"<b>NaluBoardManager</b><br>Provides methods for configuring board and starting readout\"] style X fill:#66cc66 Y[\"<b>NaluEventCollector</b><br>Provides methods for starting collector threads and polling for events\"] style Y fill:#cc9900 ODB[\"<b>ODB Manager</b><br>Handles initializing and managing ODB structure for Nalu Equipment\"] style ODB fill:#ff4d4d MEC[\"<b>Midas Event Constructor</b><br>Builds Midas Events from NaluEvents\"] style MEC fill:#ff4d4d end A -->|Uses| B A -->|Uses| C B -->|Provides| X C -->|Provides| Y A --> ODB A --> MEC %% Connect libraries to the PythonPackages layer B -->|Pybind| P2 17/02/2025 20:11 Sometimes, duplicate packets happen, which get grouped as their own event: For example: --- Standard Event Collection --- Collected events: 272 Time taken to collect events (standard mode): 0.00371872 seconds Mode packet count: 62 packets per event Sample Correct Events: Event 270 (62 packets): Packet 0 { Ch: 0, Time: 15765671, Logical: 0, Physical: 7, Index: 16679, Samples: [ Samples: [ 1500, 1518, 1519, 1531, 1497, 1516, 1503, 1496, 1514, 1530, 1489, 1514, 1504, 1490, 1494, 1476, 1486, 1516, 1528, 1517, 1488, 1468, 1521, 1516, 1513, 1496, 1540, 1513, 1522, 1517, 1512, 1539 ], Footer: [ 250, 90 ] } Packet 1 { Ch: 0, Time: 15765671, Logical: 0, Physical: 8, Index: 16680, Samples: [ Samples: [ 1528, 1496, 1466, 1516, 1522, 1498, 1486, 1502, 1488, 1504, 1493, 1493, 1512, 1522, 1512, 1516, 1520, 1516, 1505, 1507, 1474, 1507, 1467, 1490, 1464, 1487, 1518, 1534, 1488, 1517, 1568, 1496 ], Footer: [ 250, 90 ] } Packet 2 { Ch: 0, Time: 15765671, Logical: 0, Physical: 9, Index: 16681, Samples: [ Samples: [ 1510, 1480, 1526, 1525, 1484, 1504, 1490, 1506, 1506, 1535, 1544, 1511, 1483, 1507, 1462, 1509, 1518, 1534, 1484, 1490, 1490, 1475, 1496, 1516, 1519, 1540, 1538, 1517, 1502, 1509, 1540, 1566 ], Footer: [ 250, 90 ] } Packet 3 { Ch: 0, Time: 15765671, Logical: 0, Physical: 10, Index: ... [truncated] Event 269 (62 packets): Packet 0 { Ch: 0, Time: 15755341, Logical: 0, Physical: 31, Index: 16617, Samples: [ Samples: [ 1514, 1498, 1536, 1567, 1483, 1516, 1500, 1494, 1502, 1510, 1531, 1490, 1487, 1488, 1504, 1516, 1517, 1520, 1543, 1535, 1514, 1536, 1506, 1489, 1516, 1518, 1536, 1498, 1526, 1522, 1513, 1538 ], Footer: [ 250, 90 ] } Packet 1 { Ch: 0, Time: 15755341, Logical: 0, Physical: 32, Index: 16618, Samples: [ Samples: [ 1514, 1486, 1476, 1516, 1497, 1494, 1490, 1486, 1513, 1522, 1475, 1489, 1475, 1541, 1490, 1484, 1530, 1542, 1518, 1490, 1513, 1517, 1500, 1495, 1538, 1513, 1488, 1514, 1502, 1516, 1542, 1538 ], Footer: [ 250, 90 ] } Packet 2 { Ch: 0, Time: 15755341, Logical: 0, Physical: 33, Index: 16619, Samples: [ Samples: [ 1491, 1506, 1488, 1513, 1488, 1514, 1515, 1518, 1499, 1506, 1543, 1512, 1453, 1508, 1496, 1511, 1499, 1490, 1498, 1502, 1486, 1490, 1514, 1514, 1514, 1493, 1508, 1469, 1504, 1516, 1508, 1566 ], Footer: [ 250, 90 ] } Packet 3 { Ch: 0, Time: 15755341, Logical: 0, Physical: 34, Inde ... [truncated] Event 268 (62 packets): Packet 0 { Ch: 0, Time: 15745011, Logical: 0, Physical: 55, Index: 16555, Samples: [ Samples: [ 1460, 1529, 1490, 1531, 1526, 1527, 1519, 1525, 1510, 1517, 1532, 1516, 1523, 1484, 1504, 1489, 1518, 1488, 1520, 1495, 1491, 1490, 1538, 1532, 1530, 1519, 1525, 1492, 1496, 1517, 1491, 1539 ], Footer: [ 250, 90 ] } Packet 1 { Ch: 0, Time: 15745011, Logical: 0, Physical: 56, Index: 16556, Samples: [ Samples: [ 1525, 1502, 1456, 1516, 1503, 1512, 1494, 1494, 1500, 1488, 1494, 1511, 1500, 1504, 1483, 1486, 1495, 1521, 1508, 1495, 1510, 1508, 1513, 1472, 1490, 1516, 1500, 1512, 1502, 1513, 1518, 1496 ], Footer: [ 250, 90 ] } Packet 2 { Ch: 0, Time: 15745011, Logical: 0, Physical: 57, Index: 16557, Samples: [ Samples: [ 1516, 1506, 1538, 1534, 1484, 1518, 1520, 1486, 1519, 1519, 1527, 1481, 1494, 1512, 1533, 1516, 1532, 1564, 1536, 1513, 1518, 1516, 1514, 1480, 1520, 1514, 1514, 1455, 1484, 1520, 1496, 1520 ], Footer: [ 250, 90 ] } Packet 3 { Ch: 0, Time: 15745011, Logical: 0, Physical: 58, Inde ... [truncated] Sample Incorrect Events: Event 271 (1 packets): Packet 0 { Ch: 0, Time: 15776001, Logical: 0, Physical: 45, Index: 16741, Samples: [ Samples: [ 1543, 1515, 1496, 1526, 1530, 1522, 1512, 1520, 1524, 1525, 1506, 1516, 1497, 1493, 1483, 1488, 1516, 1533, 1519, 1488, 1511, 1487, 1512, 1518, 1516, 1489, 1524, 1467, 1472, 1491, 1480, 1521 ], Footer: [ 250, 90 ] } Event 135 (1 packets): Packet 0 { Ch: 0, Time: 15776001, Logical: 0, Physical: 45, Index: 8370, Samples: [ Samples: [ 1543, 1515, 1496, 1526, 1530, 1522, 1512, 1520, 1524, 1525, 1506, 1516, 1497, 1493, 1483, 1488, 1516, 1533, 1519, 1488, 1511, 1487, 1512, 1518, 1516, 1489, 1524, 1467, 1472, 1491, 1480, 1521 ], Footer: [ 250, 90 ] } Total Correct Events: 270 (99.2647%) Total Incorrect Events: 2 (0.735294%) --- Lazy Mode Event Collection --- Collected events: 272 Time taken to collect events (lazy mode): 0.00137712 seconds Mode packet count: 62 packets per event Sample Correct Events: Event 271 (62 packets): Packet 0 { Ch: 0, Time: 15765671, Logical: 0, Physical: 7, Index: 16679, Samples: [ Samples: [ 1500, 1518, 1519, 1531, 1497, 1516, 1503, 1496, 1514, 1530, 1489, 1514, 1504, 1490, 1494, 1476, 1486, 1516, 1528, 1517, 1488, 1468, 1521, 1516, 1513, 1496, 1540, 1513, 1522, 1517, 1512, 1539 ], Footer: [ 250, 90 ] } Packet 1 { Ch: 0, Time: 15765671, Logical: 0, Physical: 8, Index: 16680, Samples: [ Samples: [ 1528, 1496, 1466, 1516, 1522, 1498, 1486, 1502, 1488, 1504, 1493, 1493, 1512, 1522, 1512, 1516, 1520, 1516, 1505, 1507, 1474, 1507, 1467, 1490, 1464, 1487, 1518, 1534, 1488, 1517, 1568, 1496 ], Footer: [ 250, 90 ] } Packet 2 { Ch: 0, Time: 15765671, Logical: 0, Physical: 9, Index: 16681, Samples: [ Samples: [ 1510, 1480, 1526, 1525, 1484, 1504, 1490, 1506, 1506, 1535, 1544, 1511, 1483, 1507, 1462, 1509, 1518, 1534, 1484, 1490, 1490, 1475, 1496, 1516, 1519, 1540, 1538, 1517, 1502, 1509, 1540, 1566 ], Footer: [ 250, 90 ] } Packet 3 { Ch: 0, Time: 15765671, Logical: 0, Physical: 10, Index: ... [truncated] Event 270 (62 packets): Packet 0 { Ch: 0, Time: 15755341, Logical: 0, Physical: 31, Index: 16617, Samples: [ Samples: [ 1514, 1498, 1536, 1567, 1483, 1516, 1500, 1494, 1502, 1510, 1531, 1490, 1487, 1488, 1504, 1516, 1517, 1520, 1543, 1535, 1514, 1536, 1506, 1489, 1516, 1518, 1536, 1498, 1526, 1522, 1513, 1538 ], Footer: [ 250, 90 ] } Packet 1 { Ch: 0, Time: 15755341, Logical: 0, Physical: 32, Index: 16618, Samples: [ Samples: [ 1514, 1486, 1476, 1516, 1497, 1494, 1490, 1486, 1513, 1522, 1475, 1489, 1475, 1541, 1490, 1484, 1530, 1542, 1518, 1490, 1513, 1517, 1500, 1495, 1538, 1513, 1488, 1514, 1502, 1516, 1542, 1538 ], Footer: [ 250, 90 ] } Packet 2 { Ch: 0, Time: 15755341, Logical: 0, Physical: 33, Index: 16619, Samples: [ Samples: [ 1491, 1506, 1488, 1513, 1488, 1514, 1515, 1518, 1499, 1506, 1543, 1512, 1453, 1508, 1496, 1511, 1499, 1490, 1498, 1502, 1486, 1490, 1514, 1514, 1514, 1493, 1508, 1469, 1504, 1516, 1508, 1566 ], Footer: [ 250, 90 ] } Packet 3 { Ch: 0, Time: 15755341, Logical: 0, Physical: 34, Inde ... [truncated] Event 269 (62 packets): Packet 0 { Ch: 0, Time: 15745011, Logical: 0, Physical: 55, Index: 16555, Samples: [ Samples: [ 1460, 1529, 1490, 1531, 1526, 1527, 1519, 1525, 1510, 1517, 1532, 1516, 1523, 1484, 1504, 1489, 1518, 1488, 1520, 1495, 1491, 1490, 1538, 1532, 1530, 1519, 1525, 1492, 1496, 1517, 1491, 1539 ], Footer: [ 250, 90 ] } Packet 1 { Ch: 0, Time: 15745011, Logical: 0, Physical: 56, Index: 16556, Samples: [ Samples: [ 1525, 1502, 1456, 1516, 1503, 1512, 1494, 1494, 1500, 1488, 1494, 1511, 1500, 1504, 1483, 1486, 1495, 1521, 1508, 1495, 1510, 1508, 1513, 1472, 1490, 1516, 1500, 1512, 1502, 1513, 1518, 1496 ], Footer: [ 250, 90 ] } Packet 2 { Ch: 0, Time: 15745011, Logical: 0, Physical: 57, Index: 16557, Samples: [ Samples: [ 1516, 1506, 1538, 1534, 1484, 1518, 1520, 1486, 1519, 1519, 1527, 1481, 1494, 1512, 1533, 1516, 1532, 1564, 1536, 1513, 1518, 1516, 1514, 1480, 1520, 1514, 1514, 1455, 1484, 1520, 1496, 1520 ], Footer: [ 250, 90 ] } Packet 3 { Ch: 0, Time: 15745011, Logical: 0, Physical: 58, Inde ... [truncated] Sample Incorrect Events: Event 272 (1 packets): Packet 0 { Ch: 0, Time: 15776001, Logical: 0, Physical: 45, Index: 16741, Samples: [ Samples: [ 1543, 1515, 1496, 1526, 1530, 1522, 1512, 1520, 1524, 1525, 1506, 1516, 1497, 1493, 1483, 1488, 1516, 1533, 1519, 1488, 1511, 1487, 1512, 1518, 1516, 1489, 1524, 1467, 1472, 1491, 1480, 1521 ], Footer: [ 250, 90 ] } Event 136 (1 packets): Packet 0 { Ch: 0, Time: 15776001, Logical: 0, Physical: 45, Index: 8370, Samples: [ Samples: [ 1543, 1515, 1496, 1526, 1530, 1522, 1512, 1520, 1524, 1525, 1506, 1516, 1497, 1493, 1483, 1488, 1516, 1533, 1519, 1488, 1511, 1487, 1512, 1518, 1516, 1489, 1524, 1467, 1472, 1491, 1480, 1521 ], Footer: [ 250, 90 ] } Total Correct Events: 270 (99.2647%) Total Incorrect Events: 2 (0.735294%) --- Standard Event Collection --- Collected events: 272 Time taken to collect events (standard mode): 0.00371872 seconds Mode packet count: 62 packets per event Sample Correct Events: Event 270 (62 packets): Packet 0 { Ch: 0, Time: 15765671, Logical: 0, Physical: 7, Index: 16679, Samples: [ Samples: [ 1500, 1518, 1519, 1531, 1497, 1516, 1503, 1496, 1514, 1530, 1489, 1514, 1504, 1490, 1494, 1476, 1486, 1516, 1528, 1517, 1488, 1468, 1521, 1516, 1513, 1496, 1540, 1513, 1522, 1517, 1512, 1539 ], Footer: [ 250, 90 ] } Packet 1 { Ch: 0, Time: 15765671, Logical: 0, Physical: 8, Index: 16680, Samples: [ Samples: [ 1528, 1496, 1466, 1516, 1522, 1498, 1486, 1502, 1488, 1504, 1493, 1493, 1512, 1522, 1512, 1516, 1520, 1516, 1505, 1507, 1474, 1507, 1467, 1490, 1464, 1487, 1518, 1534, 1488, 1517, 1568, 1496 ], Footer: [ 250, 90 ] } Packet 2 { Ch: 0, Time: 15765671, Logical: 0, Physical: 9, Index: 16681, Samples: [ Samples: [ 1510, 1480, 1526, 1525, 1484, 1504, 1490, 1506, 1506, 1535, 1544, 1511, 1483, 1507, 1462, 1509, 1518, 1534, 1484, 1490, 1490, 1475, 1496, 1516, 1519, 1540, 1538, 1517, 1502, 1509, 1540, 1566 ], Footer: [ 250, 90 ] } Packet 3 { Ch: 0, Time: 15765671, Logical: 0, Physical: 10, Index: ... [truncated] Event 269 (62 packets): Packet 0 { Ch: 0, Time: 15755341, Logical: 0, Physical: 31, Index: 16617, Samples: [ Samples: [ 1514, 1498, 1536, 1567, 1483, 1516, 1500, 1494, 1502, 1510, 1531, 1490, 1487, 1488, 1504, 1516, 1517, 1520, 1543, 1535, 1514, 1536, 1506, 1489, 1516, 1518, 1536, 1498, 1526, 1522, 1513, 1538 ], Footer: [ 250, 90 ] } Packet 1 { Ch: 0, Time: 15755341, Logical: 0, Physical: 32, Index: 16618, Samples: [ Samples: [ 1514, 1486, 1476, 1516, 1497, 1494, 1490, 1486, 1513, 1522, 1475, 1489, 1475, 1541, 1490, 1484, 1530, 1542, 1518, 1490, 1513, 1517, 1500, 1495, 1538, 1513, 1488, 1514, 1502, 1516, 1542, 1538 ], Footer: [ 250, 90 ] } Packet 2 { Ch: 0, Time: 15755341, Logical: 0, Physical: 33, Index: 16619, Samples: [ Samples: [ 1491, 1506, 1488, 1513, 1488, 1514, 1515, 1518, 1499, 1506, 1543, 1512, 1453, 1508, 1496, 1511, 1499, 1490, 1498, 1502, 1486, 1490, 1514, 1514, 1514, 1493, 1508, 1469, 1504, 1516, 1508, 1566 ], Footer: [ 250, 90 ] } Packet 3 { Ch: 0, Time: 15755341, Logical: 0, Physical: 34, Inde ... [truncated] Event 268 (62 packets): Packet 0 { Ch: 0, Time: 15745011, Logical: 0, Physical: 55, Index: 16555, Samples: [ Samples: [ 1460, 1529, 1490, 1531, 1526, 1527, 1519, 1525, 1510, 1517, 1532, 1516, 1523, 1484, 1504, 1489, 1518, 1488, 1520, 1495, 1491, 1490, 1538, 1532, 1530, 1519, 1525, 1492, 1496, 1517, 1491, 1539 ], Footer: [ 250, 90 ] } Packet 1 { Ch: 0, Time: 15745011, Logical: 0, Physical: 56, Index: 16556, Samples: [ Samples: [ 1525, 1502, 1456, 1516, 1503, 1512, 1494, 1494, 1500, 1488, 1494, 1511, 1500, 1504, 1483, 1486, 1495, 1521, 1508, 1495, 1510, 1508, 1513, 1472, 1490, 1516, 1500, 1512, 1502, 1513, 1518, 1496 ], Footer: [ 250, 90 ] } Packet 2 { Ch: 0, Time: 15745011, Logical: 0, Physical: 57, Index: 16557, Samples: [ Samples: [ 1516, 1506, 1538, 1534, 1484, 1518, 1520, 1486, 1519, 1519, 1527, 1481, 1494, 1512, 1533, 1516, 1532, 1564, 1536, 1513, 1518, 1516, 1514, 1480, 1520, 1514, 1514, 1455, 1484, 1520, 1496, 1520 ], Footer: [ 250, 90 ] } Packet 3 { Ch: 0, Time: 15745011, Logical: 0, Physical: 58, Inde ... [truncated] Sample Incorrect Events: Event 271 (1 packets): Packet 0 { Ch: 0, Time: 15776001, Logical: 0, Physical: 45, Index: 16741, Samples: [ Samples: [ 1543, 1515, 1496, 1526, 1530, 1522, 1512, 1520, 1524, 1525, 1506, 1516, 1497, 1493, 1483, 1488, 1516, 1533, 1519, 1488, 1511, 1487, 1512, 1518, 1516, 1489, 1524, 1467, 1472, 1491, 1480, 1521 ], Footer: [ 250, 90 ] } Event 135 (1 packets): Packet 0 { Ch: 0, Time: 15776001, Logical: 0, Physical: 45, Index: 8370, Samples: [ Samples: [ 1543, 1515, 1496, 1526, 1530, 1522, 1512, 1520, 1524, 1525, 1506, 1516, 1497, 1493, 1483, 1488, 1516, 1533, 1519, 1488, 1511, 1487, 1512, 1518, 1516, 1489, 1524, 1467, 1472, 1491, 1480, 1521 ], Footer: [ 250, 90 ] } Total Correct Events: 270 (99.2647%) Total Incorrect Events: 2 (0.735294%) --- Lazy Mode Event Collection --- Collected events: 272 Time taken to collect events (lazy mode): 0.00137712 seconds Mode packet count: 62 packets per event Sample Correct Events: Event 271 (62 packets): Packet 0 { Ch: 0, Time: 15765671, Logical: 0, Physical: 7, Index: 16679, Samples: [ Samples: [ 1500, 1518, 1519, 1531, 1497, 1516, 1503, 1496, 1514, 1530, 1489, 1514, 1504, 1490, 1494, 1476, 1486, 1516, 1528, 1517, 1488, 1468, 1521, 1516, 1513, 1496, 1540, 1513, 1522, 1517, 1512, 1539 ], Footer: [ 250, 90 ] } Packet 1 { Ch: 0, Time: 15765671, Logical: 0, Physical: 8, Index: 16680, Samples: [ Samples: [ 1528, 1496, 1466, 1516, 1522, 1498, 1486, 1502, 1488, 1504, 1493, 1493, 1512, 1522, 1512, 1516, 1520, 1516, 1505, 1507, 1474, 1507, 1467, 1490, 1464, 1487, 1518, 1534, 1488, 1517, 1568, 1496 ], Footer: [ 250, 90 ] } Packet 2 { Ch: 0, Time: 15765671, Logical: 0, Physical: 9, Index: 16681, Samples: [ Samples: [ 1510, 1480, 1526, 1525, 1484, 1504, 1490, 1506, 1506, 1535, 1544, 1511, 1483, 1507, 1462, 1509, 1518, 1534, 1484, 1490, 1490, 1475, 1496, 1516, 1519, 1540, 1538, 1517, 1502, 1509, 1540, 1566 ], Footer: [ 250, 90 ] } Packet 3 { Ch: 0, Time: 15765671, Logical: 0, Physical: 10, Index: ... [truncated] Event 270 (62 packets): Packet 0 { Ch: 0, Time: 15755341, Logical: 0, Physical: 31, Index: 16617, Samples: [ Samples: [ 1514, 1498, 1536, 1567, 1483, 1516, 1500, 1494, 1502, 1510, 1531, 1490, 1487, 1488, 1504, 1516, 1517, 1520, 1543, 1535, 1514, 1536, 1506, 1489, 1516, 1518, 1536, 1498, 1526, 1522, 1513, 1538 ], Footer: [ 250, 90 ] } Packet 1 { Ch: 0, Time: 15755341, Logical: 0, Physical: 32, Index: 16618, Samples: [ Samples: [ 1514, 1486, 1476, 1516, 1497, 1494, 1490, 1486, 1513, 1522, 1475, 1489, 1475, 1541, 1490, 1484, 1530, 1542, 1518, 1490, 1513, 1517, 1500, 1495, 1538, 1513, 1488, 1514, 1502, 1516, 1542, 1538 ], Footer: [ 250, 90 ] } Packet 2 { Ch: 0, Time: 15755341, Logical: 0, Physical: 33, Index: 16619, Samples: [ Samples: [ 1491, 1506, 1488, 1513, 1488, 1514, 1515, 1518, 1499, 1506, 1543, 1512, 1453, 1508, 1496, 1511, 1499, 1490, 1498, 1502, 1486, 1490, 1514, 1514, 1514, 1493, 1508, 1469, 1504, 1516, 1508, 1566 ], Footer: [ 250, 90 ] } Packet 3 { Ch: 0, Time: 15755341, Logical: 0, Physical: 34, Inde ... [truncated] Event 269 (62 packets): Packet 0 { Ch: 0, Time: 15745011, Logical: 0, Physical: 55, Index: 16555, Samples: [ Samples: [ 1460, 1529, 1490, 1531, 1526, 1527, 1519, 1525, 1510, 1517, 1532, 1516, 1523, 1484, 1504, 1489, 1518, 1488, 1520, 1495, 1491, 1490, 1538, 1532, 1530, 1519, 1525, 1492, 1496, 1517, 1491, 1539 ], Footer: [ 250, 90 ] } Packet 1 { Ch: 0, Time: 15745011, Logical: 0, Physical: 56, Index: 16556, Samples: [ Samples: [ 1525, 1502, 1456, 1516, 1503, 1512, 1494, 1494, 1500, 1488, 1494, 1511, 1500, 1504, 1483, 1486, 1495, 1521, 1508, 1495, 1510, 1508, 1513, 1472, 1490, 1516, 1500, 1512, 1502, 1513, 1518, 1496 ], Footer: [ 250, 90 ] } Packet 2 { Ch: 0, Time: 15745011, Logical: 0, Physical: 57, Index: 16557, Samples: [ Samples: [ 1516, 1506, 1538, 1534, 1484, 1518, 1520, 1486, 1519, 1519, 1527, 1481, 1494, 1512, 1533, 1516, 1532, 1564, 1536, 1513, 1518, 1516, 1514, 1480, 1520, 1514, 1514, 1455, 1484, 1520, 1496, 1520 ], Footer: [ 250, 90 ] } Packet 3 { Ch: 0, Time: 15745011, Logical: 0, Physical: 58, Inde ... [truncated] Sample Incorrect Events: Event 272 (1 packets): Packet 0 { Ch: 0, Time: 15776001, Logical: 0, Physical: 45, Index: 16741, Samples: [ Samples: [ 1543, 1515, 1496, 1526, 1530, 1522, 1512, 1520, 1524, 1525, 1506, 1516, 1497, 1493, 1483, 1488, 1516, 1533, 1519, 1488, 1511, 1487, 1512, 1518, 1516, 1489, 1524, 1467, 1472, 1491, 1480, 1521 ], Footer: [ 250, 90 ] } Event 136 (1 packets): Packet 0 { Ch: 0, Time: 15776001, Logical: 0, Physical: 45, Index: 8370, Samples: [ Samples: [ 1543, 1515, 1496, 1526, 1530, 1522, 1512, 1520, 1524, 1525, 1506, 1516, 1497, 1493, 1483, 1488, 1516, 1533, 1519, 1488, 1511, 1487, 1512, 1518, 1516, 1489, 1524, 1467, 1472, 1491, 1480, 1521 ], Footer: [ 250, 90 ] } Total Correct Events: 270 (99.2647%) Total Incorrect Events: 2 (0.735294%) 17/02/2025 20:51 I'm realizing the timestamp difference between events depends on number of windows and number of channels. This is making me think I left the trigger rate at a saturated value: Time diff between 1 channel, 62 windows == ~ 10,000 Time diff between 1 channel, 1 windows == ~ 1,000 Time diff between 32 channel, 31 windows == ~40,000 Time diff between 32 channel, 62 windows == ~ 80,000 18/02/2025 20:31 I was right, the trigger rate was at ~28kHz. I turned it down to 1kHz, but even this saturates the data rate once there's too many windows or channels: Processing file: captured_events_w62_ch1_1kHz.bin Sample Positive Time Differences from captured_events_w62_ch1_1kHz.bin: [23843, 23844, 23844, 23842, 23844] Sample Negative Time Differences from captured_events_w62_ch1_1kHz.bin: [-1120635, -1144479, -1144479, -1144479] ======================================== Processing file: captured_events_w62_ch32_1kHz.bin Sample Positive Time Differences from captured_events_w62_ch32_1kHz.bin: [95373, 95374, 95372, 95375, 95372] Sample Negative Time Differences from captured_events_w62_ch32_1kHz.bin: [] ======================================== Processing file: captured_events_w31_ch32_1kHz.bin Sample Positive Time Differences from captured_events_w31_ch32_1kHz.bin: [47688, 47686, 47686, 47686, 47688] Sample Negative Time Differences from captured_events_w31_ch32_1kHz.bin: [] ======================================== Processing file: captured_events_w31_ch1_1kHz.bin Sample Positive Time Differences from captured_events_w31_ch1_1kHz.bin: [23844, 23843, 23843, 23844, 23842] Sample Negative Time Differences from captured_events_w31_ch1_1kHz.bin: [-1192172, -1192172, -1192172, -1192172, -1192172] ======================================== Processing file: captured_events_w1_ch32_1kHz.bin Sample Positive Time Differences from captured_events_w1_ch32_1kHz.bin: [23843, 23844, 23842, 23845, 23844] Sample Negative Time Differences from captured_events_w1_ch32_1kHz.bin: [-1096796, -1096796, -1096796, -1096796, -1096796] ======================================== Processing file: captured_events_w1_ch1_1kHz.bin Sample Positive Time Differences from captured_events_w1_ch1_1kHz.bin: [23844, 23842, 23844, 23843, 23843] Sample Negative Time Differences from captured_events_w1_ch1_1kHz.bin: [-929890, -929890, -929890, -929890, -929890] Processing file: captured_events_w62_ch1_1kHz.bin Sample Positive Time Differences from captured_events_w62_ch1_1kHz.bin: [23843, 23844, 23844, 23842, 23844] Sample Negative Time Differences from captured_events_w62_ch1_1kHz.bin: [-1120635, -1144479, -1144479, -1144479] ======================================== Processing file: captured_events_w62_ch32_1kHz.bin Sample Positive Time Differences from captured_events_w62_ch32_1kHz.bin: [95373, 95374, 95372, 95375, 95372] Sample Negative Time Differences from captured_events_w62_ch32_1kHz.bin: [] ======================================== Processing file: captured_events_w31_ch32_1kHz.bin Sample Positive Time Differences from captured_events_w31_ch32_1kHz.bin: [47688, 47686, 47686, 47686, 47688] Sample Negative Time Differences from captured_events_w31_ch32_1kHz.bin: [] ======================================== Processing file: captured_events_w31_ch1_1kHz.bin Sample Positive Time Differences from captured_events_w31_ch1_1kHz.bin: [23844, 23843, 23843, 23844, 23842] Sample Negative Time Differences from captured_events_w31_ch1_1kHz.bin: [-1192172, -1192172, -1192172, -1192172, -1192172] ======================================== Processing file: captured_events_w1_ch32_1kHz.bin Sample Positive Time Differences from captured_events_w1_ch32_1kHz.bin: [23843, 23844, 23842, 23845, 23844] Sample Negative Time Differences from captured_events_w1_ch32_1kHz.bin: [-1096796, -1096796, -1096796, -1096796, -1096796] ======================================== Processing file: captured_events_w1_ch1_1kHz.bin Sample Positive Time Differences from captured_events_w1_ch1_1kHz.bin: [23844, 23842, 23844, 23843, 23843] Sample Negative Time Differences from captured_events_w1_ch1_1kHz.bin: [-929890, -929890, -929890, -929890, -929890] 20/02/2025 20:35 I discovered the origin of the b\"\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\" \"error code\". It seems to be a UDP packet header. UDP payloads from the board come in 1040 byte chunks, the first 16 bytes are this header. So really they're 1024 byte payloads, which makes more sense. captured_events_w62_ch1_1kHz.bin: 1084 occurrences, expected ~1084.00 (size / 1040) Occurrences found at: [0, 1040, 2080, 3120, 4160, '...', 1122160, 1123200, 1124240, 1125280, 1126320] captured_events_w62_ch32_1kHz.bin: 1000 occurrences, expected ~1000.00 (size / 1040) Occurrences found at: [0, 1040, 2080, 3120, 4160, '...', 1034800, 1035840, 1036880, 1037920, 1038960] captured_events_w62_ch32_28kHz.bin: 1000 occurrences, expected ~1000.00 (size / 1040) Occurrences found at: [0, 1040, 2080, 3120, 4160, '...', 1034800, 1035840, 1036880, 1037920, 1038960] captured_events_w62_ch1_28kHz.bin: 1210 occurrences, expected ~1210.00 (size / 1040) Occurrences found at: [0, 1040, 2080, 3120, 4160, '...', 1253200, 1254240, 1255280, 1256320, 1257360] captured_events_w31_ch32_1kHz.bin: 1000 occurrences, expected ~1000.00 (size / 1040) Occurrences found at: [0, 1040, 2080, 3120, 4160, '...', 1034800, 1035840, 1036880, 1037920, 1038960] captured_events_w31_ch32_28kHz.bin: 1000 occurrences, expected ~1000.00 (size / 1040) Occurrences found at: [0, 1040, 2080, 3120, 4160, '...', 1034800, 1035840, 1036880, 1037920, 1038960] captured_events_w31_ch1_1kHz.bin: 1024 occurrences, expected ~1024.00 (size / 1040) Occurrences found at: [0, 1040, 2080, 3120, 4160, '...', 1059760, 1060800, 1061840, 1062880, 1063920] captured_events_w1_ch1_28kHz.bin: 1028 occurrences, expected ~1028.00 (size / 1040) Occurrences found at: [0, 1040, 2080, 3120, 4160, '...', 1063920, 1064960, 1066000, 1067040, 1068080] captured_events_w1_ch32_1kHz.bin: 1080 occurrences, expected ~1080.00 (size / 1040) Occurrences found at: [0, 1040, 2080, 3120, 4160, '...', 1118000, 1119040, 1120080, 1121120, 1122160] captured_events_w1_ch1_1kHz.bin: 0 occurrences, expected ~1002.00 (size / 1040) Occurrences found at: [] captured_events_w62_ch1_1kHz.bin: 1084 occurrences, expected ~1084.00 (size / 1040) Occurrences found at: [0, 1040, 2080, 3120, 4160, '...', 1122160, 1123200, 1124240, 1125280, 1126320] captured_events_w62_ch32_1kHz.bin: 1000 occurrences, expected ~1000.00 (size / 1040) Occurrences found at: [0, 1040, 2080, 3120, 4160, '...', 1034800, 1035840, 1036880, 1037920, 1038960] captured_events_w62_ch32_28kHz.bin: 1000 occurrences, expected ~1000.00 (size / 1040) Occurrences found at: [0, 1040, 2080, 3120, 4160, '...', 1034800, 1035840, 1036880, 1037920, 1038960] captured_events_w62_ch1_28kHz.bin: 1210 occurrences, expected ~1210.00 (size / 1040) Occurrences found at: [0, 1040, 2080, 3120, 4160, '...', 1253200, 1254240, 1255280, 1256320, 1257360] captured_events_w31_ch32_1kHz.bin: 1000 occurrences, expected ~1000.00 (size / 1040) Occurrences found at: [0, 1040, 2080, 3120, 4160, '...', 1034800, 1035840, 1036880, 1037920, 1038960] captured_events_w31_ch32_28kHz.bin: 1000 occurrences, expected ~1000.00 (size / 1040) Occurrences found at: [0, 1040, 2080, 3120, 4160, '...', 1034800, 1035840, 1036880, 1037920, 1038960] captured_events_w31_ch1_1kHz.bin: 1024 occurrences, expected ~1024.00 (size / 1040) Occurrences found at: [0, 1040, 2080, 3120, 4160, '...', 1059760, 1060800, 1061840, 1062880, 1063920] captured_events_w1_ch1_28kHz.bin: 1028 occurrences, expected ~1028.00 (size / 1040) Occurrences found at: [0, 1040, 2080, 3120, 4160, '...', 1063920, 1064960, 1066000, 1067040, 1068080] captured_events_w1_ch32_1kHz.bin: 1080 occurrences, expected ~1080.00 (size / 1040) Occurrences found at: [0, 1040, 2080, 3120, 4160, '...', 1118000, 1119040, 1120080, 1121120, 1122160] captured_events_w1_ch1_1kHz.bin: 0 occurrences, expected ~1002.00 (size / 1040) Occurrences found at: [] For some reason, they don't occur in the \"captured_events_w1_ch1_1kHz.bin\" case. At first I thought maybe the header has information of how many bytes are in this \"event\", but that doesn't make sense. 20/02/2025 20:49 \"captured_events_w1_ch1_1kHz.bin\" appears to have more headers. I've highlighted them here: 01720000 00000000 00000000 00000000 0e000c27 01fb002f 05a705bd 05d105ef 05d005d2 05d705ad 05b905d8 05d505be 05bd05ae 05b705be 05b205d9 05d005b0 05ea05bb 05d205c5 05d405d6 05d905b3 05bc05a6 05a805d1 fa5a0e00 0c2c0f1f 001505de 05c505c6 05ed05a6 05b505b7 05b805ba 05db05e0 05d105b4 05de05e2 05d405c1 05e205de 05fd05c2 05bc05c4 05d605be 05d605d0 05c605b6 05c705b4 05d3fa5a 0e000c32 0c410037 059e05e8 05c305e8 05e005e6 05de05e0 05d005d8 05e705d4 05dd05b6 05d005ba 05da05ba 05de05cd 05c205be 05ed05e7 05e705da 05e405c4 05c605d5 05c405ee fa5a0e00 0c380965 001d05d4 05e205d8 05e905be 05d005d2 05bc05cb 05ce05c4 05b805b7 05b805c2 05d505b6 05dd05d4 05c005d0 05cc05d8 05eb05e0 05a205c2 05b205d3 05c905cf 0611fa5a 0e000c3e 06880002 05e905cb 05a005bc 05cc05c0 05d605bb 05b805c9 05d005ce 05f005f0 05e005d1 05b805ec 05d305d1 05bd05d2 05c805ed 05d405d2 05d505bf 05d405d2 05ee05fa fa5a 0206 00000000 00000000 00000000 0000 0e00 0c4403ab 002505c4 05b805e6 05d305c7 05d305e4 05e005d2 05dd05e0 05a305d1 05ce05c3 05be05bd 05b605ac 05c505bd 05b405bf 05bc05dc 05d305d3 05b605b8 05b605a2 05ecfa5a 0e000c4a 00ce000a 05e205b2 05d005d0 05d505d0 05d405e1 05ed05bc 05ce05ba 05ee05ea 05a205a0 05ba05da 05de05cb 05b105d2 05a405c2 05bb05d8 05d205d0 05c705d2 05d605d3 fa5a0e00 0c4f0df1 002d05ee 05d405c6 05e205e7 05de05d2 05d905df 05dc05c9 05d405c6 05c005b2 05b805d2 05e705d9 05bc05d2 05b905d2 05d605d6 05bb05e1 05a405ab 05be05b2 05dcfa5a 0e000c55 0b150013 05cd05d0 05d205fb 05b905c0 05b405c6 05b605d9 05d805bc 05b705cf 05dc05cf 05d105bc 05b605c8 05d005d0 05d805dc 05b405d6 05c805a3 05b505ce 05c205f6 fa5a0e00 0c5b083b 003905d5 05d005ec 05ec05b8 05da05dc 05b805d8 05da05df 05b205c1 05d005e5 05d305e5 060605ec 05d205d8 05d605d5 05b405dc 05d505d5 059e05b6 05d805c4 05d9fa5a 0e000c61 055e001e 05ee05bd 05c405e5 05eb05c0 05a205b9 05d005c5 05b805ca 05d305ec 05b805ba 05ce05ed 05ea05e4 05d40602 05c705d4 05d405d3 05d105d0 05cf05c2 05ed05e5 fa5a0e00 0c670281 000305b6 05b605dc 05fe05d7 05df05e6 05bb05cc 05b905ed 05e105d6 05d605d5 05e605b3 05d705d6 05ba05be 05d205d5 05e705d4 05e805b4 05b805d6 05d105d1 0606fa5a 02060000 00000000 00000000 00000000 0e000c6c 0fa40026 05f105b7 05bf05ca 05cf05e6 05d305c8 05cd05d6 05c105d0 05c405d8 05af05c2 05c505c6 05cf05d3 05d005df 05c705c9 05d005ed 05ec05d6 05d605e5 060005f0 fa5a0e00 0c720cc7 000b05d2 05d205c8 05e505c6 05dc05c4 05ca05c0 05ec05e1 If you convert 0x0206 to decimal, you get 518, which is exactly how many bytes are before the next header. Similarly you can do the same for 0x0172 to 370 in decimal. This makes sense because 0x0400 is 1024 in hex, which is the largest UDP packet the board will send. Sample Incorrect Events: Event 22962 (25 packets): Packet 0 { Ch: 0, Time: 843213, Logical: 0, Physical: 3, Index: 1423528, Samples: [ Samples: [ 1472, 1470, 1517, 1544, 1510, 1517, 1520, 1482, 1495, 1483, 1532, 1519, 1511, 1506, 1509, 1522, 1472, 1514, 1513, 1480, 1485, 1495, 1510, 1525, 1506, 1522, 1470, 1478, 1515, 1503, 1493, 1550 ], Footer: [ 250, 90 ] } Packet 1 { Ch: 0, Time: 843213, Logical: 0, Physical: 4, Index: 1423529, Samples: [ Samples: [ 1537, 1480, 1438, 1512, 1519, 1502, 1517, 1510, 1526, 1490, 1486, 1488, 1498, 1480, 1469, 1515, 1488, 1519, 1515, 1508, 1522, 1516, 1493, 1513, 1466, 1511, 1523, 1530, 1492, 1518, 1534, 1525 ], Footer: [ 250, 90 ] } Packet 2 { Ch: 0, Time: 843213, Logical: 0, Physical: 5, Index: 1423530, Samples: [ Samples: [ 1512, 1496, 1458, 1519, 1499, 1496, 1504, 1503, 1456, 1516, 1524, 1514, 1493, 1459, 1513, 1500, 1497, 1501, 1512, 1520, 1515, 1493, 1517, 1501, 1507, 1510, 1493, 1465, 1468, 1489, 1492, 1516 ], Footer: [ 250, 90 ] } Packet 3 { Ch: 0, Time: 843213, Logical: 0, Physical: 6, Index: 142 ... [truncated] Event 1 (8 packets): Packet 0 { Ch: 0, Time: 6961400, Logical: 0, Physical: 52, Index: 0, Samples: [ Samples: [ 1535, 1470, 1486, 1536, 1528, 1504, 1518, 1498, 1520, 1516, 1516, 1498, 1518, 1516, 1495, 1471, 1514, 1537, 1495, 1470, 1521, 1526, 1488, 1492, 1506, 1519, 1495, 1522, 1489, 1540, 1526, 1528 ], Footer: [ 250, 90 ] } Packet 1 { Ch: 0, Time: 6961400, Logical: 0, Physical: 53, Index: 1, Samples: [ Samples: [ 1496, 1506, 1476, 1540, 1493, 1503, 1463, 1464, 1521, 1528, 1510, 1490, 1496, 1499, 1506, 1469, 1470, 1496, 1512, 1516, 1516, 1500, 1508, 1489, 1492, 1500, 1497, 1493, 1472, 1507, 1519, 1515 ], Footer: [ 250, 90 ] } Packet 2 { Ch: 0, Time: 6961400, Logical: 0, Physical: 54, Index: 2, Samples: [ Samples: [ 1541, 1438, 1470, 1512, 1490, 1506, 1496, 1482, 1502, 1514, 1496, 1516, 1491, 1504, 1476, 1484, 1504, 1521, 1480, 1486, 1478, 1491, 1480, 1492, 1487, 1498, 1500, 1515, 1500, 1513, 1485, 1492 ], Footer: [ 250, 90 ] } Packet 3 { Ch: 0, Time: 6961400, Logical: 0, Physical: 55, Index: 3, Samples: [ ... [truncated] Total Correct Events: 22960 (99.9913%) Total Incorrect Events: 2 (0.00871004%) Sample Incorrect Events: Event 22962 (25 packets): Packet 0 { Ch: 0, Time: 843213, Logical: 0, Physical: 3, Index: 1423528, Samples: [ Samples: [ 1472, 1470, 1517, 1544, 1510, 1517, 1520, 1482, 1495, 1483, 1532, 1519, 1511, 1506, 1509, 1522, 1472, 1514, 1513, 1480, 1485, 1495, 1510, 1525, 1506, 1522, 1470, 1478, 1515, 1503, 1493, 1550 ], Footer: [ 250, 90 ] } Packet 1 { Ch: 0, Time: 843213, Logical: 0, Physical: 4, Index: 1423529, Samples: [ Samples: [ 1537, 1480, 1438, 1512, 1519, 1502, 1517, 1510, 1526, 1490, 1486, 1488, 1498, 1480, 1469, 1515, 1488, 1519, 1515, 1508, 1522, 1516, 1493, 1513, 1466, 1511, 1523, 1530, 1492, 1518, 1534, 1525 ], Footer: [ 250, 90 ] } Packet 2 { Ch: 0, Time: 843213, Logical: 0, Physical: 5, Index: 1423530, Samples: [ Samples: [ 1512, 1496, 1458, 1519, 1499, 1496, 1504, 1503, 1456, 1516, 1524, 1514, 1493, 1459, 1513, 1500, 1497, 1501, 1512, 1520, 1515, 1493, 1517, 1501, 1507, 1510, 1493, 1465, 1468, 1489, 1492, 1516 ], Footer: [ 250, 90 ] } Packet 3 { Ch: 0, Time: 843213, Logical: 0, Physical: 6, Index: 142 ... [truncated] Event 1 (8 packets): Packet 0 { Ch: 0, Time: 6961400, Logical: 0, Physical: 52, Index: 0, Samples: [ Samples: [ 1535, 1470, 1486, 1536, 1528, 1504, 1518, 1498, 1520, 1516, 1516, 1498, 1518, 1516, 1495, 1471, 1514, 1537, 1495, 1470, 1521, 1526, 1488, 1492, 1506, 1519, 1495, 1522, 1489, 1540, 1526, 1528 ], Footer: [ 250, 90 ] } Packet 1 { Ch: 0, Time: 6961400, Logical: 0, Physical: 53, Index: 1, Samples: [ Samples: [ 1496, 1506, 1476, 1540, 1493, 1503, 1463, 1464, 1521, 1528, 1510, 1490, 1496, 1499, 1506, 1469, 1470, 1496, 1512, 1516, 1516, 1500, 1508, 1489, 1492, 1500, 1497, 1493, 1472, 1507, 1519, 1515 ], Footer: [ 250, 90 ] } Packet 2 { Ch: 0, Time: 6961400, Logical: 0, Physical: 54, Index: 2, Samples: [ Samples: [ 1541, 1438, 1470, 1512, 1490, 1506, 1496, 1482, 1502, 1514, 1496, 1516, 1491, 1504, 1476, 1484, 1504, 1521, 1480, 1486, 1478, 1491, 1480, 1492, 1487, 1498, 1500, 1515, 1500, 1513, 1485, 1492 ], Footer: [ 250, 90 ] } Packet 3 { Ch: 0, Time: 6961400, Logical: 0, Physical: 55, Index: 3, Samples: [ ... [truncated] Total Correct Events: 22960 (99.9913%) Total Incorrect Events: 2 (0.00871004%)",
    "textLength": 5597
  },
  {
    "kind": "work-log",
    "title": "30_03_2025 - 05_04_2025.html",
    "fileName": "30_03_2025 - 05_04_2025.html",
    "url": "resources/work_logs/30_03_2025 - 05_04_2025.html",
    "createdDate": "2025-03-30",
    "text": "30/03/2025 - 05/04/2025 30/03/2025 - 05/04/2025 04/04/2025 21:30 I tried running the \"double trigger\" test on the HDSoC. I first set the PWM frequency to a low rate. The parameter space point was: (10 Hz, 4 channels, 32 windows) And I only saw 10 Hz worth of events, i.e. the second trigger is not being processed 04/04/2025 21:33 I tried a slightly smaller data rate I could, just to make sure the system is not somehow being overwhelemed. I.e. I tried (10 Hz, 1 channel, 1 window) I found the similar results (strangely the event rate is usually stuck at 9.3, then spikes to 14 for a second. I think the net rate is still 10 Hz) 04/04/2025 21:57 To be absolutely sure the collector isn't just \"missing\" the packet, I printed some collector output. I used this parameter space point: (10 Hz, 1 channel, 1 window) And looked at the collector output (a slightly modified version of the main exectuable in the collector library ). I told it to try to collect events every 100 ms (corresponding to 10Hz). Each time, it only saw one event, and only one event was in the buffer. In short, this means the second trigger is completely being ignored. Here's the full output: pioneer@pioneer-MS-7D41:~/packages/software/nalu_event_collector/scripts$ ./run.sh Running the executable... [DEBUG] Starting NaluUdpReceiver... [DEBUG] Receiver started. [DEBUG] Initializing socket... [DEBUG] Socket initialization completed. Event index: 0 Event is complete: 1 Event num packets: 1 Event reference time: 14694110 Rolling Average (1): +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ | Avg Data Rate (MB/s) | Avg Parse Time (\u00b5s) | Avg Event Time (\u00b5s) | Avg UDP Time (\u00b5s) | Avg Total Time (\u00b5s) | Avg Data Processed (KB) | +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ | 0.498886 | 5.739000 | 122.724000 | 10.341000 | 141.459000 | 0.072266 | +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ Summary of Events Received: Total events received: 1 ------------------------------------------- Serialized Event (Middle Event) Buffer (First 252 bytes): bb bb 00 00 00 00 00 de 36 e0 00 50 00 01 00 00 00 00 00 00 00 01 01 00 aa aa 00 00 de 36 e0 00 00 00 28 00 06 00 05 d7 05 ce 05 de 05 d0 05 cc 05 d3 05 bc 05 9e 05 c6 05 b8 05 d1 05 ea 05 e7 05 c6 05 d7 05 f7 06 16 05 d0 05 ce 05 c9 05 db 05 ce 05 c1 05 d5 05 eb 05 eb 05 eb 05 ba 05 db 05 fc 05 d8 00 00 ff ff ee ee Serialized Event (Middle Event) Buffer (Last 50 bytes): 05 b8 05 d1 05 ea 05 e7 05 c6 05 d7 05 f7 06 16 05 d0 05 ce 05 c9 05 db 05 ce 05 c1 05 d5 05 eb 05 eb 05 eb 05 ba 05 db 05 fc 05 d8 00 00 ff ff ee ee Middle Event Details: Header: 48059 Info: 0 Index: 0 Reference Time: 14694110 Packet Size: 80 Number of Packets: 1 Footer: 61166 Timestamp: 2454461905ms Event index: 1 Event is complete: 1 Event num packets: 1 Event reference time: 1041885 Rolling Average (2): +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ | 000Avg Data Rate (MB/s) | 0000Avg Parse Time (\u00b5s) | 0000Avg Event Time (\u00b5s) | 000000Avg UDP Time (\u00b5s) | 0000Avg Total Time (\u00b5s) | Avg Data Processed (KB) | +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ | 0000000000000001.799928 | 0000000000000005.161000 | 0000000000000064.959500 | 0000000000000009.497500 | 0000000000000082.108500 | 0000000000000000.072266 | +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ Summary of Events Received: Total events received: 1 ------------------------------------------- Serialized Event (Middle Event) Buffer (First 252 bytes): bb bb 00 01 00 00 00 dd e5 0f 00 50 00 01 00 00 00 00 00 00 00 01 01 00 aa aa 00 00 dd e5 0f 00 00 00 2d 00 06 04 05 e6 05 da 05 f5 05 f8 05 ee 05 e7 05 ec 05 ec 05 ee 05 dd 05 e8 05 d6 05 d4 05 c7 05 d1 05 e7 05 f8 05 ec 05 d2 05 e2 05 ce 05 e5 05 e8 05 e9 05 d0 05 f1 05 b8 05 bc 05 d2 05 c2 05 ed 01 00 ff ff ee ee Serialized Event (Middle Event) Buffer (Last 50 bytes): 05 dd 05 e8 05 d6 05 d4 05 c7 05 d1 05 e7 05 f8 05 ec 05 d2 05 e2 05 ce 05 e5 05 e8 05 e9 05 d0 05 f1 05 b8 05 bc 05 d2 05 c2 05 ed 01 00 ff ff ee ee Middle Event Details: Header: 48059 Info: 0 Index: 1 Reference Time: 1041885 Packet Size: 80 Number of Packets: 1 Footer: 61166 Timestamp: 2454462005ms Event index: 2 Event is complete: 1 Event num packets: 1 Event reference time: 4166876 Rolling Average (3): +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ | 000Avg Data Rate (MB/s) | 0000Avg Parse Time (\u00b5s) | 0000Avg Event Time (\u00b5s) | 000000Avg UDP Time (\u00b5s) | 0000Avg Total Time (\u00b5s) | Avg Data Processed (KB) | +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ | 0000000000000002.230214 | 0000000000000005.000000 | 0000000000000045.652000 | 0000000000000009.256333 | 0000000000000062.350000 | 0000000000000000.072266 | +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ Summary of Events Received: Total events received: 1 ------------------------------------------- Serialized Event (Middle Event) Buffer (First 252 bytes): bb bb 00 02 00 00 00 dc 94 3f 00 50 00 01 00 00 00 00 00 00 00 01 01 00 aa aa 00 00 dc 94 3f 00 00 00 32 00 05 f0 05 ed 05 a2 05 de 05 ed 05 cb 05 e8 05 e4 05 d6 05 d4 05 d0 05 cf 05 dd 05 d6 05 bb 05 d8 05 ed 06 04 05 d2 05 de 05 dd 05 d0 05 bc 05 bd 05 c1 05 d3 06 03 05 ee 05 ed 05 fa 06 0b 06 04 02 00 ff ff ee ee Serialized Event (Middle Event) Buffer (Last 50 bytes): 05 d0 05 cf 05 dd 05 d6 05 bb 05 d8 05 ed 06 04 05 d2 05 de 05 dd 05 d0 05 bc 05 bd 05 c1 05 d3 06 03 05 ee 05 ed 05 fa 06 0b 06 04 02 00 ff ff ee ee Middle Event Details: Header: 48059 Info: 0 Index: 2 Reference Time: 4166876 Packet Size: 80 Number of Packets: 1 Footer: 61166 Timestamp: 2454462106ms Event index: 3 Event is complete: 1 Event num packets: 1 Event reference time: 7291867 Rolling Average (4): +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ | 000Avg Data Rate (MB/s) | 0000Avg Parse Time (\u00b5s) | 0000Avg Event Time (\u00b5s) | 000000Avg UDP Time (\u00b5s) | 0000Avg Total Time (\u00b5s) | Avg Data Processed (KB) | +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ | 0000000000000002.438116 | 0000000000000004.923250 | 0000000000000036.085500 | 0000000000000009.114250 | 0000000000000052.524750 | 0000000000000000.072266 | +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ Summary of Events Received: Total events received: 1 ------------------------------------------- Serialized Event (Middle Event) Buffer (First 252 bytes): bb bb 00 03 00 00 00 db 43 6f 00 50 00 01 00 00 00 00 00 00 00 01 01 00 aa aa 00 00 db 43 6f 00 00 00 37 00 05 ac 05 f5 05 d6 06 00 05 f1 05 f8 05 f0 05 f4 05 e1 05 eb 05 f6 05 eb 05 f0 05 cc 05 db 05 d0 05 ec 05 d0 05 ef 05 d9 05 d5 05 d4 06 06 05 fb 05 f5 05 ec 05 f2 05 d6 05 d6 05 e9 05 d6 06 03 03 00 ff ff ee ee Serialized Event (Middle Event) Buffer (Last 50 bytes): 05 f6 05 eb 05 f0 05 cc 05 db 05 d0 05 ec 05 d0 05 ef 05 d9 05 d5 05 d4 06 06 05 fb 05 f5 05 ec 05 f2 05 d6 05 d6 05 e9 05 d6 06 03 03 00 ff ff ee ee Middle Event Details: Header: 48059 Info: 0 Index: 3 Reference Time: 7291867 Packet Size: 80 Number of Packets: 1 Footer: 61166 Timestamp: 2454462206ms Event index: 4 Event is complete: 1 Event num packets: 1 Event reference time: 10416858 Rolling Average (5): +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ | 000Avg Data Rate (MB/s) | 0000Avg Parse Time (\u00b5s) | 0000Avg Event Time (\u00b5s) | 000000Avg UDP Time (\u00b5s) | 0000Avg Total Time (\u00b5s) | Avg Data Processed (KB) | +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ | 0000000000000002.573204 | 0000000000000004.879200 | 0000000000000030.294200 | 0000000000000008.998200 | 0000000000000046.553000 | 0000000000000000.072266 | +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ Summary of Events Received: Total events received: 1 ------------------------------------------- Serialized Event (Middle Event) Buffer (First 252 bytes): bb bb 00 04 00 00 00 da f2 9e 00 50 00 01 00 00 00 00 00 00 00 01 01 00 aa aa 00 00 da f2 9e 00 00 00 3c 00 05 f8 05 ce 05 d0 05 e8 05 da 05 ec 05 ce 05 ca 05 b6 05 d2 05 ec 05 ed 05 c6 05 e2 05 9e 05 d0 05 d6 05 f2 05 f6 05 d8 05 f0 05 eb 05 d4 05 e9 05 cd 05 ea 05 ce 05 e6 05 d0 05 de 05 da 05 e6 04 00 ff ff ee ee Serialized Event (Middle Event) Buffer (Last 50 bytes): 05 ec 05 ed 05 c6 05 e2 05 9e 05 d0 05 d6 05 f2 05 f6 05 d8 05 f0 05 eb 05 d4 05 e9 05 cd 05 ea 05 ce 05 e6 05 d0 05 de 05 da 05 e6 04 00 ff ff ee ee Middle Event Details: Header: 48059 Info: 0 Index: 4 Reference Time: 10416858 Packet Size: 80 Number of Packets: 1 Footer: 61166 Timestamp: 2454462307ms Event index: 5 Event is complete: 1 Event num packets: 1 Event reference time: 13541849 Rolling Average (6): +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ | 000Avg Data Rate (MB/s) | 0000Avg Parse Time (\u00b5s) | 0000Avg Event Time (\u00b5s) | 000000Avg UDP Time (\u00b5s) | 0000Avg Total Time (\u00b5s) | Avg Data Processed (KB) | +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ | 0000000000000002.660281 | 0000000000000004.855500 | 0000000000000026.418333 | 0000000000000008.946333 | 0000000000000042.593667 | 0000000000000000.072266 | +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ Summary of Events Received: Total events received: 1 ------------------------------------------- Serialized Event (Middle Event) Buffer (First 252 bytes): bb bb 00 05 00 00 00 d9 a1 ce 00 50 00 01 00 00 00 00 00 00 00 01 01 00 aa aa 00 00 d9 a1 ce 00 00 00 03 00 05 c7 05 c7 05 ed 06 10 05 ea 05 ec 05 f6 05 d0 05 dc 05 ce 06 02 05 ef 05 e9 05 e7 05 e9 05 f4 05 be 05 ea 05 e9 05 ce 05 d3 05 df 05 e9 05 f8 05 e7 05 fc 05 c7 05 cd 05 ea 05 e2 05 de 06 14 05 00 ff ff ee ee Serialized Event (Middle Event) Buffer (Last 50 bytes): 06 02 05 ef 05 e9 05 e7 05 e9 05 f4 05 be 05 ea 05 e9 05 ce 05 d3 05 df 05 e9 05 f8 05 e7 05 fc 05 c7 05 cd 05 ea 05 e2 05 de 06 14 05 00 ff ff ee ee Middle Event Details: Header: 48059 Info: 0 Index: 5 Reference Time: 13541849 Packet Size: 80 Number of Packets: 1 Footer: 61166 Timestamp: 2454462407ms Event index: 6 Event is complete: 1 Event num packets: 1 Event reference time: 16666840 Rolling Average (7): +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ | 000Avg Data Rate (MB/s) | 0000Avg Parse Time (\u00b5s) | 0000Avg Event Time (\u00b5s) | 000000Avg UDP Time (\u00b5s) | 0000Avg Total Time (\u00b5s) | Avg Data Processed (KB) | +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ | 0000000000000002.697876 | 0000000000000004.841857 | 0000000000000023.679857 | 0000000000000009.077714 | 0000000000000039.957429 | 0000000000000000.072266 | +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ Summary of Events Received: Total events received: 1 ------------------------------------------- Serialized Event (Middle Event) Buffer (First 252 bytes): bb bb 00 06 00 00 00 d8 50 fe 00 50 00 01 00 00 00 00 00 00 00 01 01 00 aa aa 00 00 d8 50 fe 00 00 00 08 00 05 f3 05 d4 05 bb 05 ec 05 f8 05 dc 05 ce 05 df 05 c8 05 d8 05 d0 05 d0 05 e0 05 ef 05 e6 05 ec 05 f0 05 ee 05 da 05 dd 05 c0 05 de 05 b8 05 cd 05 b9 05 cc 05 ef 05 fd 05 c7 05 ed 06 20 05 d3 06 00 ff ff ee ee Serialized Event (Middle Event) Buffer (Last 50 bytes): 05 d0 05 d0 05 e0 05 ef 05 e6 05 ec 05 f0 05 ee 05 da 05 dd 05 c0 05 de 05 b8 05 cd 05 b9 05 cc 05 ef 05 fd 05 c7 05 ed 06 20 05 d3 06 00 ff ff ee ee Middle Event Details: Header: 48059 Info: 0 Index: 6 Reference Time: 16666840 Packet Size: 80 Number of Packets: 1 Footer: 61166 Timestamp: 2454462508ms Event index: 7 Event is complete: 1 Event num packets: 1 Event reference time: 3014615 Rolling Average (8): +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ | 000Avg Data Rate (MB/s) | 0000Avg Parse Time (\u00b5s) | 0000Avg Event Time (\u00b5s) | 000000Avg UDP Time (\u00b5s) | 0000Avg Total Time (\u00b5s) | Avg Data Processed (KB) | +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ | 0000000000000002.744001 | 0000000000000004.816375 | 0000000000000021.627625 | 0000000000000009.038625 | 0000000000000037.839125 | 0000000000000000.072266 | +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ Summary of Events Received: Total events received: 1 ------------------------------------------- Serialized Event (Middle Event) Buffer (First 252 bytes): bb bb 00 07 00 00 00 d7 ff 2d 00 50 00 01 00 00 00 00 00 00 00 01 01 00 aa aa 00 00 d7 ff 2d 00 00 00 0d 00 05 e2 05 eb 05 ec 06 03 05 d9 05 ee 05 f1 05 de 05 d3 05 d7 05 dc 05 e8 05 ed 05 ef 05 ce 05 d9 05 d7 05 ce 05 f0 05 bc 05 e8 05 e0 05 ee 05 f8 05 ec 05 ee 05 d5 05 dc 05 ee 05 ec 05 d8 05 f6 07 00 ff ff ee ee Serialized Event (Middle Event) Buffer (Last 50 bytes): 05 dc 05 e8 05 ed 05 ef 05 ce 05 d9 05 d7 05 ce 05 f0 05 bc 05 e8 05 e0 05 ee 05 f8 05 ec 05 ee 05 d5 05 dc 05 ee 05 ec 05 d8 05 f6 07 00 ff ff ee ee Middle Event Details: Header: 48059 Info: 0 Index: 7 Reference Time: 3014615 Packet Size: 80 Number of Packets: 1 Footer: 61166 Timestamp: 2454462608ms Event index: 8 Event is complete: 1 Event num packets: 1 Event reference time: 6139606 Rolling Average (9): +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ | 000Avg Data Rate (MB/s) | 0000Avg Parse Time (\u00b5s) | 0000Avg Event Time (\u00b5s) | 000000Avg UDP Time (\u00b5s) | 0000Avg Total Time (\u00b5s) | Avg Data Processed (KB) | +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ | 0000000000000002.771048 | 0000000000000004.805778 | 0000000000000020.062889 | 0000000000000009.030778 | 0000000000000036.259556 | 0000000000000000.072266 | +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ Summary of Events Received: Total events received: 1 ------------------------------------------- Serialized Event (Middle Event) Buffer (First 252 bytes): bb bb 00 08 00 00 00 d6 ae 5d 00 50 00 01 00 00 00 00 00 00 00 01 01 00 aa aa 00 00 d6 ae 5d 00 00 00 12 00 05 f7 05 d6 05 da 05 ec 05 ec 05 c9 05 d0 05 d6 05 f2 05 f6 05 ea 05 ce 05 e7 05 e4 05 ec 05 ce 05 f2 06 00 05 e0 05 e7 05 d5 05 ed 05 ce 05 ed 05 d2 05 ec 05 d1 05 d2 05 dd 05 f0 06 0e 05 f0 08 00 ff ff ee ee Serialized Event (Middle Event) Buffer (Last 50 bytes): 05 ea 05 ce 05 e7 05 e4 05 ec 05 ce 05 f2 06 00 05 e0 05 e7 05 d5 05 ed 05 ce 05 ed 05 d2 05 ec 05 d1 05 d2 05 dd 05 f0 06 0e 05 f0 08 00 ff ff ee ee Middle Event Details: Header: 48059 Info: 0 Index: 8 Reference Time: 6139606 Packet Size: 80 Number of Packets: 1 Footer: 61166 Timestamp: 2454462709ms Event index: 9 Event is complete: 1 Event num packets: 1 Event reference time: 9264597 Rolling Average (10): +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ | 000Avg Data Rate (MB/s) | 0000Avg Parse Time (\u00b5s) | 0000Avg Event Time (\u00b5s) | 000000Avg UDP Time (\u00b5s) | 0000Avg Total Time (\u00b5s) | Avg Data Processed (KB) | +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ | 0000000000000002.804819 | 0000000000000004.800200 | 0000000000000018.769100 | 0000000000000008.983400 | 0000000000000034.903700 | 0000000000000000.072266 | +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ Summary of Events Received: Total events received: 1 ------------------------------------------- Serialized Event (Middle Event) Buffer (First 252 bytes): bb bb 00 09 00 00 00 d5 5d 8d 00 50 00 01 00 00 00 00 00 00 00 01 01 00 aa aa 00 00 d5 5d 8d 00 00 00 17 00 05 ec 05 d9 05 f1 06 07 05 d9 05 d6 05 e0 05 b8 05 d3 05 e0 06 0c 05 f0 05 dd 05 d2 06 1e 06 00 05 ed 05 f6 05 e4 05 d4 05 d6 05 dc 05 ec 05 f1 05 ec 05 d8 05 f8 05 eb 05 ff 05 f0 05 cf 06 1e 09 00 ff ff ee ee Serialized Event (Middle Event) Buffer (Last 50 bytes): 06 0c 05 f0 05 dd 05 d2 06 1e 06 00 05 ed 05 f6 05 e4 05 d4 05 d6 05 dc 05 ec 05 f1 05 ec 05 d8 05 f8 05 eb 05 ff 05 f0 05 cf 06 1e 09 00 ff ff ee ee Middle Event Details: Header: 48059 Info: 0 Index: 9 Reference Time: 9264597 Packet Size: 80 Number of Packets: 1 Footer: 61166 Timestamp: 2454462809ms [DEBUG] NaluEventCollector destroyed. [DEBUG] Destroying NaluUdpReceiver. [DEBUG] Stopping NaluUdpReceiver... [DEBUG] Socket closed. [DEBUG] Receiver thread joined. [DEBUG] Receiver stopped. pioneer@pioneer-MS-7D41:~/packages/software/nalu_event_collector/scripts$ ./run.sh Running the executable... [DEBUG] Starting NaluUdpReceiver... [DEBUG] Receiver started. [DEBUG] Initializing socket... [DEBUG] Socket initialization completed. Event index: 0 Event is complete: 1 Event num packets: 1 Event reference time: 14694110 Rolling Average (1): +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ | Avg Data Rate (MB/s) | Avg Parse Time (\u00b5s) | Avg Event Time (\u00b5s) | Avg UDP Time (\u00b5s) | Avg Total Time (\u00b5s) | Avg Data Processed (KB) | +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ | 0.498886 | 5.739000 | 122.724000 | 10.341000 | 141.459000 | 0.072266 | +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ Summary of Events Received: Total events received: 1 ------------------------------------------- Serialized Event (Middle Event) Buffer (First 252 bytes): bb bb 00 00 00 00 00 de 36 e0 00 50 00 01 00 00 00 00 00 00 00 01 01 00 aa aa 00 00 de 36 e0 00 00 00 28 00 06 00 05 d7 05 ce 05 de 05 d0 05 cc 05 d3 05 bc 05 9e 05 c6 05 b8 05 d1 05 ea 05 e7 05 c6 05 d7 05 f7 06 16 05 d0 05 ce 05 c9 05 db 05 ce 05 c1 05 d5 05 eb 05 eb 05 eb 05 ba 05 db 05 fc 05 d8 00 00 ff ff ee ee Serialized Event (Middle Event) Buffer (Last 50 bytes): 05 b8 05 d1 05 ea 05 e7 05 c6 05 d7 05 f7 06 16 05 d0 05 ce 05 c9 05 db 05 ce 05 c1 05 d5 05 eb 05 eb 05 eb 05 ba 05 db 05 fc 05 d8 00 00 ff ff ee ee Middle Event Details: Header: 48059 Info: 0 Index: 0 Reference Time: 14694110 Packet Size: 80 Number of Packets: 1 Footer: 61166 Timestamp: 2454461905ms Event index: 1 Event is complete: 1 Event num packets: 1 Event reference time: 1041885 Rolling Average (2): +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ | 000Avg Data Rate (MB/s) | 0000Avg Parse Time (\u00b5s) | 0000Avg Event Time (\u00b5s) | 000000Avg UDP Time (\u00b5s) | 0000Avg Total Time (\u00b5s) | Avg Data Processed (KB) | +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ | 0000000000000001.799928 | 0000000000000005.161000 | 0000000000000064.959500 | 0000000000000009.497500 | 0000000000000082.108500 | 0000000000000000.072266 | +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ Summary of Events Received: Total events received: 1 ------------------------------------------- Serialized Event (Middle Event) Buffer (First 252 bytes): bb bb 00 01 00 00 00 dd e5 0f 00 50 00 01 00 00 00 00 00 00 00 01 01 00 aa aa 00 00 dd e5 0f 00 00 00 2d 00 06 04 05 e6 05 da 05 f5 05 f8 05 ee 05 e7 05 ec 05 ec 05 ee 05 dd 05 e8 05 d6 05 d4 05 c7 05 d1 05 e7 05 f8 05 ec 05 d2 05 e2 05 ce 05 e5 05 e8 05 e9 05 d0 05 f1 05 b8 05 bc 05 d2 05 c2 05 ed 01 00 ff ff ee ee Serialized Event (Middle Event) Buffer (Last 50 bytes): 05 dd 05 e8 05 d6 05 d4 05 c7 05 d1 05 e7 05 f8 05 ec 05 d2 05 e2 05 ce 05 e5 05 e8 05 e9 05 d0 05 f1 05 b8 05 bc 05 d2 05 c2 05 ed 01 00 ff ff ee ee Middle Event Details: Header: 48059 Info: 0 Index: 1 Reference Time: 1041885 Packet Size: 80 Number of Packets: 1 Footer: 61166 Timestamp: 2454462005ms Event index: 2 Event is complete: 1 Event num packets: 1 Event reference time: 4166876 Rolling Average (3): +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ | 000Avg Data Rate (MB/s) | 0000Avg Parse Time (\u00b5s) | 0000Avg Event Time (\u00b5s) | 000000Avg UDP Time (\u00b5s) | 0000Avg Total Time (\u00b5s) | Avg Data Processed (KB) | +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ | 0000000000000002.230214 | 0000000000000005.000000 | 0000000000000045.652000 | 0000000000000009.256333 | 0000000000000062.350000 | 0000000000000000.072266 | +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ Summary of Events Received: Total events received: 1 ------------------------------------------- Serialized Event (Middle Event) Buffer (First 252 bytes): bb bb 00 02 00 00 00 dc 94 3f 00 50 00 01 00 00 00 00 00 00 00 01 01 00 aa aa 00 00 dc 94 3f 00 00 00 32 00 05 f0 05 ed 05 a2 05 de 05 ed 05 cb 05 e8 05 e4 05 d6 05 d4 05 d0 05 cf 05 dd 05 d6 05 bb 05 d8 05 ed 06 04 05 d2 05 de 05 dd 05 d0 05 bc 05 bd 05 c1 05 d3 06 03 05 ee 05 ed 05 fa 06 0b 06 04 02 00 ff ff ee ee Serialized Event (Middle Event) Buffer (Last 50 bytes): 05 d0 05 cf 05 dd 05 d6 05 bb 05 d8 05 ed 06 04 05 d2 05 de 05 dd 05 d0 05 bc 05 bd 05 c1 05 d3 06 03 05 ee 05 ed 05 fa 06 0b 06 04 02 00 ff ff ee ee Middle Event Details: Header: 48059 Info: 0 Index: 2 Reference Time: 4166876 Packet Size: 80 Number of Packets: 1 Footer: 61166 Timestamp: 2454462106ms Event index: 3 Event is complete: 1 Event num packets: 1 Event reference time: 7291867 Rolling Average (4): +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ | 000Avg Data Rate (MB/s) | 0000Avg Parse Time (\u00b5s) | 0000Avg Event Time (\u00b5s) | 000000Avg UDP Time (\u00b5s) | 0000Avg Total Time (\u00b5s) | Avg Data Processed (KB) | +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ | 0000000000000002.438116 | 0000000000000004.923250 | 0000000000000036.085500 | 0000000000000009.114250 | 0000000000000052.524750 | 0000000000000000.072266 | +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ Summary of Events Received: Total events received: 1 ------------------------------------------- Serialized Event (Middle Event) Buffer (First 252 bytes): bb bb 00 03 00 00 00 db 43 6f 00 50 00 01 00 00 00 00 00 00 00 01 01 00 aa aa 00 00 db 43 6f 00 00 00 37 00 05 ac 05 f5 05 d6 06 00 05 f1 05 f8 05 f0 05 f4 05 e1 05 eb 05 f6 05 eb 05 f0 05 cc 05 db 05 d0 05 ec 05 d0 05 ef 05 d9 05 d5 05 d4 06 06 05 fb 05 f5 05 ec 05 f2 05 d6 05 d6 05 e9 05 d6 06 03 03 00 ff ff ee ee Serialized Event (Middle Event) Buffer (Last 50 bytes): 05 f6 05 eb 05 f0 05 cc 05 db 05 d0 05 ec 05 d0 05 ef 05 d9 05 d5 05 d4 06 06 05 fb 05 f5 05 ec 05 f2 05 d6 05 d6 05 e9 05 d6 06 03 03 00 ff ff ee ee Middle Event Details: Header: 48059 Info: 0 Index: 3 Reference Time: 7291867 Packet Size: 80 Number of Packets: 1 Footer: 61166 Timestamp: 2454462206ms Event index: 4 Event is complete: 1 Event num packets: 1 Event reference time: 10416858 Rolling Average (5): +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ | 000Avg Data Rate (MB/s) | 0000Avg Parse Time (\u00b5s) | 0000Avg Event Time (\u00b5s) | 000000Avg UDP Time (\u00b5s) | 0000Avg Total Time (\u00b5s) | Avg Data Processed (KB) | +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ | 0000000000000002.573204 | 0000000000000004.879200 | 0000000000000030.294200 | 0000000000000008.998200 | 0000000000000046.553000 | 0000000000000000.072266 | +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ Summary of Events Received: Total events received: 1 ------------------------------------------- Serialized Event (Middle Event) Buffer (First 252 bytes): bb bb 00 04 00 00 00 da f2 9e 00 50 00 01 00 00 00 00 00 00 00 01 01 00 aa aa 00 00 da f2 9e 00 00 00 3c 00 05 f8 05 ce 05 d0 05 e8 05 da 05 ec 05 ce 05 ca 05 b6 05 d2 05 ec 05 ed 05 c6 05 e2 05 9e 05 d0 05 d6 05 f2 05 f6 05 d8 05 f0 05 eb 05 d4 05 e9 05 cd 05 ea 05 ce 05 e6 05 d0 05 de 05 da 05 e6 04 00 ff ff ee ee Serialized Event (Middle Event) Buffer (Last 50 bytes): 05 ec 05 ed 05 c6 05 e2 05 9e 05 d0 05 d6 05 f2 05 f6 05 d8 05 f0 05 eb 05 d4 05 e9 05 cd 05 ea 05 ce 05 e6 05 d0 05 de 05 da 05 e6 04 00 ff ff ee ee Middle Event Details: Header: 48059 Info: 0 Index: 4 Reference Time: 10416858 Packet Size: 80 Number of Packets: 1 Footer: 61166 Timestamp: 2454462307ms Event index: 5 Event is complete: 1 Event num packets: 1 Event reference time: 13541849 Rolling Average (6): +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ | 000Avg Data Rate (MB/s) | 0000Avg Parse Time (\u00b5s) | 0000Avg Event Time (\u00b5s) | 000000Avg UDP Time (\u00b5s) | 0000Avg Total Time (\u00b5s) | Avg Data Processed (KB) | +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ | 0000000000000002.660281 | 0000000000000004.855500 | 0000000000000026.418333 | 0000000000000008.946333 | 0000000000000042.593667 | 0000000000000000.072266 | +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ Summary of Events Received: Total events received: 1 ------------------------------------------- Serialized Event (Middle Event) Buffer (First 252 bytes): bb bb 00 05 00 00 00 d9 a1 ce 00 50 00 01 00 00 00 00 00 00 00 01 01 00 aa aa 00 00 d9 a1 ce 00 00 00 03 00 05 c7 05 c7 05 ed 06 10 05 ea 05 ec 05 f6 05 d0 05 dc 05 ce 06 02 05 ef 05 e9 05 e7 05 e9 05 f4 05 be 05 ea 05 e9 05 ce 05 d3 05 df 05 e9 05 f8 05 e7 05 fc 05 c7 05 cd 05 ea 05 e2 05 de 06 14 05 00 ff ff ee ee Serialized Event (Middle Event) Buffer (Last 50 bytes): 06 02 05 ef 05 e9 05 e7 05 e9 05 f4 05 be 05 ea 05 e9 05 ce 05 d3 05 df 05 e9 05 f8 05 e7 05 fc 05 c7 05 cd 05 ea 05 e2 05 de 06 14 05 00 ff ff ee ee Middle Event Details: Header: 48059 Info: 0 Index: 5 Reference Time: 13541849 Packet Size: 80 Number of Packets: 1 Footer: 61166 Timestamp: 2454462407ms Event index: 6 Event is complete: 1 Event num packets: 1 Event reference time: 16666840 Rolling Average (7): +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ | 000Avg Data Rate (MB/s) | 0000Avg Parse Time (\u00b5s) | 0000Avg Event Time (\u00b5s) | 000000Avg UDP Time (\u00b5s) | 0000Avg Total Time (\u00b5s) | Avg Data Processed (KB) | +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ | 0000000000000002.697876 | 0000000000000004.841857 | 0000000000000023.679857 | 0000000000000009.077714 | 0000000000000039.957429 | 0000000000000000.072266 | +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ Summary of Events Received: Total events received: 1 ------------------------------------------- Serialized Event (Middle Event) Buffer (First 252 bytes): bb bb 00 06 00 00 00 d8 50 fe 00 50 00 01 00 00 00 00 00 00 00 01 01 00 aa aa 00 00 d8 50 fe 00 00 00 08 00 05 f3 05 d4 05 bb 05 ec 05 f8 05 dc 05 ce 05 df 05 c8 05 d8 05 d0 05 d0 05 e0 05 ef 05 e6 05 ec 05 f0 05 ee 05 da 05 dd 05 c0 05 de 05 b8 05 cd 05 b9 05 cc 05 ef 05 fd 05 c7 05 ed 06 20 05 d3 06 00 ff ff ee ee Serialized Event (Middle Event) Buffer (Last 50 bytes): 05 d0 05 d0 05 e0 05 ef 05 e6 05 ec 05 f0 05 ee 05 da 05 dd 05 c0 05 de 05 b8 05 cd 05 b9 05 cc 05 ef 05 fd 05 c7 05 ed 06 20 05 d3 06 00 ff ff ee ee Middle Event Details: Header: 48059 Info: 0 Index: 6 Reference Time: 16666840 Packet Size: 80 Number of Packets: 1 Footer: 61166 Timestamp: 2454462508ms Event index: 7 Event is complete: 1 Event num packets: 1 Event reference time: 3014615 Rolling Average (8): +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ | 000Avg Data Rate (MB/s) | 0000Avg Parse Time (\u00b5s) | 0000Avg Event Time (\u00b5s) | 000000Avg UDP Time (\u00b5s) | 0000Avg Total Time (\u00b5s) | Avg Data Processed (KB) | +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ | 0000000000000002.744001 | 0000000000000004.816375 | 0000000000000021.627625 | 0000000000000009.038625 | 0000000000000037.839125 | 0000000000000000.072266 | +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ Summary of Events Received: Total events received: 1 ------------------------------------------- Serialized Event (Middle Event) Buffer (First 252 bytes): bb bb 00 07 00 00 00 d7 ff 2d 00 50 00 01 00 00 00 00 00 00 00 01 01 00 aa aa 00 00 d7 ff 2d 00 00 00 0d 00 05 e2 05 eb 05 ec 06 03 05 d9 05 ee 05 f1 05 de 05 d3 05 d7 05 dc 05 e8 05 ed 05 ef 05 ce 05 d9 05 d7 05 ce 05 f0 05 bc 05 e8 05 e0 05 ee 05 f8 05 ec 05 ee 05 d5 05 dc 05 ee 05 ec 05 d8 05 f6 07 00 ff ff ee ee Serialized Event (Middle Event) Buffer (Last 50 bytes): 05 dc 05 e8 05 ed 05 ef 05 ce 05 d9 05 d7 05 ce 05 f0 05 bc 05 e8 05 e0 05 ee 05 f8 05 ec 05 ee 05 d5 05 dc 05 ee 05 ec 05 d8 05 f6 07 00 ff ff ee ee Middle Event Details: Header: 48059 Info: 0 Index: 7 Reference Time: 3014615 Packet Size: 80 Number of Packets: 1 Footer: 61166 Timestamp: 2454462608ms Event index: 8 Event is complete: 1 Event num packets: 1 Event reference time: 6139606 Rolling Average (9): +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ | 000Avg Data Rate (MB/s) | 0000Avg Parse Time (\u00b5s) | 0000Avg Event Time (\u00b5s) | 000000Avg UDP Time (\u00b5s) | 0000Avg Total Time (\u00b5s) | Avg Data Processed (KB) | +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ | 0000000000000002.771048 | 0000000000000004.805778 | 0000000000000020.062889 | 0000000000000009.030778 | 0000000000000036.259556 | 0000000000000000.072266 | +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ Summary of Events Received: Total events received: 1 ------------------------------------------- Serialized Event (Middle Event) Buffer (First 252 bytes): bb bb 00 08 00 00 00 d6 ae 5d 00 50 00 01 00 00 00 00 00 00 00 01 01 00 aa aa 00 00 d6 ae 5d 00 00 00 12 00 05 f7 05 d6 05 da 05 ec 05 ec 05 c9 05 d0 05 d6 05 f2 05 f6 05 ea 05 ce 05 e7 05 e4 05 ec 05 ce 05 f2 06 00 05 e0 05 e7 05 d5 05 ed 05 ce 05 ed 05 d2 05 ec 05 d1 05 d2 05 dd 05 f0 06 0e 05 f0 08 00 ff ff ee ee Serialized Event (Middle Event) Buffer (Last 50 bytes): 05 ea 05 ce 05 e7 05 e4 05 ec 05 ce 05 f2 06 00 05 e0 05 e7 05 d5 05 ed 05 ce 05 ed 05 d2 05 ec 05 d1 05 d2 05 dd 05 f0 06 0e 05 f0 08 00 ff ff ee ee Middle Event Details: Header: 48059 Info: 0 Index: 8 Reference Time: 6139606 Packet Size: 80 Number of Packets: 1 Footer: 61166 Timestamp: 2454462709ms Event index: 9 Event is complete: 1 Event num packets: 1 Event reference time: 9264597 Rolling Average (10): +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ | 000Avg Data Rate (MB/s) | 0000Avg Parse Time (\u00b5s) | 0000Avg Event Time (\u00b5s) | 000000Avg UDP Time (\u00b5s) | 0000Avg Total Time (\u00b5s) | Avg Data Processed (KB) | +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ | 0000000000000002.804819 | 0000000000000004.800200 | 0000000000000018.769100 | 0000000000000008.983400 | 0000000000000034.903700 | 0000000000000000.072266 | +-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+-------------------------+ Summary of Events Received: Total events received: 1 ------------------------------------------- Serialized Event (Middle Event) Buffer (First 252 bytes): bb bb 00 09 00 00 00 d5 5d 8d 00 50 00 01 00 00 00 00 00 00 00 01 01 00 aa aa 00 00 d5 5d 8d 00 00 00 17 00 05 ec 05 d9 05 f1 06 07 05 d9 05 d6 05 e0 05 b8 05 d3 05 e0 06 0c 05 f0 05 dd 05 d2 06 1e 06 00 05 ed 05 f6 05 e4 05 d4 05 d6 05 dc 05 ec 05 f1 05 ec 05 d8 05 f8 05 eb 05 ff 05 f0 05 cf 06 1e 09 00 ff ff ee ee Serialized Event (Middle Event) Buffer (Last 50 bytes): 06 0c 05 f0 05 dd 05 d2 06 1e 06 00 05 ed 05 f6 05 e4 05 d4 05 d6 05 dc 05 ec 05 f1 05 ec 05 d8 05 f8 05 eb 05 ff 05 f0 05 cf 06 1e 09 00 ff ff ee ee Middle Event Details: Header: 48059 Info: 0 Index: 9 Reference Time: 9264597 Packet Size: 80 Number of Packets: 1 Footer: 61166 Timestamp: 2454462809ms [DEBUG] NaluEventCollector destroyed. [DEBUG] Destroying NaluUdpReceiver. [DEBUG] Stopping NaluUdpReceiver... [DEBUG] Socket closed. [DEBUG] Receiver thread joined. [DEBUG] Receiver stopped.",
    "textLength": 5479
  },
  {
    "kind": "work-log",
    "title": "03_11_2024 - 09_11_2024.html",
    "fileName": "03_11_2024 - 09_11_2024.html",
    "url": "resources/work_logs/03_11_2024 - 09_11_2024.html",
    "createdDate": "2024-11-03",
    "text": "03/11/2024 - 09/11/2024 03/11/2024 - 09/11/2024 06/11/2024 01:47 I asked a question on the xilinx forums which basically boiled down to \"use axi interconnect instead of axi smart connect\". So I did that and created this diagram. 06/11/2024 01:52 After generating and exporting a bitstream of the above block design, I was able pass the ddr3 memory tests by programming the FPGA with vitis. --Starting Memory Test Application-- NOTE: This application runs with D-Cache disabled.As a result, cacheline requests will not be generated Testing memory region: mig_7series_0_memaddr Memory Controller: mig_7series_0 Base Address: 0x80000000 Size: 0x80000000 bytes 32-bit test: PASSED! 16-bit test: PASSED! 8-bit test: PASSED! --Memory Test Application Complete-- Successfully ran Memory Test Application --Starting Memory Test Application-- NOTE: This application runs with D-Cache disabled.As a result, cacheline requests will not be generated Testing memory region: mig _7series_0_memaddr Memory Controller: mig_7series_ 0 Base Address: 0x80000000 Size: 0x80000000 bytes 32-bit test: PASSED! 16-bit test: PASSED! 8-bit test: PASSED! --Memory Test Application Complete-- Successfully ran Memory Test Application 06/11/2024 02:21 I uploaded the bitstream to the device as a bin file and I cannot see the device under lspci like I normally can. I do see the device light up, so it's not a connection issue. 06/11/2024 02:34 I made a new block design by just deleting the second AXI interconnect and running connection automation It basically just uses one big axi interconnect instead of two. I'm not sure how it knows which AXI traffic to route where... 06/11/2024 02:36 The above diagram has the exact same issue. 06/11/2024 03:01 I discovered a grave issue with the above diagram. The port names are incorrect, this means the constraint file used is not accurate, this is what we used: set_property -dict {PACKAGE_PIN K6} [get_ports pcie_refclk_clk_p] set_property -dict {PACKAGE_PIN K5} [get_ports pcie_refclk_clk_n] set_property -dict {PACKAGE_PIN R3} [get_ports {pcie_rxn[3]}] set_property -dict {PACKAGE_PIN R4} [get_ports {pcie_rxp[3]}] set_property -dict {PACKAGE_PIN N3} [get_ports {pcie_rxn[2]}] set_property -dict {PACKAGE_PIN N4} [get_ports {pcie_rxp[2]}] set_property -dict {PACKAGE_PIN L3} [get_ports {pcie_rxn[1]}] set_property -dict {PACKAGE_PIN L4} [get_ports {pcie_rxp[1]}] set_property -dict {PACKAGE_PIN J3} [get_ports {pcie_rxn[0]}] set_property -dict {PACKAGE_PIN J4} [get_ports {pcie_rxp[0]}] set_property -dict {PACKAGE_PIN P1} [get_ports {pcie_txn[3]}] set_property -dict {PACKAGE_PIN P2} [get_ports {pcie_txp[3]}] set_property -dict {PACKAGE_PIN M1} [get_ports {pcie_txn[2]}] set_property -dict {PACKAGE_PIN M2} [get_ports {pcie_txp[2]}] set_property -dict {PACKAGE_PIN K1} [get_ports {pcie_txn[1]}] set_property -dict {PACKAGE_PIN K2} [get_ports {pcie_txp[1]}] set_property -dict {PACKAGE_PIN H1} [get_ports {pcie_txn[0]}] set_property -dict {PACKAGE_PIN H2} [get_ports {pcie_txp[0]}] set_property -dict {PACKAGE_PIN E21 IOSTANDARD LVCMOS33} [get_ports pcie_reset] set_property BITSTREAM.CONFIG.CONFIGRATE 16 [current_design] set_property BITSTREAM.GENERAL.COMPRESS TRUE [current_design] set_property BITSTREAM.CONFIG.SPI_BUSWIDTH 4 [current_design]` set_property -dict {PACKAGE_PIN K6} [get_ports pcie_refclk_clk_p] set_property -dict {PACKAGE_PIN K5} [get_ports pcie_refclk_clk_n] set_property -dict {PACKAGE_PIN R3} [get_ports {pcie_rxn[3]}] set_property -dict {PACKAGE_PIN R4} [get_ports {pcie_rxp[3]}] set_property -dict {PACKAGE_PIN N3} [get_ports {pcie_rxn[2]}] set_property -dict {PACKAGE_PIN N4} [get_ports {pcie_rxp[2]}] set_property -dict {PACKAGE_PIN L3} [get_ports {pcie_rxn[1]}] set_property -dict {PACKAGE_PIN L4} [get_ports {pcie_rxp[1]}] set_property -dict {PACKAGE_PIN J3} [get_ports {pcie_rxn[0]}] set_property -dict {PACKAGE_PIN J4} [get_ports {pcie_rxp[0]}] set_property -dict {PACKAGE_PIN P1} [get_ports {pcie_txn[3]}] set_property -dict {PACKAGE_PIN P2} [get_ports {pcie_txp[3]}] set_property -dict {PACKAGE_PIN M1} [get_ports {pcie_txn[2]}] set_property -dict {PACKAGE_PIN M2} [get_ports {pcie_txp[2]}] set_property -dict {PACKAGE_PIN K1} [get_ports {pcie_txn[1]}] set_property -dict {PACKAGE_PIN K2} [get_ports {pcie_txp[1]}] set_property -dict {PACKAGE_PIN H1} [get_ports {pcie_txn[0]}] set_property -dict {PACKAGE_PIN H2} [get_ports {pcie_txp[0]}] set_property -dict {PACKAGE_PIN E21 IOSTANDARD LVCMOS33} [get_ports pcie_reset] set_property BITSTREAM.CONFIG.CONFIGRATE 16 [current_design] set_property BITSTREAM.GENERAL.COMPRESS TRUE [current_design] set_property BITSTREAM.CONFIG.SPI_BUSWIDTH 4 [current_design]` But we have no port pcie or pcie_reset! So I changed the following port names: pci_express_x4 --> pcie pcie_perstn --> pcie_reset I also went back to the first diagram, so the new diagram looks like: 06/11/2024 03:07 After those adjustments, I'm now able to see the device and pass memory tests! lspci output: [root@dhcp-10-163-102-46 scripts]# lspci -vv | grep -A 35 \"Xilinx\" 04:00.0 Serial controller: Xilinx Corporation Device 7024 (prog-if 01 [16450]) Subsystem: Xilinx Corporation Device 0007 Control: I/O+ Mem+ BusMaster+ SpecCycle- MemWINV- VGASnoop- ParErr- Stepping- SERR- FastB2B- DisINTx- Status: Cap+ 66MHz- UDF- FastB2B- ParErr- DEVSEL=fast >TAbort- <TAbort- <MAbort- >SERR- <PERR- INTx- Latency: 0, Cache Line Size: 64 bytes Interrupt: pin A routed to IRQ 41 Region 0: Memory at f5ff0000 (32-bit, non-prefetchable) [size=64K] Capabilities: [40] Power Management version 3 Flags: PMEClk- DSI- D1- D2- AuxCurrent=0mA PME(D0+,D1+,D2+,D3hot+,D3cold-) Status: D0 NoSoftRst+ PME-Enable- DSel=0 DScale=0 PME- Capabilities: [48] MSI: Enable- Count=1/1 Maskable- 64bit+ Address: 0000000000000000 Data: 0000 Capabilities: [60] Express (v2) Endpoint, MSI 00 DevCap: MaxPayload 512 bytes, PhantFunc 0, Latency L0s <64ns, L1 unlimited ExtTag+ AttnBtn- AttnInd- PwrInd- RBE+ FLReset- SlotPowerLimit 225.000W DevCtl: CorrErr- NonFatalErr+ FatalErr+ UnsupReq- RlxdOrd+ ExtTag+ PhantFunc- AuxPwr- NoSnoop+ MaxPayload 256 bytes, MaxReadReq 512 bytes DevSta: CorrErr- NonFatalErr- FatalErr- UnsupReq- AuxPwr- TransPend- LnkCap: Port #0, Speed 5GT/s, Width x4, ASPM L0s, Exit Latency L0s unlimited ClockPM- Surprise- LLActRep- BwNot- ASPMOptComp- LnkCtl: ASPM Disabled; RCB 64 bytes, Disabled- CommClk+ ExtSynch- ClockPM- AutWidDis- BWInt- AutBWInt- LnkSta: Speed 5GT/s (ok), Width x4 (ok) TrErr- Train- SlotClk+ DLActive- BWMgmt- ABWMgmt- DevCap2: Completion Timeout: Range B, TimeoutDis- NROPrPrP- LTR- 10BitTagComp- 10BitTagReq- OBFF Not Supported, ExtFmt- EETLPPrefix- EmergencyPowerReduction Not Supported, EmergencyPowerReductionInit- FRS- TPHComp- ExtTPHComp- AtomicOpsCap: 32bit- 64bit- 128bitCAS- DevCtl2: Completion Timeout: 50us to 50ms, TimeoutDis- LTR- OBFF Disabled, AtomicOpsCtl: ReqEn- LnkCtl2: Target Link Speed: 5GT/s, EnterCompliance- SpeedDis- Transmit Margin: Normal Operating Range, EnterModifiedCompliance- ComplianceSOS- Compliance De-emphasis: -6dB LnkSta2: Current De-emphasis Level: -6dB, EqualizationComplete- EqualizationPhase1- EqualizationPhase2- EqualizationPhase3- LinkEqualizationRequest- [root@dhcp-10-163-102-46 scripts]# [root@dhcp-10-163-102-46 scripts]# lspci -vv | grep -A 35 \"Xilinx\" 04:00.0 Serial controller: Xilinx Corporation Device 7024 (prog-if 01 [16450]) Subsystem: Xilinx Corporation Device 0007 Control: I/O+ Mem+ BusMaster+ SpecCycle- MemWINV- VGASnoop- ParErr- Stepping- SERR- FastB2B- DisINTx- Status: Cap+ 66MHz- UDF- FastB2B- ParErr- DEVSEL=fast >TAbort- <TAbort- <MAbort- >SERR- <PERR- INTx- Latency: 0, Cache Line Size: 64 bytes Interrupt: pin A routed to IRQ 41 Region 0: Memory at f5ff0000 (32-bit, non-prefetchable) [size=64K] Capabilities: [40] Power Management version 3 Flags: PMEClk- DSI- D1- D2- AuxCurrent=0mA PME(D0+,D1+,D2+,D3hot+,D3cold-) Status: D0 NoSoftRst+ PME-Enable- DSel=0 DScale=0 PME- Capabilities: [48] MSI: Enable- Count=1/1 Maskable- 64bit+ Address: 0000000000000000 Data: 0000 Capabilities: [60] Express (v2) Endpoint, MSI 00 DevCap: MaxPayload 512 bytes, PhantFunc 0, Latency L0s <64ns, L1 unlimited ExtTag+ AttnBtn- AttnInd- PwrInd- RBE+ FLReset- SlotPowerLimit 225.000W DevCtl: CorrErr- NonFatalErr+ FatalErr+ UnsupReq- RlxdOrd+ ExtTag+ PhantFunc- AuxPwr- NoSnoop+ MaxPayload 256 bytes, MaxReadReq 512 bytes DevSta: CorrErr- NonFatalErr- FatalErr- UnsupReq- AuxPwr- TransPend- LnkCap: Port #0, Speed 5GT/s, Width x4, ASPM L0s, Exit Latency L0s unlimited ClockPM- Surprise- LLActRep- BwNot- ASPMOptComp- LnkCtl: ASPM Disabled; RCB 64 bytes, Disabled- CommClk+ ExtSynch- ClockPM- AutWidDis- BWInt- AutBWInt- LnkSta: Speed 5GT/s (ok), Width x4 (ok) TrErr- Train- SlotClk+ DLActive- BWMgmt- ABWMgmt- DevCap2: Completion Timeout: Range B, TimeoutDis- NROPrPrP- LTR- 10BitTagComp- 10BitTagReq- OBFF Not Supported, ExtFmt- EETLPPrefix- EmergencyPowerReduction Not Supported, EmergencyPowerReductionInit- FRS- TPHComp- ExtTPHComp- AtomicOpsCap: 32bit- 64bit- 128bitCAS- DevCtl2: Completion Timeout: 50us to 50ms, TimeoutDis- LTR- OBFF Disabled, AtomicOpsCtl: ReqEn- LnkCtl2: Target Link Speed: 5GT/s, EnterCompliance- SpeedDis- Transmit Margin: Normal Operating Range, EnterModifiedCompliance- ComplianceSOS- Compliance De-emphasis: -6dB LnkSta2: Current De-emphasis Level: -6dB, EqualizationComplete- EqualizationPhase1- EqualizationPhase2- EqualizationPhase3- LinkEqualizationRequest- [root@dhcp-10-163-102-46 scripts]# loading driver: [root@dhcp-10-163-102-46 tests]# ./load_driver.sh interrupt_selection . xdma 167936 0 Loading driver...insmod xdma.ko interrupt_mode=2 ... The Kernel module installed correctly and the xmda devices were recognized. DONE [root@dhcp-10-163-102-46 tests]# [root@dhcp -10 -163 -102 -46 tests]# ./load_driver.sh interrupt_selection . xdma 167936 0 Loading driver...insmod xdma.ko interrupt_mode=2 ... The Kernel module installed correctly and the xmda devices were recognized. DONE [root@dhcp -10 -163 -102 -46 tests]# Running tests using my library: [root@dhcp-10-163-102-46 scripts]# ./run_test.sh -a 0x80000000 Write operation successful. Time taken: 0.040745 seconds. Speed: 0.00299596 MB/s Read operation successful. Time taken: 0.000196852 seconds. Speed: 0.620112 MB/s Data verification succeeded Hex dump of read data: 54 72 61 6e 73 66 65 72 20 74 65 73 74 3a 30 20 53 69 7a 65 3a 31 32 38 20 20 20 20 20 20 20 20 43 68 61 6e 6e 65 6c 3a 30 20 20 20 20 20 20 20 31 36 42 20 45 78 61 6d 70 6c 65 20 4c 69 6e 65 31 36 42 20 45 78 61 6d 70 6c 65 20 4c 69 6e 65 31 36 42 20 45 78 61 6d 70 6c 65 20 4c 69 6e 65 31 36 42 20 45 78 61 6d 70 6c 65 20 4c 69 6e 65 31 36 42 20 45 78 61 6d 70 6c 65 20 4c 69 6e 65 Number of h2c channels: 2 Number of c2h channels: 2 The PCIe DMA core is memory-mapped. [root@dhcp-10-163-102-46 scripts]# [root@dhcp-10-163-102-46 scripts] # ./run_test.sh -a 0x80000000 Write operation successful. Time taken: 0.040745 seconds. Speed: 0.00299596 MB/s Read operation successful. Time taken: 0.000196852 seconds. Speed: 0.620112 MB/s Data verification succeeded Hex dump of read data: 54 72 61 6e 73 66 65 72 20 74 65 73 74 3a 30 20 53 69 7a 65 3a 31 32 38 20 20 20 20 20 20 20 20 43 68 61 6e 6e 65 6c 3a 30 20 20 20 20 20 20 20 31 36 42 20 45 78 61 6d 70 6c 65 20 4c 69 6e 65 31 36 42 20 45 78 61 6d 70 6c 65 20 4c 69 6e 65 31 36 42 20 45 78 61 6d 70 6c 65 20 4c 69 6e 65 31 36 42 20 45 78 61 6d 70 6c 65 20 4c 69 6e 65 31 36 42 20 45 78 61 6d 70 6c 65 20 4c 69 6e 65 Number of h2c channels: 2 Number of c2h channels: 2 The PCIe DMA core is memory-mapped. [root@dhcp-10-163-102-46 scripts] # 07/11/2024 14:47 Triumf registration: https://indico.psi.ch/event/16647/registrations/2402/?token=81826272-bc17-400f-96ba-672a17a045f3 Travel funding potential: UK GSC - $400 Huffaker - $500 07/11/2024 14:54 How to correctly write a midas client, forum post and answer: https://daq00.triumf.ca/elog-midas/Midas/2885",
    "textLength": 1801
  },
  {
    "kind": "work-log",
    "title": "09_06_2024 - 15_06_2024.html",
    "fileName": "09_06_2024 - 15_06_2024.html",
    "url": "resources/work_logs/09_06_2024 - 15_06_2024.html",
    "createdDate": "2024-06-09",
    "text": "09/06/2024 - 15/06/2024 09/06/2024 - 15/06/2024 12/06/2024 06:38 I'm trying to use PCIe gen 3 by switching the card into our newer machine in the lab. Indeed I can see it with lspci -vv as expected: 05:00.0 Serial controller: Xilinx Corporation Device 7024 (prog-if 01 [16450]) Subsystem: Xilinx Corporation Device 0007 Control: I/O- Mem+ BusMaster+ SpecCycle- MemWINV- VGASnoop- ParErr- Stepping- SERR- FastB2B- DisINTx- Status: Cap+ 66MHz- UDF- FastB2B- ParErr- DEVSEL=fast >TAbort- <TAbort- <MAbort- >SERR- <PERR- INTx- Latency: 0, Cache Line Size: 64 bytes Interrupt: pin A routed to IRQ 160 Region 0: Memory at 51100000 (32-bit, non-prefetchable) [size=1M] Region 1: Memory at 51200000 (32-bit, non-prefetchable) [size=64K] Capabilities: [40] Power Management version 3 Flags: PMEClk- DSI- D1- D2- AuxCurrent=0mA PME(D0+,D1+,D2+,D3hot+,D3cold-) Status: D0 NoSoftRst+ PME-Enable- DSel=0 DScale=0 PME- Capabilities: [48] MSI: Enable+ Count=1/1 Maskable- 64bit+ Address: 00000000fee006d8 Data: 0000 Capabilities: [60] Express (v2) Endpoint, MSI 00 DevCap: MaxPayload 512 bytes, PhantFunc 0, Latency L0s <64ns, L1 unlimited ExtTag+ AttnBtn- AttnInd- PwrInd- RBE+ FLReset- SlotPowerLimit 25.000W DevCtl: CorrErr- NonFatalErr- FatalErr- UnsupReq- RlxdOrd+ ExtTag+ PhantFunc- AuxPwr- NoSnoop+ MaxPayload 256 bytes, MaxReadReq 512 bytes DevSta: CorrErr- NonFatalErr- FatalErr- UnsupReq- AuxPwr- TransPend- LnkCap: Port #0, Speed 5GT/s, Width x4, ASPM L0s, Exit Latency L0s unlimited ClockPM- Surprise- LLActRep- BwNot- ASPMOptComp- LnkCtl: ASPM Disabled; RCB 64 bytes, Disabled- CommClk+ ExtSynch- ClockPM- AutWidDis- BWInt- AutBWInt- LnkSta: Speed 5GT/s (ok), Width x4 (ok) TrErr- Train- SlotClk+ DLActive- BWMgmt- ABWMgmt- DevCap2: Completion Timeout: Range B, TimeoutDis- NROPrPrP- LTR- 10BitTagComp- 10BitTagReq- OBFF Not Supported, ExtFmt- EETLPPrefix- EmergencyPowerReduction Not Supported, EmergencyPowerReductionInit- FRS- TPHComp- ExtTPHComp- AtomicOpsCap: 32bit- 64bit- 128bitCAS- DevCtl2: Completion Timeout: 50us to 50ms, TimeoutDis- LTR- OBFF Disabled, AtomicOpsCtl: ReqEn- LnkCtl2: Target Link Speed: 5GT/s, EnterCompliance- SpeedDis- Transmit Margin: Normal Operating Range, EnterModifiedCompliance- ComplianceSOS- Compliance De-emphasis: -6dB LnkSta2: Current De-emphasis Level: -6dB, EqualizationComplete- EqualizationPhase1- EqualizationPhase2- EqualizationPhase3- LinkEqualizationRequest- Retimer- 2Retimers- CrosslinkRes: unsupported Capabilities: [100 v1] Device Serial Number 00-00-00-00-00-00-00-00 Kernel driver in use: xdma Kernel modules: xdma 05:00.0 Serial controller: Xilinx Corporation Device 7024 (prog-if 01 [16450]) Subsystem: Xilinx Corporation Device 0007 Control: I/O- Mem+ BusMaster+ SpecCycle- MemWINV- VGASnoop- ParErr- Stepping- SERR- FastB2B- DisINTx- Status: Cap+ 66MHz- UDF- FastB2B- ParErr- DEVSEL=fast >TAbort- <TAbort- <MAbort- >SERR- <PERR- INTx- Latency: 0, Cache Line Size: 64 bytes Interrupt: pin A routed to IRQ 160 Region 0: Memory at 51100000 (32-bit, non-prefetchable) [size=1M] Region 1: Memory at 51200000 (32-bit, non-prefetchable) [size=64K] Capabilities: [40] Power Management version 3 Flags: PMEClk- DSI- D1- D2- AuxCurrent=0mA PME(D0+,D1+,D2+,D3hot+,D3cold-) Status: D0 NoSoftRst+ PME-Enable- DSel=0 DScale=0 PME- Capabilities: [48] MSI: Enable+ Count=1/1 Maskable- 64bit+ Address: 00000000fee006d8 Data: 0000 Capabilities: [60] Express (v2) Endpoint, MSI 00 DevCap: MaxPayload 512 bytes, PhantFunc 0, Latency L0s <64ns, L1 unlimited ExtTag+ AttnBtn- AttnInd- PwrInd- RBE+ FLReset- SlotPowerLimit 25.000W DevCtl: CorrErr- NonFatalErr- FatalErr- UnsupReq- RlxdOrd+ ExtTag+ PhantFunc- AuxPwr- NoSnoop+ MaxPayload 256 bytes, MaxReadReq 512 bytes DevSta: CorrErr- NonFatalErr- FatalErr- UnsupReq- AuxPwr- TransPend- LnkCap: Port #0, Speed 5GT/s, Width x4, ASPM L0s, Exit Latency L0s unlimited ClockPM- Surprise- LLActRep- BwNot- ASPMOptComp- LnkCtl: ASPM Disabled; RCB 64 bytes, Disabled- CommClk+ ExtSynch- ClockPM- AutWidDis- BWInt- AutBWInt- LnkSta: Speed 5GT/s (ok), Width x4 (ok) TrErr- Train- SlotClk+ DLActive- BWMgmt- ABWMgmt- DevCap2: Completion Timeout: Range B, TimeoutDis- NROPrPrP- LTR- 10BitTagComp- 10BitTagReq- OBFF Not Supported, ExtFmt- EETLPPrefix- EmergencyPowerReduction Not Supported, EmergencyPowerReductionInit- FRS- TPHComp- ExtTPHComp- AtomicOpsCap: 32bit- 64bit- 128bitCAS- DevCtl2: Completion Timeout: 50us to 50ms, TimeoutDis- LTR- OBFF Disabled, AtomicOpsCtl: ReqEn- LnkCtl2: Target Link Speed: 5GT/s, EnterCompliance- SpeedDis- Transmit Margin: Normal Operating Range, EnterModifiedCompliance- ComplianceSOS- Compliance De-emphasis: -6dB LnkSta2: Current De-emphasis Level: -6dB, EqualizationComplete- EqualizationPhase1- EqualizationPhase2- EqualizationPhase3- LinkEqualizationRequest- Retimer- 2Retimers- CrosslinkRes: unsupported Capabilities: [100 v1] Device Serial Number 00-00-00-00-00-00-00-00 Kernel driver in use: xdma Kernel modules: xdma I moved the driver files from fe01 to the newer desktop. When trying to run build-install-driver-linux.sh in /home/pioneer/pcie_testing/XilinxAR65444/Linux it didn't work initially. the make call in the script complains: function \u2018mmiowb\u2019 [-Werror=implicit-function-declaration] 921 | mmiowb(); | ^~~~~~ cc1: some warnings being treated as errors function \u2018mmiowb\u2019 [-Werror= implicit - function -declaration] 921 | mmiowb(); | ^~~~~~ cc1: some warnings being treated as errors I googled the issue and found this forum post: https://support.xilinx.com/s/question/0D52E00006hpLONSA2/compilation-error-pcie-drivers-for-linux?language=en_US Which basically just says \"comment out all instances of \" mmiowb() . There is exactly one in xdma-core.c, so I commented it out. Then things compiled. Loading the the driver and attempting to run some tests seemed to work: root@pioneer-MS-7D41:/home/pioneer/pcie_testing/XilinxAR65444/Linux/Xilinx_Answer_65444_Linux_Files/tests# ./load_driver.sh xdma 61440 0 Loading driver... The Kernel module installed correctly and the xmda devices were recognized. DONE root@pioneer-MS-7D41:/home/pioneer/pcie_testing/XilinxAR65444/Linux/Xilinx_Answer_65444_Linux_Files/tests# ./run_test.sh Info: Number of enabled h2c channels = 2 Info: Number of enabled c2h channels = 2 Info: The PCIe DMA core is memory mapped. Info: Running PCIe DMA memory mapped write read test transfer size: 1024 transfer count: 1 Info: Writing to h2c channel 0 at address offset 0. Info: Writing to h2c channel 1 at address offset 1024. Info: Wait for current transactions to complete. sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000000 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_h2c_0, address = 0x00000000, size = 0x00000400, offset = 0x00000000, count = 1 host memory buffer = 0x559fc9f48800 CLOCK_MONOTONIC reports 0.000095085 seconds (total) for last transfer of 1024 bytes Transfer speed: 10.27 MB/s sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_h2c_1, address = 0x00000400, size = 0x00000400, offset = 0x00000000, count = 1 host memory buffer = 0x55ff1d607800 CLOCK_MONOTONIC reports 0.000060218 seconds (total) for last transfer of 1024 bytes Transfer speed: 16.22 MB/s Info: Writing to h2c channel 0 at address offset 2048. Info: Writing to h2c channel 1 at address offset 3072. Info: Wait for current transactions to complete. sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000800 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_h2c_0, address = 0x00000800, size = 0x00000400, offset = 0x00000000, count = 1 host memory buffer = 0x555ae6579800 CLOCK_MONOTONIC reports 0.000055266 seconds (total) for last transfer of 1024 bytes Transfer speed: 17.67 MB/s sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000c00 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_h2c_1, address = 0x00000c00, size = 0x00000400, offset = 0x00000000, count = 1 host memory buffer = 0x55790b0e3800 CLOCK_MONOTONIC reports 0.000055462 seconds (total) for last transfer of 1024 bytes Transfer speed: 17.61 MB/s Info: Reading from c2h channel 0 at address offset 0. sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000000 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_c2h_0, address = 0x00000000, size = 0x00000400, offset = 0x00000000, count = 1 host memory buffer = 0x555ba77dc000 Info: Reading from c2h channel 1 at address offset 1024. Info: Wait for the current transactions to complete. sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_c2h_1, address = 0x00000400, size = 0x00000400, offset = 0x00000000, count = 1 host memory buffer = 0x559ca193d000 CLOCK_MONOTONIC reports 0.000066850 seconds (total) for last transfer of 1024 bytes Transfer speed: 14.61 MB/s CLOCK_MONOTONIC reports 0.000048417 seconds (total) for last transfer of 1024 bytes Transfer speed: 20.17 MB/s Info: Reading from c2h channel 0 at address offset 2048. sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000800 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_c2h_0, address = 0x00000800, size = 0x00000400, offset = 0x00000000, count = 1 host memory buffer = 0x55654b13d000 Info: Reading from c2h channel 1 at address offset 3072. Info: Wait for the current transactions to complete. sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000c00 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_c2h_1, address = 0x00000c00, size = 0x00000400, offset = 0x00000000, count = 1 host memory buffer = 0x555b3109f000 CLOCK_MONOTONIC reports 0.000077351 seconds (total) for last transfer of 1024 bytes Transfer speed: 12.63 MB/s CLOCK_MONOTONIC reports 0.000049442 seconds (total) for last transfer of 1024 bytes Transfer speed: 19.75 MB/s Info: Checking data integrity. Info: Data check passed for address range 0 - 1024. Info: Data check passed for address range 1024 - 2048. Info: Data check passed for address range 2048 - 3072. Info: Data check passed for address range 3072 - 4096. Info: All PCIe DMA memory mapped tests passed. Info: All tests in run_tests.sh passed. root@pioneer-MS-7D41:/home/pioneer/pcie_testing/XilinxAR65444/Linux/Xilinx_Answer_65444_Linux_Files/tests# root@pioneer-MS-7D41:/home/pioneer/pcie_testing/XilinxAR65444/Linux/Xilinx_Answer_65444_Linux_Files/tests# ./load_driver.sh xdma 61440 0 Loading driver... The Kernel module installed correctly and the xmda devices were recognized. DONE root@pioneer-MS-7D41:/home/pioneer/pcie_testing/XilinxAR65444/Linux/Xilinx_Answer_65444_Linux_Files/tests# ./run_test.sh Info: Number of enabled h2c channels = 2 Info: Number of enabled c2h channels = 2 Info: The PCIe DMA core is memory mapped. Info: Running PCIe DMA memory mapped write read test transfer size: 1024 transfer count: 1 Info: Writing to h2c channel 0 at address offset 0. Info: Writing to h2c channel 1 at address offset 1024. Info: Wait for current transactions to complete. sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000000 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_h2c_0, address = 0x00000000, size = 0x00000400, offset = 0x00000000, count = 1 host memory buffer = 0x559fc9f48800 CLOCK_MONOTONIC reports 0.000095085 seconds (total) for last transfer of 1024 bytes Transfer speed: 10.27 MB/s sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_h2c_1, address = 0x00000400, size = 0x00000400, offset = 0x00000000, count = 1 host memory buffer = 0x55ff1d607800 CLOCK_MONOTONIC reports 0.000060218 seconds (total) for last transfer of 1024 bytes Transfer speed: 16.22 MB/s Info: Writing to h2c channel 0 at address offset 2048. Info: Writing to h2c channel 1 at address offset 3072. Info: Wait for current transactions to complete. sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000800 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_h2c_0, address = 0x00000800, size = 0x00000400, offset = 0x00000000, count = 1 host memory buffer = 0x555ae6579800 CLOCK_MONOTONIC reports 0.000055266 seconds (total) for last transfer of 1024 bytes Transfer speed: 17.67 MB/s sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000c00 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_h2c_1, address = 0x00000c00, size = 0x00000400, offset = 0x00000000, count = 1 host memory buffer = 0x55790b0e3800 CLOCK_MONOTONIC reports 0.000055462 seconds (total) for last transfer of 1024 bytes Transfer speed: 17.61 MB/s Info: Reading from c2h channel 0 at address offset 0. sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000000 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_c2h_0, address = 0x00000000, size = 0x00000400, offset = 0x00000000, count = 1 host memory buffer = 0x555ba77dc000 Info: Reading from c2h channel 1 at address offset 1024. Info: Wait for the current transactions to complete. sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_c2h_1, address = 0x00000400, size = 0x00000400, offset = 0x00000000, count = 1 host memory buffer = 0x559ca193d000 CLOCK_MONOTONIC reports 0.000066850 seconds (total) for last transfer of 1024 bytes Transfer speed: 14.61 MB/s CLOCK_MONOTONIC reports 0.000048417 seconds (total) for last transfer of 1024 bytes Transfer speed: 20.17 MB/s Info: Reading from c2h channel 0 at address offset 2048. sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000800 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_c2h_0, address = 0x00000800, size = 0x00000400, offset = 0x00000000, count = 1 host memory buffer = 0x55654b13d000 Info: Reading from c2h channel 1 at address offset 3072. Info: Wait for the current transactions to complete. sscanf() = 1, value = 0x00000400 sscanf() = 1, value = 0x00000c00 sscanf() = 1, value = 0x00000001 device = /dev/xdma0_c2h_1, address = 0x00000c00, size = 0x00000400, offset = 0x00000000, count = 1 host memory buffer = 0x555b3109f000 CLOCK_MONOTONIC reports 0.000077351 seconds (total) for last transfer of 1024 bytes Transfer speed: 12.63 MB/s CLOCK_MONOTONIC reports 0.000049442 seconds (total) for last transfer of 1024 bytes Transfer speed: 19.75 MB/s Info: Checking data integrity. Info: Data check passed for address range 0 - 1024. Info: Data check passed for address range 1024 - 2048. Info: Data check passed for address range 2048 - 3072. Info: Data check passed for address range 3072 - 4096. Info: All PCIe DMA memory mapped tests passed. Info: All tests in run_tests.sh passed. root@pioneer-MS-7D41:/home/pioneer/pcie_testing/XilinxAR65444/Linux/Xilinx_Answer_65444_Linux_Files/tests# 12/06/2024 06:46 Trying to run the speed tests root@pioneer-MS-7D41:/home/pioneer/pcie_testing/XilinxAR65444/Linux/Xilinx_Answer_65444_Linux_Files/tests# ./dma_from_device -d /dev/xdma0_c2h_0 -f data/datafile_32M.bin -s 33554432 sscanf() = 1, value = 0x02000000 device = /dev/xdma0_c2h_0, address = 0x00000000, size = 0x02000000, offset = 0x00000000, count = 1 host memory buffer = 0x7ff3074ed000 CLOCK_MONOTONIC reports 0.041413173 seconds (total) for last transfer of 33554432 bytes Transfer speed: 772.70 MB/s root@pioneer-MS-7D41:/home/pioneer/pcie_testing/XilinxAR65444/Linux/Xilinx_Answer_65444_Linux_Files/tests# ./dma_to_devi ce -d /dev/xdma0_h2c_0 -f data/datafile_32M.bin -s 33554432 sscanf() = 1, value = 0x02000000 device = /dev/xdma0_h2c_0, address = 0x00000000, size = 0x02000000, offset = 0x00000000, count = 1 host memory buffer = 0x7f5e9806d400 CLOCK_MONOTONIC reports 0.035558064 seconds (total) for last transfer of 33554432 bytes Transfer speed: 899.94 MB/s root@pioneer-MS-7D41:/home/pioneer/pcie_testing/XilinxAR65444/Linux/Xilinx_Answer_65444_Linux_Files/tests# root@pioneer-MS-7D41:/home/pioneer/pcie_testing/XilinxAR65444/Linux/Xilinx_Answer_65444_Linux_Files/tests# ./dma_from_device -d /dev/xdma0_c2h_0 -f data/datafile_32M.bin -s 33554432 sscanf() = 1, value = 0x02000000 device = /dev/xdma0_c2h_0, address = 0x00000000, size = 0x02000000, offset = 0x00000000, count = 1 host memory buffer = 0x7ff3074ed000 CLOCK_MONOTONIC reports 0.041413173 seconds (total) for last transfer of 33554432 bytes Transfer speed: 772.70 MB/s root@pioneer-MS-7D41:/home/pioneer/pcie_testing/XilinxAR65444/Linux/Xilinx_Answer_65444_Linux_Files/tests# ./dma_to_devi ce -d /dev/xdma0_h2c_0 -f data/datafile_32M.bin -s 33554432 sscanf() = 1, value = 0x02000000 device = /dev/xdma0_h2c_0, address = 0x00000000, size = 0x02000000, offset = 0x00000000, count = 1 host memory buffer = 0x7f5e9806d400 CLOCK_MONOTONIC reports 0.035558064 seconds (total) for last transfer of 33554432 bytes Transfer speed: 899.94 MB/s root@pioneer-MS-7D41:/home/pioneer/pcie_testing/XilinxAR65444/Linux/Xilinx_Answer_65444_Linux_Files/tests# Shows that putting the card in the PCIe3.0 slot does not speed it up. This is expected becuase somehow Vivado is hardcoding a limit of 5.0 GT/s. 12/06/2024 07:10 Upon further investigation, this limit is somehow specified by the board files. I opened another board file (Versal VCK190 Evaluation Platform) and created an XDMA IP block. This had the option for transfer speeds up to PCIE gen 4 (16 GT/s). It seems the speed we see is a limitation of the card. Maybe we can try to push the HTG-K700 to see if we can push that further.",
    "textLength": 2408
  },
  {
    "kind": "work-log",
    "title": "15_09_2024 - 21_09_2024.html",
    "fileName": "15_09_2024 - 21_09_2024.html",
    "url": "resources/work_logs/15_09_2024 - 21_09_2024.html",
    "createdDate": "2024-09-15",
    "text": "15/09/2024 - 21/09/2024 15/09/2024 - 21/09/2024 18/09/2024 04:06 Cockpit is a web interface that shows server information (really computer information) about the machine with cockpit installed. It seems to have \"come with\" alma9 linux. It may be useful. To activate, I did the following: systemctl enable --now cockpit.socket systemctl enable --now cockpit.socket This opens a webpage on localhost:9090 . You have to port forward an ssh connection to do this, for example: ssh -L 9090:localhost:9090 root@10.163.102.46 ssh -L 9090 :localhost: 9090 root@ 10.163.102.46 If you need to login as a root user, you need to edit the file /etc/cockpit/disallowed-users . Simply remove the line with root in the file, save and exit using your favorite text editor (for example vi /etc/cockpit/disallowed-users ). Then you can login as root. 19/09/2024 05:07 While making the pcie_readout test frontend, I had an error due to midas writing the the events to the ODB. [DataSimulator,ERROR] [odb.cxx:559:realloc_data,ERROR] cannot malloc_data(1048576), called from db_set_data1 [DataSimulator,ERROR] [odb.cxx:6999:db_set_data1,ERROR] Cannot reallocate \"/Equipment/Data Simulator/Variables/CR00\" with new size 1048576 bytes, online database full [DataSimulator,ERROR] [midas.cxx:17635:cm_write_event_to_odb,ERROR] cannot write bank \"CR00\" to ODB, db_set_data1() status 310 [DataSimulator, ERROR ] [odb.cxx:559:realloc_data, ERROR ] cannot malloc_data(1048576), called from db_set_data1 [DataSimulator, ERROR ] [odb.cxx:6999:db_set_data1, ERROR ] Cannot reallocate \"/Equipment/Data Simulator/Variables/CR00\" with new size 1048576 bytes, online database full [DataSimulator, ERROR ] [midas.cxx:17635:cm_write_event_to_odb, ERROR ] cannot write bank \"CR00\" to ODB, db_set_data1() status 310 This can be removed by editting the equipment setting RO_ODB and RO_TRANSITIONS from being added to the \"Read on\" mask: EQUIPMENT equipment[] = { {\"Data Simulator\", {2, 0, \"SYSTEM\", EQ_POLLED, 0, \"MIDAS\", TRUE, RO_RUNNING, //remove RO_TRANSITIONS, remove RO_ODB, 1, //poll time 0, 0, TRUE, \"\", \"\", \"\",}, read_trigger_event }, {\"\"} }; EQUIPMENT equipment[] = { { \"Data Simulator\" , { 2 , 0 , \"SYSTEM\" , EQ_POLLED, 0, \"MIDAS\" , TRUE, RO_RUNNING, //remove RO_TRANSITIONS, remove RO_ODB, 1, //poll time 0, 0, TRUE, \"\" , \"\" , \"\" ,}, read_trigger_event }, { \"\" } } ; 19/09/2024 05:35 This is as fast as I can get the PCIe data readout to work. Basically, it's just reading data from the PCIe (not writing). 19/09/2024 08:07 There is some mystery going on with the transfer rates. Upon updating the operating system (and consequently needing to update the driver), I am now achieving lower data rates. First, here is a plot with serveral benchmarks overlayed: It's a bit hard to see, but the Xilinx tools reads out perform my C++ library reads for some reason. Also, the shapes are very different. The shapes are more clear in these individual plots And here are individual test some comparison plots: The shape of the XDMA tools is more what I expect, however the data rates are significantly lower than what I saw before updating the operating system (and using the older driver) as seen below. In any event, these plots explain why the midas frontend is capped at around 600 MB/s right now; because that's the fastest reads can be made using my C++ library (for 1 channel, at least). 19/09/2024 14:52 Some more data on the distriubtion because I don't trust the error bars.",
    "textLength": 553
  },
  {
    "kind": "work-log",
    "title": "17_11_2024 - 23_11_2024.html",
    "fileName": "17_11_2024 - 23_11_2024.html",
    "url": "resources/work_logs/17_11_2024 - 23_11_2024.html",
    "createdDate": "2024-11-17",
    "text": "17/11/2024 - 23/11/2024 17/11/2024 - 23/11/2024 18/11/2024 20:27 I started trying to get nalu's UDP data capture example to work so we don't have to use the 2Mbps serial line which is painfully slow. However, I'm stuck on the cell: BOARD.connect_udp( board_addr=(\"192.168.22.40\", 4660), receiver_addr=(\"192.168.22.129\", 4660), # backend_addr=('127.0.0.1', 7878), # Optional, if you want to connect to an external backend, only if you don't run `BOARD.start_server` ) BOARD.connect_udp( board_addr=(\"192.168.22.40\", 4660 ), receiver_addr=( \"192.168.22.129\" , 4660 ), # backend_addr=('127.0.0.1', 7878), # Optional, if you want to connect to an external backend, only if you don't run `BOARD.start_server` ) Getting errors about not establishing a connection: Pre-error output: 2024-11-18 20:07:01,629 naludaq.board [INFO ]: Connecting UDP with board_addr=('10.0.0.4', 4660), receiver_addr=('192.168.22.129', 4660), backend_addr=None 2024-11-18 20:07:01,629 urllib3.connectionpool [DEBUG ]: Starting new HTTP connection (1): 127.0.0.1:58934 2024-11-18 20:07:01,630 urllib3.connectionpool [DEBUG ]: http://127.0.0.1:58934 \"GET /connection/info HTTP/1.1\" 200 65 2024-11-18 20:07:01,632 urllib3.connectionpool [DEBUG ]: http://127.0.0.1:58934 \"PUT /server/data-format?model=hdsocv1_evalr2&events=fa5a&answers=cafe HTTP/1.1\" 200 4 2024-11-18 20:07:01,632 urllib3.connectionpool [DEBUG ]: http://127.0.0.1:58934 \"GET /connection/info HTTP/1.1\" 200 65 2024-11-18 20:07:01,633 urllib3.connectionpool [DEBUG ]: http://127.0.0.1:58934 \"PUT /connection/disconnect HTTP/1.1\" 200 4 2024-11-18 20:07:01,634 urllib3.connectionpool [DEBUG ]: http://127.0.0.1:58934 \"PUT /connection/udp?board=10.0.0.4%3A4660&receiver=192.168.22.129%3A4660 HTTP/1.1\" 400 54 2024-11-19T01:07:01.631913Z DEBUG ThreadId(22) run:run_packager_task_controller: src/workers/packager.rs:206: Starting packager: PackagerConfig { model: \"hdsocv1_evalr2\", event_stop_word: [250, 90], answer_stop_word: [202, 254] } 2024-11-19T01:07:01.631952Z DEBUG ThreadId(22) run_packager_impl: src/workers/packager.rs:256: Running package worker with config: PackagerConfig { model: \"hdsocv1_evalr2\", event_stop_word: [250, 90], answer_stop_word: [202, 254] } 2024-11-19T01:07:01.631957Z DEBUG ThreadId(22) run_packager_impl: src/workers/packager.rs:259: SELECTING HDSOC PACKAGER 2024-11-19T01:07:01.634374Z ERROR ThreadId(24) connect_udp: src/web_api/connection.rs:34: error=failed to open a connection state=ServerState { root: \"/root/nalu_related/naluexamples/examples/output\", workers: Workers { connection: ConnectionWorker { command_rx: Receiver, response_tx: Sender, from_board_tx: Sender, response_handler: WorkerResponseHandler { responses: RwLock { data: {} }, tx: Sender, rx: Receiver, timeout: 5s } }, package: PackageWorker { command_rx: Receiver, response_tx: Sender, events_tx: Sender, answers_tx: Sender, data_rx: Receiver, response_handler: WorkerResponseHandler { responses: RwLock { data: {} }, tx: Sender, rx: Receiver, timeout: 5s } }, storage: StorageWorker { root: \"/root/nalu_related/naluexamples/examples/output\", command_rx: Receiver, response_tx: Sender, events_rx: Receiver, response_handler: WorkerResponseHandler { responses: RwLock { data: {} }, tx: Sender, rx: Receiver, timeout: 5s } }, answer: AnswerWorker { answers_rx: Receiver, answers: Answers { answers: RwLock { data: BoundedHashMap { capacity: 128, map: {}, order: [] } } } } } } payload=UdpConnectionAddress { board: \"10.0.0.4:4660\", receiver: \"192.168.22.129:4660\" } 2024-11-18 20:07:01,629 naludaq.board [INFO ]: Connecting UDP with board_addr=('10.0.0.4', 4660), receiver_addr=('192.168.22.129', 4660), backend_addr=None 2024-11-18 20:07:01,629 urllib3.connectionpool [DEBUG ]: Starting new HTTP connection (1): 127.0.0.1:58934 2024-11-18 20:07:01,630 urllib3.connectionpool [DEBUG ]: http://127.0.0.1:58934 \"GET /connection/info HTTP/1.1\" 200 65 2024-11-18 20:07:01,632 urllib3.connectionpool [DEBUG ]: http://127.0.0.1:58934 \"PUT /server/data-format?model=hdsocv1_evalr2&events=fa5a&answers=cafe HTTP/1.1\" 200 4 2024-11-18 20:07:01,632 urllib3.connectionpool [DEBUG ]: http://127.0.0.1:58934 \"GET /connection/info HTTP/1.1\" 200 65 2024-11-18 20:07:01,633 urllib3.connectionpool [DEBUG ]: http://127.0.0.1:58934 \"PUT /connection/disconnect HTTP/1.1\" 200 4 2024-11-18 20:07:01,634 urllib3.connectionpool [DEBUG ]: http://127.0.0.1:58934 \"PUT /connection/udp?board=10.0.0.4%3A4660&receiver=192.168.22.129%3A4660 HTTP/1.1\" 400 54 2024-11-19T01:07:01.631913Z DEBUG ThreadId(22) run:run_packager_task_controller: src/workers/packager.rs:206: Starting packager: PackagerConfig { model: \"hdsocv1_evalr2\", event_stop_word: [250, 90], answer_stop_word: [202, 254] } 2024-11-19T01:07:01.631952Z DEBUG ThreadId(22) run_packager_impl: src/workers/packager.rs:256: Running package worker with config: PackagerConfig { model: \"hdsocv1_evalr2\", event_stop_word: [250, 90], answer_stop_word: [202, 254] } 2024-11-19T01:07:01.631957Z DEBUG ThreadId(22) run_packager_impl: src/workers/packager.rs:259: SELECTING HDSOC PACKAGER 2024-11-19T01:07:01.634374Z ERROR ThreadId(24) connect_udp: src/web_api/connection.rs:34: error=failed to open a connection state=ServerState { root: \"/root/nalu_related/naluexamples/examples/output\", workers: Workers { connection: ConnectionWorker { command_rx: Receiver, response_tx: Sender, from_board_tx: Sender, response_handler: WorkerResponseHandler { responses: RwLock { data: {} }, tx: Sender, rx: Receiver, timeout: 5s } }, package: PackageWorker { command_rx: Receiver, response_tx: Sender, events_tx: Sender, answers_tx: Sender, data_rx: Receiver, response_handler: WorkerResponseHandler { responses: RwLock { data: {} }, tx: Sender, rx: Receiver, timeout: 5s } }, storage: StorageWorker { root: \"/root/nalu_related/naluexamples/examples/output\", command_rx: Receiver, response_tx: Sender, events_rx: Receiver, response_handler: WorkerResponseHandler { responses: RwLock { data: {} }, tx: Sender, rx: Receiver, timeout: 5s } }, answer: AnswerWorker { answers_rx: Receiver, answers: Answers { answers: RwLock { data: BoundedHashMap { capacity: 128, map: {}, order: [] } } } } } } payload=UdpConnectionAddress { board: \"10.0.0.4:4660\", receiver: \"192.168.22.129:4660\" } Error: --------------------------------------------------------------------------- ConnectionError Traceback (most recent call last) Cell In[12], line 5 2 board_ip = \"10.0.0.4\" 3 receiver_ip = \"192.168.22.129\" ----> 5 BOARD.connect_udp( 6 board_addr=(board_ip, 4660), 7 receiver_addr=(receiver_ip, 4660), 8 # backend_addr=('127.0.0.1', 7878), # Optional, if you want to connect to an external backend, only if you don't run `BOARD.start_server` 9 ) File /usr/local/lib/python3.10/dist-packages/naludaq/board/__init__.py:340, in Board.connect_udp(self, board_addr, receiver_addr, backend_addr) 333 LOGGER.info( 334 \"Connecting UDP with board_addr=%s, receiver_addr=%s, backend_addr=%s\", 335 board_addr, 336 receiver_addr, 337 backend_addr, 338 ) 339 self.connect_server(backend_addr) --> 340 device = ConnectionManager(self).connect_udp(board_addr, receiver_addr) 341 self.connection_info = device.info 342 get_connection_controller(self).configure_connection() File /usr/local/lib/python3.10/dist-packages/naludaq/backend/managers/connection.py:88, in ConnectionManager.connect_udp(self, board_addr, receiver_addr, attempts) 86 receiver_addr = \":\".join(map(str, receiver_addr)) 87 arguments = {\"board\": board_addr, \"receiver\": receiver_addr} ---> 88 self._connect_with_attempts(\"udp\", arguments, attempts) 89 return UdpDevice(self.context) File /usr/local/lib/python3.10/dist-packages/naludaq/backend/managers/connection.py:214, in ConnectionManager._connect_with_attempts(self, type_name, params, attempts) 212 self.disconnect() 213 try: --> 214 self.context.client.put(ROUTE, params=params) 215 except HttpError: 216 pass File /usr/local/lib/python3.10/dist-packages/naludaq/backend/client.py:51, in HttpClient.put(self, route, params, json) 49 def put(self, route: str, *, params=None, json=None) -> requests.Response: 50 \"\"\"Send a PUT request to the server.\"\"\" ---> 51 return self._request(\"put\", route, params=params, json=json) File /usr/local/lib/python3.10/dist-packages/naludaq/backend/client.py:123, in HttpClient._request(self, method, route, **kwargs) 121 except Exception as e: 122 raise BackendError(\"The server sent a malformed response\") from e --> 123 error.raise_typed() File /usr/local/lib/python3.10/dist-packages/naludaq/backend/exceptions.py:52, in HttpError.raise_typed(self) 50 message = f\"[Status {self.status_code}, ID {self.error_id}] {self.message}\" 51 exception = type(message) ---> 52 raise exception ConnectionError: [Status 400, ID 5] failed to open a connection --------------------------------------------------------------------------- ConnectionError Traceback (most recent call last) Cell In[12], line 5 2 board_ip = \"10.0.0.4\" 3 receiver_ip = \"192.168.22.129\" ----> 5 BOARD.connect_udp( 6 board_addr=(board_ip, 4660), 7 receiver_addr=(receiver_ip, 4660), 8 # backend_addr=('127.0.0.1', 7878), # Optional, if you want to connect to an external backend, only if you don't run `BOARD.start_server` 9 ) File /usr/local/lib/python3.10/dist-packages/naludaq/board/__init__.py:340, in Board.connect_udp(self, board_addr, receiver_addr, backend_addr) 333 LOGGER.info( 334 \"Connecting UDP with board_addr=%s, receiver_addr=%s, backend_addr=%s\", 335 board_addr, 336 receiver_addr, 337 backend_addr, 338 ) 339 self.connect_server(backend_addr) --> 340 device = ConnectionManager(self).connect_udp(board_addr, receiver_addr) 341 self.connection_info = device.info 342 get_connection_controller(self).configure_connection() File /usr/local/lib/python3.10/dist-packages/naludaq/backend/managers/connection.py:88, in ConnectionManager.connect_udp(self, board_addr, receiver_addr, attempts) 86 receiver_addr = \":\".join(map(str, receiver_addr)) 87 arguments = {\"board\": board_addr, \"receiver\": receiver_addr} ---> 88 self._connect_with_attempts(\"udp\", arguments, attempts) 89 return UdpDevice(self.context) File /usr/local/lib/python3.10/dist-packages/naludaq/backend/managers/connection.py:214, in ConnectionManager._connect_with_attempts(self, type_name, params, attempts) 212 self.disconnect() 213 try: --> 214 self.context.client.put(ROUTE, params=params) 215 except HttpError: 216 pass File /usr/local/lib/python3.10/dist-packages/naludaq/backend/client.py:51, in HttpClient.put(self, route, params, json) 49 def put(self, route: str, *, params=None, json=None) -> requests.Response: 50 \"\"\"Send a PUT request to the server.\"\"\" ---> 51 return self._request(\"put\", route, params=params, json=json) File /usr/local/lib/python3.10/dist-packages/naludaq/backend/client.py:123, in HttpClient._request(self, method, route, **kwargs) 121 except Exception as e: 122 raise BackendError(\"The server sent a malformed response\") from e --> 123 error.raise_typed() File /usr/local/lib/python3.10/dist-packages/naludaq/backend/exceptions.py:52, in HttpError.raise_typed(self) 50 message = f\"[Status {self.status_code}, ID {self.error_id}] {self.message}\" 51 exception = type(message) ---> 52 raise exception ConnectionError: [Status 400, ID 5] failed to open a connection After reading the product sheet I noticed the part: Communication Interfaces: The system requires the use of a Micro USB cable to the Nexys Artix 7 Video Card for connecting and communicating with the ASIC. \u25cf UART over USB, using virtual comport, up to 2M baud \u25cf JTAG over USB for firmware updates \u25cf Ethernet (Not yet available) However, this product sheet was last updated in 2020. At this point, it seems there is no updated documentation on how to use this board with the naludaq python package. We need to talk with support. 18/11/2024 20:45 I did a network scan to try to find the board on 192.168.22.xxx but had no luck. It seems the computer's ethernet port is sending and recieving some packets though, meaning something is happening. pioneer@pioneer-MS-7D41:~$ ifconfig enp3s0: flags=4099<UP,BROADCAST,MULTICAST> mtu 1500 inet 192.168.22.10 netmask 255.255.255.0 broadcast 192.168.22.255 inet6 fe80::e616:f656:d20f:19a1 prefixlen 64 scopeid 0x20<link> ether 04:7c:16:78:ec:d2 txqueuelen 1000 (Ethernet) RX packets 13 bytes 780 (780.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 1190 bytes 92266 (92.2 KB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 lo: flags=73<UP,LOOPBACK,RUNNING> mtu 65536 inet 127.0.0.1 netmask 255.0.0.0 inet6 ::1 prefixlen 128 scopeid 0x10<host> loop txqueuelen 1000 (Local Loopback) RX packets 23701064 bytes 2893604250 (2.8 GB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 23701064 bytes 2893604250 (2.8 GB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 wlo1: flags=4163<UP,BROADCAST,RUNNING,MULTICAST> mtu 1500 inet 10.47.95.44 netmask 255.255.0.0 broadcast 10.47.255.255 inet6 fe80::febb:bcfe:69eb:ae8c prefixlen 64 scopeid 0x20<link> ether f4:c8:8a:c1:4f:ad txqueuelen 1000 (Ethernet) RX packets 202322600 bytes 51343973482 (51.3 GB) RX errors 0 dropped 2060 overruns 0 frame 0 TX packets 2261409 bytes 379350954 (379.3 MB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 pioneer@pioneer-MS-7D41:~$ 192.168.22.40 192.168.22.40: command not found pioneer@pioneer-MS-7D41:~$ ping 192.168.22.40 PING 192.168.22.40 (192.168.22.40) 56(84) bytes of data. ^C --- 192.168.22.40 ping statistics --- 2 packets transmitted, 0 received, 100% packet loss, time 1017ms pioneer@pioneer-MS-7D41:~$ sudo nmap -sn 192.168.22.0/24 Starting Nmap 7.80 ( https://nmap.org ) at 2024-11-18 20:19 EST Nmap scan report for pioneer-MS-7D41 (192.168.22.10) Host is up. Nmap done: 256 IP addresses (1 host up) scanned in 10.50 seconds pioneer@pioneer-MS-7D41:~$ pioneer@pioneer-MS-7D41:~$ ifconfig enp3s0: flags=4099<UP,BROADCAST,MULTICAST> mtu 1500 inet 192.168.22.10 netmask 255.255.255.0 broadcast 192.168.22.255 inet6 fe80::e616:f656:d20f:19a1 prefixlen 64 scopeid 0x20<link> ether 04:7c:16:78:ec:d2 txqueuelen 1000 (Ethernet) RX packets 13 bytes 780 (780.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 1190 bytes 92266 (92.2 KB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 lo: flags=73<UP,LOOPBACK,RUNNING> mtu 65536 inet 127.0.0.1 netmask 255.0.0.0 inet6 ::1 prefixlen 128 scopeid 0x10<host> loop txqueuelen 1000 (Local Loopback) RX packets 23701064 bytes 2893604250 (2.8 GB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 23701064 bytes 2893604250 (2.8 GB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 wlo1: flags=4163<UP,BROADCAST,RUNNING,MULTICAST> mtu 1500 inet 10.47.95.44 netmask 255.255.0.0 broadcast 10.47.255.255 inet6 fe80::febb:bcfe:69eb:ae8c prefixlen 64 scopeid 0x20<link> ether f4:c8:8a:c1:4f:ad txqueuelen 1000 (Ethernet) RX packets 202322600 bytes 51343973482 (51.3 GB) RX errors 0 dropped 2060 overruns 0 frame 0 TX packets 2261409 bytes 379350954 (379.3 MB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 pioneer@pioneer-MS-7D41:~$ 192.168.22.40 192.168.22.40: command not found pioneer@pioneer-MS-7D41:~$ ping 192.168.22.40 PING 192.168.22.40 (192.168.22.40) 56(84) bytes of data. ^C --- 192.168.22.40 ping statistics --- 2 packets transmitted, 0 received, 100% packet loss, time 1017ms pioneer@pioneer-MS-7D41:~$ sudo nmap -sn 192.168.22.0/24 Starting Nmap 7.80 ( https://nmap.org ) at 2024-11-18 20:19 EST Nmap scan report for pioneer-MS-7D41 (192.168.22.10) Host is up. Nmap done: 256 IP addresses (1 host up) scanned in 10.50 seconds pioneer@pioneer-MS-7D41:~$ 19/11/2024 16:15 Using these email from Marcus Luck of Nalu Scientific, I was able to connect to the HDSoc board over UDP Hi Simone, Thank you for forwarding this. HDSoCv1 (32-channel) and v2 (64-channel) versions both support GbE. I recommend a peer-to-peer connection to make it easier to troubleshoot. The latest HDSoCv1 firmware is v938, it supports Gigabit Ethernet. The firmware you need is found here: HDSoCv1 Eval Rev. 2 | Nalu Scientific Support First, replace the .bit file on the SD card, it's on the bottom of the Nexys FPGA board, accessible from the left side. NaluScope has a built-in DAQ server, (it's possible to run the server as a stand-alone program if needed) This is how to select using the built-in server in the connection dialog: The default IP address for the board is 192.168.1.59:4660 At the moment, we don't have DHCP on the board and the IP can't be changed. The default Destination address in the Firmware is 192.168.1.165:4660 using NaluDAQ: naluexamples/examples/udp_data_capture.ipynb at main \u00b7 NaluScientific/naluexamples The best examples are the externally triggered examples towards the end. Please note the immediate trigger doesn't work well on the HDSoC boards due to the data rate. Let me know if you have any further questions. Cheers, Marcus Luck Lead Software Engineer Nalu Scientific LLC \u25ac\u25ac\u25ac\u25ac\u25ac\u25ac\u25ac\u25ac\u25ac\u25ac\u25ac M (503) 804-3900 E marcus@naluscientific.com W www.naluscientific.com I was able to follow these instructions. I setup the desktop's ethernet port to 192.168.1.1 with netmask 255.255.255.0 to see if I could see 192.168.1.59. Sure enough, I could ping it. I then used naluscope to connec to the board and force some triggers to see some traces 19/11/2024 18:32 I figured out how to plot the data nalu outputs. Basically you can just follow this notebook: https://github.com/NaluScientific/naluexamples/blob/main/examples/opening_acquisitions.ipynb Just point it to the correct acquisition notebook. (Note: I had to remove methods from naluexamples.helpers.plotting import get_color_mapping, set_plot_style and replace them becuase the helpers folder is missing from the github. They're just styling anyways). Here's a really poor example plot: The code that output this was in this notebook https://github.com/NaluScientific/naluexamples/blob/main/examples/udp_data_capture.ipynb But the relevant parts were with BOARD: get_readout_controller(BOARD).set_read_window( windows=8, lookback=8, write_after_trig=4, ) get_readout_controller(BOARD).set_readout_channels( [0, 1, 2, 4] ) # Can be left out to read all channels with BOARD: get_readout_controller (BOARD) .set_read_window ( windows =8, lookback =8, write_after_trig =4, ) get_readout_controller (BOARD) .set_readout_channels ( [0, 1, 2, 4] ) # Can be left out to read all channels and with BOARD: get_board_controller(BOARD).start_readout( \"imm\" ) # Start readout in immediate mode, the board will trigger itself. try: time.sleep(3) finally: get_board_controller(BOARD).stop_readout() with BOARD: get_board_controller(BOARD).start_readout( \"imm\" ) # Start readout in immediate mode, the board will trigger itself. try : time .sleep( 3 ) finally : get_board_controller(BOARD).stop_readout() Here you can see we specify channels 0,1,2,4 (which are the ones that show up). I can't really make sense of the delay, I guess the trigger fires \"immediately\" at some rate that's differenet for each channel? In any event this will be useful to using python to plot output from the naluscope. 19/11/2024 18:38 I figured out how to \"collect\" the data within python Again using this notebook: The relevant code is: from naludaq.tools.data_collector import get_data_collector COLLECTOR = get_data_collector(BOARD) # Don't forget you can always ask for help help(COLLECTOR) # Setting up the readout settings is a bit different with the data collector COLLECTOR.channels = [0, 1, 2, 3] # Can be left out to read all channels COLLECTOR.forced = False # IF True the board will readout based on memory address instead of trigger position. DON'T USE. COLLECTOR.set_external_trigger() COLLECTOR.set_window( windows=8, lookback=8, write_after_trig=4, ) ### Create a data capture pipeline num_captures = 10 num_evt_to_throw_away = 10 # warmup captures def validator(x): \"\"\"A function that returns True if the data is valid, False otherwise.\"\"\" return True def inner(x): \"\"\"When calling with enumerated data the argument is a tuple with the index in the block and the data.\"\"\" idx = x[0] _ = x[1] # The data print(f\"Capturing event {idx + 1}/{num_captures}\") pipeline = COLLECTOR.iter_inf(attempts=10) pipeline = pipeline.for_each(lambda _: print(\"Do something here with data\")) pipeline = pipeline.filter(validator, exclusion_limit=10) pipeline = ( pipeline.enumerate().for_each(inner).unenumerate() ) # Example of how an event can be enumerated. pipeline = pipeline.skip(num_evt_to_throw_away) with BOARD: pipeline.take(num_captures).collect() from naludaq.tools.data_collector import get_data_collector COLLECTOR = get_data_collector(BOARD) # Don't forget you can always ask for help help(COLLECTOR) # Setting up the readout settings is a bit different with the data collector COLLECTOR.channels = [0, 1, 2, 3] # Can be left out to read all channels COLLECTOR.forced = False # IF True the board will readout based on memory address instead of trigger position. DON'T USE. COLLECTOR.set_external_trigger() COLLECTOR.set_window( windows=8, lookback=8, write_after_trig=4, ) ### Create a data capture pipeline num_captures = 10 num_evt_to_throw_away = 10 # warmup captures def validator(x): \"\"\"A function that returns True if the data is valid, False otherwise.\"\"\" return True def inner(x): \"\"\"When calling with enumerated data the argument is a tuple with the index in the block and the data.\"\"\" idx = x[0] _ = x[1] # The data print(f\"Capturing event {idx + 1}/{num_captures}\") pipeline = COLLECTOR.iter_inf(attempts=10) pipeline = pipeline.for_each(lambda _: print(\"Do something here with data\")) pipeline = pipeline.filter(validator, exclusion_limit=10) pipeline = ( pipeline.enumerate().for_each(inner).unenumerate() ) # Example of how an event can be enumerated. pipeline = pipeline.skip(num_evt_to_throw_away) with BOARD: pipeline.take(num_captures).collect() I changed def inner(x): \"\"\"When calling with enumerated data the argument is a tuple with the index in the block and the data.\"\"\" idx = x[0] _ = x[1] # The data print(f\"Capturing event {idx + 1}/{num_captures}\") def inner ( x ): \"\"\"When calling with enumerated data the argument is a tuple with the index in the block and the data.\"\"\" idx = x[ 0 ] _ = x[ 1 ] # The data print ( f\"Capturing event {idx + 1 } / {num_captures} \" ) to print the data (contained in the _ variable); I saw the traces. It was a lot of data, so here is the truncated version (first 100 characters of the data). Do something here with data {'window_labels': [[12, 13, 14, 15, 16, 17, 18, 19, 54, 55, 56, 57, 58, 59, 60, 61], [54, 55, 56, 57... Capturing event 1/10 Do something here with data {'window_labels': [[32, 33, 34, 35, 36, 37, 38, 39], [12, 13, 14, 15, 16, 17, 18, 19], [54, 55, 56, ... Capturing event 2/10 Do something here with data {'window_labels': [[12, 13, 14, 15, 16, 17, 18, 19], [54, 55, 56, 57, 58, 59, 60, 61], [34, 35, 36, ... Capturing event 3/10 Do something here with data {'window_labels': [[52, 53, 54, 55, 56, 57, 58, 59, 32, 33, 34, 35, 36, 37, 38, 39], [32, 33, 34, 35... Capturing event 4/10 Do something here with data {'window_labels': [[10, 11, 12, 13, 14, 15, 16, 17, 52, 53, 54, 55, 56, 57, 58, 59], [52, 53, 54, 55... Capturing event 5/10 Do something here with data {'window_labels': [[32, 33, 34, 35, 36, 37, 38, 39], [12, 13, 14, 15, 16, 17, 18, 19], [54, 55, 56, ... Capturing event 6/10 Do something here with data {'window_labels': [[10, 11, 12, 13, 14, 15, 16, 17, 52, 53, 54, 55, 56, 57, 58, 59], [52, 53, 54, 55... Capturing event 7/10 Do something here with data {'window_labels': [[30, 31, 32, 33, 34, 35, 36, 37, 10, 11, 12, 13, 14, 15, 16, 17], [10, 11, 12, 13... Capturing event 8/10 Do something here with data {'window_labels': [[50, 51, 52, 53, 54, 55, 56, 57, 30, 31, 32, 33, 34, 35, 36, 37], [30, 31, 32, 33... Capturing event 9/10 Do something here with data {'window_labels': [[8, 9, 10, 11, 12, 13, 14, 15, 50, 51, 52, 53, 54, 55, 56, 57], [50, 51, 52, 53, ... Capturing event 10/10 Do something here with data {'window_labels': [[30, 31, 32, 33, 34, 35, 36, 37], [10, 11, 12, 13, 14, 15, 16, 17], [52, 53, 54, ... Capturing event 11/10 Do something here with data {'window_labels': [[8, 9, 10, 11, 12, 13, 14, 15, 50, 51, 52, 53, 54, 55, 56, 57], [50, 51, 52, 53, ... Capturing event 12/10 Do something here with data {'window_labels': [[28, 29, 30, 31, 32, 33, 34, 35, 8, 9, 10, 11, 12, 13, 14, 15], [8, 9, 10, 11, 12... Capturing event 13/10 Do something here with data {'window_labels': [[48, 49, 50, 51, 52, 53, 54, 55, 28, 29, 30, 31, 32, 33, 34, 35], [28, 29, 30, 31... Capturing event 14/10 Do something here with data {'window_labels': [[6, 7, 8, 9, 10, 11, 12, 13, 48, 49, 50, 51, 52, 53, 54, 55], [48, 49, 50, 51, 52... Capturing event 15/10 Do something here with data {'window_labels': [[28, 29, 30, 31, 32, 33, 34, 35], [8, 9, 10, 11, 12, 13, 14, 15], [50, 51, 52, 53... Capturing event 16/10 Do something here with data {'window_labels': [[6, 7, 8, 9, 10, 11, 12, 13, 48, 49, 50, 51, 52, 53, 54, 55], [48, 49, 50, 51, 52... Capturing event 17/10 Do something here with data {'window_labels': [[26, 27, 28, 29, 30, 31, 32, 33, 6, 7, 8, 9, 10, 11, 12, 13], [6, 7, 8, 9, 10, 11... Capturing event 18/10 Do something here with data {'window_labels': [[46, 47, 48, 49, 50, 51, 52, 53, 26, 27, 28, 29, 30, 31, 32, 33], [26, 27, 28, 29... Capturing event 19/10 Do something here with data {'window_labels': [[4, 5, 6, 7, 8, 9, 10, 11, 46, 47, 48, 49, 50, 51, 52, 53], [46, 47, 48, 49, 50, ... Capturing event 20/10 Do something here with data {'window_labels': [[12, 13, 14, 15, 16, 17, 18, 19, 54, 55, 56, 57, 58, 59, 60, 61], [54, 55, 56, 57... Capturing event 1/10 Do something here with data {'window_labels': [[32, 33, 34, 35, 36, 37, 38, 39], [12, 13, 14, 15, 16, 17, 18, 19], [54, 55, 56, ... Capturing event 2/10 Do something here with data {'window_labels': [[12, 13, 14, 15, 16, 17, 18, 19], [54, 55, 56, 57, 58, 59, 60, 61], [34, 35, 36, ... Capturing event 3/10 Do something here with data {'window_labels': [[52, 53, 54, 55, 56, 57, 58, 59, 32, 33, 34, 35, 36, 37, 38, 39], [32, 33, 34, 35... Capturing event 4/10 Do something here with data {'window_labels': [[10, 11, 12, 13, 14, 15, 16, 17, 52, 53, 54, 55, 56, 57, 58, 59], [52, 53, 54, 55... Capturing event 5/10 Do something here with data {'window_labels': [[32, 33, 34, 35, 36, 37, 38, 39], [12, 13, 14, 15, 16, 17, 18, 19], [54, 55, 56, ... Capturing event 6/10 Do something here with data {'window_labels': [[10, 11, 12, 13, 14, 15, 16, 17, 52, 53, 54, 55, 56, 57, 58, 59], [52, 53, 54, 55... Capturing event 7/10 Do something here with data {'window_labels': [[30, 31, 32, 33, 34, 35, 36, 37, 10, 11, 12, 13, 14, 15, 16, 17], [10, 11, 12, 13... Capturing event 8/10 Do something here with data {'window_labels': [[50, 51, 52, 53, 54, 55, 56, 57, 30, 31, 32, 33, 34, 35, 36, 37], [30, 31, 32, 33... Capturing event 9/10 Do something here with data {'window_labels': [[8, 9, 10, 11, 12, 13, 14, 15, 50, 51, 52, 53, 54, 55, 56, 57], [50, 51, 52, 53, ... Capturing event 10/10 Do something here with data {'window_labels': [[30, 31, 32, 33, 34, 35, 36, 37], [10, 11, 12, 13, 14, 15, 16, 17], [52, 53, 54, ... Capturing event 11/10 Do something here with data {'window_labels': [[8, 9, 10, 11, 12, 13, 14, 15, 50, 51, 52, 53, 54, 55, 56, 57], [50, 51, 52, 53, ... Capturing event 12/10 Do something here with data {'window_labels': [[28, 29, 30, 31, 32, 33, 34, 35, 8, 9, 10, 11, 12, 13, 14, 15], [8, 9, 10, 11, 12... Capturing event 13/10 Do something here with data {'window_labels': [[48, 49, 50, 51, 52, 53, 54, 55, 28, 29, 30, 31, 32, 33, 34, 35], [28, 29, 30, 31... Capturing event 14/10 Do something here with data {'window_labels': [[6, 7, 8, 9, 10, 11, 12, 13, 48, 49, 50, 51, 52, 53, 54, 55], [48, 49, 50, 51, 52... Capturing event 15/10 Do something here with data {'window_labels': [[28, 29, 30, 31, 32, 33, 34, 35], [8, 9, 10, 11, 12, 13, 14, 15], [50, 51, 52, 53... Capturing event 16/10 Do something here with data {'window_labels': [[6, 7, 8, 9, 10, 11, 12, 13, 48, 49, 50, 51, 52, 53, 54, 55], [48, 49, 50, 51, 52... Capturing event 17/10 Do something here with data {'window_labels': [[26, 27, 28, 29, 30, 31, 32, 33, 6, 7, 8, 9, 10, 11, 12, 13], [6, 7, 8, 9, 10, 11... Capturing event 18/10 Do something here with data {'window_labels': [[46, 47, 48, 49, 50, 51, 52, 53, 26, 27, 28, 29, 30, 31, 32, 33], [26, 27, 28, 29... Capturing event 19/10 Do something here with data {'window_labels': [[4, 5, 6, 7, 8, 9, 10, 11, 46, 47, 48, 49, 50, 51, 52, 53], [46, 47, 48, 49, 50, ... Capturing event 20/10 20/11/2024 20:20 I was able to make it so the appropriate firmware loads on boot with the following steps: Open hardware manager, connect to the board using JTAG interface (or microUSB interface) Convert the bitstream to flash: write_flash -force -file /path/to/output/firmware.bin -bitstream /path/to/input/firmware.bit write_flash -force - file /path/ to /output/ firmware.bin -bitstream /path/ to /input/ firmware.bit for example: write_flash -force -file /home/pioneer/vivado_stuff/Nexsys_Video_A7_For_HDSoc/HDSoC_eval_v938.bin -bitstream /home/pioneer/vivado_stuff/Nexsys_Video_A7_For_HDSoc/HDSoC_eval_v938.bit write_flash -force - file /home/ pioneer /vivado_stuff/ Nexsys_Video_A7_For_HDSoc /HDSoC_eval_v938.bin -bitstream / home /pioneer/ vivado_stuff /Nexsys_Video_A7_For_HDSoc/ HDSoC_eval_v938.bit Right click on the device, click add configuration memory device. Select part s25fl256sxxxxxx0-spi-x1_x2_x4 It will then prompt to program flash memory. Select the generated bin file and continue. This takes a bit. After programming is complete, power down the device and power it back up. You should see some green lights on the HDSoC board appear indicating the firmware is loaded.",
    "textLength": 4852
  },
  {
    "kind": "work-log",
    "title": "15_06_2025 - 21_06_2025.html",
    "fileName": "15_06_2025 - 21_06_2025.html",
    "url": "resources/work_logs/15_06_2025 - 21_06_2025.html",
    "createdDate": "2025-06-15",
    "text": "15/06/2025 - 21/06/2025 15/06/2025 - 21/06/2025 17/06/2025 14:50 graph TD; DataSimulator[\"<b><a href='https://github.com/PIONEER-Experiment/data_simulator/tree/nalu-sim'>data_simulator</a></b><br>Simulates and publishes MIDAS-style event data\"] subgraph Libraries FakeDataGen[\"<b><a href='https://github.com/jaca230/nalu_fake_data_generator'>nalu_fake_data_generator</a></b><br>Generates configurable fake hardware event streams\"] EventCollector[\"<b><a href='https://github.com/jaca230/nalu_event_collector'>nalu_event_collector</a></b><br>Used just to keep same format as real collected events\"] end %% Connect the layers DataSimulator -->|Depends on| FakeDataGen FakeDataGen -->|Depends on| EventCollector graph TD; DataSimulator[\" < b > < a href = 'https://github.com/PIONEER-Experiment/data_simulator/tree/nalu-sim' > data_simulator </ a > </ b > < br > Simulates and publishes MIDAS-style event data\"] subgraph Libraries FakeDataGen[\" < b > < a href = 'https://github.com/jaca230/nalu_fake_data_generator' > nalu_fake_data_generator </ a > </ b > < br > Generates configurable fake hardware event streams\"] EventCollector[\" < b > < a href = 'https://github.com/jaca230/nalu_event_collector' > nalu_event_collector </ a > </ b > < br > Used just to keep same format as real collected events\"] end %% Connect the layers DataSimulator -->|Depends on| FakeDataGen FakeDataGen -->|Depends on| EventCollector 17/06/2025 14:54 graph TD; ZmqPublisher[\"<b><a href='https://github.com/PIONEER-Experiment/zmq_publisher/tree/midas'>zmq_publisher</a></b><br>Publishes MIDAS events as ROOT objects over ZMQ\"] subgraph Core Libraries MidasReceiver[\"<b><a href='https://github.com/jaca230/midas_receiver'>midas_receiver</a></b><br>Async receiver for MIDAS events/messages\"] AnalysisPipeline[\"<b><a href='https://github.com/jaca230/analysis_pipeline/tree/midas'>analysis_pipeline</a></b><br>TBB-based configurable ROOT analysis pipeline\"] CppZmq[\"<b><a href='https://github.com/zeromq/cppzmq'>cppzmq</a></b><br>Header-only C++ binding for libzmq\"] end subgraph More Libraries AnalysisStages[\"<b><a href='https://github.com/jaca230/analysis_pipeline_stages/tree/midas_with_unpackers'>analysis_pipeline_stages</a></b><br>Collection of plugin stages for analysis_pipeline\"] Unpacker[\"<b><a href='https://github.com/sbfoster12/unpacker'>unpacker</a></b><br>Parses raw MIDAS data into structured event banks\"] end subgraph More Libraries ROOT[\"<b><a href='https://root.cern/'>ROOT</a></b><br>CERN data analysis framework\"] end %% Top-level dependencies ZmqPublisher --> MidasReceiver ZmqPublisher --> AnalysisPipeline ZmqPublisher --> CppZmq %% Transitive dependencies AnalysisPipeline --> AnalysisStages AnalysisStages --> Unpacker Unpacker --> ROOT graph TD; ZmqPublisher[\"<b><a href='https://github.com/PIONEER-Experiment/zmq_publisher/tree/midas'>zmq_publisher</a></b><br>Publishes MIDAS events as ROOT objects over ZMQ\"] subgraph Core Libraries MidasReceiver[\"<b><a href='https://github.com/jaca230/midas_receiver'>midas_receiver</a></b><br>Async receiver for MIDAS events/messages\"] AnalysisPipeline[\"<b><a href='https://github.com/jaca230/analysis_pipeline/tree/midas'>analysis_pipeline</a></b><br>TBB-based configurable ROOT analysis pipeline\"] CppZmq[\"<b><a href='https://github.com/zeromq/cppzmq'>cppzmq</a></b><br>Header-only C++ binding for libzmq\"] end subgraph More Libraries AnalysisStages[\"<b><a href='https://github.com/jaca230/analysis_pipeline_stages/tree/midas_with_unpackers'>analysis_pipeline_stages</a></b><br>Collection of plugin stages for analysis_pipeline\"] Unpacker[\"<b><a href='https://github.com/sbfoster12/unpacker'>unpacker</a></b><br>Parses raw MIDAS data into structured event banks\"] end subgraph More Libraries ROOT[\"<b><a href='https://root.cern/'>ROOT</a></b><br>CERN data analysis framework\"] end %% Top-level dependencies ZmqPublisher --> MidasReceiver ZmqPublisher --> AnalysisPipeline ZmqPublisher --> CppZmq %% Transitive dependencies AnalysisPipeline --> AnalysisStages AnalysisStages --> Unpacker Unpacker --> ROOT",
    "textLength": 528
  },
  {
    "kind": "work-log",
    "title": "23_03_2025 - 29_03_2025.html",
    "fileName": "23_03_2025 - 29_03_2025.html",
    "url": "resources/work_logs/23_03_2025 - 29_03_2025.html",
    "createdDate": "2025-03-23",
    "text": "23/03/2025 - 29/03/2025 23/03/2025 - 29/03/2025 24/03/2025 17:31 Here is my \"simplified\" software diagram for the atar daq graph TD; NaluFrontend[\"<b><a href='https://github.com/PIONEER-Experiment/atar_daq'>Nalu MIDAS Frontend</a></b><br>Coordinates MIDAS event construction\"] subgraph Libraries NaluBoardLib[\"<b><a href='https://github.com/jaca230/nalu_board_controller'>Nalu Board Controller</a></b><br>C++ Wrapper around naludaq methods for configuring the board and starting readout\"] NaluEventCollectorLib[\"<b><a href='https://github.com/jaca230/nalu_event_collector'>Nalu Event Collector</a></b><br>C++ API for launching collector threads. Handles receiving data over UDP, processing packets, and collecting into NaluEvents\"] MidasLib[\"<b><a href='https://bitbucket.org/tmidas/midas/src/develop/'>MIDAS</a></b><br>Data acquisition framework\"] ReflectCppLib[\"<b><a href='https://github.com/getml/reflect-cpp'>reflect-cpp</a></b><br>C++ reflection library used for serialization\"] end subgraph Python Packages NaludaqPython[\"<b><a href='https://pypi.org/project/naludaq/0.31.9/'>naludaq</a></b><br>Python interface for Naludaq\"] end subgraph Classes NaluBoardController[\"<b><a href='https://github.com/jaca230/nalu_board_controller/blob/main/include/nalu_board_controller.h'>nalu_board_controller</a></b><br>Provides methods for configuring the board and starting readout\"] NaluEventCollector[\"<b><a href='https://github.com/jaca230/nalu_event_collector/blob/main/include/nalu_event_collector.h'>nalu_event_collector</a></b><br>Provides methods for starting collector threads and polling for events\"] OdbManager[\"<b><a href='https://github.com/PIONEER-Experiment/atar_daq/blob/main/include/odb_manager.h'>odb_manager</a></b><br>Handles initializing and managing ODB structure for Nalu Equipment\"] MidasFrontend[\"<b><a href='https://bitbucket.org/tmidas/midas/src/develop/include/mfe.h'>mfe</a></b><br>Handles MIDAS frontend logic\"] end %% Connect libraries to the PythonPackages layer NaluBoardLib -->|Pybind| NaludaqPython %% Connect libraries to the Classes layer NaluFrontend -->|Uses| NaluBoardLib NaluFrontend -->|Uses| NaluEventCollectorLib NaluFrontend -->|Uses| MidasLib NaluFrontend -->|Uses| ReflectCppLib NaluBoardLib -->|Provides| NaluBoardController NaluEventCollectorLib -->|Provides| NaluEventCollector MidasLib -->|Provides| MidasFrontend ReflectCppLib --> |Used By| OdbManager graph TD; NaluFrontend[\"<b><a href='https://github.com/PIONEER-Experiment/atar_daq'>Nalu MIDAS Frontend</a></b><br>Coordinates MIDAS event construction\"] subgraph Libraries NaluBoardLib[\"<b><a href='https://github.com/jaca230/nalu_board_controller'>Nalu Board Controller</a></b><br>C++ Wrapper around naludaq methods for configuring the board and starting readout\"] NaluEventCollectorLib[\"<b><a href='https://github.com/jaca230/nalu_event_collector'>Nalu Event Collector</a></b><br>C++ API for launching collector threads. Handles receiving data over UDP, processing packets, and collecting into NaluEvents\"] MidasLib[\"<b><a href='https://bitbucket.org/tmidas/midas/src/develop/'>MIDAS</a></b><br>Data acquisition framework\"] ReflectCppLib[\"<b><a href='https://github.com/getml/reflect-cpp'>reflect-cpp</a></b><br>C++ reflection library used for serialization\"] end subgraph Python Packages NaludaqPython[\"<b><a href='https://pypi.org/project/naludaq/0.31.9/'>naludaq</a></b><br>Python interface for Naludaq\"] end subgraph Classes NaluBoardController[\"<b><a href='https://github.com/jaca230/nalu_board_controller/blob/main/include/nalu_board_controller.h'>nalu_board_controller</a></b><br>Provides methods for configuring the board and starting readout\"] NaluEventCollector[\"<b><a href='https://github.com/jaca230/nalu_event_collector/blob/main/include/nalu_event_collector.h'>nalu_event_collector</a></b><br>Provides methods for starting collector threads and polling for events\"] OdbManager[\"<b><a href='https://github.com/PIONEER-Experiment/atar_daq/blob/main/include/odb_manager.h'>odb_manager</a></b><br>Handles initializing and managing ODB structure for Nalu Equipment\"] MidasFrontend[\"<b><a href='https://bitbucket.org/tmidas/midas/src/develop/include/mfe.h'>mfe</a></b><br>Handles MIDAS frontend logic\"] end %% Connect libraries to the PythonPackages layer NaluBoardLib -->|Pybind| NaludaqPython %% Connect libraries to the Classes layer NaluFrontend -->|Uses| NaluBoardLib NaluFrontend -->|Uses| NaluEventCollectorLib NaluFrontend -->|Uses| MidasLib NaluFrontend -->|Uses| ReflectCppLib NaluBoardLib -->|Provides| NaluBoardController NaluEventCollectorLib -->|Provides| NaluEventCollector MidasLib -->|Provides| MidasFrontend ReflectCppLib --> |Used By| OdbManager 25/03/2025 13:35 I identified \"problematic\" rate test parameters with this script # Step 1: First filter based on Expected Data Rate df_filtered_initial = df[df['Expected Data Rate (KB/s)'] < 55000].copy() # Step 2: Define filtering conditions on this subset condition_1 = df_filtered_initial['Collector Error'].notna() & (df_filtered_initial['Collector Error'] != \"None\") condition_2 = ~df_filtered_initial['kBytes per sec'].div(df_filtered_initial['Expected Data Rate (KB/s)']).between(0.8, 1.4) condition_3 = ~df_filtered_initial['Frequency (Hz)'].div(df_filtered_initial['Data Rate (Events per sec)']).between(0.9, 1.1) condition_4 = df_filtered_initial['Frequency (Hz)'] > 1000 # Frequency must be above 1 kHz # Step 3: Create a reason column to track which conditions were met df_filtered_initial['Reason'] = '' df_filtered_initial.loc[condition_1, 'Reason'] += 'Collector Error; ' df_filtered_initial.loc[condition_2, 'Reason'] += 'Data Rate Mismatch; ' df_filtered_initial.loc[condition_3, 'Reason'] += 'Frequency/Data Rate Mismatch; ' # Step 4: Apply the additional filtering conditions filtered_df = df_filtered_initial[(condition_1 | condition_2 | condition_3) & condition_4].copy() # Display row count and first few rows for verification print(f\"Filtered DataFrame has {filtered_df.shape[0]} rows.\") filtered_df[['File', 'Frequency (Hz)', 'Data Rate (Events per sec)', 'Windows', 'Events Sent', 'kBytes per sec', 'Active Channels Length', 'Expected Data Rate (KB/s)', 'Collector Error', 'Reason']] # Define the output file path output_file = \"filtered_data.txt\" # Open the file and write each row in the specified format with open(output_file, \"w\") as f: for _, row in filtered_df.iterrows(): frequency = int(row['Frequency (Hz)']) windows = int(row['Windows']) channels = int(row['Active Channels Length']) computed_value = frequency * windows * channels # Format the line as: 0 0 0 {frequency} {windows} {channels} {computed_value} f.write(f\"0 0 0 {frequency} {windows} {channels} {computed_value}\\n\") print(f\"Filtered data has been written to {output_file}\") # Step 1: First filter based on Expected Data Rate df_filtered_initial = df[df['Expected Data Rate (KB/s)'] < 55000].copy() # Step 2: Define filtering conditions on this subset condition_1 = df_filtered_initial['Collector Error'].notna() & (df_filtered_initial['Collector Error'] != \"None\") condition_2 = ~df_filtered_initial['kBytes per sec'].div(df_filtered_initial['Expected Data Rate (KB/s)']).between(0.8, 1.4) condition_3 = ~df_filtered_initial['Frequency (Hz)'].div(df_filtered_initial['Data Rate (Events per sec)']).between(0.9, 1.1) condition_4 = df_filtered_initial['Frequency (Hz)'] > 1000 # Frequency must be above 1 kHz # Step 3: Create a reason column to track which conditions were met df_filtered_initial['Reason'] = '' df_filtered_initial.loc[condition_1, 'Reason'] += 'Collector Error; ' df_filtered_initial.loc[condition_2, 'Reason'] += 'Data Rate Mismatch; ' df_filtered_initial.loc[condition_3, 'Reason'] += 'Frequency/Data Rate Mismatch; ' # Step 4: Apply the additional filtering conditions filtered_df = df_filtered_initial[(condition_1 | condition_2 | condition_3) & condition_4].copy() # Display row count and first few rows for verification print(f\"Filtered DataFrame has {filtered_df.shape[0]} rows.\") filtered_df[['File', 'Frequency (Hz)', 'Data Rate (Events per sec)', 'Windows', 'Events Sent', 'kBytes per sec', 'Active Channels Length', 'Expected Data Rate (KB/s)', 'Collector Error', 'Reason']] # Define the output file path output_file = \"filtered_data.txt\" # Open the file and write each row in the specified format with open(output_file, \"w\") as f: for _, row in filtered_df.iterrows(): frequency = int(row['Frequency (Hz)']) windows = int(row['Windows']) channels = int(row['Active Channels Length']) computed_value = frequency * windows * channels # Format the line as: 0 0 0 {frequency} {windows} {channels} {computed_value} f.write(f\"0 0 0 {frequency} {windows} {channels} {computed_value}\\n\") print(f\"Filtered data has been written to {output_file}\") So my criteria are: The expected data rate must be below 55 MB/s. This is the limit the board can output, so we don't expect good performance above this. Must over over 1kHz trigger rate I only do this because the \"expected data rate\" calculation is poor for low event rates. If I don't make this cut, I get a lot of data points that weren't problematic The \"normalized\" data rate is outside the range [0.8,1.4]. So we differ from the expected data rate by a meaningful percentage The \"normalized\" event rate is outside the range [0.9,1.1] So we differ from the expected event rate (the external trigger rate) by a meaningul percentage The run contained an error 25/03/2025 13:44 Using the above criteria, I created a parmeter space for the sequencer to go through. For each value in the parameter space I did a 1 minute long run. I took a sample every 4 seconds of midas' measured data rate and event rate. So each \"problematic parameter set\" had 15 sequential samples. 25/03/2025 13:43 After collecting this data I average it and computed means and uncertainties like so: # Function to compute Time to Stability def time_to_stability(data_rates, tolerance=0.01, window=3): \"\"\"Returns the index where data rate stabilizes within tolerance of final value for a given run.\"\"\" final_value = data_rates.iloc[-1] # Assume last value is steady-state threshold = final_value * (1 - tolerance) # Define stability threshold for i in range(len(data_rates) - window): if np.all(data_rates.iloc[i:i+window] >= threshold): return i # First index where stability is reached return len(data_rates) # If never stabilizes, return full lengths def count_collector_errors(errors): \"\"\"Counts the number of non-'None' and non-'N/A' collector errors.\"\"\" return errors[~errors.isin(['None', 'N/A'])].count() # Define the aggregation functions for each column agg_funcs = { 'Frequency (Hz)': 'mean', # No uncertainty needed 'Data Rate (Events per sec)': [ 'mean', # Mean lambda x: np.std(x) / np.sqrt(len(x)), # Uncertainty (standard error) time_to_stability # Compute stability time ], 'Windows': 'mean', # No uncertainty needed 'Events Sent': 'max', # Take the maximum value 'kBytes per sec': [ 'mean', # Mean lambda x: np.std(x) / np.sqrt(len(x)) # Uncertainty (standard error) ], 'Active Channels Length': 'mean', # No uncertainty needed 'Expected Data Rate (KB/s)': 'mean', # No uncertainty needed 'Collector Error': count_collector_errors # Count occurrences of actual errors } # Perform the groupby aggregation consolidated_df = df.groupby('Run Number').agg(agg_funcs) # Rename the columns for clarity consolidated_df.columns = [ 'Avg Frequency (Hz)', 'Avg Data Rate (Events per sec)', 'Uncertainty Data Rate', 'Time to Stability', 'Avg Windows', 'Max Events Sent', 'Avg kBytes per sec', 'Uncertainty kBytes per sec', 'Avg Active Channels Length', 'Avg Expected Data Rate (KB/s)', 'Collector Error Count' ] # Compute the normalized values and their uncertainties consolidated_df['Normalized Frequency'] = consolidated_df['Avg Data Rate (Events per sec)'] / consolidated_df['Avg Frequency (Hz)'] consolidated_df['Uncertainty Normalized Frequency'] = consolidated_df['Uncertainty Data Rate'] / consolidated_df['Avg Frequency (Hz)'] consolidated_df['Normalized kBytes per sec to Expected Data Rate'] = consolidated_df['Avg kBytes per sec'] / consolidated_df['Avg Expected Data Rate (KB/s)'] consolidated_df['Uncertainty Normalized kBytes per sec to Expected Data Rate'] = consolidated_df['Uncertainty kBytes per sec'] / consolidated_df['Avg Expected Data Rate (KB/s)'] # Reset index for better readability consolidated_df.reset_index(inplace=True) # Display the consolidated DataFrame consolidated_df # Function to compute Time to Stability def time_to_stability(data_rates, tolerance=0.01, window=3): \"\"\"Returns the index where data rate stabilizes within tolerance of final value for a given run.\"\"\" final_value = data_rates.iloc[-1] # Assume last value is steady-state threshold = final_value * (1 - tolerance) # Define stability threshold for i in range(len(data_rates) - window): if np.all(data_rates.iloc[i:i+window] >= threshold): return i # First index where stability is reached return len(data_rates) # If never stabilizes, return full lengths def count_collector_errors(errors): \"\"\"Counts the number of non-'None' and non-'N/A' collector errors.\"\"\" return errors[~errors.isin(['None', 'N/A'])].count() # Define the aggregation functions for each column agg_funcs = { 'Frequency (Hz)': 'mean', # No uncertainty needed 'Data Rate (Events per sec)': [ 'mean', # Mean lambda x: np.std(x) / np.sqrt(len(x)), # Uncertainty (standard error) time_to_stability # Compute stability time ], 'Windows': 'mean', # No uncertainty needed 'Events Sent': 'max', # Take the maximum value 'kBytes per sec': [ 'mean', # Mean lambda x: np.std(x) / np.sqrt(len(x)) # Uncertainty (standard error) ], 'Active Channels Length': 'mean', # No uncertainty needed 'Expected Data Rate (KB/s)': 'mean', # No uncertainty needed 'Collector Error': count_collector_errors # Count occurrences of actual errors } # Perform the groupby aggregation consolidated_df = df.groupby('Run Number').agg(agg_funcs) # Rename the columns for clarity consolidated_df.columns = [ 'Avg Frequency (Hz)', 'Avg Data Rate (Events per sec)', 'Uncertainty Data Rate', 'Time to Stability', 'Avg Windows', 'Max Events Sent', 'Avg kBytes per sec', 'Uncertainty kBytes per sec', 'Avg Active Channels Length', 'Avg Expected Data Rate (KB/s)', 'Collector Error Count' ] # Compute the normalized values and their uncertainties consolidated_df['Normalized Frequency'] = consolidated_df['Avg Data Rate (Events per sec)'] / consolidated_df['Avg Frequency (Hz)'] consolidated_df['Uncertainty Normalized Frequency'] = consolidated_df['Uncertainty Data Rate'] / consolidated_df['Avg Frequency (Hz)'] consolidated_df['Normalized kBytes per sec to Expected Data Rate'] = consolidated_df['Avg kBytes per sec'] / consolidated_df['Avg Expected Data Rate (KB/s)'] consolidated_df['Uncertainty Normalized kBytes per sec to Expected Data Rate'] = consolidated_df['Uncertainty kBytes per sec'] / consolidated_df['Avg Expected Data Rate (KB/s)'] # Reset index for better readability consolidated_df.reset_index(inplace=True) # Display the consolidated DataFrame consolidated_df I also computed 2 \"new\" metrics: Number of collectors errors This is just how many of these samples had a collector error If sample X in a run has a collector error, all subsequent samples in that run will report having a collector error (i.e. errors are only cleared at the start of a new run). This means this gives a metric for how long a run lasted before seeing a collector error Time to Stability This is how many samples in a run it took before the data rate stabilized. Mathematically if we take N N N N samples per run, this is the index i i i i such that \\forall i \\leq j \\leq N \u2200 i \u2264 j \u2264 N \\forall i \\leq j \\leq N \u2200 i \u2264 j \u2264 N \\text{DataRate}[j] \\geq 0.99\\cdot \\text{DataRate}[N] DataRate [ j ] \u2265 0.99 \u22c5 DataRate [ N ] \\text{DataRate}[j] \\geq 0.99\\cdot \\text{DataRate}[N] DataRate [ j ] \u2265 0.99 \u22c5 DataRate [ N ] Really I should also require \\text{DataRate}[j] \\leq 1.01\\cdot \\text{DataRate}[N] DataRate [ j ] \u2264 1.01 \u22c5 DataRate [ N ] \\text{DataRate}[j] \\leq 1.01\\cdot \\text{DataRate}[N] DataRate [ j ] \u2264 1.01 \u22c5 DataRate [ N ] but I didn't and I don't image it has much effect on the metric result shown below. I retroactively added \\text{DataRate}[j] \\leq 1.01\\cdot \\text{DataRate}[N] DataRate [ j ] \u2264 1.01 \u22c5 DataRate [ N ] \\text{DataRate}[j] \\leq 1.01\\cdot \\text{DataRate}[N] DataRate [ j ] \u2264 1.01 \u22c5 DataRate [ N ] . See plots below. 25/03/2025 13:58 Here are the plots from the last round of analyzation just for comparison purposes. They don't give much insight into what's causing the lower data rates: Note : The reson some of the data points are out of the range 55 MB/s expected data rate range despite the fact I made a cut to exclude those earlier is as folllows: When I made the cut, I used data rate calculation: \\text{Data Rate (B/s)} \\approx \\text{Trigger rate}\\cdot(\\text{N}_\\text{channels}\\cdot\\text{N}_\\text{windows}\\cdot(\\text{Packet Length = 80 bytes}) + (\\text{Event Header+Footer = 28 bytes})) Data Rate (B/s) \u2248 Trigger rate \u22c5 ( N channels \u22c5 N windows \u22c5 ( Packet Length = 80 bytes ) + ( Event Header+Footer = 28 bytes ) ) \\text{Data Rate (B/s)} \\approx \\text{Trigger rate}\\cdot(\\text{N}_\\text{channels}\\cdot\\text{N}_\\text{windows}\\cdot(\\text{Packet Length = 80 bytes}) + (\\text{Event Header+Footer = 28 bytes})) Data Rate (B/s) \u2248 Trigger rate \u22c5 ( N channels \u200b \u22c5 N windows \u200b \u22c5 ( Packet Length = 80 bytes ) + ( Event Header+Footer = 28 bytes )) However, this is a mistake, it should be: \\text{Data Rate (B/s)} \\approx \\text{Trigger rate}\\cdot(\\text{N}_\\text{channels}\\cdot\\text{N}_\\text{windows}\\cdot(\\text{Packet Length = 80 bytes}) + (\\text{Event Header+Footer = 34 bytes}) + (\\text{Timing Data = 64 bytes})) Data Rate (B/s) \u2248 Trigger rate \u22c5 ( N channels \u22c5 N windows \u22c5 ( Packet Length = 80 bytes ) + ( Event Header+Footer = 34 bytes ) + ( Timing Data = 64 bytes ) ) \\text{Data Rate (B/s)} \\approx \\text{Trigger rate}\\cdot(\\text{N}_\\text{channels}\\cdot\\text{N}_\\text{windows}\\cdot(\\text{Packet Length = 80 bytes}) + (\\text{Event Header+Footer = 34 bytes}) + (\\text{Timing Data = 64 bytes})) Data Rate (B/s) \u2248 Trigger rate \u22c5 ( N channels \u200b \u22c5 N windows \u200b \u22c5 ( Packet Length = 80 bytes ) + ( Event Header+Footer = 34 bytes ) + ( Timing Data = 64 bytes )) So our cut was off by a little bit 25/03/2025 14:05 Here are some \"new\" plots that are a bit more telling: Collector error analysis : We can see how collector errors are dependenat on our parameters. For some reason, they were very prevalent in 2 channels. But the thing most correlated with collector errors is the expected data rate. Time to stability analysis Just \\text{DataRate}[j] \\geq 0.99\\cdot \\text{DataRate}[N] DataRate [ j ] \u2265 0.99 \u22c5 DataRate [ N ] \\text{DataRate}[j] \\geq 0.99\\cdot \\text{DataRate}[N] DataRate [ j ] \u2265 0.99 \u22c5 DataRate [ N ] : \\text{DataRate}[j] \\geq 0.99\\cdot \\text{DataRate}[N] DataRate [ j ] \u2265 0.99 \u22c5 DataRate [ N ] \\text{DataRate}[j] \\geq 0.99\\cdot \\text{DataRate}[N] DataRate [ j ] \u2265 0.99 \u22c5 DataRate [ N ] and \\text{DataRate}[j] \\leq 1.01\\cdot \\text{DataRate}[N] DataRate [ j ] \u2264 1.01 \u22c5 DataRate [ N ] \\text{DataRate}[j] \\leq 1.01\\cdot \\text{DataRate}[N] DataRate [ j ] \u2264 1.01 \u22c5 DataRate [ N ] : We can see how time for the data rate to stabilize depends on our parameters. Again, it's most correlated with the expected data rate. Average data rate with uncertainty vs parameters We have see how the data rate depends on our parameters. We see artifacts of \"skipping\" event in there. Normalied average data rate with uncertainty vs parameters Same plot as above, just normalized based on \\frac{\\text{average data rate}}{\\text{expected data rate}} average data rate expected data rate \\frac{\\text{average data rate}}{\\text{expected data rate}} expected data rate average data rate \u200b This gives insight into which parameters are problematic. However, this \"expected data rate\" calculation has issues because I don't know how to correctly account for all the data going into midas. I.e. the logger logs some additional data (such as bank names, index, etc.) that skews the actual result upwards. as a result, I believe a lot of these events are actual \"normal\". They were just picked out by my cuts above due to this lack of understanding. Normalized average event rate with uncertainty vs parameters This is similar to the plot above, except we're plotting normalized event rate i.e. \\frac{\\text{average event rate}}{\\text{input trigger frequency}} average event rate input trigger frequency \\frac{\\text{average event rate}}{\\text{input trigger frequency}} input trigger frequency average event rate \u200b . I believe this plot is slightly more telling that the one above because we really expect every one of these data points to be on the red dotted line, otherwise we're missing events. Overall, it's unclear what's causing events to be missed. It's most correlated with the expected data rate. 28/03/2025 16:22 I did a longer run where I don't just look at the failure modes to get more data for the \"working modes\". What I find is there are actually more errrors than expected. I.e. the 4 second tests did not reveal as many errors as the 60 second tests. I suspect this may have to do with the collectors \"time_threshold\" parameter choice. If it's not set properly, the collect can fill up. Below are some plots (very similar to above).",
    "textLength": 3133
  },
  {
    "kind": "work-log",
    "title": "29_06_2025 - 05_07_2025.html",
    "fileName": "29_06_2025 - 05_07_2025.html",
    "url": "resources/work_logs/29_06_2025 - 05_07_2025.html",
    "createdDate": "2025-06-29",
    "text": "29/06/2025 - 05/07/2025 29/06/2025 - 05/07/2025 29/06/2025 21:06 Possible clue on why we see cut off events at the end: It seems when we stop capture, we still process some stuff at the end? [DEBUG] Configuring connection controller... [DEBUG] Connection controller configured successfully. [DEBUG] Capture configuration completed. [DEBUG] Starting capture... [DEBUG] Setting target IP to 192.168.1.1:12345 [DEBUG] Configuring Ethernet connection... [DEBUG] Ethernet configured [DEBUG] Starting readout with trigger mode: self [INFO] Capture started successfully Started run 42006 [DEBUG] Stopping capture... [INFO] Capture stopped successfully [WARN] Byte stream too short to check stop marker at expected position. Run stopped [ DEBUG ] Configuring connection controller .. . [ DEBUG ] Connection controller configured successfully. [ DEBUG ] Capture configuration completed. [ DEBUG ] Starting capture .. . [ DEBUG ] Setting target IP to 192.168.1.1:12345 [ DEBUG ] Configuring Ethernet connection .. . [ DEBUG ] Ethernet configured [ DEBUG ] Starting readout with trigger mode: self [ INFO ] Capture started successfully Started run 42006 [ DEBUG ] Stopping capture .. . [ INFO ] Capture stopped successfully [WARN] Byte stream too short to check stop marker at expected position. Run stopped",
    "textLength": 179
  },
  {
    "kind": "work-log",
    "title": "22_09_2024 - 28_09_2024.html",
    "fileName": "22_09_2024 - 28_09_2024.html",
    "url": "resources/work_logs/22_09_2024 - 28_09_2024.html",
    "createdDate": "2024-09-22",
    "text": "22/09/2024 - 28/09/2024 22/09/2024 - 28/09/2024 25/09/2024 04:36 I established a faster \"python\" midas frontend by instead having a python thread put it's data in a shared memory buffer that the C++ script reads: import mmap import posix_ipc import numpy as np SHM_NAME = \"/my_shared_memory\" SEM_NAME = \"/my_semaphore\" DATA_SIZE = 1024 * 1024 # 1 MB # Create or open shared memory shared_mem = posix_ipc.SharedMemory(SHM_NAME, posix_ipc.O_CREAT, size=DATA_SIZE) memory = mmap.mmap(shared_mem.fd, shared_mem.size) shared_mem.close_fd() # Create or open semaphore semaphore = posix_ipc.Semaphore(SEM_NAME, posix_ipc.O_CREAT, initial_value=0) try: while True: # Generate or retrieve data data = np.random.randint(0, 65535, size=DATA_SIZE // 2, dtype=np.uint16) byte_data = data.tobytes() # Write data to shared memory memory.seek(0) memory.write(byte_data) # Signal the C++ frontend semaphore.release() # Control the data generation rate as needed except KeyboardInterrupt: pass finally: # Clean up memory.close() shared_mem.unlink() semaphore.unlink() import mmap import posix_ipc import numpy as np SHM_NAME = \"/my_shared_memory\" SEM_NAME = \"/my_semaphore\" DATA_SIZE = 1024 * 1024 # 1 MB # Create or open shared memory shared_mem = posix_ipc. SharedMemory ( SHM_NAME , posix_ipc. O_CREAT , size= DATA_SIZE ) memory = mmap.mmap(shared_mem.fd, shared_mem.size) shared_mem .close_fd() # Create or open semaphore semaphore = posix_ipc. Semaphore ( SEM_NAME , posix_ipc. O_CREAT , initial_value= 0 ) try : while True : # Generate or retrieve data data = np.random.randint(0, 65535, size = DATA_SIZE // 2, dtype = np . uint16 ) byte_data = data .tobytes() # Write data to shared memory memory.seek( 0 ) memory.write(byte_data) # Signal the C ++ frontend semaphore.release() # Control the data generation rate as needed except KeyboardInterrupt : pass finally : # Clean up memory.close() shared_mem.unlink() semaphore.unlink() Then the midas frontend is out standard C++ frontend, to eliminate the python slowdown we were seeing: #include <stdio.h> #include <stdlib.h> #include <math.h> #include <string.h> #include <iostream> #include <fstream> #include <sstream> #include <vector> #include \"midas.h\" #include \"mfe.h\" #include <curl/curl.h> #include <sys/mman.h> #include <fcntl.h> #include <unistd.h> #include <semaphore.h> #include <chrono> #include <errno.h> void trigger_update(INT, INT, void*); /*-- Globals -------------------------------------------------------*/ /* The frontend name (client name) as seen by other MIDAS clients */ const char *frontend_name = \"DataSimulator\"; /* The frontend file name, don't change it */ const char *frontend_file_name = __FILE__; /* frontend_loop is called periodically if this variable is TRUE */ BOOL frontend_call_loop = FALSE; /* a frontend status page is displayed with this frequency in ms */ INT display_period = 0; /* maximum event size produced by this frontend */ INT max_event_size = 1024 * 1024 * 32; /* maximum event size for fragmented events (EQ_FRAGMENTED) */ INT max_event_size_frag = 5 * max_event_size; /* buffer size to hold events */ INT event_buffer_size = 5 * max_event_size; /*-- Shared Memory Configuration --*/ #define SHM_NAME \"/my_shared_memory\" #define SEM_NAME \"/my_semaphore\" #define SHM_DATA_SIZE (1024 * 1024) // 1 MB // Shared memory and semaphore handles int shm_fd = -1; void* shm_ptr = nullptr; sem_t* semaphore = nullptr; /*-- Function declarations -----------------------------------------*/ INT frontend_init(void); INT frontend_exit(void); INT begin_of_run(INT run_number, char *error); INT end_of_run(INT run_number, char *error); INT pause_run(INT run_number, char *error); INT resume_run(INT run_number, char *error); INT frontend_loop(void); INT read_trigger_event(char *pevent, INT off); INT poll_event(INT source, INT count, BOOL test); INT interrupt_configure(INT cmd, INT source, POINTER_T adr); /*-- Equipment list ------------------------------------------------*/ BOOL equipment_common_overwrite = TRUE; EQUIPMENT equipment[] = { {\"Data Simulator\", /* equipment name */ {2, 0, /* event ID, trigger mask */ \"SYSTEM\", /* event buffer */ EQ_POLLED, /* equipment type */ 0, /* event source */ \"MIDAS\", /* format */ TRUE, /* enabled */ RO_RUNNING, /* and update ODB */ 100, /* read every 100 ms */ 0, /* stop run after this event limit */ 0, /* number of sub events */ TRUE, /* log history */ \"\", \"\", \"\",}, read_trigger_event /* readout routine */ }, {\"\"} }; /*-- Frontend Init -------------------------------------------------*/ INT frontend_init() { // Open shared memory shm_fd = shm_open(SHM_NAME, O_RDONLY, 0666); if (shm_fd == -1) { cm_msg(MERROR, \"frontend_init\", \"Failed to open shared memory: %s\", strerror(errno)); return FE_ERR_HW; } // Map shared memory shm_ptr = mmap(0, SHM_DATA_SIZE, PROT_READ, MAP_SHARED, shm_fd, 0); if (shm_ptr == MAP_FAILED) { cm_msg(MERROR, \"frontend_init\", \"Failed to map shared memory: %s\", strerror(errno)); close(shm_fd); return FE_ERR_HW; } close(shm_fd); // Close the file descriptor; it's no longer needed // Open semaphore semaphore = sem_open(SEM_NAME, 0); if (semaphore == SEM_FAILED) { cm_msg(MERROR, \"frontend_init\", \"Failed to open semaphore: %s\", strerror(errno)); munmap(shm_ptr, SHM_DATA_SIZE); return FE_ERR_HW; } return SUCCESS; } /*-- Frontend Exit -------------------------------------------------*/ INT frontend_exit() { // Unmap shared memory if (shm_ptr != nullptr) { munmap(shm_ptr, SHM_DATA_SIZE); } // Close semaphore if (semaphore != nullptr) { sem_close(semaphore); } return SUCCESS; } /*-- Begin of Run --------------------------------------------------*/ INT begin_of_run(INT run_number, char *error) { return SUCCESS; } /*-- End of Run ----------------------------------------------------*/ INT end_of_run(INT run_number, char *error) { return SUCCESS; } /*-- Pause Run -----------------------------------------------------*/ INT pause_run(INT run_number, char *error) { return SUCCESS; } /*-- Resume Run ----------------------------------------------------*/ INT resume_run(INT run_number, char *error) { return SUCCESS; } /*-- Frontend Loop -------------------------------------------------*/ INT frontend_loop() { // No action needed here return SUCCESS; } /*-- Event readout -------------------------------------------------*/ INT poll_event(INT source, INT count, BOOL test) { if (test) { // For testing, return FALSE to indicate no event return FALSE; } else { // Check if semaphore is available without blocking if (sem_trywait(semaphore) == 0) { // Semaphore acquired, event is ready return 1; // Event is available } else { if (errno == EAGAIN) { // Semaphore not available, no event ready return 0; } else { // An error occurred cm_msg(MERROR, \"poll_event\", \"sem_trywait failed: %s\", strerror(errno)); return 0; } } } } /*-- Interrupt configuration ---------------------------------------*/ INT interrupt_configure(INT cmd, INT source, POINTER_T adr) { switch (cmd) { case CMD_INTERRUPT_ENABLE: break; case CMD_INTERRUPT_DISABLE: break; case CMD_INTERRUPT_ATTACH: break; case CMD_INTERRUPT_DETACH: break; } return SUCCESS; } /*-- Trigger event routine -----------------------------------------*/ INT read_trigger_event(char *pevent, INT off) { char *pdata; // Initialize bank structure bk_init32(pevent); // Create a bank named \"CR00\" and specify the data type as TID_BYTE bk_create(pevent, \"CR00\", TID_BYTE, (void **)&pdata); // Read data from shared memory memcpy(pdata, shm_ptr, SHM_DATA_SIZE); // Close the bank pdata += SHM_DATA_SIZE; bk_close(pevent, pdata); return bk_size(pevent); } #include <stdio.h> #include <stdlib.h> #include <math.h> #include <string.h> #include <iostream> #include <fstream> #include <sstream> #include <vector> #include \"midas.h\" #include \"mfe.h\" #include <curl/curl.h> #include <sys/mman.h> #include <fcntl.h> #include <unistd.h> #include <semaphore.h> #include <chrono> #include <errno.h> void trigger_update(INT, INT, void*); /*-- Globals -------------------------------------------------------*/ /* The frontend name (client name) as seen by other MIDAS clients */ const char *frontend_name = \"DataSimulator\"; /* The frontend file name, don't change it */ const char *frontend_file_name = __FILE__; /* frontend_loop is called periodically if this variable is TRUE */ BOOL frontend_call_loop = FALSE; /* a frontend status page is displayed with this frequency in ms */ INT display_period = 0; /* maximum event size produced by this frontend */ INT max_event_size = 1024 * 1024 * 32; /* maximum event size for fragmented events (EQ_FRAGMENTED) */ INT max_event_size_frag = 5 * max_event_size; /* buffer size to hold events */ INT event_buffer_size = 5 * max_event_size; /*-- Shared Memory Configuration --*/ #define SHM_NAME \"/my_shared_memory\" #define SEM_NAME \"/my_semaphore\" #define SHM_DATA_SIZE (1024 * 1024) // 1 MB // Shared memory and semaphore handles int shm_fd = -1; void* shm_ptr = nullptr; sem_t* semaphore = nullptr; /*-- Function declarations -----------------------------------------*/ INT frontend_init(void); INT frontend_exit(void); INT begin_of_run(INT run_number, char *error); INT end_of_run(INT run_number, char *error); INT pause_run(INT run_number, char *error); INT resume_run(INT run_number, char *error); INT frontend_loop(void); INT read_trigger_event(char *pevent, INT off); INT poll_event(INT source, INT count, BOOL test); INT interrupt_configure(INT cmd, INT source, POINTER_T adr); /*-- Equipment list ------------------------------------------------*/ BOOL equipment_common_overwrite = TRUE; EQUIPMENT equipment[] = { {\"Data Simulator\", /* equipment name */ {2, 0, /* event ID, trigger mask */ \"SYSTEM\", /* event buffer */ EQ_POLLED, /* equipment type */ 0, /* event source */ \"MIDAS\", /* format */ TRUE, /* enabled */ RO_RUNNING, /* and update ODB */ 100, /* read every 100 ms */ 0, /* stop run after this event limit */ 0, /* number of sub events */ TRUE, /* log history */ \"\", \"\", \"\",}, read_trigger_event /* readout routine */ }, {\"\"} }; /*-- Frontend Init -------------------------------------------------*/ INT frontend_init() { // Open shared memory shm_fd = shm_open(SHM_NAME, O_RDONLY, 0666); if (shm_fd == -1) { cm_msg(MERROR, \"frontend_init\", \"Failed to open shared memory: %s\", strerror(errno)); return FE_ERR_HW; } // Map shared memory shm_ptr = mmap(0, SHM_DATA_SIZE, PROT_READ, MAP_SHARED, shm_fd, 0); if (shm_ptr == MAP_FAILED) { cm_msg(MERROR, \"frontend_init\", \"Failed to map shared memory: %s\", strerror(errno)); close(shm_fd); return FE_ERR_HW; } close(shm_fd); // Close the file descriptor; it's no longer needed // Open semaphore semaphore = sem_open(SEM_NAME, 0); if (semaphore == SEM_FAILED) { cm_msg(MERROR, \"frontend_init\", \"Failed to open semaphore: %s\", strerror(errno)); munmap(shm_ptr, SHM_DATA_SIZE); return FE_ERR_HW; } return SUCCESS; } /*-- Frontend Exit -------------------------------------------------*/ INT frontend_exit() { // Unmap shared memory if (shm_ptr != nullptr) { munmap(shm_ptr, SHM_DATA_SIZE); } // Close semaphore if (semaphore != nullptr) { sem_close(semaphore); } return SUCCESS; } /*-- Begin of Run --------------------------------------------------*/ INT begin_of_run(INT run_number, char *error) { return SUCCESS; } /*-- End of Run ----------------------------------------------------*/ INT end_of_run(INT run_number, char *error) { return SUCCESS; } /*-- Pause Run -----------------------------------------------------*/ INT pause_run(INT run_number, char *error) { return SUCCESS; } /*-- Resume Run ----------------------------------------------------*/ INT resume_run(INT run_number, char *error) { return SUCCESS; } /*-- Frontend Loop -------------------------------------------------*/ INT frontend_loop() { // No action needed here return SUCCESS; } /*-- Event readout -------------------------------------------------*/ INT poll_event(INT source, INT count, BOOL test) { if (test) { // For testing, return FALSE to indicate no event return FALSE; } else { // Check if semaphore is available without blocking if (sem_trywait(semaphore) == 0) { // Semaphore acquired, event is ready return 1; // Event is available } else { if (errno == EAGAIN) { // Semaphore not available, no event ready return 0; } else { // An error occurred cm_msg(MERROR, \"poll_event\", \"sem_trywait failed: %s\", strerror(errno)); return 0; } } } } /*-- Interrupt configuration ---------------------------------------*/ INT interrupt_configure(INT cmd, INT source, POINTER_T adr) { switch (cmd) { case CMD_INTERRUPT_ENABLE: break; case CMD_INTERRUPT_DISABLE: break; case CMD_INTERRUPT_ATTACH: break; case CMD_INTERRUPT_DETACH: break; } return SUCCESS; } /*-- Trigger event routine -----------------------------------------*/ INT read_trigger_event(char *pevent, INT off) { char *pdata; // Initialize bank structure bk_init32(pevent); // Create a bank named \"CR00\" and specify the data type as TID_BYTE bk_create(pevent, \"CR00\", TID_BYTE, (void **)&pdata); // Read data from shared memory memcpy(pdata, shm_ptr, SHM_DATA_SIZE); // Close the bank pdata += SHM_DATA_SIZE; bk_close(pevent, pdata); return bk_size(pevent); } And this seems to go significantly faster (~10x faster) than the python frontend solution: 25/09/2024 05:03 I wanted to further investigate the difference between my C++ Library and the Xilinx DMA tools perfromance, so I made some plots of sequentual tests: Custom C++ Library, 256KB transfer, 1,000,000 samples: Xilinx DMA tools, 256KB transfer, 100,000 samples: Custom C++ Library, 32MB transfer, 1,000 samples: Xilinx DMA tools, 32MB transfer, 1,000 samples: 25/09/2024 05:22 I also smoothed the \"ticker\" plots and animated them to see the whole data set. I can't put the animation here, but I noticed \"average down time\" where there are long periods of slowdown on average visible in the plots below. There are also sharp peaks of downtime, visible in the plots above. 25/09/2024 05:49 I made a mistake in my first attempt at the shared memory buffer. The C++ script would just read whatever was in the buffer, with no concern if it was a new data or not. This meant the python script could not bottleneck the rate. I made edits so that the C++ script would not read the same data multiple times by adding a \"sequence number\" header to the data packets: data_backend.py import mmap import posix_ipc import struct import numpy as np import time SHM_NAME = \"/my_shared_memory\" SEM_NAME = \"/my_semaphore\" SHM_DATA_SIZE = 1024 * 1024 # 1 MB HEADER_FORMAT = 'Q' # Unsigned long long (8 bytes) # Calculate total size: header + data TOTAL_SIZE = struct.calcsize(HEADER_FORMAT) + SHM_DATA_SIZE # Create or open shared memory shared_mem = posix_ipc.SharedMemory(SHM_NAME, posix_ipc.O_CREAT, size=TOTAL_SIZE) memory = mmap.mmap(shared_mem.fd, shared_mem.size) shared_mem.close_fd() # Create or open semaphore semaphore = posix_ipc.Semaphore(SEM_NAME, posix_ipc.O_CREAT, initial_value=0) sequence_number = 0 try: while True: # Increment the sequence number sequence_number += 1 # Generate or retrieve data data = np.random.randint(0, 256, size=SHM_DATA_SIZE, dtype=np.uint8) byte_data = data.tobytes() # Pack the sequence number header = struct.pack(HEADER_FORMAT, sequence_number) # Write header and data to shared memory memory.seek(0) memory.write(header + byte_data) # Signal the C++ frontend semaphore.release() # Control the data generation rate as needed except KeyboardInterrupt: pass finally: # Clean up memory.close() shared_mem.unlink() semaphore.unlink() import mmap import posix_ipc import struct import numpy as np import time SHM_NAME = \"/my_shared_memory\" SEM_NAME = \"/my_semaphore\" SHM_DATA_SIZE = 1024 * 1024 # 1 MB HEADER_FORMAT = 'Q' # Unsigned long long (8 bytes) # Calculate total size: header + data TOTAL_SIZE = struct.calcsize(HEADER_FORMAT) + SHM_DATA_SIZE # Create or open shared memory shared_mem = posix_ipc.SharedMemory(SHM_NAME, posix_ipc.O_CREAT, size=TOTAL_SIZE) memory = mmap.mmap(shared_mem.fd, shared_mem.size) shared_mem.close_fd() # Create or open semaphore semaphore = posix_ipc.Semaphore(SEM_NAME, posix_ipc.O_CREAT, initial_value=0) sequence_number = 0 try: while True: # Increment the sequence number sequence_number += 1 # Generate or retrieve data data = np.random.randint(0, 256, size=SHM_DATA_SIZE, dtype=np.uint8) byte_data = data.tobytes() # Pack the sequence number header = struct.pack(HEADER_FORMAT, sequence_number) # Write header and data to shared memory memory.seek(0) memory.write(header + byte_data) # Signal the C++ frontend semaphore.release() # Control the data generation rate as needed except KeyboardInterrupt: pass finally: # Clean up memory.close() shared_mem.unlink() semaphore.unlink() frontend.cxx #include <stdio.h> #include <stdlib.h> #include <math.h> #include <string.h> #include <iostream> #include <fstream> #include <sstream> #include <vector> #include <cstdint> #include \"midas.h\" #include \"mfe.h\" #include <curl/curl.h> #include <sys/mman.h> #include <fcntl.h> #include <unistd.h> #include <semaphore.h> #include <chrono> #include <errno.h> void trigger_update(INT, INT, void*); /*-- Globals -------------------------------------------------------*/ /* The frontend name (client name) as seen by other MIDAS clients */ const char *frontend_name = \"DataSimulator\"; /* The frontend file name, don't change it */ const char *frontend_file_name = __FILE__; /* frontend_loop is called periodically if this variable is TRUE */ BOOL frontend_call_loop = FALSE; /* a frontend status page is displayed with this frequency in ms */ INT display_period = 0; /* maximum event size produced by this frontend */ INT max_event_size = 1024 * 1024 * 32; /* maximum event size for fragmented events (EQ_FRAGMENTED) */ INT max_event_size_frag = 5 * max_event_size; /* buffer size to hold events */ INT event_buffer_size = 5 * max_event_size; /*-- Shared Memory Configuration --*/ #define SHM_NAME \"/my_shared_memory\" #define SEM_NAME \"/my_semaphore\" #define SHM_DATA_SIZE (1024 * 1024) // 1 MB // Total size: header + data #define TOTAL_SIZE (sizeof(uint64_t) + SHM_DATA_SIZE) // Shared memory and semaphore handles int shm_fd = -1; void* shm_ptr = nullptr; sem_t* semaphore = nullptr; /*-- Function declarations -----------------------------------------*/ INT frontend_init(void); INT frontend_exit(void); INT begin_of_run(INT run_number, char *error); INT end_of_run(INT run_number, char *error); INT pause_run(INT run_number, char *error); INT resume_run(INT run_number, char *error); INT frontend_loop(void); INT read_trigger_event(char *pevent, INT off); INT poll_event(INT source, INT count, BOOL test); INT interrupt_configure(INT cmd, INT source, POINTER_T adr); /*-- Equipment list ------------------------------------------------*/ BOOL equipment_common_overwrite = TRUE; EQUIPMENT equipment[] = { {\"Data Simulator\", /* equipment name */ {2, 0, /* event ID, trigger mask */ \"SYSTEM\", /* event buffer */ EQ_POLLED, /* equipment type */ 0, /* event source */ \"MIDAS\", /* format */ TRUE, /* enabled */ RO_RUNNING, /* read when running */ 0, /* read every event (0 for ASAP) */ 0, /* stop run after this event limit */ 0, /* number of sub events */ TRUE, /* log history */ \"\", \"\", \"\",}, read_trigger_event /* readout routine */ }, {\"\"} }; /*-- Global Variables ----------------------------------------------*/ uint64_t last_sequence_number = 0; /*-- Frontend Init -------------------------------------------------*/ INT frontend_init() { // Open shared memory shm_fd = shm_open(SHM_NAME, O_RDONLY, 0666); if (shm_fd == -1) { cm_msg(MERROR, \"frontend_init\", \"Failed to open shared memory: %s\", strerror(errno)); return FE_ERR_HW; } // Map shared memory shm_ptr = mmap(0, TOTAL_SIZE, PROT_READ, MAP_SHARED, shm_fd, 0); if (shm_ptr == MAP_FAILED) { cm_msg(MERROR, \"frontend_init\", \"Failed to map shared memory: %s\", strerror(errno)); close(shm_fd); return FE_ERR_HW; } close(shm_fd); // Close the file descriptor; it's no longer needed // Open semaphore semaphore = sem_open(SEM_NAME, 0); if (semaphore == SEM_FAILED) { cm_msg(MERROR, \"frontend_init\", \"Failed to open semaphore: %s\", strerror(errno)); munmap(shm_ptr, TOTAL_SIZE); return FE_ERR_HW; } return SUCCESS; } /*-- Frontend Exit -------------------------------------------------*/ INT frontend_exit() { // Unmap shared memory if (shm_ptr != nullptr) { munmap(shm_ptr, TOTAL_SIZE); } // Close semaphore if (semaphore != nullptr) { sem_close(semaphore); } return SUCCESS; } /*-- Begin of Run --------------------------------------------------*/ INT begin_of_run(INT run_number, char *error) { // Reset the last sequence number last_sequence_number = 0; return SUCCESS; } /*-- End of Run ----------------------------------------------------*/ INT end_of_run(INT run_number, char *error) { return SUCCESS; } /*-- Pause Run -----------------------------------------------------*/ INT pause_run(INT run_number, char *error) { return SUCCESS; } /*-- Resume Run ----------------------------------------------------*/ INT resume_run(INT run_number, char *error) { return SUCCESS; } /*-- Frontend Loop -------------------------------------------------*/ INT frontend_loop() { // No action needed here return SUCCESS; } /*-- Event readout -------------------------------------------------*/ INT poll_event(INT source, INT count, BOOL test) { if (test) { // For testing, return FALSE to indicate no event return FALSE; } else { // Check if semaphore is available without blocking if (sem_trywait(semaphore) == 0) { // Semaphore acquired, event is ready // Read the sequence number from shared memory uint64_t sequence_number = *(reinterpret_cast<uint64_t*>(shm_ptr)); if (sequence_number != last_sequence_number) { // New data is available last_sequence_number = sequence_number; return 1; // Event is available } else { // Duplicate data, ignore return 0; } } else { if (errno == EAGAIN) { // Semaphore not available, no event ready return 0; } else { // An error occurred cm_msg(MERROR, \"poll_event\", \"sem_trywait failed: %s\", strerror(errno)); return 0; } } } } /*-- Interrupt configuration ---------------------------------------*/ INT interrupt_configure(INT cmd, INT source, POINTER_T adr) { switch (cmd) { case CMD_INTERRUPT_ENABLE: break; case CMD_INTERRUPT_DISABLE: break; case CMD_INTERRUPT_ATTACH: break; case CMD_INTERRUPT_DETACH: break; } return SUCCESS; } /*-- Trigger event routine -----------------------------------------*/ INT read_trigger_event(char *pevent, INT off) { char *pdata; // Initialize bank structure bk_init32(pevent); // Create a bank named \"CR00\" and specify the data type as TID_BYTE bk_create(pevent, \"CR00\", TID_BYTE, (void **)&pdata); // Copy data from shared memory (excluding the sequence number) memcpy(pdata, (char*)shm_ptr + sizeof(uint64_t), SHM_DATA_SIZE); // Close the bank pdata += SHM_DATA_SIZE; bk_close(pevent, pdata); return bk_size(pevent); } #include <stdio.h> #include <stdlib.h> #include <math.h> #include <string.h> #include <iostream> #include <fstream> #include <sstream> #include <vector> #include <cstdint> #include \"midas.h\" #include \"mfe.h\" #include <curl/curl.h> #include <sys/mman.h> #include <fcntl.h> #include <unistd.h> #include <semaphore.h> #include <chrono> #include <errno.h> void trigger_update(INT, INT, void*); /*-- Globals -------------------------------------------------------*/ /* The frontend name (client name) as seen by other MIDAS clients */ const char *frontend_name = \"DataSimulator\"; /* The frontend file name, don't change it */ const char *frontend_file_name = __FILE__; /* frontend_loop is called periodically if this variable is TRUE */ BOOL frontend_call_loop = FALSE; /* a frontend status page is displayed with this frequency in ms */ INT display_period = 0; /* maximum event size produced by this frontend */ INT max_event_size = 1024 * 1024 * 32; /* maximum event size for fragmented events (EQ_FRAGMENTED) */ INT max_event_size_frag = 5 * max_event_size; /* buffer size to hold events */ INT event_buffer_size = 5 * max_event_size; /*-- Shared Memory Configuration --*/ #define SHM_NAME \"/my_shared_memory\" #define SEM_NAME \"/my_semaphore\" #define SHM_DATA_SIZE (1024 * 1024) // 1 MB // Total size: header + data #define TOTAL_SIZE (sizeof(uint64_t) + SHM_DATA_SIZE) // Shared memory and semaphore handles int shm_fd = -1; void* shm_ptr = nullptr; sem_t* semaphore = nullptr; /*-- Function declarations -----------------------------------------*/ INT frontend_init(void); INT frontend_exit(void); INT begin_of_run(INT run_number, char *error); INT end_of_run(INT run_number, char *error); INT pause_run(INT run_number, char *error); INT resume_run(INT run_number, char *error); INT frontend_loop(void); INT read_trigger_event(char *pevent, INT off); INT poll_event(INT source, INT count, BOOL test); INT interrupt_configure(INT cmd, INT source, POINTER_T adr); /*-- Equipment list ------------------------------------------------*/ BOOL equipment_common_overwrite = TRUE; EQUIPMENT equipment[] = { {\"Data Simulator\", /* equipment name */ {2, 0, /* event ID, trigger mask */ \"SYSTEM\", /* event buffer */ EQ_POLLED, /* equipment type */ 0, /* event source */ \"MIDAS\", /* format */ TRUE, /* enabled */ RO_RUNNING, /* read when running */ 0, /* read every event (0 for ASAP) */ 0, /* stop run after this event limit */ 0, /* number of sub events */ TRUE, /* log history */ \"\", \"\", \"\",}, read_trigger_event /* readout routine */ }, {\"\"} }; /*-- Global Variables ----------------------------------------------*/ uint64_t last_sequence_number = 0; /*-- Frontend Init -------------------------------------------------*/ INT frontend_init() { // Open shared memory shm_fd = shm_open(SHM_NAME, O_RDONLY, 0666); if (shm_fd == -1) { cm_msg(MERROR, \"frontend_init\", \"Failed to open shared memory: %s\", strerror(errno)); return FE_ERR_HW; } // Map shared memory shm_ptr = mmap(0, TOTAL_SIZE, PROT_READ, MAP_SHARED, shm_fd, 0); if (shm_ptr == MAP_FAILED) { cm_msg(MERROR, \"frontend_init\", \"Failed to map shared memory: %s\", strerror(errno)); close(shm_fd); return FE_ERR_HW; } close(shm_fd); // Close the file descriptor; it's no longer needed // Open semaphore semaphore = sem_open(SEM_NAME, 0); if (semaphore == SEM_FAILED) { cm_msg(MERROR, \"frontend_init\", \"Failed to open semaphore: %s\", strerror(errno)); munmap(shm_ptr, TOTAL_SIZE); return FE_ERR_HW; } return SUCCESS; } /*-- Frontend Exit -------------------------------------------------*/ INT frontend_exit() { // Unmap shared memory if (shm_ptr != nullptr) { munmap(shm_ptr, TOTAL_SIZE); } // Close semaphore if (semaphore != nullptr) { sem_close(semaphore); } return SUCCESS; } /*-- Begin of Run --------------------------------------------------*/ INT begin_of_run(INT run_number, char *error) { // Reset the last sequence number last_sequence_number = 0; return SUCCESS; } /*-- End of Run ----------------------------------------------------*/ INT end_of_run(INT run_number, char *error) { return SUCCESS; } /*-- Pause Run -----------------------------------------------------*/ INT pause_run(INT run_number, char *error) { return SUCCESS; } /*-- Resume Run ----------------------------------------------------*/ INT resume_run(INT run_number, char *error) { return SUCCESS; } /*-- Frontend Loop -------------------------------------------------*/ INT frontend_loop() { // No action needed here return SUCCESS; } /*-- Event readout -------------------------------------------------*/ INT poll_event(INT source, INT count, BOOL test) { if (test) { // For testing, return FALSE to indicate no event return FALSE; } else { // Check if semaphore is available without blocking if (sem_trywait(semaphore) == 0) { // Semaphore acquired, event is ready // Read the sequence number from shared memory uint64_t sequence_number = *(reinterpret_cast<uint64_t*>(shm_ptr)); if (sequence_number != last_sequence_number) { // New data is available last_sequence_number = sequence_number; return 1; // Event is available } else { // Duplicate data, ignore return 0; } } else { if (errno == EAGAIN) { // Semaphore not available, no event ready return 0; } else { // An error occurred cm_msg(MERROR, \"poll_event\", \"sem_trywait failed: %s\", strerror(errno)); return 0; } } } } /*-- Interrupt configuration ---------------------------------------*/ INT interrupt_configure(INT cmd, INT source, POINTER_T adr) { switch (cmd) { case CMD_INTERRUPT_ENABLE: break; case CMD_INTERRUPT_DISABLE: break; case CMD_INTERRUPT_ATTACH: break; case CMD_INTERRUPT_DETACH: break; } return SUCCESS; } /*-- Trigger event routine -----------------------------------------*/ INT read_trigger_event(char *pevent, INT off) { char *pdata; // Initialize bank structure bk_init32(pevent); // Create a bank named \"CR00\" and specify the data type as TID_BYTE bk_create(pevent, \"CR00\", TID_BYTE, (void **)&pdata); // Copy data from shared memory (excluding the sequence number) memcpy(pdata, (char*)shm_ptr + sizeof(uint64_t), SHM_DATA_SIZE); // Close the bank pdata += SHM_DATA_SIZE; bk_close(pevent, pdata); return bk_size(pevent); } 26/09/2024 05:59 I tried a few things to get the \"correct shape\" of the transfer rate curve using that we see using Xilinx XDMA tools (as seen in the figure below) 1. Writing the script solely in C I made a few more testing smaller things: second data set: 100 trials per data point: 500 trials per data point, adjusted makefile compiler flags to match Xilinx's makefile: 100 trials per data point, a delay added in the code to allow for \"recovery\": 2. Optimizing the C++ library I made a branch of my C++ Library that \"optimizes\" the code a bit; instead using pointers to avoid any sort of overhead. However, I still did not see the expected \"shape\"",
    "textLength": 3434
  },
  {
    "kind": "work-log",
    "title": "08_12_2024 - 14_12_2024.html",
    "fileName": "08_12_2024 - 14_12_2024.html",
    "url": "resources/work_logs/08_12_2024 - 14_12_2024.html",
    "createdDate": "2024-12-08",
    "text": "08/12/2024 - 14/12/2024 08/12/2024 - 14/12/2024 11/12/2024 22:07 As per instructions, The self trigger works but the trigger values are tricky since they don't correspond to the Y-axis. The HDSoC series of cards uses low and high reference values to set the lower and upper limit for the comparator circuit, then an 8-bit register controls the trigger values between the limits. To help users we added the Threshold scanner, to map the signal values to the trigger values. i It will step through a range of trigger values and ask the ASIC how many times it triggers then create a plot with x-axis: trigger_value and y-axis: times triggered: The peak shows the trigger value for the noise and the actual position depends on the external bias value and the individual channel. A good starting point is low_ref: 6 and high_ref: 12, with 0-255 in steps of 1. The time it takes to scan scales linearly with the number of channels since the internal counter needs time to reset, it's a good idea to start with one channel. The peak is only slightly temperature dependent and will only move a few points over time, you can re-use the result in the future, or use them to guide you for future scans. The external trigger input should work now, it's an LVCMOS25 input and accepts pulses 0-2.5V with a width of 10-100ns. Let me know if you want more clarification! Cheers, Marcus Luck Lead Software Engineer Nalu Scientific LLC First I followed these instructions for just channel 0, but had no luck. Then I followed these instructions, and was able to produce a trigger plot for channels 0, 1, 16, and 17: low threshold 6, high threshold 12 I scanned with low threshold 6 and high threshold 12. I scanned 0-255 in this range at first but then switched to 60-80 for a better plot. I also tried shortening the low threshold to 8 and high threshold to 9. I still saw the signal, but to my surpise it wasn't wider. low threshold 8, high threshold 9 I must not be understanding what the thresholds did. I though they effectively define the range of the comparator, and the scan divides that range up further in 256 parts. So by that logic making the threshold 6 times smaller (12 - 6 = 6 to 9 - 8 = 1) should make the signal 6 times wider. Even worse, I wasn't able to trigger on these settings using the naluscope. I was just setting the thresholds and values shown on the graph in the trigger settings then starting an acquisiton. I tried varying the thresholds a lot, but with no luck, I was not able to trigger on a single noise trace. 12/12/2024 22:10 Earlier I tried running the 2 crate system, but i could not connect to the digitizers in the second crate. I could still talk to the MCH and AMC13 however. So I went to the lab and noticed the crate looked like this Immediately you notice the blue lights on the WFD5s that indicate they're disabled. There's also the red critical light on the crate itself. I first tried restarting the WFD5s by pulling out the tab and putting it back in. That worked for about 20 seconds before they went back to their disabled state. I then tried power cycling that crate. After about 2 minutes the crate's red \"crit\" light goes on first, then a few seconds after both the WFD5s disable themselves. The AMC13 and MCH still seem to work fine. We don't have this problem with crate one. I don't know how to debug this, though I'm almost certain it's a crate issue. 12/12/2024 22:53 I tried doing another threshold scan today. This time it worked. Threshold scan for channel 0 low ref 6 high ref 12 I did exactly as I did before, setting the triggers to where the threshold scan peaked with the same high and low ref. This time I was able to trigger on noise. The difference was ALL other channels had to be set to zero threshold (before I had them set to 1) 13/12/2024 14:04 Taking the WFD5s out of the crate and leaving it on seemed to get rid of the \"cirtical\" warning. I have left it up for about 30 minutes with no error. Also, I found the correct fru print command: [root@dhcp-10-163-105-238 ~]# ipmitool -H 192.168.2.15 fru print Password: Activate Session command failed Error: Unable to establish LAN session Error: Unable to establish IPMI v1.5 / RMCP session [root@dhcp-10-163-105-238 ~]# ipmitool -H 192.168.2.15 -U 'shelf' -P 'shelf' fru print FRU Device Description : Builtin FRU Device (ID 0) Board Mfg Date : Tue May 14 12:51:00 2024 Board Mfg : VadaTech Board Product : ShMC Board Serial : na Board Part Number : VTUTCSH Product Manufacturer : VadaTech Product Name : ShMC Product Part Number : VTUTCSH Product Version : n/a Product Serial : na Product Extra : 5D32 FRU Device Description : SHELF FRU INFO (ID 254) Chassis Type : Other Chassis Part Number : VT892 Chassis Serial : 1940394 Board Mfg Date : Sun Apr 5 08:09:00 2015 Board Mfg : VadaTech Board Product : UTCA Shelf Board Serial : 1940394 Board Part Number : VTSH INFO Product Manufacturer : VadaTech Product Name : UTCA Shelf Product Part Number : VTSH INFO Product Version : 3.2.0 Product Serial : 1940394 Product Extra : 5D32 FRU Device Description : UTCA CARRIER (ID 0) Unsupported device FRU Device Description : UTCA CARRIER Board Mfg Date : Tue May 14 12:51:00 2024 Board Mfg : VadaTech Board Product : UTCC Board Serial : na Board Part Number : VTUTCC Product Manufacturer : VadaTech Product Name : UTCC Product Part Number : VTUTCC Product Version : 7.5.0 Product Serial : na Product Extra : 5D32 FRU Device Description : SH FRU DEV1 (ID 1) Chassis Type : Other Chassis Part Number : VT892 Chassis Serial : 1940394 Board Mfg Date : Sun Apr 5 08:09:00 2015 Board Mfg : VadaTech Board Product : UTCA Shelf Board Serial : 1940394 Board Part Number : VTSH INFO Product Manufacturer : VadaTech Product Name : UTCA Shelf Product Part Number : VTSH INFO Product Version : 3.2.0 Product Serial : 1940394 Product Extra : 5D32 FRU Device Description : UTCA MCH (ID 3) Unsupported device FRU Device Description : VT VT095 (ID 40) Unsupported device FRU Device Description : VT VT095 (ID 41) Unsupported device FRU Device Description : VT UTC020 (ID 50) Unsupported device FRU Device Description : MCH DA INFO (ID 80) Board Mfg Date : Thu Jul 27 10:14:00 2017 Board Mfg : VadaTech Board Product : DA-None Board Part Number : 0000 Product Manufacturer : VadaTech Product Name : DA-None Product Version : 1.0.0 [root@dhcp-10-163-105-238 ~]# ipmitool -H 192.168.2.15 fru print Password: Activate Session command failed Error: Unable to establish LAN session Error: Unable to establish IPMI v1.5 / RMCP session [root@dhcp-10-163-105-238 ~]# ipmitool -H 192.168.2.15 -U 'shelf' -P 'shelf' fru print FRU Device Description : Builtin FRU Device (ID 0) Board Mfg Date : Tue May 14 12:51:00 2024 Board Mfg : VadaTech Board Product : ShMC Board Serial : na Board Part Number : VTUTCSH Product Manufacturer : VadaTech Product Name : ShMC Product Part Number : VTUTCSH Product Version : n/a Product Serial : na Product Extra : 5D32 FRU Device Description : SHELF FRU INFO (ID 254) Chassis Type : Other Chassis Part Number : VT892 Chassis Serial : 1940394 Board Mfg Date : Sun Apr 5 08:09:00 2015 Board Mfg : VadaTech Board Product : UTCA Shelf Board Serial : 1940394 Board Part Number : VTSH INFO Product Manufacturer : VadaTech Product Name : UTCA Shelf Product Part Number : VTSH INFO Product Version : 3.2.0 Product Serial : 1940394 Product Extra : 5D32 FRU Device Description : UTCA CARRIER (ID 0) Unsupported device FRU Device Description : UTCA CARRIER Board Mfg Date : Tue May 14 12:51:00 2024 Board Mfg : VadaTech Board Product : UTCC Board Serial : na Board Part Number : VTUTCC Product Manufacturer : VadaTech Product Name : UTCC Product Part Number : VTUTCC Product Version : 7.5.0 Product Serial : na Product Extra : 5D32 FRU Device Description : SH FRU DEV1 (ID 1) Chassis Type : Other Chassis Part Number : VT892 Chassis Serial : 1940394 Board Mfg Date : Sun Apr 5 08:09:00 2015 Board Mfg : VadaTech Board Product : UTCA Shelf Board Serial : 1940394 Board Part Number : VTSH INFO Product Manufacturer : VadaTech Product Name : UTCA Shelf Product Part Number : VTSH INFO Product Version : 3.2.0 Product Serial : 1940394 Product Extra : 5D32 FRU Device Description : UTCA MCH (ID 3) Unsupported device FRU Device Description : VT VT095 (ID 40) Unsupported device FRU Device Description : VT VT095 (ID 41) Unsupported device FRU Device Description : VT UTC020 (ID 50) Unsupported device FRU Device Description : MCH DA INFO (ID 80) Board Mfg Date : Thu Jul 27 10:14:00 2017 Board Mfg : VadaTech Board Product : DA-None Board Part Number : 0000 Product Manufacturer : VadaTech Product Name : DA-None Product Version : 1.0.0 13/12/2024 14:11 Putting just one of the WFD5s back into slot 3 causes the same issue as before. This is the case with either of the digitizers (i.e. putting just the WFD5 that was previously in slot 5 into slot 3 or putting the WFD5 that was previous in slot 3 into slot 3). Here's the fru print : [root@dhcp-10-163-105-238 ~]# ipmitool -H 192.168.2.15 -U 'shelf' -P 'shelf' fru print FRU Device Description : Builtin FRU Device (ID 0) Board Mfg Date : Tue May 14 12:51:00 2024 Board Mfg : VadaTech Board Product : ShMC Board Serial : na Board Part Number : VTUTCSH Product Manufacturer : VadaTech Product Name : ShMC Product Part Number : VTUTCSH Product Version : n/a Product Serial : na Product Extra : 5D32 FRU Device Description : SHELF FRU INFO (ID 254) Chassis Type : Other Chassis Part Number : VT892 Chassis Serial : 1940394 Board Mfg Date : Sun Apr 5 08:09:00 2015 Board Mfg : VadaTech Board Product : UTCA Shelf Board Serial : 1940394 Board Part Number : VTSH INFO Product Manufacturer : VadaTech Product Name : UTCA Shelf Product Part Number : VTSH INFO Product Version : 3.2.0 Product Serial : 1940394 Product Extra : 5D32 FRU Device Description : UTCA CARRIER (ID 0) Unsupported device FRU Device Description : UTCA CARRIER Board Mfg Date : Tue May 14 12:51:00 2024 Board Mfg : VadaTech Board Product : UTCC Board Serial : na Board Part Number : VTUTCC Product Manufacturer : VadaTech Product Name : UTCC Product Part Number : VTUTCC Product Version : 7.5.0 Product Serial : na Product Extra : 5D32 FRU Device Description : SH FRU DEV1 (ID 1) Chassis Type : Other Chassis Part Number : VT892 Chassis Serial : 1940394 Board Mfg Date : Sun Apr 5 08:09:00 2015 Board Mfg : VadaTech Board Product : UTCA Shelf Board Serial : 1940394 Board Part Number : VTSH INFO Product Manufacturer : VadaTech Product Name : UTCA Shelf Product Part Number : VTSH INFO Product Version : 3.2.0 Product Serial : 1940394 Product Extra : 5D32 FRU Device Description : UTCA MCH (ID 3) Unsupported device FRU Device Description : CU WFD5 (ID 7) Unsupported device FRU Device Description : VT VT095 (ID 40) Unsupported device FRU Device Description : VT VT095 (ID 41) Unsupported device FRU Device Description : VT UTC020 (ID 50) Unsupported device FRU Device Description : MCH DA INFO (ID 80) Board Mfg Date : Thu Jul 27 10:14:00 2017 Board Mfg : VadaTech Board Product : DA-None Board Part Number : 0000 Product Manufacturer : VadaTech Product Name : DA-None Product Version : 1.0.0 [root@dhcp-10-163-105-238 ~]# ping 192.168.2.3 PING 192.168.2.3 (192.168.2.3) 56(84) bytes of data. ^C --- 192.168.2.3 ping statistics --- 2 packets transmitted, 0 received, 100% packet loss, time 1023ms [root@dhcp-10-163-105-238 ~]# [root@dhcp-10-163-105-238 ~]# ipmitool -H 192.168.2.15 -U 'shelf' -P 'shelf' fru print FRU Device Description : Builtin FRU Device (ID 0) Board Mfg Date : Tue May 14 12:51:00 2024 Board Mfg : VadaTech Board Product : ShMC Board Serial : na Board Part Number : VTUTCSH Product Manufacturer : VadaTech Product Name : ShMC Product Part Number : VTUTCSH Product Version : n/a Product Serial : na Product Extra : 5D32 FRU Device Description : SHELF FRU INFO (ID 254) Chassis Type : Other Chassis Part Number : VT892 Chassis Serial : 1940394 Board Mfg Date : Sun Apr 5 08:09:00 2015 Board Mfg : VadaTech Board Product : UTCA Shelf Board Serial : 1940394 Board Part Number : VTSH INFO Product Manufacturer : VadaTech Product Name : UTCA Shelf Product Part Number : VTSH INFO Product Version : 3.2.0 Product Serial : 1940394 Product Extra : 5D32 FRU Device Description : UTCA CARRIER (ID 0) Unsupported device FRU Device Description : UTCA CARRIER Board Mfg Date : Tue May 14 12:51:00 2024 Board Mfg : VadaTech Board Product : UTCC Board Serial : na Board Part Number : VTUTCC Product Manufacturer : VadaTech Product Name : UTCC Product Part Number : VTUTCC Product Version : 7.5.0 Product Serial : na Product Extra : 5D32 FRU Device Description : SH FRU DEV1 (ID 1) Chassis Type : Other Chassis Part Number : VT892 Chassis Serial : 1940394 Board Mfg Date : Sun Apr 5 08:09:00 2015 Board Mfg : VadaTech Board Product : UTCA Shelf Board Serial : 1940394 Board Part Number : VTSH INFO Product Manufacturer : VadaTech Product Name : UTCA Shelf Product Part Number : VTSH INFO Product Version : 3.2.0 Product Serial : 1940394 Product Extra : 5D32 FRU Device Description : UTCA MCH (ID 3) Unsupported device FRU Device Description : CU WFD5 (ID 7) Unsupported device FRU Device Description : VT VT095 (ID 40) Unsupported device FRU Device Description : VT VT095 (ID 41) Unsupported device FRU Device Description : VT UTC020 (ID 50) Unsupported device FRU Device Description : MCH DA INFO (ID 80) Board Mfg Date : Thu Jul 27 10:14:00 2017 Board Mfg : VadaTech Board Product : DA-None Board Part Number : 0000 Product Manufacturer : VadaTech Product Name : DA-None Product Version : 1.0.0 [root@dhcp-10-163-105-238 ~]# ping 192.168.2.3 PING 192.168.2.3 (192.168.2.3) 56(84) bytes of data. ^C --- 192.168.2.3 ping statistics --- 2 packets transmitted, 0 received, 100% packet loss, time 1023ms [root@dhcp-10-163-105-238 ~]# commands like read_status fail because IP connection is down, i.e. you cannot ping the WFD5s [root@dhcp-10-163-105-238 software]# python read_status.py 2 3 Crate 02, Slot 03 Traceback (most recent call last): File \"/home/pioneer/packages/wfdConfig/software/read_status.py\", line 55, in <module> wfd.dispatch() uhal._core.UdpTimeout: Timeout (1000 milliseconds) occurred for UDP receive from target with URI: ipbusudp-2.0://192.168.2.3:50001 [root@dhcp-10-163-105-238 software]# python read_status.py 2 5 Crate 02, Slot 05 Traceback (most recent call last): File \"/home/pioneer/packages/wfdConfig/software/read_status.py\", line 55, in <module> wfd.dispatch() uhal._core.UdpTimeout: Timeout (1000 milliseconds) occurred for UDP receive from target with URI: ipbusudp-2.0://192.168.2.5:50001 [root@dhcp-10-163-105-238 software]# [root @dhcp -10 -163 -105 -238 software]# python read_status.py 2 3 Crate 02 , Slot 03 Traceback (most recent call last ): File \"/home/pioneer/packages/wfdConfig/software/read_status.py\", line 55 , in < module > wfd.dispatch() uhal._core.UdpTimeout: Timeout ( 1000 milliseconds) occurred for UDP receive from target with URI: ipbusudp -2.0 : / / 192.168 .2 .3 : 50001 [root @dhcp -10 -163 -105 -238 software]# python read_status.py 2 5 Crate 02 , Slot 05 Traceback (most recent call last ): File \"/home/pioneer/packages/wfdConfig/software/read_status.py\", line 55 , in < module > wfd.dispatch() uhal._core.UdpTimeout: Timeout ( 1000 milliseconds) occurred for UDP receive from target with URI: ipbusudp -2.0 : / / 192.168 .2 .5 : 50001 [root @dhcp -10 -163 -105 -238 software]# 13/12/2024 14:25 I swapped out the WFD5 that was in slot 11 of crate 1 with the WFD5 that was in slot 3 of crate 2. Now there is just a WFD5 that we know is working in slot 3 of crate 2 and no other WFD5. This causes the same \"critical error\", indicating it is not a problem with the digitizer itself but a combination of the crate and digitizers. 13/12/2024 14:36 I tried moving the WFD5 that was working in crate 1 slot 11 to crate 2 slot 9 now. The issue still persists.",
    "textLength": 2720
  },
  {
    "kind": "work-log",
    "title": "13_10_2024 - 19_10_2024.html",
    "fileName": "13_10_2024 - 19_10_2024.html",
    "url": "resources/work_logs/13_10_2024 - 19_10_2024.html",
    "createdDate": "2024-10-13",
    "text": "13/10/2024 - 19/10/2024 13/10/2024 - 19/10/2024 16/10/2024 17:44 Applything the fix detailed in this midas forum post: https://daq00.triumf.ca/elog-midas/Midas/2860 We see a factor of 10 improvement from the previous python based frontend. This is about the same speed as the python backend solution (which is more or less expected).",
    "textLength": 64
  },
  {
    "kind": "work-log",
    "title": "02_03_2025 - 08_03_2025.html",
    "fileName": "02_03_2025 - 08_03_2025.html",
    "url": "resources/work_logs/02_03_2025 - 08_03_2025.html",
    "createdDate": "2025-03-02",
    "text": "02/03/2025 - 08/03/2025 02/03/2025 - 08/03/2025 03/03/2025 06:29 I discovered a strange \"bug\" in the HDSoC. If you never set the channels before taking data like so: readout_controller.attr(\"set_readout_channels\")(py_channels); // Pass the Python list to the function readout_controller. attr ( \"set_readout_channels\" )(py_channels); // Pass the Python list to the function The board will still spit out data, but in a very strange way. All the packets will have the correct structure, but \"later\" in the event the data payload will slowly \"fade\" to zeros. I.e. the first packets in the event look right, but later the data slowly becomes very 0 dominant. The header and trailer information stays correct. Furthermore, at higher window sizes, the timing for the events becomes impossible to form correct events. Regardless, I fixed the bug where I wasn't setting this every time and everything appears to be working as expected. 07/03/2025 08:38 I started a rate test exploring the (external trigger rate, number of channels, number of windows) parameter space. (size(unique rates), size(unique number of channels), size(unique number of windows)) = (101, 6, 7) --> 101\\cdot6\\cdot7 = 4242 101 \u22c5 6 \u22c5 7 = 4242 101\\cdot6\\cdot7 = 4242 101 \u22c5 6 \u22c5 7 = 4242 samples (aka runs). The boundaries of the parameter spaces are rates: [100, 30000] Hz channels: [1,32] windows: [1,62] These spaces are sampled as follow: rates : [100, 150, 200, ..., 1000, 1250, 1500, ..., 10000, 10500, 11000, ..., 30000] (i.e. we move in 20 steps of 50, then 40 steps of 250, then 40 steps of 500) channels: [1,2,4,8,16,32] windows : [1,2,4,8,16,32,62] I use python scripts in /home/pioneer/packages/experiments/atar_daq/scripts/python_sequencer_helpers/ (and some ODB tricks) to sample in this fashion. For each run/sample, I wait 5 seconds before recorded the rate. It takes at least 3 seconds in principle (that's the ODB referesh rate, maybe we can change this somewhere?) but I add 2 seconds just to be safe. The first measurement is very slightly unstable (off by ~1-5% of the requested rate) because of some startup overhead. But this is a price we must pay for speed, otherwise we increase the data taking time. We can conservatively estimate the data taking time as: T = \\text{number of runs} \\cdot 20 \\text{ seconds} T = number of runs \u22c5 20 seconds T = \\text{number of runs} \\cdot 20 \\text{ seconds} T = number of runs \u22c5 20 seconds Because the transition between starting and stopping a run takes some time. More realistically this is probably closer to 10 seconds per run. In any event, our estimate for the total time of this run is T = 4242 \\cdot 20 \\text{ seconds} = 84840 \\text{ seconds} = 0.98 \\text{ days} T = 4242 \u22c5 20 seconds = 84840 seconds = 0.98 days T = 4242 \\cdot 20 \\text{ seconds} = 84840 \\text{ seconds} = 0.98 \\text{ days} T = 4242 \u22c5 20 seconds = 84840 seconds = 0.98 days So it will take about a day to run (assuming no errors). If the sequencer completes, we will show the system is very stable! I'm hopeful. /home/pioneer/packages/experiments/atar_daq/rate_data { \"/Equipment/HDSoC-00/Settings/pwm\": { \"pwm_frequency_hz\": 100, \"pwm_pulse_width_ns\": 10000 }, \"/Equipment/HDSoC-00/Statistics\": { \"Events sent\": 294, \"Events per sec.\": 97.97, \"kBytes per sec.\": 21.945 }, \"/Equipment/HDSoC-00/Settings/nalu_board_controller/nalu_capture\": { \"lookback\": 1, \"lookback_mode\": \"\", \"trigger_mode\": \"ext\", \"windows\": 1, \"write_after_trig\": 1, \"active_channels\": [ 0 ] }, \"/Runinfo\": { \"Run number\": 60, \"Start time\": \"Fri Mar 7 08:28:22 2025\", \"Start time binary\": 1741354102, \"Stop time\": \"Fri Mar 7 08:27:17 2025\", \"Stop time binary\": 0 } } { \"/Equipment/HDSoC-00/Settings/pwm\" : { \"pwm_frequency_hz\" : 100 , \"pwm_pulse_width_ns\" : 10000 }, \"/Equipment/HDSoC-00/Statistics\" : { \"Events sent\" : 294 , \"Events per sec.\" : 97.97 , \"kBytes per sec.\" : 21.945 }, \"/Equipment/HDSoC-00/Settings/nalu_board_controller/nalu_capture\" : { \"lookback\" : 1 , \"lookback_mode\" : \"\" , \"trigger_mode\" : \"ext\" , \"windows\" : 1 , \"write_after_trig\" : 1 , \"active_channels\" : [ 0 ] }, \"/Runinfo\" : { \"Run number\" : 60 , \"Start time\" : \"Fri Mar 7 08:28:22 2025\" , \"Start time binary\" : 1741354102 , \"Stop time\" : \"Fri Mar 7 08:27:17 2025\" , \"Stop time binary\" : 0 } } /home/pioneer/packages/data/atar/userfiles/sequencer/nalu_rate_test.msl ODBCREATE /Sequencer/Helpers/rate_index, UINT8 ODBCREATE /Sequencer/Helpers/num_channels_index, UINT8 ODBCREATE /Sequencer/Helpers/num_windows_index, UINT8 ODBCREATE /Sequencer/Helpers/num_channels, UINT8 LOOP rate_index, 101 ODBSET /Sequencer/Helpers/rate_index, $rate_index SCRIPT /home/pioneer/packages/experiments/atar_daq/scripts/python_sequencer_helpers/get_rate.py rate = $SCRIPT_RESULT ODBSET /Equipment/HDSoC-00/Settings/pwm/pwm_frequency_hz, $rate num_channels = 1 LOOP num_channels_index, 6 ODBSET /Sequencer/Helpers/num_channels_index, $num_channels_index SCRIPT /home/pioneer/packages/experiments/atar_daq/scripts/python_sequencer_helpers/get_num_channels.py num_channels = $SCRIPT_RESULT ODBSET /Sequencer/Helpers/num_channels, $num_channels SCRIPT /home/pioneer/packages/experiments/atar_daq/scripts/python_sequencer_helpers/set_enabled_channels.py num_windows = 1 LOOP num_windows_index, 7 ODBSET /Sequencer/Helpers/num_windows_index, $num_windows_index SCRIPT /home/pioneer/packages/experiments/atar_daq/scripts/python_sequencer_helpers/get_num_windows.py num_windows = $SCRIPT_RESULT ODBSET /Equipment/HDSoC-00/Settings/nalu_board_controller/nalu_capture/lookback, $num_windows ODBSET /Equipment/HDSoC-00/Settings/nalu_board_controller/nalu_capture/write_after_trig, $num_windows ODBSET /Equipment/HDSoC-00/Settings/nalu_board_controller/nalu_capture/windows, $num_windows TRANSITION START WAIT Seconds, 5 SCRIPT /home/pioneer/packages/experiments/atar_daq/scripts/python_sequencer_helpers/save_odb_rate_info.py TRANSITION STOP ENDLOOP ENDLOOP ENDLOOP ODBDELETE /Sequencer/Helpers/rate_index ODBDELETE /Sequencer/Helpers/num_channels_index ODBDELETE /Sequencer/Helpers/num_windows_index ODBDELETE /Sequencer/Helpers/num_channels ODBCREATE /Sequencer/Helpers/rate_index, UINT8 ODBCREATE /Sequencer/Helpers/num_channels_index, UINT8 ODBCREATE /Sequencer/Helpers/num_windows_index, UINT8 ODBCREATE /Sequencer/Helpers/num_channels, UINT8 LOOP rate_index, 101 ODBSET /Sequencer/Helpers/rate_index, $rate_index SCRIPT /home/pioneer/packages/experiments/atar_daq/scripts/python_sequencer_helpers/get_rate.py rate = $SCRIPT_RESULT ODBSET /Equipment/HDSoC-00/Settings/pwm/pwm_frequency_hz, $rate num_channels = 1 LOOP num_channels_index, 6 ODBSET /Sequencer/Helpers/num_channels_index, $num_channels_index SCRIPT /home/pioneer/packages/experiments/atar_daq/scripts/python_sequencer_helpers/get_num_channels.py num_channels = $SCRIPT_RESULT ODBSET /Sequencer/Helpers/num_channels, $num_channels SCRIPT /home/pioneer/packages/experiments/atar_daq/scripts/python_sequencer_helpers/set_enabled_channels.py num_windows = 1 LOOP num_windows_index, 7 ODBSET /Sequencer/Helpers/num_windows_index, $num_windows_index SCRIPT /home/pioneer/packages/experiments/atar_daq/scripts/python_sequencer_helpers/get_num_windows.py num_windows = $SCRIPT_RESULT ODBSET /Equipment/HDSoC-00/Settings/nalu_board_controller/nalu_capture/lookback, $num_windows ODBSET /Equipment/HDSoC-00/Settings/nalu_board_controller/nalu_capture/write_after_trig, $num_windows ODBSET /Equipment/HDSoC-00/Settings/nalu_board_controller/nalu_capture/windows, $num_windows TRANSITION START WAIT Seconds, 5 SCRIPT /home/pioneer/packages/experiments/atar_daq/scripts/python_sequencer_helpers/save_odb_rate_info.py TRANSITION STOP ENDLOOP ENDLOOP ENDLOOP ODBDELETE /Sequencer/Helpers/rate_index ODBDELETE /Sequencer/Helpers/num_channels_index ODBDELETE /Sequencer/Helpers/num_windows_index ODBDELETE /Sequencer/Helpers/num_channels 07/03/2025 23:13 My previous entry had some bad math, here is the corrected entry: I started a rate test exploring the (external trigger rate, number of channels, number of windows) parameter space. (size(unique rates), size(unique number of channels), size(unique number of windows)) = ( 95 , 6, 7) --> 95\\cdot6\\cdot7 = 3990 95 \u22c5 6 \u22c5 7 = 3990 95\\cdot6\\cdot7 = 3990 95 \u22c5 6 \u22c5 7 = 3990 samples (aka runs). The boundaries of the parameter spaces are rates: [100, 30000] Hz channels: [1,32] windows: [1,62] These spaces are sampled as follow: rates : [100, 150, 200, ..., 1000, 1250, 1500, ..., 10000, 10500, 11000, ..., 30000] (i.e. we move in 18 steps of 50, then 36 steps of 250, then 40 steps of 500) channels: [1,2,4,8,16,32] windows : [1,2,4,8,16,32,62] I use python scripts in /home/pioneer/packages/experiments/atar_daq/scripts/python_sequencer_helpers/ (and some ODB tricks) to sample in this fashion. For each run/sample, I wait 5 seconds before recorded the rate. It takes at least 3 seconds in principle (that's the ODB referesh rate, maybe we can change this somewhere?) but I add 2 seconds just to be safe. The first measurement is very slightly unstable (off by ~1-5% of the requested rate) because of some startup overhead. But this is a price we must pay for speed, otherwise we increase the data taking time. We can conservatively estimate the data taking time as: T = \\text{number of runs} \\cdot 20 \\text{ seconds} T = number of runs \u22c5 20 seconds T = \\text{number of runs} \\cdot 20 \\text{ seconds} T = number of runs \u22c5 20 seconds Because the transition between starting and stopping a run takes some time. More realistically this is probably closer to 10 seconds per run. In any event, our estimate for the total time of this run is T = 3990 \\cdot 20 \\text{ seconds} = 79800 \\text{ seconds} = 0.92 \\text{ days} T = 3990 \u22c5 20 seconds = 79800 seconds = 0.92 days T = 3990 \\cdot 20 \\text{ seconds} = 79800 \\text{ seconds} = 0.92 \\text{ days} T = 3990 \u22c5 20 seconds = 79800 seconds = 0.92 days So it will take about a day to run (assuming no errors). If the sequencer completes, we will show the system is very stable! I'm hopeful. /home/pioneer/packages/experiments/atar_daq/rate_data { \"/Equipment/HDSoC-00/Settings/pwm\": { \"pwm_frequency_hz\": 100, \"pwm_pulse_width_ns\": 10000 }, \"/Equipment/HDSoC-00/Statistics\": { \"Events sent\": 294, \"Events per sec.\": 97.97, \"kBytes per sec.\": 21.945 }, \"/Equipment/HDSoC-00/Settings/nalu_board_controller/nalu_capture\": { \"lookback\": 1, \"lookback_mode\": \"\", \"trigger_mode\": \"ext\", \"windows\": 1, \"write_after_trig\": 1, \"active_channels\": [ 0 ] }, \"/Runinfo\": { \"Run number\": 60, \"Start time\": \"Fri Mar 7 08:28:22 2025\", \"Start time binary\": 1741354102, \"Stop time\": \"Fri Mar 7 08:27:17 2025\", \"Stop time binary\": 0 } } { \"/Equipment/HDSoC-00/Settings/pwm\" : { \"pwm_frequency_hz\" : 100 , \"pwm_pulse_width_ns\" : 10000 }, \"/Equipment/HDSoC-00/Statistics\" : { \"Events sent\" : 294 , \"Events per sec.\" : 97.97 , \"kBytes per sec.\" : 21.945 }, \"/Equipment/HDSoC-00/Settings/nalu_board_controller/nalu_capture\" : { \"lookback\" : 1 , \"lookback_mode\" : \"\" , \"trigger_mode\" : \"ext\" , \"windows\" : 1 , \"write_after_trig\" : 1 , \"active_channels\" : [ 0 ] }, \"/Runinfo\" : { \"Run number\" : 60 , \"Start time\" : \"Fri Mar 7 08:28:22 2025\" , \"Start time binary\" : 1741354102 , \"Stop time\" : \"Fri Mar 7 08:27:17 2025\" , \"Stop time binary\" : 0 } } /home/pioneer/packages/data/atar/userfiles/sequencer/nalu_rate_test.msl PARAM start_rate_index, \"Index to start rate at (for continuing failed tests)\", 1 PARAM start_num_channels_index, \"Index to start num_windows at (for continuing failed tests)\", 1 PARAM start_num_windows_index, \"Index to start num_channels at (for continuing failed tests)\", 1 end_rate_index = 95 end_num_channels_index = 6 end_num_windows_index = 7 rate_iterations = $end_rate_index - $start_rate_index num_channels_iterations = $end_num_channels_index - $start_num_channels_index num_windows_iterations = $end_num_windows_index - $start_num_windows_index ODBCREATE /Sequencer/Helpers/rate_index, UINT8 ODBCREATE /Sequencer/Helpers/num_channels_index, UINT8 ODBCREATE /Sequencer/Helpers/num_windows_index, UINT8 ODBCREATE /Sequencer/Helpers/num_channels, UINT8 events_sent = 0 LOOP i, $rate_iterations rate_index = $i + $start_rate_index - 1 ODBSET /Sequencer/Helpers/rate_index, $rate_index SCRIPT /home/pioneer/packages/experiments/atar_daq/scripts/python_sequencer_helpers/get_rate.py rate = $SCRIPT_RESULT ODBSET /Equipment/HDSoC-00/Settings/pwm/pwm_frequency_hz, $rate num_channels = 1 LOOP j, $num_channels_iterations num_channels_index = $j + $start_num_channels_index - 1 ODBSET /Sequencer/Helpers/num_channels_index, $num_channels_index SCRIPT /home/pioneer/packages/experiments/atar_daq/scripts/python_sequencer_helpers/get_num_channels.py num_channels = $SCRIPT_RESULT ODBSET /Sequencer/Helpers/num_channels, $num_channels SCRIPT /home/pioneer/packages/experiments/atar_daq/scripts/python_sequencer_helpers/set_enabled_channels.py num_windows = 1 LOOP k, $num_windows_iterations num_windows_index = $k + $start_num_windows_index - 1 ODBSET /Sequencer/Helpers/num_windows_index, $num_windows_index SCRIPT /home/pioneer/packages/experiments/atar_daq/scripts/python_sequencer_helpers/get_num_windows.py num_windows = $SCRIPT_RESULT ODBSET /Equipment/HDSoC-00/Settings/nalu_board_controller/nalu_capture/lookback, $num_windows ODBSET /Equipment/HDSoC-00/Settings/nalu_board_controller/nalu_capture/write_after_trig, $num_windows ODBSET /Equipment/HDSoC-00/Settings/nalu_board_controller/nalu_capture/windows, $num_windows TRANSITION START WAIT Seconds, 5 ODBGET /Equipment/HDSoC-00/Statistics/Events sent, event_sent IF ($event_sent <= 0) MSG \"Sequencer read 0 events sent, exiting prematurely\" ODBDELETE /Sequencer/Helpers/rate_index ODBDELETE /Sequencer/Helpers/num_channels_index ODBDELETE /Sequencer/Helpers/num_windows_index ODBDELETE /Sequencer/Helpers/num_channels EXIT ENDIF SCRIPT /home/pioneer/packages/experiments/atar_daq/scripts/python_sequencer_helpers/save_odb_rate_info.py TRANSITION STOP ENDLOOP num_windows_iterations = $end_num_windows_index start_num_windows_index = 1 ENDLOOP num_channels_iterations = $end_num_channels_index start_num_channels_index = 1 ENDLOOP num_rate_iterations = $end_rate start_rate_index = 1 ODBDELETE /Sequencer/Helpers/rate_index ODBDELETE /Sequencer/Helpers/num_channels_index ODBDELETE /Sequencer/Helpers/num_windows_index ODBDELETE /Sequencer/Helpers/num_channels PARAM start_rate_index, \"Index to start rate at (for continuing failed tests)\", 1 PARAM start_num_channels_index, \"Index to start num_windows at (for continuing failed tests)\", 1 PARAM start_num_windows_index, \"Index to start num_channels at (for continuing failed tests)\", 1 end_rate_index = 95 end_num_channels_index = 6 end_num_windows_index = 7 rate_iterations = $end_rate_index - $start_rate_index num_channels_iterations = $end_num_channels_index - $start_num_channels_index num_windows_iterations = $end_num_windows_index - $start_num_windows_index ODBCREATE /Sequencer/Helpers/rate_index, UINT8 ODBCREATE /Sequencer/Helpers/num_channels_index, UINT8 ODBCREATE /Sequencer/Helpers/num_windows_index, UINT8 ODBCREATE /Sequencer/Helpers/num_channels, UINT8 events_sent = 0 LOOP i, $rate_iterations rate_index = $i + $start_rate_index - 1 ODBSET /Sequencer/Helpers/rate_index, $rate_index SCRIPT /home/pioneer/packages/experiments/atar_daq/scripts/python_sequencer_helpers/get_rate.py rate = $SCRIPT_RESULT ODBSET /Equipment/HDSoC-00/Settings/pwm/pwm_frequency_hz, $rate num_channels = 1 LOOP j, $num_channels_iterations num_channels_index = $j + $start_num_channels_index - 1 ODBSET /Sequencer/Helpers/num_channels_index, $num_channels_index SCRIPT /home/pioneer/packages/experiments/atar_daq/scripts/python_sequencer_helpers/get_num_channels.py num_channels = $SCRIPT_RESULT ODBSET /Sequencer/Helpers/num_channels, $num_channels SCRIPT /home/pioneer/packages/experiments/atar_daq/scripts/python_sequencer_helpers/set_enabled_channels.py num_windows = 1 LOOP k, $num_windows_iterations num_windows_index = $k + $start_num_windows_index - 1 ODBSET /Sequencer/Helpers/num_windows_index, $num_windows_index SCRIPT /home/pioneer/packages/experiments/atar_daq/scripts/python_sequencer_helpers/get_num_windows.py num_windows = $SCRIPT_RESULT ODBSET /Equipment/HDSoC-00/Settings/nalu_board_controller/nalu_capture/lookback, $num_windows ODBSET /Equipment/HDSoC-00/Settings/nalu_board_controller/nalu_capture/write_after_trig, $num_windows ODBSET /Equipment/HDSoC-00/Settings/nalu_board_controller/nalu_capture/windows, $num_windows TRANSITION START WAIT Seconds, 5 ODBGET /Equipment/HDSoC-00/Statistics/Events sent, event_sent IF ($event_sent <= 0) MSG \"Sequencer read 0 events sent, exiting prematurely\" ODBDELETE /Sequencer/Helpers/rate_index ODBDELETE /Sequencer/Helpers/num_channels_index ODBDELETE /Sequencer/Helpers/num_windows_index ODBDELETE /Sequencer/Helpers/num_channels EXIT ENDIF SCRIPT /home/pioneer/packages/experiments/atar_daq/scripts/python_sequencer_helpers/save_odb_rate_info.py TRANSITION STOP ENDLOOP num_windows_iterations = $end_num_windows_index start_num_windows_index = 1 ENDLOOP num_channels_iterations = $end_num_channels_index start_num_channels_index = 1 ENDLOOP num_rate_iterations = $end_rate start_rate_index = 1 ODBDELETE /Sequencer/Helpers/rate_index ODBDELETE /Sequencer/Helpers/num_channels_index ODBDELETE /Sequencer/Helpers/num_windows_index ODBDELETE /Sequencer/Helpers/num_channels 08/03/2025 03:17 For some reason, my sequencer runs are getting cut short by these errors: 00:55:42.172 2025/03/08 [Sequencer,INFO] Client 'HDSoC00' on database 'ODB' pid 304009 does not exist and db_cleanup2 called by cm_cleanup removed it 00:55:42.172 2025/03/08 [Sequencer,INFO] Client 'HDSoC00' on 'SYSMSG' removed by cm_cleanup (idle 2.2s, timeout 2s) 00:55:42.129 2025/03/08 [Sequencer,ERROR] [midas.cxx:7423:cm_shutdown,ERROR] Killing and Deleting client 'HDSoC00' pid 304009 00:55:42.129 2025/03/08 [Sequencer,ERROR] [midas.cxx:7420:cm_shutdown,ERROR] Cannot connect to client 'HDSoC00' on host 'localhost', port 36979 00:55:42.129 2025/03/08 [Sequencer,ERROR] [midas.cxx:12195:rpc_client_connect,ERROR] timeout waiting for server reply 00:55:42.129 2025/03/08 [Sequencer,ERROR] [midas.cxx:13590:rpc_client_call,ERROR] call to \"HDSoC00\" on \"localhost\" RPC \"rc_transition\": error, ss_recv_net_command() status 411 00:55:42.129 2025/03/08 [Sequencer,ERROR] [system.cxx:5626:ss_recv_net_command,ERROR] error receiving network command header, see messages 00:55:42.129 2025/03/08 [Sequencer,ERROR] [system.cxx:5578:recv_tcp2,ERROR] unexpected connection error, recv() errno 104 (Connection reset by peer) 00:55:42.172 2025/03/08 [Sequencer,INFO] Client 'HDSoC00' on database 'ODB' pid 304009 does not exist and db_cleanup2 called by cm_cleanup removed it 00:55:42.172 2025/03/08 [Sequencer,INFO] Client 'HDSoC00' on 'SYSMSG' removed by cm_cleanup (idle 2.2s, timeout 2s) 00:55:42.129 2025/03/08 [Sequencer,ERROR] [midas.cxx:7423:cm_shutdown,ERROR] Killing and Deleting client 'HDSoC00' pid 304009 00:55:42.129 2025/03/08 [Sequencer,ERROR] [midas.cxx:7420:cm_shutdown,ERROR] Cannot connect to client 'HDSoC00' on host 'localhost', port 36979 00:55:42.129 2025/03/08 [Sequencer,ERROR] [midas.cxx:12195:rpc_client_connect,ERROR] timeout waiting for server reply 00:55:42.129 2025/03/08 [Sequencer,ERROR] [midas.cxx:13590:rpc_client_call,ERROR] call to \"HDSoC00\" on \"localhost\" RPC \"rc_transition\": error, ss_recv_net_command() status 411 00:55:42.129 2025/03/08 [Sequencer,ERROR] [system.cxx:5626:ss_recv_net_command,ERROR] error receiving network command header, see messages 00:55:42.129 2025/03/08 [Sequencer,ERROR] [system.cxx:5578:recv_tcp2,ERROR] unexpected connection error, recv() errno 104 (Connection reset by peer) Which looks like it has nothing to do with my DAQ code... Unsure how to fix this? Maybe there's a memory leak, but that's hard to believe because the whole system would bottleneck if htat's the case, and it looks like the sequencer doesn't ever slow down. 08/03/2025 03:42 I'm wrong, there seems to be something particularly wrong about parameters: (rate (Hz), num_channels, num_windows) = (3250, 16, 62) [INFO] Data capture started successfully. Started run 7670 [WARN] Start marker not found at expected position. ./run.sh: line 74: 450315 Killed \"$EXECUTABLE\" \"${EXEC_ARGS[@]}\" [ INFO ] Data capture started successfully. Started run 7670 [WARN] Start marker not found at expected position. ./run.sh: line 74: 450315 Killed \" $EXECUTABLE \" \" ${EXEC_ARGS[@]} \" This appears to only happen if I start it with the sequencer. I don't even see the start marker warning unless I start with the sequencer. My only theory is somehow the sequencer is messing with the ability to receive UDP data? The debugger gives no help... pioneer@pioneer-MS-7D41:~/packages/experiments/atar_daq/scripts$ ./run.sh --debug Running with debugger (gdb)... GNU gdb (Ubuntu 12.1-0ubuntu1~22.04) 12.1 Copyright (C) 2022 Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html> This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Type \"show copying\" and \"show warranty\" for details. This GDB was configured as \"x86_64-linux-gnu\". Type \"show configuration\" for configuration details. For bug reporting instructions, please see: <https://www.gnu.org/software/gdb/bugs/>. Find the GDB manual and other documentation resources online at: <http://www.gnu.org/software/gdb/documentation/>. For help, type \"help\". Type \"apropos word\" to search for commands related to \"word\"... Reading symbols from /home/pioneer/packages/experiments/atar_daq/scripts/../bin/frontend... (gdb) run Starting program: /home/pioneer/packages/experiments/atar_daq/bin/frontend -i 0 [Thread debugging using libthread_db enabled] Using host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\". Frontend name : HDSoC00 Event buffer size : 671088640 User max event size : 134217728 User max frag. size : 671088640 # of events per buffer : 5 Connect to experiment ATAR_DAQ... OK [New Thread 0x7fffef2ca640 (LWP 459507)] [HDSoC00,INFO] Client 'HDSoC00' on buffer 'SYSTEM' removed by bm_open_buffer because process pid 458746 does not exist Init hardware... [DEBUG] Initializing Python interpreter... [DEBUG] Python interpreter initialized. [DEBUG] Importing 'naludaq.board' module... [New Thread 0x7fffe39ff640 (LWP 459508)] [New Thread 0x7fffe31fe640 (LWP 459509)] [New Thread 0x7fffde9fd640 (LWP 459510)] [New Thread 0x7fffde1fc640 (LWP 459511)] [New Thread 0x7fffdb9fb640 (LWP 459512)] [New Thread 0x7fffd91fa640 (LWP 459513)] [New Thread 0x7fffd49f9640 (LWP 459514)] [New Thread 0x7fffd41f8640 (LWP 459515)] [New Thread 0x7fffd19f7640 (LWP 459516)] [New Thread 0x7fffcd1f6640 (LWP 459517)] [New Thread 0x7fffcc9f5640 (LWP 459518)] [New Thread 0x7fffc81f4640 (LWP 459519)] [New Thread 0x7fffc79f3640 (LWP 459520)] [New Thread 0x7fffc51f2640 (LWP 459521)] [New Thread 0x7fffc09f1640 (LWP 459522)] [New Thread 0x7fffbe1f0640 (LWP 459523)] [New Thread 0x7fffbd9ef640 (LWP 459524)] [New Thread 0x7fffb91ee640 (LWP 459525)] [New Thread 0x7fffb89ed640 (LWP 459526)] [New Thread 0x7fffb41ec640 (LWP 459527)] [New Thread 0x7fffb19eb640 (LWP 459528)] [New Thread 0x7fffb11ea640 (LWP 459529)] [New Thread 0x7fffac9e9640 (LWP 459530)] [New Thread 0x7fffa9a8f640 (LWP 459531)] [New Thread 0x7fffa928e640 (LWP 459532)] D3XX import failed: Support for USB 3 on Linux is unavailable [New Thread 0x7fffa89c2640 (LWP 459533)] [New Thread 0x7fffa2851640 (LWP 459534)] [Detaching after vfork from child process 459535] [DEBUG] 'naludaq.board' module imported. [DEBUG] Creating board object... [DEBUG] Board object created. [DEBUG] Getting UDP connection... [DEBUG] UDP connection established. [DEBUG] Resetting board... [DEBUG] Board reset. [DEBUG] Initializing control registers... [DEBUG] Control registers initialized. [DEBUG] Importing 'naludaq.tools.data_collector'... [DEBUG] Getting trigger controller... [DEBUG] Starting up board... [DEBUG] Disconnecting board... [INFO] Board initialization complete. Connected to /dev/ttyACM0 OK [DEBUG] NaluUdpReceiver initialized with address: 192.168.1.1 and port: 12345 [DEBUG] NaluUdpReceiver initialized with parameters from NaluUdpReceiverParams. [DEBUG] NaluEventCollector created. [DEBUG] Starting NaluUdpReceiver... [New Thread 0x7fffa09bc640 (LWP 459747)] [DEBUG] Receiver started. [DEBUG] Capture parameters initialized. [DEBUG] Readout window set: windows=62, lookback=62, write_after_trig=62 [DEBUG] Importing naludaq.controllers... [DEBUG] Retrieving connection controller... [DEBUG] Initializing socket... [DEBUG] Establishing UDP connection between board and host... [DEBUG] Socket initialization completed. [DEBUG] Retrieving readout controller... [DEBUG] Checking if readout channels are provided... [DEBUG] Setting readout channels... [DEBUG] Activating channels: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15] [DEBUG] Configuring readout window... [DEBUG] Setting receiver address to 192.168.1.1:12345 [DEBUG] Configuring Ethernet settings... [DEBUG] Retrieving board controller... [DEBUG] Starting readout with trigger_mode=ext and lookback_mode= [INFO] Data capture started successfully. Started run 7679 [WARN] Start marker not found at expected position. [WARN] Start marker not found at expected position. [WARN] Start marker not found at expected position. [WARN] Start marker not found at expected position. [WARN] Start marker not found at expected position. [WARN] Start marker not found at expected position. [WARN] Start marker not found at expected position. [WARN] Start marker not found at expected position. [WARN] Start marker not found at expected position. [WARN] Start marker not found at expected position. [WARN] Start marker not found at expected position. [WARN] Start marker not found at expected position. [Thread 0x7fffa09bc640 (LWP 459747) exited] [Thread 0x7fffa2851640 (LWP 459534) exited] [Thread 0x7fffa89c2640 (LWP 459533) exited] [Thread 0x7fffa928e640 (LWP 459532) exited] [Thread 0x7fffa9a8f640 (LWP 459531) exited] [Thread 0x7fffac9e9640 (LWP 459530) exited] [Thread 0x7fffb11ea640 (LWP 459529) exited] [Thread 0x7fffb19eb640 (LWP 459528) exited] [Thread 0x7fffb41ec640 (LWP 459527) exited] [Thread 0x7fffb89ed640 (LWP 459526) exited] [Thread 0x7fffb91ee640 (LWP 459525) exited] [Thread 0x7fffbd9ef640 (LWP 459524) exited] [Thread 0x7fffbe1f0640 (LWP 459523) exited] [Thread 0x7fffc09f1640 (LWP 459522) exited] [Thread 0x7fffc51f2640 (LWP 459521) exited] [Thread 0x7fffc79f3640 (LWP 459520) exited] [Thread 0x7fffc81f4640 (LWP 459519) exited] [Thread 0x7fffcc9f5640 (LWP 459518) exited] [Thread 0x7fffcd1f6640 (LWP 459517) exited] [Thread 0x7fffd19f7640 (LWP 459516) exited] [Thread 0x7fffd41f8640 (LWP 459515) exited] [Thread 0x7fffd49f9640 (LWP 459514) exited] [Thread 0x7fffd91fa640 (LWP 459513) exited] [Thread 0x7fffdb9fb640 (LWP 459512) exited] [Thread 0x7fffde1fc640 (LWP 459511) exited] [Thread 0x7fffde9fd640 (LWP 459510) exited] [Thread 0x7fffe31fe640 (LWP 459509) exited] [Thread 0x7fffe39ff640 (LWP 459508) exited] [Thread 0x7fffef2ca640 (LWP 459507) exited] Program terminated with signal SIGKILL, Killed. The program no longer exists. (gdb) backtrace No stack. (gdb) pioneer@pioneer-MS-7D41:~/packages/experiments/atar_daq/scripts$ ./run.sh --debug Running with debugger (gdb)... GNU gdb (Ubuntu 12.1-0ubuntu1~22.04) 12.1 Copyright (C) 2022 Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html> This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Type \"show copying\" and \"show warranty\" for details. This GDB was configured as \"x86_64-linux-gnu\". Type \"show configuration\" for configuration details. For bug reporting instructions, please see: <https://www.gnu.org/software/gdb/bugs/>. Find the GDB manual and other documentation resources online at: <http://www.gnu.org/software/gdb/documentation/>. For help, type \"help\". Type \"apropos word\" to search for commands related to \"word\"... Reading symbols from /home/pioneer/packages/experiments/atar_daq/scripts/../bin/frontend... (gdb) run Starting program: /home/pioneer/packages/experiments/atar_daq/bin/frontend -i 0 [Thread debugging using libthread_db enabled] Using host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\". Frontend name : HDSoC00 Event buffer size : 671088640 User max event size : 134217728 User max frag. size : 671088640 # of events per buffer : 5 Connect to experiment ATAR_DAQ... OK [New Thread 0x7fffef2ca640 (LWP 459507)] [HDSoC00,INFO] Client 'HDSoC00' on buffer 'SYSTEM' removed by bm_open_buffer because process pid 458746 does not exist Init hardware... [DEBUG] Initializing Python interpreter... [DEBUG] Python interpreter initialized. [DEBUG] Importing 'naludaq.board' module... [New Thread 0x7fffe39ff640 (LWP 459508)] [New Thread 0x7fffe31fe640 (LWP 459509)] [New Thread 0x7fffde9fd640 (LWP 459510)] [New Thread 0x7fffde1fc640 (LWP 459511)] [New Thread 0x7fffdb9fb640 (LWP 459512)] [New Thread 0x7fffd91fa640 (LWP 459513)] [New Thread 0x7fffd49f9640 (LWP 459514)] [New Thread 0x7fffd41f8640 (LWP 459515)] [New Thread 0x7fffd19f7640 (LWP 459516)] [New Thread 0x7fffcd1f6640 (LWP 459517)] [New Thread 0x7fffcc9f5640 (LWP 459518)] [New Thread 0x7fffc81f4640 (LWP 459519)] [New Thread 0x7fffc79f3640 (LWP 459520)] [New Thread 0x7fffc51f2640 (LWP 459521)] [New Thread 0x7fffc09f1640 (LWP 459522)] [New Thread 0x7fffbe1f0640 (LWP 459523)] [New Thread 0x7fffbd9ef640 (LWP 459524)] [New Thread 0x7fffb91ee640 (LWP 459525)] [New Thread 0x7fffb89ed640 (LWP 459526)] [New Thread 0x7fffb41ec640 (LWP 459527)] [New Thread 0x7fffb19eb640 (LWP 459528)] [New Thread 0x7fffb11ea640 (LWP 459529)] [New Thread 0x7fffac9e9640 (LWP 459530)] [New Thread 0x7fffa9a8f640 (LWP 459531)] [New Thread 0x7fffa928e640 (LWP 459532)] D3XX import failed: Support for USB 3 on Linux is unavailable [New Thread 0x7fffa89c2640 (LWP 459533)] [New Thread 0x7fffa2851640 (LWP 459534)] [Detaching after vfork from child process 459535] [DEBUG] 'naludaq.board' module imported. [DEBUG] Creating board object... [DEBUG] Board object created. [DEBUG] Getting UDP connection... [DEBUG] UDP connection established. [DEBUG] Resetting board... [DEBUG] Board reset. [DEBUG] Initializing control registers... [DEBUG] Control registers initialized. [DEBUG] Importing 'naludaq.tools.data_collector'... [DEBUG] Getting trigger controller... [DEBUG] Starting up board... [DEBUG] Disconnecting board... [INFO] Board initialization complete. Connected to /dev/ttyACM0 OK [DEBUG] NaluUdpReceiver initialized with address: 192.168.1.1 and port: 12345 [DEBUG] NaluUdpReceiver initialized with parameters from NaluUdpReceiverParams. [DEBUG] NaluEventCollector created. [DEBUG] Starting NaluUdpReceiver... [New Thread 0x7fffa09bc640 (LWP 459747)] [DEBUG] Receiver started. [DEBUG] Capture parameters initialized. [DEBUG] Readout window set: windows=62, lookback=62, write_after_trig=62 [DEBUG] Importing naludaq.controllers... [DEBUG] Retrieving connection controller... [DEBUG] Initializing socket... [DEBUG] Establishing UDP connection between board and host... [DEBUG] Socket initialization completed. [DEBUG] Retrieving readout controller... [DEBUG] Checking if readout channels are provided... [DEBUG] Setting readout channels... [DEBUG] Activating channels: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15] [DEBUG] Configuring readout window... [DEBUG] Setting receiver address to 192.168.1.1:12345 [DEBUG] Configuring Ethernet settings... [DEBUG] Retrieving board controller... [DEBUG] Starting readout with trigger_mode=ext and lookback_mode= [INFO] Data capture started successfully. Started run 7679 [WARN] Start marker not found at expected position. [WARN] Start marker not found at expected position. [WARN] Start marker not found at expected position. [WARN] Start marker not found at expected position. [WARN] Start marker not found at expected position. [WARN] Start marker not found at expected position. [WARN] Start marker not found at expected position. [WARN] Start marker not found at expected position. [WARN] Start marker not found at expected position. [WARN] Start marker not found at expected position. [WARN] Start marker not found at expected position. [WARN] Start marker not found at expected position. [Thread 0x7fffa09bc640 (LWP 459747) exited] [Thread 0x7fffa2851640 (LWP 459534) exited] [Thread 0x7fffa89c2640 (LWP 459533) exited] [Thread 0x7fffa928e640 (LWP 459532) exited] [Thread 0x7fffa9a8f640 (LWP 459531) exited] [Thread 0x7fffac9e9640 (LWP 459530) exited] [Thread 0x7fffb11ea640 (LWP 459529) exited] [Thread 0x7fffb19eb640 (LWP 459528) exited] [Thread 0x7fffb41ec640 (LWP 459527) exited] [Thread 0x7fffb89ed640 (LWP 459526) exited] [Thread 0x7fffb91ee640 (LWP 459525) exited] [Thread 0x7fffbd9ef640 (LWP 459524) exited] [Thread 0x7fffbe1f0640 (LWP 459523) exited] [Thread 0x7fffc09f1640 (LWP 459522) exited] [Thread 0x7fffc51f2640 (LWP 459521) exited] [Thread 0x7fffc79f3640 (LWP 459520) exited] [Thread 0x7fffc81f4640 (LWP 459519) exited] [Thread 0x7fffcc9f5640 (LWP 459518) exited] [Thread 0x7fffcd1f6640 (LWP 459517) exited] [Thread 0x7fffd19f7640 (LWP 459516) exited] [Thread 0x7fffd41f8640 (LWP 459515) exited] [Thread 0x7fffd49f9640 (LWP 459514) exited] [Thread 0x7fffd91fa640 (LWP 459513) exited] [Thread 0x7fffdb9fb640 (LWP 459512) exited] [Thread 0x7fffde1fc640 (LWP 459511) exited] [Thread 0x7fffde9fd640 (LWP 459510) exited] [Thread 0x7fffe31fe640 (LWP 459509) exited] [Thread 0x7fffe39ff640 (LWP 459508) exited] [Thread 0x7fffef2ca640 (LWP 459507) exited] Program terminated with signal SIGKILL, Killed. The program no longer exists. (gdb) backtrace No stack. (gdb) 08/03/2025 04:38 It seems the problem is that the fontend for some reason consumes the entirety of the system RAM, causing it to terminte itself: Again, this only happens with the sequencer. I.e. running the frontend with parameters (rate (Hz), num_channels, num_windows) = (3250, 16, 62) by hand will not crash it. Furthermore, running with parameters (rate (Hz), num_channels, num_windows) = (3250, 16, 32) with the sequencer will not crash it, and I see not such memory rising. Furthmore, (rate (Hz), num_channels, num_windows) = (3250, 32, 62) to (3250, 32, 62) had no such memory or crashing issues. I have absolutely no idea why this is happening. Things it shouldn't be: Rate bottleneck: Counter-point: (3250, 32, 62) has twice the rate but worked fine UDP bottleneck: Counter-point: The UDP buffer has a max buffer size, it would error out before this happens RP Pico Bug: *Counter-point: *the rate parameter is the only RP pico parameter here, and it worked just fine for all other 3250 Hz samples Anything to do with my libraries alone: Counter-point: it works when I run the same parameters without the sequencer 08/03/2025 05:03 My only idea to get around this is say \"screw the sequencer\" and just write a midas frontend that will do what the sequencer does. I.e. 1 continous run, but we pause to change parameters every so often.",
    "textLength": 4626
  },
  {
    "kind": "work-log",
    "title": "16_06_2024 - 22_06_2024.html",
    "fileName": "16_06_2024 - 22_06_2024.html",
    "url": "resources/work_logs/16_06_2024 - 22_06_2024.html",
    "createdDate": "2024-06-16",
    "text": "16/06/2024 - 22/06/2024 16/06/2024 - 22/06/2024 21/06/2024 18:12 On CENPA DAQ: Made cpu_stress.sh #!/bin/bash # Function to keep the CPU core busy cpu_stress() { while true; do : # do nothing, just hog CPU done } # Start the CPU stress function in the background cpu_stress & #!/bin/bash # Function to keep the CPU core busy cpu_stress () { while true ; do : # do nothing, just hog CPU done } # Start the CPU stress function in the background cpu_stress & and cpu_stress_mdump.sh #!/bin/bash # Function to keep the CPU core busy cpu_stress() { while true; do $MIDASSYS/bin/mdump -z BUF00 done } # Start the CPU stress function in the background cpu_stress & #!/bin/bash # Function to keep the CPU core busy cpu_stress () { while true ; do $MIDASSYS /bin/mdump -z BUF00 done } # Start the CPU stress function in the background cpu_stress & cpu_stress_pi.sh #!/bin/bash # Function to keep the CPU core busy cpu_stress() { while true; do # Perform a computational task to keep the CPU busy echo \"scale=5000; 4*a(1)\" | bc -l -q > /dev/null done } # Start the CPU stress function in the background cpu_stress & #!/bin/bash # Function to keep the CPU core busy cpu_stress () { while true ; do # Perform a computational task to keep the CPU busy echo \"scale=5000; 4*a(1)\" | bc -l -q > /dev/null done } # Start the CPU stress function in the background cpu_stress & 1 copy of: cpu_stress_mdump.sh causes crash at 5kHz. cpu_stress_mdump.sh did not causes crash at 2kHz. 1 copy of: publisher did causes crash at 2kHz. publisher did not causes crash at 1kHz. 1 copy of: cpu_stress.sh did not cause a crash at 5kHz 6 copies of cpu_stress.sh cpu_stress.sh did cause a crash at 1kHz(?) 1 copy of: cpu_stress_pi.sh did not cause a crash at 5kHz 21/06/2024 18:38 Note: For second crate at UKY { \"CCC: FMC SFP Number (1-8)/key\": { \"type\": 7, \"access_mode\": 7, \"last_written\": 1719020320 }, \"CCC: FMC SFP Number (1-8)\": 3 } { \"CCC: FMC SFP Number (1-8)/key\" : { \"type\" : 7 , \"access_mode\" : 7 , \"last_written\" : 1719020320 } , \"CCC: FMC SFP Number (1-8)\" : 3 }",
    "textLength": 347
  },
  {
    "kind": "presentation",
    "title": "Hyperparameters, Optuna, General ML notes_2025-12-12_19-41-04.pdf",
    "fileName": "Hyperparameters, Optuna, General ML notes_2025-12-12_19-41-04.pdf",
    "url": "resources/presentations/Hyperparameters, Optuna, General ML notes_2025-12-12_19-41-04.pdf",
    "createdDate": "2025-12-12",
    "text": "Hyperparameters and Optuna Jack Carlton University of Kentucky What are Hyperparameters \u25cf\u201cA Hyperparameter is a parameter that can be set in order to define any configurable part of a model's learning process\u201d \u25cbThese are parameters that are not learned by the model \u25cbChosen before the model is trained \u25cfExamples of what they control \u25cbOptimization dynamics (learning rate, batch size, optimizer) \u25cbModel capacity (hidden size, depth, heads) \u25cbRegularization (dropout, weight decay) Example: Fitting data with a polynomial. The degree of the polynomial, d, is a hyperparameter Hyperparameters Need to be Tuned Appropriately \u25cfImproper hyperparameter choices can lead to \u25cbOvertraining \u25cbSlower convergence \u25cbVanishing or exploding gradients \u25a0Impossible to find true solution at this point \u25cfTuning hyperparameters can be hard \u25cbThey interact with each other (often non-linearly) \u25cbOptimal choice varies with each dataset/model Example: Moving average window size is a hyperparameter. It can be over, or under tuned. Hyperparameters for Neural Networks Hyperparameters (Batch Size) \u25cfMore detail in this article \u25cfBatch size is how many training data points are processed before updating the model \u25cbMakes predictions on batch, uses error to inform gradient descent algorithm \u25cfLarger batch size \u25cbMore accurate gradient descent \u25cbFewer updates per epoch \u25cbLess noisy gradient \u25cbLess general, can get stuck in local minima \u25cfSmall batch size \u25cbLess accurate gradient descent \u25cbMore updates per epoch \u25cbNoiser gradient \u25cbCan escape local minima Hyperparameters (Learning Rate) \u25cfMore detail in this article \u25cfLearning Rate controls how large each parameter update is in the direction of the gradient \u25cfLarger learning rate: \u25cb Bigger, more exploratory steps \u25cb Less likely to get stuck in local minima \u25cb Harder to settle precisely at the optimum \u25cfSmaller learning rate: \u25cb Smaller, more precise steps \u25cb More likely to get trapped in local minima \u25cb Better at fine-tuning near the optimum Hyperparameters (Dropout) \u25cfMore detail in this article \u25cfDropout randomly disables a fraction of activations during training to reduce overfitting \u25cfHigher dropout: \u25cbBetter for noisy datasets \u25cbLess risk of overfitting \u25cbHigher risk of underfitting \u25cfLower dropout: \u25cbBetter for less noisy datasets \u25cbLess risk of underfitting \u25cbHigher risk of overfitting Hyperparameters (Hidden dim) \u25cfMore detail in this article \u25cfHidden dimension sets the size of the model\u2019s internal feature representations at each layer. \u25cfLarger hidden dim: \u25cbCan represent more complex patterns \u25cbHigher risk of overfitting \u25cbHigher memory and compute cost \u25cfSmaller hidden dim: \u25cbLimited ability to model complex patterns \u25cbLower risk of overfitting \u25cbLower memory/compute cost Hyperparameters (# of layers) \u25cfMore detail in this article \u25cfHidden dimension sets the size of the model\u2019s internal feature representations at each layer. \u25cfMore layers: \u25cbLearns more \u201chierarchical\u201d/ \u201cabstract\u201d features \u25cbHigher risk of overfitting or training instability (higher loss fluctuations) \u25cbHigher memory and compute cost \u25cfLess layers: \u25cbLearns \u201csimpler\u201d/\u201cshallow\u201d features \u25cbLower risk of overfitting \u25cbLower memory/compute cost Hyperparameters (weight decay) \u25cfMore detail in this article \u25cfWeight decay adds a penalty on large weights to the loss, encouraging simpler models. Similar to dropout. \u25cfHigher weight Decay: \u25cbBetter for noisy datasets, stronger regularization \u25cbLower risk of overfitting \u25cbHigher risk of underfitting \u25cfLower weight decay: \u25cbBetter for less noisy datasets, less regularization \u25cbLower risk of underfitting \u25cbHigher risk of overfitting Hyperparameters (# of attention heads) \u25cfMore detail in this article \u25cfThe number of attention heads controls how many independent subspaces the model attends to in parallel within each attention layer \u25cfMore attention heads: \u25cb Learns multiple attention patterns in parallel \u25cb Higher memory/compute cost \u25cb Diminishing returns if per-head dimension is too small \u25cb Can overfit and destabilize training \u25cfFewer attention heads: \u25cb Learns fewer attention patterns \u25cb Lower memory/compute cost \u25cb May miss distinct relationships \u25cb Can underfit if data is very heterogeneous Hyperparameters (activation functions) \u25cfMore detail in this article \u25cfThe activation function controls the nonlinearity applied at each layer Examples: \u25cfReLU \u25cbSimple, piecewise-linear activation \u25cbFast training; can form sharp, noisy boundaries \u25cfTanh \u25cbSmooth, bounded activation \u25cbProduces smoother boundaries; may saturate \u25cfGELU \u25cbSmooth, probabilistic gating \u25cbBalances smoothness and expressiveness Hyperparameters (optimizers) \u25cfMore detail in this article \u25cfOptimizers control how gradients are transformed into parameter updates during training Examples: \u25cfStochastic Gradient Descent (SGD) with momentum \u25cb Simple, stable updates \u25cb Often performs well on unseen data, not just the training set \u25cb Sensitive to learning rate and scaling \u25cfAdaptive Moment Estimation (Adam) \u25cb Adaptive learning rates per parameter \u25cb Fast convergence, less sensitive to hyperparameter choice \u25cb Can overfit or generalize worse than SGD \u25cfAdamW \u25cb Adam with decoupled weight decay \u25cb More reliable regularization behavior \u25cb Standard choice for modern deep models Optuna What is Optuna? \u25cfMany hyper parameters means manual tuning is bad \u25cbToo slow \u25cbSuboptimal tuning means you spend more resources (time, computing power, etc.) training unused models \u25cfOptuna is a python package that solves this problem \u25cbFramework for optimization black box objective functions \u25cbTechnically not an ML package, but rather a package that supports many optimized sampling strategies Example Optuna workflow diagram How Optuna Works \u25cfOptuna supports many sampling algorithms , examples: \u25cbGrid search \u25cbRandom search \u25cbGaussian process-based Bayesian optimization \u25cfFor single object functions, the default for Optuna is Tree-S tructured Parzen Estimator (TPE) TPE flow diagram (in a nutshell) Optuna in Practice \u25cfIn practice, Optuna abstracts away all the details: 1.Define object, return the loss 2.Inside the objective, define hyper parameters to optimize with ranges and suggestions for how to optimize 3.Return the object to minimize (or maximize) 4.Run the study \u25cfOptuna will handle storing the history, optimizing the search, etc. Example code to run an optuna study Auxiliary Slides Example Notebooks \u25cfMost plots in this presentation were generated using some interact jupyter notebooks I made \u25cfIn these notebooks, one can change parameters to \u201cplay around\u201d and better visualize the effects of each hyperparameter \u25cfSee github repo Backpropagation (Overview) \u25cfMuch more detail in this article , and wikipedia \u25cfBackpropagation computes gradients of the loss with respect to all model parameters by applying the chain rule backward through the network \u25cfCompute the gradient of the loss in the space of weights \u25cbOptimal weight updates for the next iteration Backpropagation (Explicit, Part I) \u25cfDiagram with some labels to conceptualize the variables Backpropagation (Explicit, Part II) \u25cfEquations for how to update weights from back propagation 1. Backpropagate activation gradients: 2. Weight gradient via local chain rule: 3. Gradient descent update to weights: Backpropagation (Explicit, Part III) \u25cfThe back propagation step is a recursive step The backpropagation step: This formula is recursive, so for N layers you have explicitly: Or more commonly you can write in Jacobian form, which cleans up the notation Backpropagation (Explicit, Part IV) \u25cfThe actual values of xl,i are architecture dependent \u25cfIn this simple example, you can compute them by defining a bias and activation function (eg. softmax) We can define zl,i for the raw computed \u201cresponse\u201d from the previous layer: Then we apply some activation, usually to constrain values between 0 and 1 to prevent exponential blowup. This allows to (finally) formally compute all needed partial derivatives: Hyperparameters (Gradient Descents) \u25cfMuch more detail in this article \u25cfBatch Gradient Descent (BGD): \u25cbUses the entire dataset in one iteration. The batch size is equal to the total number of training samples. \u25cfMini-Batch Gradient Descent (MBGD): \u25cbUses a predefined number of samples from the dataset for each update. This method lies between batch and stochastic gradient descent (SGD). \u25cfStochastic Gradient Descent (SGD): \u25cbProcesses only one sample at a time for each update, making the batch size equal to 1. Hyperparameters (why are more layers harder to train) \u25cfMore layers \u2192 more loss instability \u25cb Due to back propagation \u25cb The size of your step becomes more \u201cuntrainable\u201d the more layers you add \u25cfCases: \u25cb \u03bb \u2248 1 \u25a0 Gradients stable as model layers increase \u25cb \u03bb < 1 \u25a0 Gradients vanish as model layers increase \u25a0 No more learning occurs! \u25cb \u03bb > 1 \u25a0 Gradients blow up as model layers increase \u25a0 Cannot converge on solution \u25cfOne goal of model architecture choice is to get \u03bb \u2248 1 What is a Tree-Structured Parzen Estimator (TPE) (Part I) \u25cfGiven a (possibly stochastic) black box function you want to minimize (ex. model loss) \u25cfHyperparams \u2261 \u03b8 \u25cfDefine the following: \u25cfThen, for any given theta we can define expected improvement \u25cfGoal: Maximize expected improvement Note: See paper on arxiv What is a Tree-Structured Parzen Estimator (TPE) (Part II) \u25cfFor a 1 dimensional y, it turns out to be easier to work with , we can invert using Bayes\u2019 rule: \u25cfAnd substitute \u25cfSince we don\u2019t know every value of y this becomes an impossible task. We must make an approximation by dividing into \u201cgood\u201d and \u201cbad\u201d distributions Note: See paper on arxiv What is a Tree-Structured Parzen Estimator (TPE) (Part III) \u25cfThe integral, by construction, only cares about the \u201cgood\u201d region, so the integral simplifies to \u25cfBut the integral is now constant in theta! So we have: \u25cfWhere so we can write: Note: See paper on arxiv What is a Tree-Structured Parzen Estimator (TPE) (Part IV) \u25cfBut \u03b3 is fixed, so \u25cfWhere the final step is because x/(bx+c) is monotonic in x for x >0 ,let x = l/g \u25cfIn other words, we just need to find which is doable via algorithm! Note: See paper on arxiv What is a Tree-Structured Parzen Estimator (TPE) (Part V) \u25cfNow to define the algorithm, first we observe T (~10) trials randomly: \u25cfFrom this data, we want to build: \u25cfSo we define \u25cfAnd assume: Note: See paper on arxiv What is a Tree-Structured Parzen Estimator (TPE) (Part VI) \u25cfThis allows us to write: \u25cfWe can fit to our samples to get a continuous distribution spaces for each param \u25cfThen we sample from the \u201cgood\u201d spaces for M candidates index by m \u25cfAnd finally, choose our next theta, add it to the data set, and repeat Note: See paper on arxiv What is a Tree-Structured Parzen Estimator (TPE) (Part VII) \u25cfHow do we obtain our fits from the data? \u25cfUses Kernel Density Estimation (KDE) \u25cbThe actual fit is done when determining each \u201cgaussian kernel\u201d (or sigma) \u25cbLikelihood-optimal is expensive ~O(n2d) \u25a0n = # samples \u25a0d = # hyperparameters \u25cbOptuna uses the \u201cheuristic\u201d version, which requires choosing some value for c. Note: See paper on arxiv",
    "textLength": 1660
  },
  {
    "kind": "presentation",
    "title": "DAQ Introduciton Collaboration Meeting June 2024_2024-05-28_21-22-49.pdf",
    "fileName": "DAQ Introduciton Collaboration Meeting June 2024_2024-05-28_21-22-49.pdf",
    "url": "resources/presentations/DAQ Introduciton Collaboration Meeting June 2024_2024-05-28_21-22-49.pdf",
    "createdDate": "2024-05-28",
    "text": "DAQ Introduction Jack Carlton University of Kentucky What is Data Acquisition (DAQ)? \u25cf\u201cDAQ\u201d refers to the system of electronics used to convert analog signals from an experiment and package them into digital \u201cevents\u201d \u25cbUsually \u201cDAQ\u201d refers to the \u201csoftware side\u201d, but sometimes refers to hardware as well \u25cbHardware side also called \u201celectronics\u201d \u25cfI like to differentiate between the software and hardware sides Digitizers & trigger processors ...Array of readout computers, Midas server ... Detectors Hardware Side Software Side j.carlton@uky.edu 1/15 Proposed Data Acquisition (DAQ) Framework arXiv:2203.05505 Citation: Testing Lepton Flavor Universality and CKM Unitarity with Rare Pion Decays in the PIONEER experiment, PIONEER collab (pg. 20, arxiv: 2203.05505) Hardware Side SW Side j.carlton@uky.edu 2/15 Proposed Data Acquisition (DAQ) Framework arXiv:2203.05505 Citation: Testing Lepton Flavor Universality and CKM Unitarity with Rare Pion Decays in the PIONEER experiment, PIONEER collab (pg. 21) Software Side Receive Data over PCIe Build events in Midas \u201cNearline\u201d Tools j.carlton@uky.edu 3/15 Data Rates arXiv:2203.01981 \u25cfPIONEER DAQ expects data rate of ~ 3.5GB/s \u25cfThis is ~ 100,000 TB/year \u25cfHow do we compress this in real time? (Not in this talk) \u25cbFit data, store fit parameters \u25cbCompress and store residuals, throw some out \u25cbGraphics Processing Units (GPUs) used for this operation Citation: PSI Ring Cyclotron Proposal R-22-01.1 PIONEER: Studies of Rare Pion Decays, PIONEER collab (pg. 33) j.carlton@uky.edu 4/15 Our Two DAQs \u25cfg-2 modified DAQ \u25cbModified for various experiments across the collaboration (test beam, LXe testing, LYSO testing, \u2026) \u25cfPIONEER DAQ \u25cbIn nascent development state \u25cbDesign catered to PIONEER full experiment necessities UKY test stand MicroTCA crates PIONEER ADC schematic drawings Citation: DAQ electronics status, Lawrence Gibbons (Slide 1) https://pioneer.npl.washington.edu/cgi-bin/private/ShowDocument?docid=245 j.carlton@uky.edu 5/15 What is a Field Programmable Gate Array (FPGA)? \u25cfCommonly used for real time data processing \u25cfProgrammable \u25cbTypically use a software tool called Vivado \u25cbTypically programmed using Verilog or VHDL \u25cbUse low-level software called \u201cfirmware\u201d \u25cfAllows for fast, flexible control of logic signals to board components \u25cfBuilding block in almost all of our hardware (WFD5s, FC7s, AMC13s) A Xilinx Development Board with a XC6LX45T FPGA (Spartan-6) This is the FPGA j.carlton@uky.edu 6/15 Teststand DAQ Hardware (Modified g-2 DAQ) \u25cfDifferential signal into WFD5 (Waveform Digitizer) \u25cfTrigger signal into FC7 (Flexible Controller) \u25cfAMC13 (Advanced Mezzanine Card) gathers data, sends over 10GbE (10 Gigabit Ethernet) to desktop \u25cfMCH (MicroTCA Carrier Hub) facilitates Desktop\u2194Crate communication over 1GbE \u25cfDesktop CPU handles event processing \u25cfMeinberg gives trigger timestamp to computer Differential Signal(s) Trigger WFD5(s) FC7 AMC13(s) MCH Desktop Ribbon Cable Optical Pentabus Cable Crate Optical Crate Crate Crate 1GbE Ethernet Red - Data Blue - Trigger Gray - Control Crate Bank Meinberg SMA SMA to D9 To storage Crate components PCIe j.carlton@uky.edu 7/15 Teststand DAQ Hardware (Modified g-2 DAQ) j.carlton@uky.edu 8/15 Teststand DAQ Hardware (Modified g-2 DAQ) 10GbE out (data) AMC13\u2192desktop Trigger in AMC13 Trigger out FC7 1GbE MCH in/out (comm.) FC7 Trigger in WFD5 5-channel, differential signal in (no connection in this picture) WFD5s M C HA M C 1 3 F C 7Note: AMC13 and MCH are half slot modules W F D 5W F D 5Crate Power Supply j.carlton@uky.edu 8/15 PIONEER DAQ Hardware (In a Nascent State) \u25cfUsing APOLLO system (no more \u00b5TCA crates) \u25cfData is moved using \u201cFirefly\u201d optical flyover system \u25cb25 gb/s > 10gb/s links from g-2 \u25cfData received by desktop through Firefly PCIe cards Firefly PCIe board Citation: DAQ backbone exploration, Lawrence Gibbons https://pioneer.npl.washington.edu/docdb/0000/000023/001/apollo.pdf j.carlton@uky.edu 9/15 Midas Framework \u25cfC/C++ (mostly) package of modules for \u25cbrun control, \u25cbexpt. configuration \u25cbdata readout \u25cbevent building \u25cbdata storage \u25cbslow control \u25cbalarm systems \u25cbEtc. \u25cfCan link with custom software Example g-2 Midas Webpage j.carlton@uky.edu 10/15 Midas Frontends \u25cfC++ programs operating in the midas framework \u25cfTypically handle receiving, processing, and packing data into midas events \u25cfSimple example frontend Example g-2 Midas Webpage List of frontends j.carlton@uky.edu 11/15 Online Database (ODB) \u25cfGUI on midas webpage \u25cbAlso available command line \u25cfAllows for \u201con the fly\u201d adjustments between runs \u25cfBuilt in configurations: \u25cbMidas webpage \u25cbLogger write location \u25cbWebpage update rate \u25cbEtc. \u25cfCustom configurations \u25cbConfigure hardware \u25cbetc. Example ODB Page on Midas Webpage j.carlton@uky.edu 12/15 Custom Software \u25cfCan write \u201cclients\u201d that connect to midas experiment \u25cbPython \u25cbC++ \u25cfAllows for user to write software to fit their needs, for example: \u25cbData Quality Monitor \u25cbOffline analysis scripts \u25cbAutomatic ODB management Example System Performance Webpage that Links with Midas j.carlton@uky.edu 13/15 Nearline Processing \u25cfAny preliminary processing on the data before moving to permanent storage Examples: \u25cfData quality monitors (DQM) that effectively sample and display data \u25cfBuilding ROOT trees from midas files (Unpacker, by Sean Foster) \u25cfMoving/Mirroring files Josh LaBounty\u2019s 2023 testbeam DQM page j.carlton@uky.edu 14/15 Offline Processing \u25cfAny processing on the data after it has been moved to permanent storage Examples: \u25cfCreating deposited energy histograms \u25cfChaining runs together \u25cfPretty much any rigorous analysis Preliminary Energy Sum Histograms from the 2023 Testbeam j.carlton@uky.edu 15/15 Auxiliary Slides Outline I.[] Introduction and Motivation A. What is DAQ? B. Proposed PIONEER DAQ Framework C. Why do all this? - Data Rates D. Two DAQs - Why? II.[] The Hardware Side A. What is an FPGA? B. g-2 DAQ Hardware C. PIONEER DAQ proposed hardware III. [] The Software Side A. Midas B. Frontends C. \u201cNearline\u201d Processing D. \u201cOffline\u201d Processing Hardware Initialism Cheatsheet Initialism Meaning Example (if applicable) DAQ Data Acquisition ADC Analog-to- Digital Converter 10GbE 10 Gigabit Ethernet AFE Analog Front End FPGA Field Programmable Gate Array CPU Central Processing Unit Intel Core i7-12700K GPU Graphics Processing Unit NVIDIA A5000 uTCA (or \u00b5TCA) Micro Telecommunications Computing Architecture WFD Waveform Digitizer WFD5 FC Flexible Controller FC7 AMC Advanced Mezzanine Card AMC13 (confusingly, also FC7 and WFD5) MCH MicroTCA Carrier Hub DDR Double Data Rate DDR3, DDR4 (RAM) PCIe Peripheral Component Interconnect Express PCIe2, PCIe3, \u2026 FPGA Types Series Example FPGA Virtex UltraScale+ XCVU9P Virtex UltraScale XCVU190 Kintex UltraScale+ XCKU15P Kintex UltraScale XCKU040 Artix UltraScale+ XA7A50T Artix-7 XC7A200T Zynq UltraScale+ MPSoC XCZU9EG Zynq-7000 SoC XC7Z045 Spartan-7 XC7S100 Spartan-6 XC6SLX75 Rough example name breakdown: XCVU190+1 : \u25cfX: Xilinx \u25cfC: Some family indicator (?) \u25cfVU: FPGA Family. \"VU\" \u2192 Virtex UltraScale family. \u25cf9: Device capacity or size \u25cf+1,+2,+3: A speed grade for the FPGA Why a Differential Signal? \u25cfMore resistant to noise \u2192 cleaner signal \u25cfLower supply voltages can be used \u25cbreduce power consumption, and allow for higher operating frequencies. \u25cbLow Voltage CMOS (LVCMOS) is 3.0\u20133.3 V Multiple Crate g-2 DAQ Hardware \u25cfEach crate needs an MCH to communicate with desktop \u25cbAnother 1GbE link required, ethernet splitter introduced (see blue 1GbE cables) \u25cfEach crate needs an AMC13 \u25cbAnother 10GbE data link to desktop introduced (see bottom mint cable) \u25cbTrigger signal fed from FC7 in first crate to AMC13 in bottom crate via optical cable (see orange cable) \u25cfNote: There are two mint optical cables running towards a desktop rather than 1 mint cable connecting both AMC13s Why the Apollo System? \u25cfCERN + CMS/ATLAS \u2192 APOLLO platform \u25cbCornell already had a hand in designing boards for APOLLO system \u25cfUnlike \u00b5TCA, the actual data handling does not need to move through the backplane \u25cbMore user control \u25cfAPOLLO system handles more channels per optical link \u2192 fewer desktops needed \u25cbAPOLLO System ~ 3000 channels/(400 chan/board * 2 boards/computer) ~ 4 computers \u25cb\u00b5TCA System ~ 3000 channels/(60 chan/crate * 2 crates/computer) ~ 30 computers Citation: DAQ backbone exploration, Lawrence Gibbons https://pioneer.npl.washington.edu/docdb/0000/000023/001/apollo.pdf Why Firefly Cables? Citation: DAQ backbone exploration, Lawrence Gibbons https://pioneer.npl.washington.edu/docdb/0000/000023/001/apollo.pdf ~ 1000 GB/s ~ 100 GB/s ~ 10 GB/s Firefly cables moving large amounts of data before it gets to DAQ computers FPGAs sample data Further processing and cuts Optical \u2192 More noise resistant than serial lines of similar speeds Communication with FPGA over PCIe \u25cfWant a midas frontend that communicates with an FPGA over PCIe \u25cfThis should streamline implementation when Cornell finalizes hardware Example block diagram (made in Vivado) for a PCIe FPGA Adding More Debugging Diagnostics to g-2 modified DAQ \u25cfCreated a more general DQM page (no assumption on number of channels/channel mapping) \u25cfRate limitations were an issue during 2023 test beam \u25cbCould only run at ~300Hz \u25cfAdded timing diagnostics to identify bottleneck \u25cfPlan to add CPU, RAM, and FC7 diagnostic pages as well Example System Performance Webpage that Links with Midas Rate Testing/Improving g-2 modified DAQ \u25cfAnalyzed test beam and UKY teststand performance data \u25cbBottlenecks are due to rare, long pauses between events \u25cbYet to determine exact reason for pauses \u25cfPlan to remove Meinberg card from system, replace with parallel port system \u25cbShould be faster and more straightforward Citation: Unpacking and analysis of the CC performance banks, Sean Foster (Slide 9) Timings of various stages of the data readout midas frontend Signal Conditioning \u25cfWant a narrow distribution for compression. Let ri be the numbers we compress \u25cfMethods tried: \u25cbNo conditioning \u25cbDelta encoding: ri = yi+1-yi \u25cbTwice Delta Encoding: ri = yi+2-2yi+1+yi \u25cbDouble Exponential Fit: ri= yi - (A \u22c5exp(ati)+ B \u22c5exp(bti)) \u25cbShape Fit : ri =yi- (A \u22c5T(ti-t0) + B) No Conditioning Shape Fit Frequency Frequency Voltage [Arbitrary Units] Voltage [Arbitrary Units] Shape Fitting Algorithm 1.Construct a discrete template from sample pulses 2.Interpolate template to form a continuous Template, T(t) 3.\u201cStretch\u201d and \u201cshift\u201d template to match signal: [Note: a and b can be calculated explicitly given t0] 4.Compute \u03c72 (assuming equal uncertainty on each channel i) 5.Use Euler\u2019s method to minimize \u03c72 Lossless Compression Algorithm \u25cfRice-Golomb Encoding \u25cbLet x be number to encode y = \u201cs\u201d+\u201cq\u201d+\u201dr\u201d \u25a0q = x/M (unary) \u25a0r = x%M (binary) \u25a0s = sign(x) \u25cbAny distribution \u25cbClose to optimal for valid choice of M \u25cbOne extra bit to encode negative sign \u25cbSelf-delimiting \u25cbIf quotient too large, we \u201cgive up\u201d and write x in binary with a \u201cgive up\u201d signal in front Value Encoding -1 011 0 000 1 001 2 1000Rice-Golomb Encoding (M=2) Red = sign bit Blue = quotient bit(s) (Unary) Yellow = remainder bit (binary) How to choose Rice-Golomb parameter M \u25cfGenerated fake Gaussian data (centered at zero) with variance \u03c32 \u25cfFor random variable X, M \u2248 median(|X|)/2 is a good choice \u25cbThis is the close to the diagonal on the plot \u25cf\u03c3 \u2248 32 for residuals of shape on wavedream data \u2192 M = 16 is a good choice Gaussian Noise \u03c3 MCompression Ratio Determining Optimal M waveDREAM test Compression Ratio from Rice-Golomb Encoding \u25cfLossless compression factor of ~2 \u25cfIn agreement with plot from simulated data on last slide \u25cfBest compression ratio we achieved Rice-Golomb Compression on Residuals (M = 16) Compression Ratio Sample Index Real Time Compression Algorithm \u25cfWe choose to let the FE\u2019s GPU and CPU handle compression for flexibility CPU GPU Copy initial guess, Y(t0) Allocate memory for X,Y(t0),t0*,t,r,r\u2019c timeCompute initial guess fit Y(t0)Initialization (one time) Data loop (many times) Copy many traces, X (Overwrite) Wait for enough traces\u2026 Launch 1 thread per trace Compute t0*, via \u03c72 minimization, r = X-Y(t0*)Copy r\u2019c, t0*Use header info from r\u2019c to allocate memory for rcAllocate memory for X,Y,t,r\u2019c Golomb encode r \u2192 r\u2019cStitch together rc from r\u2019c Store rc, t0* GPU Benchmarking (Timings) \u25cfBlock Size: \u25cbA GPU parameter, number of threads per multiprocessor \u25cfCan compress 226 integers (32-bit) in roughly \u2153 of a second. \u2192 ~ 0.8 GB/s compression rate Time [s] # of 32-bit Integers Fit + Compression Time using A5000 in PCIe4 (Batch Size = 1024) Other Conditioning Distributions Delta Encoding Twice Delta Encoding Double Exponential Fit Shape Fitting Details Fit Function Explicit a(t0) calc Explicit b(t0) calc Explicit \u03c72 calc Newton\u2019s method Threshold requirement Golomb Encoding \u25cfIn general, M is an arbitrary choice \u25cfSince computers work with binary, M = 2x such that x is an integer is a \u201cfast\u201d choice \u25cbThis is called Rice-Golomb Encoding \u25cfSelf delimiting so long as the information M is provided Encoding of quotient part q output bits 00 110 2110 31110 411110 5111110 61111110 \u22ee \u22ee N111 \u22ef1110Golomb Encoding Example Encoding of remainder part r offset binary output bits 00 0000 000 11 0001 001 22 0010 010 33 0011 011 44 0100 100 55 0101 101 612 1100 1100 713 1101 1101 814 11101110 915 11111111Choose M = 10, b = log2(M) = 3 2b+1 - M = 16 - 10 = 6 r < 6 \u2192 r encoded in b=3 bits r \u2265 6 \u2192 r encoded in b+1=4 bits Citation: Wikipedia (https://en.wikipedia.org/wiki/Golomb_coding) Huffman Encoding \u25cfRequires finite distribution \u25cfValues treated as \u201csymbols\u201d \u25cfSelf-delimiting (sometimes called \u201cgreedy\u201d) Value Frequency Encoding -1 \u2261 a 1 000 0 \u2261 b 10 1 1 \u2261 c 5 01 2 \u2261 d 3 001Huffman Encoding Example db ac10 10 10 d a1 0b c \u2026\u201cCombine\u201d two lowest frequencies into tree, Frequency z = 1+3 = 4 zRepeat for set {z,c,b} d ac0 101y bCitation: Wikipedia (https://en.wikipedia.org/wiki/Huffman_coding) Theoretical Uncertainty in Compression Ratio from Gaussian Noise \u25cf~ 0.1% relative error Uniform Distribution of Noise effect on Compression Ratio \u25cfHere instead we use a uniform distribution to generate the noise \u25cfNot much different than gaussian noise, same conclusions really Residuals Distribution and Optimal M M Compression Ratio 1 1.04721105 2 1.21287474 4 1.53114598 8 1.92616642 16 2.09307249 32 2.02975311 64 1.86037914 128 1.66627451 ... ... Lossy Compression Idea \u25cfIn lossless compression, Rice-Golomb encodes: 1.Fit parameters 2.Residuals \u25cfIf the residuals meet some criteria, we may choose to threw them out just keeping our fit of the signal. Example Criteria:",
    "textLength": 2363
  },
  {
    "kind": "presentation",
    "title": "DAQ Progress Report 11_19_2024_2024-11-18_16-45-49.pdf",
    "fileName": "DAQ Progress Report 11_19_2024_2024-11-18_16-45-49.pdf",
    "url": "resources/presentations/DAQ Progress Report 11_19_2024_2024-11-18_16-45-49.pdf",
    "createdDate": "2024-11-18",
    "text": "ATAR Teststand DAQ (Naludaq) \u25cfWant to use Nalu's Python library for readout integration into a python midas frontend \u25cbLoad appropriate firmware \u25cbRun naluscope \u25cbConnect to board in python \u25cbConfigure board in python \u25cbReadout data in python \u25a0UART \u25a01GbE(?) \u25cbIntegrate into midas python frontend \u25cfQuestions for Nalu about adapting their examples Nexys A7 Video Board with Nalu\u2019s HDSoC Digitizer Attached as an FMC Module NaluScope Program Screenshot with Noise Traces PIONEER DAQ: PCIe DMA Firmware Additions \u25cfAdded MicroBlaze IP Block \u25cbReadout DDR3 registers over PCIe via DMA \u25cbRun C++ code natively on the the FPGA \u25cbWant to program data generation simulators, etc. Block diagram for PCIe DMA transfer with microblaze added",
    "textLength": 112
  },
  {
    "kind": "presentation",
    "title": "Making the ML Reconstruction Pipeline Scale_2026-01-04_15-34-36.pdf",
    "fileName": "Making the ML Reconstruction Pipeline Scale_2026-01-04_15-34-36.pdf",
    "url": "resources/presentations/Making the ML Reconstruction Pipeline Scale_2026-01-04_15-34-36.pdf",
    "createdDate": "2026-01-04",
    "text": "Making the Machine Learning Reconstruction Pipeline Scalable Jack Carlton University of Kentucky Breaking down \u201cScalability\u201d I choose to break down scalability into three categories: 1.Data a. ML pipeline does not change behavior as data set grows i.Still scales in execution time 2.Compute a. ML pipeline does not change behavior as compute power is changed i.Still scales in execution time ii.Ex. Pipeline runs on developer\u2019s laptop or a CPU/GPU cluster 3.Codebase a. ML pipeline does not (greatly) change behavior as complexity grows i.New models, stages, or data products require additional code, not (major) code rewrites ii.Iteration speed does not (greatly) degrade with system size (i.e. keep things modular!) What Do We Mean by \u201cScaling\u201d (Data) \u25cfData volume should be able to grow without changing how the pipeline behaves \u25cfAdding the following should not cause pipeline behavior changes: \u25cbMore events \u25cbMore derived data products \u25a0predictions, masks, regressions, etc. \u25cbMore passes over the same data \u25cbLarger event representations \u25cfImplications: \u25cbMemory usage must not grow with dataset sizeIdeal Behavior for Different Sized Datasets ML Pipeline Output A Output B Small Dataset Large Dataset Short processing time Long processing time Small number of batches Large number of batches Techniques to Ensure Scalability (Data) \u25cfStream data in bounded batches \u25cbRAM usage should not scale with data set size \u25cbAllows RAM usage to be \u201ctunable\u201d \u25cfBase data should be immutable \u25cbNo modifications or extensions to ML pipeline input data files \u25cfSeparate derived data products \u25cbPredictions, masks, and regressions are produced as independent datasets \u25cfReference data by IDs, not by object \u25cbWhen passing data modules, use file paths or map IDs not in memory collections \u25cbSimilar to why we use pointers in C++ Simple Example Pipeline Including Derived Datasets Base Dataset Stage A Stage B Output Batch i Derived Data i Derived Dataset Storage Batch i + Derived Data i ML Pipeline Technologies for Scalability (Data) \u25cfROOT RNTuple (or similar) \u25cbHolds the necessary data from the monte carlo \u25cfApache Parquet (columnar, on disk) \u25cbML-native working datasets, append-only, shardable (aka \u201cbatchable\u201d) \u25cbCan key rows by event ID, enabling batch-scoped joins for derived data products \u25cfApache Arrow \u25cbSingle copy from disk into RAM, then zero-copy views all the way to Torch \u25cfPyTorch tensors \u25cbExecution format for models \u25cfPytorch DataLoader \u25cbHandles batching, shuffling, parallel loading, prefetching, enforcing memory bounds Flow of Data From Monte Carlo to a Model in the ML pipeline Monte Carlo ROOT RNTuple Parquet Arrow PyTorch DataLoader Model Once, offline generation Once, offline conversion Disk \u2192 RAM Copy Zero-copy views of data What Do We Mean by \u201cScaling\u201d (Compute) \u25cfComputation resources should be able to grow without changing how the pipeline behaves \u25cfAdding the following should not cause pipeline behavior changes: \u25cbNumber of GPUs \u25cbNumber of CPU cores/threads \u25cbNode count \u25cbMemory Capacity \u25cfImplications: \u25cbAlgorithms must be agnostic to resources \u25a0Caveat: PyTorch and other frameworks may change their behavior for different devices/device counts for efficiency Ideal Behavior for Different Amounts of Computing Resources ML Pipeline Output Output Dataset Dataset Long processing time Shorter processing time Low resource (ex. Laptop) High resource (ex. GPU cluster) Techniques to Ensure Scalability (Compute) \u25cfMake algorithms resource-agnostic \u25cbNo logic branches based on GPU count, core count, node count, or memory size, etc. \u25cfMake algorithms easily parallelizable \u25cbDecompose computation into independent, composable units \u25cbAvoid global state dependencies in pipeline stages \u25cbAvoid \u201csynchronization points\u201d; i.e. points where models must make inferences on whole datasets Parallelized View of Simplified Pipeline Big Dataset Batch 0 N outputs Batch 1 Batch M N events Output 1 Output 2 Output N N outputs N events \u2026 N outputs \u2026N events Stage A Stage B Compute Node 0 Stage A Stage B Compute Node 1 Stage A Stage B Compute Node M ML Pipeline Technologies for Scalability (Compute) \u25cfPyTorch \u25cbStandard framework for modern ML models \u25cbResource-agnostic execution model \u25cfCUDA \u25cbOperates purely at the level of memory, kernels, and execution, independent of algorithm or pipeline semantics \u25cbProvides an API for launching and coordinating large numbers of parallel threads on GPUs \u25cfKubernetes \u25cbSchedules identical pipeline executions onto available compute nodes \u25cbScales how many pipelines run concurrently, not what they do \u25cbHandles retry logic and resource limits Simplified \u201cScope\u201d Of Technologies Outer Technologies Manage Inner Technologies Kubernetes Distributes pipeline containers as black boxes Pipeline Container (ZenML) Pipeline logic, I/O, bookkeeping, etc. PyTorch Model semantics CUDA Kernels, threads, overall GPU execution What Do We Mean by \u201cScaling\u201d (Codebase) \u25cfCodebase complexity should be able to grow without changing how the system behaves \u25cfAdding the following should not cause system wide behavioral changes: \u25cbMore pipeline stages \u25cbMore models / algorithms \u25cbMore configuration options \u25cfImplications: \u25cbNew functionality should be added by extensions, not modification \u25cbSystem behavior should be locally understood (modularity) \u25cbExisting code should not require global refactoring to evolve The \u201cGlobal\u201d Structure Should Not Change As Complexity Increases Output B Dataset \u201cSimple\u201d pipeline with few stages \u201cComplex \u201cPipeline with many stages Stage A Stage B Stage C Stage E Stage D Stage F Output B Dataset Stage A Stage B Techniques to Ensure Scalability (Codebase) \u25cfUse abstraction where appropriate \u25cbDefine stable base interfaces / abstract classes \u25cbAdd new functionality by extending, not rewriting \u25cfAvoid global coupling \u25cbModules depend only on explicit inputs \u25cbEach module manages its own immutable local state \u25cfIsolate responsibilities to achieve modularity \u25cbEach module has a single, well-defined responsibility \u25cbChanges remain local to the owning module Simple Example of Abstraction For Adding New Models torch.nn.Module pioneerml.GraphModel pioneerml.GroupClassifier pioneerml.PionStopFinder Framework level contract Project level Contract Project level contract New file with implementation New file with implementation Technologies for Scalability (Codebase) \u25cfPyTorch \u25cbProvides a standard base abstraction classes for many model types (ex. nn.Module ) \u25cbEnforces a consistent model interface (ex. forward method) \u25cfZenML \u25cbEncodes pipelines as composable, declarative units and orchestrates execution \u25cbAllows pipelines to grow by adding or reordering steps; easy to add new pipelines \u25cbManages pipeline state, artifacts, and execution metadata outside user code \u25cfOptuna \u25cbIsolates hyperparameter search code \u25cbEnables experimentation without modifying core implementations Simplified Example Pipeline for Training Models Data Construction Optuna Optimization Model Training Evaluation Pipeline Parameters Trained Model ZenML Pipeline Load shard data Build graph inputs Sample hyperparameters Decide next trial Train our model implementation Compute Metrics Inform hyperparameter search Finished when hyperparameter search ends Auxiliary Slides What is Apache Parquet? \u25cfApache Parquet is a columnar, on-disk data format that is widely used in ML workloads \u25cfWhat parquet does \u25cbColumnar storage \u2192 read only the columns (features) your model needs \u25a0Allows one to efficiently assign a subset of columns as inputs and another subset of columns as targets \u25cbSupports nested and variable-length fields \u25cbData schema is embedded in the file, not inferred by code (ex. Not like numpy, where code defines dtype parameter) \u25cfWhy this matters for scalability \u25cbEfficient I/O for large datasets through compression and encoding \u25cbNew models using different subsets of the data becomes trivial Example time_groups.parquet file structure What is Batching? \u25cfBatching means processing a fixed-size subset of events at a time, rather than the full dataset \u25cfWhat batching does \u25cbGroups individual events into batches of size N \u25cbEach batch is processed independently \u25cbBatches are discarded after use \u25cfWhy this matters for scalability \u25cbMemory usage is bounded by batch size (for single batch process) \u25cbDataset size does not affect RAM usage \u25cbEnables streaming over arbitrarily large datasets Big Dataset Batch 0 Batch 1 Batch M Model Output 1 Output 2 Output N \u2026 \u2026N events N outputs Diagram that Shows how Batching Splits Data N events N events N outputs N outputs What is Shuffling? \u25cfShuffling changes the order in which events are seen, without changing the data itself \u25cfWhat shuffling does \u25cbRandomizes event order before forming batches \u25cbEnsures batches contain a mix of events \u25cbChanges between epochs (or passes over the data) \u25cfWhy this matters for scalability \u25cbPrevents bias from data ordering \u25cbImproves statistical independence between batches \u25cbAllows repeated passes over large datasets without correlation artifacts Dataset [A,A,A,A,B,B] Simplified Example of Shuffling vs. Not Shuffling a Dataset with Distinct Event Types A and B Without Shuffling With Shuffling Batch 1 [A,A] Batch 0 [A,A] Batch 2 [B,B] Dataset [A,A,A,A,B,B] Batch 1 [A,B] Batch 0 [A,B] Batch 2 [A,B] Batches may have biases in event types, which hinders training Batches are a better representation of the whole dataset; no ordering correlations What is Parallel Loading? \u25cfParallel loading means loading multiple batches concurrently, using multiple workers \u25cfWhat parallel loading does \u25cbMultiple workers read and prepare batches simultaneously \u25cbThe model always has a batch ready to process \u25cbData loading is decoupled from model execution \u25cfWhy this matters for scalability \u25cbHelps prevent the model from waiting on disk I/O \u25cbImproves hardware utilization (especially GPUs) Big Dataset Loader 0 (Batch 0) Loader 1 (Batch 1) Loader 2 (Batch 2) Model \u2026Data Loaded in Parallel Note: Parallel loading does not necessarily mean parallel model execution Parallel Data Loading Diagram What is Prefetching? \u25cfPrefetching means loading future batches while the current batch is being processed \u25cfWhat prefetching does \u25cbWhile the model computes on batch N the next batch (N+1) is loaded in the background \u25cbWhen computation finishes, the next batch is already ready \u25cfWhy this matters for scalability \u25cbHelps prevent the model from waiting on disk I/O Simplified Prefetching Example Diagram Without Prefetching With Prefetching Load Batch N Compute Batch NLoad Batch N+1 Compute Batch N+1Load Batch N Compute Batch N Load Batch N+1 Compute Batch N+1Time Time Subsequent batches loaded in parallel with compute of previous batch. Effectively utilizing different hardwares What is Enforcing Memory Bounds? \u25cfEnforcing memory bounds means placing a hard limit on how much data can be in memory at once \u25cfWhat enforcing memory bounds does \u25cbMaximum in-flight data size is fixed \u25cbBatch creation is throttled when memory is full \u25cbMakes memory usage predictable and stable \u25cfWhy this matters for scalability \u25cbDataset size does not affect RAM usage \u25cbEnables streaming over arbitrarily large datasets Batch 0Batch 1 Model \u2026 Diagram Showing How Memory Bounds Enforce a Limited Number of Batches Loaded in RAM Batch 2Batch 3Batch MBig Dataset Memory bound fixes limit of data in RAM, which effectively fixes the number of batches that can be in RAM at one time. As one batch finishes, more batches load into RAM What is Kubernetes (K8s)? \u25cfA system for running and managing containerized workloads across shared compute resources \u25cfWhat Kubernetes does \u25cbSchedules containers onto available compute nodes \u25cbEnforces resource limits (CPU, GPU, memory) per container \u25cbIsolates workloads from one another \u25cbHandles restarts and retries on failure \u25cfWhy this matters for scalability \u25cbEnables concurrent execution of many independent workloads \u25cbPrevents resource contention between workloads Kubernetes Control Plane Cluster of Compute Resources Compute Node A Compute Node B Schedules and distributes workload Pod PodPod Application 0 Application 1 Application 2 Note: A pod is the smallest schedulable unit Simplified Diagram of How Kubernetes Orchestrates Applications Across a Compute Cluster What is ZenML? \u25cfA framework for defining, orchestrating, and executing machine-learning pipelines with explicit steps, artifacts, and metadata \u25cfWhat ZenML does \u25cbEncodes workflows as composable, declarative pipelines \u25cbOrchestrates execution order and dependencies \u25cbIntegrates with execution backends (local, containers, clusters) without changing user code \u25cfWhy this matters for scalability \u25cbPipelines grow by adding or rearranging stages, not rewriting logic \u25cbEnables reproducibility, versioning, and parallel development \u25cbState and artifacts are managed outside user code Example ZenML pipeline diagram Stage A Stage B Stage C Pipeline Parameters Pipeline Output ZenML Pipeline Artifacts and Metadata Storage (external or local database) What is Optuna? \u25cfMany hyper parameters means manual tuning is bad \u25cbToo slow \u25cbSuboptimal tuning means you spend more resources (time, computing power, etc.) training unused models \u25cfOptuna is a python package that solves this problem \u25cbFramework for optimization black box objective functions \u25cbTechnically not an ML package, but rather a package that supports many optimized sampling strategies Example Optuna workflow diagram How Optuna Works \u25cfOptuna supports many sampling algorithms , examples: \u25cbGrid search \u25cbRandom search \u25cbGaussian process-based Bayesian optimization \u25cfFor single object functions, the default for Optuna is Tree-Structured Parzen Estimator (TPE) TPE flow diagram (in a nutshell) What is a Tree-Structured Parzen Estimator (TPE) (Part I) \u25cfGiven a (possibly stochastic) black box function you want to minimize (ex. model loss) \u25cfHyperparams \u2261 \u03b8 \u25cfDefine the following: \u25cfThen, for any given theta we can define expected improvement \u25cfGoal: Maximize expected improvement Note: See paper on arxiv What is a Tree-Structured Parzen Estimator (TPE) (Part II) \u25cfFor a 1 dimensional y, it turns out to be easier to work with , we can invert using Bayes\u2019 rule: \u25cfAnd substitute \u25cfSince we don\u2019t know every value of y this becomes an impossible task. We must make an approximation by dividing into \u201cgood\u201d and \u201cbad\u201d distributions Note: See paper on arxiv What is a Tree-Structured Parzen Estimator (TPE) (Part III) \u25cfThe integral, by construction, only cares about the \u201cgood\u201d region, so the integral simplifies to \u25cfBut the integral is now constant in theta! So we have: \u25cfWhere so we can write: Note: See paper on arxiv What is a Tree-Structured Parzen Estimator (TPE) (Part IV) \u25cfBut \u03b3 is fixed, so \u25cfWhere the final step is because x/(bx+c) is monotonic in x for x >0 ,let x = l/g \u25cfIn other words, we just need to find which is doable via algorithm! Note: See paper on arxiv What is a Tree-Structured Parzen Estimator (TPE) (Part V) \u25cfNow to define the algorithm, first we observe T (~10) trials randomly: \u25cfFrom this data, we want to build: \u25cfSo we define \u25cfAnd assume: Note: See paper on arxiv What is a Tree-Structured Parzen Estimator (TPE) (Part VI) \u25cfThis allows us to write: \u25cfWe can fit to our samples to get a continuous distribution spaces for each param \u25cfThen we sample from the \u201cgood\u201d spaces for M candidates index by m \u25cfAnd finally, choose our next theta, add it to the data set, and repeat Note: See paper on arxiv What is a Tree-Structured Parzen Estimator (TPE) (Part VII) \u25cfHow do we obtain our fits from the data? \u25cfUses Kernel Density Estimation (KDE) \u25cbThe actual fit is done when determining each \u201cgaussian kernel\u201d (or sigma) \u25cbLikelihood-optimal is expensive ~O(n2d) \u25a0n = # samples \u25a0d = # hyperparameters \u25cbOptuna uses the \u201cheuristic\u201d version, which requires choosing some value for c. Note: See paper on arxiv",
    "textLength": 2407
  },
  {
    "kind": "presentation",
    "title": "Annual postqualifiying update_2024-10-14_13-27-25.pdf",
    "fileName": "Annual postqualifiying update_2024-10-14_13-27-25.pdf",
    "url": "resources/presentations/Annual postqualifiying update_2024-10-14_13-27-25.pdf",
    "createdDate": "2024-10-14",
    "text": "PIONEER Data Acquisition Development Update Jack Carlton University of Kentucky j.carlton@uky.edu Title (Slide 1/37) Outline I.[3-7] PIONEER Refresher A. Experimental Design II.[8-13] Test Stand DAQ Development A. Hardware Description B. Software Adjustments III. [14-21] 2023 PSI Test Beam A. Contributions B. Experiment Description C. Results IV. [22-32] PIONEER DAQ Development A. Proposed Framework B. Prototyping C. Compression V.[33-37] Current and Future Work You can find this presentation in my notes Links: https://github.com/jaca230/joplin_notes_page or https://tinyurl.com/jack-uky-notes j.carlton@uky.edu Outline (Slide 2/37) PIONEER Refresher j.carlton@uky.edu I. PIONEER Refresher (Slide 3/37) PIONEER Experimental Proposal Citations: PIONEER Seminar, Tim Gorringe (Slide 20) PSI Ring Cyclotron Proposal R-22-01.1 PIONEER: Studies of Rare Pion Decays, PIONEER collab, (pg. 19 arxiv: 2203.01981) \u25cfLXe (or LYSO) has shorter decay time \u25cb~ 25 ns \u25cfAllows experiment to run at much higher rate \u25cb~300kHz (phase 1) \u25cb~2000kHz (phase 2 and 3) \u25cf\u201cactive target\u201d, muons and pions are \u201ctracked\u201d j.carlton@uky.edu I. PIONEER Refresher (Slide 4/37) 3D Render Experiment Citations: PIONeer A next-generation rare pion decay experiment, David Hertzog, (https://pioneer.npl.washington.edu/docdb/0002/000281/001/PIONEER%20Orientation%20an d%20Status%20June%202024.pdf) Digitization Electronics Spherical Calorimeter Design Not Pictured: \u25cfATAR (inside Calo) \u25cfTracker (a shell around ATAR, inside Calo) \u25cfVETOs, T0, etc. \u25cfDAQ Computers j.carlton@uky.edu I. PIONEER Refresher (Slide 5/37) How PIONEER Will Improve the Re/\u00b5 Measurement \u25cf5D space-time-energy active pion stopping target (ATAR) \u25cb Reduce e+ energy tail, identify beam pileup, identify \u03c0 \u2192 \u00b5 \u03bd\u00b5 decays \u25cfLarge acceptance, deep radiation length calorimeter \u25cb LXE or LYSO for high resolution, fast response, small tail \u25cfFast electronics, high-speed acquisition \u25cb Giga sample/second digitizers, new gen PCIe readout \u25cfPSI high intensity pion beams \u25cb 2 mA proton beam, large acceptance beamline Citation: PIONEER Seminar, Tim Gorringe (Slide 22) j.carlton@uky.edu I. PIONEER Refresher (Slide 6/37) Midas Framework \u25cfC/C++ (mostly) package of modules for \u25cbrun control, \u25cbexpt. configuration \u25cbdata readout \u25cbevent building \u25cbdata storage \u25cbslow control \u25cbalarm systems \u25cbEtc. \u25cfCan link with custom software Example g-2 Midas Webpage j.carlton@uky.edu I. PIONEER Refresher (Slide 7/37) Test Stand DAQ Development j.carlton@uky.edu II. Test Stand DAQ Development (Slide 8/37) Overview \u25cfThe test stand DAQ is used throughout the PIONEER collaboration \u25cbHelps test and develop crucial experiment components \u25cfBuilt on top of g-2 DAQ hardware and software Digitizers & trigger processors ...Array of readout computers, Midas server ... Detectors Hardware Side Software Side j.carlton@uky.edu II. Test Stand DAQ Development (Slide 9/37) Hardware - Labeled Crate 10GbE out (data) AMC13\u2192desktop Trigger in AMC13 Trigger out FC7 1GbE MCH in/out (comm.) FC7 Trigger in WFD5 5-channel, differential signal in (no connection in this picture) WFD5s M C HA M C 1 3 F C 7Note: AMC13 and MCH are half slot modules W F D 5W F D 5Crate Power Supply j.carlton@uky.edu II. Test Stand DAQ Development (Slide 10/37) Software - Adjustment Made \u25cfGeneralized the frontend code \u25cbCrate contents no longer assumed \u25cbAdded option to remove unneeded hardware reliance (meinberg card) \u25cbAdded support for arbitrary number of crates \u25cbAdded scripts for ease of setup and use \u25cfAdded features \u25cbTiming monitoring \u25cbData quality Monitoring (DQM) \u25cbSystem resource monitoring Generalized Teststand DAQ DQM Webpage j.carlton@uky.edu II. Test Stand DAQ Development (Slide 11/37) Documentation \u25cfSetup of the teststand DAQ is not straightforward \u25cbCustom software and hardware \u25cbSpecific software and hardware configurations \u25cfCreated documentation to aid users \u25cbWebsite version on github pages https://jaca230.github.io/teststand_daq_ manual/ A page from the manual webpage j.carlton@uky.edu II. Test Stand DAQ Development (Slide 12/37) Use Cases \u25cfLYSO tests at CENPA \u25cf2023 PSI Test Beam \u25cfLiquid Xenon tests at TRIUMF \u25cfExperiments at PSI Setting up test stand at University of a Washington (on a rainy day) j.carlton@uky.edu II. Test Stand DAQ Development (Slide 13/37) 2023 PSI Test Beam j.carlton@uky.edu III. 2023 PSI Test Beam (Slide 14/37) Overview \u25cfPIONEER LYSO Calorimeter test \u25cbNovember 15 - 29, 2023 \u25cfMade measurements using LYSO scintillator crystals to determine if they are an adequate candidate for PIONEER\u2019s calorimeter \u25cbEnergy resolution \u25cbTiming resolution \u25cbSpatial resolution j.carlton@uky.edu III. 2023 PSI Test Beam (Slide 15/37) Contributions \u25cfRepurposing g-2 DAQ Software \u25cfFlexible Pipeline for Data Quality Monitor \u25cfBeamtime \u201cLive\u201d DAQ Maintenance \u25cfOnsite preliminary data analysis Examples of preliminary analysis work done at PSI j.carlton@uky.edu III. 2023 PSI Test Beam (Slide 16/37) Experiment Diagram - Conceptual Picture Last Quadrupole Magnet on beamline NaI (Leakage Detector) Photomultiplier Tubes (PMTS) NaI (Leakage Detector) Array of LYSO Crystals Data Acquisition System Beam Veto T0 XY Hodoscope Calorimeter on movable XY table j.carlton@uky.edu III. 2023 PSI Test Beam (Slide 17/37) Experiment Diagram - Labeled Picture A full view of the detector setup during the PSI test beam (a) and a close-up of the calorimeter front-face during laser alignment (b). Positrons from the last quadrupole magnet \u2460 pass through the VETO counter \u2461, T0 \u2462, and beam hodoscope \u2463 before depositing energy in the LYSO array \u2464. The LYSO crystals, along with the surrounding NaI detectors \u2465, are mounted on a movable XY table \u2466.Citation: Testing Lepton Flavor Universality and CKM Unitarity with Rare Pion Decays in the PIONEER experiment, PIONEER collab (pg. 20, arxiv: 2203.05505) j.carlton@uky.edu III. 2023 PSI Test Beam (Slide 18/37) Hodoscope \u25cf2 Layers of 12 scintillator strips \u25cbLayers offset by 90 degrees \u25cf1 mm x 1 mm \u201cpixels\u201d created by strip intersections \u25cbAllows for finer positioning data Citation: Measurements of a LYSO crystal array from threshold to 100 MeV, PIONEER collab (arxiv: 2409.14691) Upstream detector analysis, Stefan Hochrein, https://pioneer.npl.washington.edu/docdb/0002/000254/005/Upstream%20detectors.pdf 1 Hodoscope layer, 12 SiPMs connecting to 12 BC404 plastic scintillator 2mm wide bars Beam Profile: Red - positrons, Blue - muons j.carlton@uky.edu III. 2023 PSI Test Beam (Slide 19/37) LYSO Calorimeter \u25cfConstructed from an array of 10 LYSO crystals \u25cbNaI for leakage detection \u25cfX0 = 1.14 cm \u25cfRM= 2.07 cm Citation: Measurements of a LYSO crystal array from threshold to 100 MeV, PIONEER collab (arxiv: 2409.14691) Front-facing image of LYSO calorimeter j.carlton@uky.edu III. 2023 PSI Test Beam (Slide 20/37) Results - Energy Resolution \u25cfMeasured an energy resolution of \u0394E/E = 1.55 \u00b1 0.05% \u25cbPublished as 1.80, recently improved with better integration strategy \u25cb70 MeV \u2248 e energy in \u03c0 \u2192 e\u03bde \u25cfOver two times better than reported results for previous generation LYSO crystals \u25cfSimilar to liquid xenon energy resolution Citation: Measurements of a LYSO crystal array from threshold to 100 MeV, PIONEER collab (arxiv: 2409.14691) j.carlton@uky.edu III. 2023 PSI Test Beam (Slide 21/37) PIONEER DAQ Development j.carlton@uky.edu IV. PIONEER DAQ Development (Slide 22/37) Development Overview \u25cfDAQ work is split into a \u201chardware side\u201d and \u201csoftware side\u201d \u25cbCornell mostly handles the hardware side \u25cbUKY mostly handles the software side \u25cfHardware side goals: \u25cbDesign a flexible system to handle real time data processing, digitizations, and triggers \u25cbCommunication to software side over PCIe \u25cfSoftware side goals: \u25cbHandle electronics readout and communication over PCIe \u25cbHandle data processing and compression j.carlton@uky.edu IV. PIONEER DAQ Development (Slide 23/37) Proposed Framework arXiv:2203.05505 Citation: Testing Lepton Flavor Universality and CKM Unitarity with Rare Pion Decays in the PIONEER experiment, PIONEER collab (pg. 20, arxiv: 2203.05505) Hardware Side SW Side j.carlton@uky.edu IV. PIONEER DAQ Development (Slide 24/37) Proposed Framework arXiv:2203.05505 Citation: Testing Lepton Flavor Universality and CKM Unitarity with Rare Pion Decays in the PIONEER experiment, PIONEER collab (pg. 21) Software Side Receive Data over PCIe Build events in Midas \u201cNearline\u201d Tools j.carlton@uky.edu IV. PIONEER DAQ Development (Slide 25/37) Proposed Experimental Hardware \u25cfUsing APOLLO system (no more \u00b5TCA crates) \u25cfData is moved using \u201cFirefly\u201d optical flyover system \u25cb25 gb/s > 10gb/s links from g-2 \u25cfData received by desktop through Firefly PCIe cards Firefly PCIe board Citation: DAQ backbone exploration, Lawrence Gibbons https://pioneer.npl.washington.edu/docdb/0000/000023/001/apollo.pdf j.carlton@uky.edu IV. PIONEER DAQ Development (Slide 26/37) Mock Experimental Hardware - Our Development FPGA \u25cfUsing Nereid Development board \u25cbKintex-7 FPGA \u25cbData transfer over PCIe \u25cbOnboard RAM (data buffers) \u25cbFMC module input \u25cfWhy this board? \u25cbMore learning resources \u25cbHas components to simulate real experimental hardware \u25cfLimitations: \u25cbOnly supports 5 GT/s (equivalent to PCIe 2) \u25cbOnly 4 lanes (max throughput 2 GB/s) Nereid K7 PCI Express FPGA Development Board j.carlton@uky.edu IV. PIONEER DAQ Development (Slide 27/37) Mock Experimental Hardware - FPGA Firmware \u25cfUsing Xilinx intellectual property (IP) blocks in Vivado \u25cbIP blocks configured by development board settings \u25cfAllows for direct memory access (DMA) transfer over PCIe between card and host Block diagram for DMA transfer between board RAM and host (desktop) RAM j.carlton@uky.edu IV. PIONEER DAQ Development (Slide 28/37) Data Rates Achieved \u25cfMore interested in read/Card-to-host (c2h) transfer rates \u25cfTransfer rates are faster for larger data transfer sizes \u25cfUsing multiple channels, highest data throughput through midas was 1GB/s \u25cfThis number is largely limited by the Nereid development board\u2019s hardware DMA transfer rate vs transfer size over one channel Transfer Size Average Transfer Rate [MB/s] Transfer Speed Vs. Transfer Size j.carlton@uky.edu IV. PIONEER DAQ Development (Slide 29/37) Template Fitting - Example \u25cfCan construct a continuous template for our traces \u25cfCan fit traces using template: \u25cfStoring unfit traces takes ~12 bits per ADC sample \u25cfStoring residuals takes ~4 bits per ADC sample \u25cfBy fitting, we can compress the data by a factor of ~3 ADC value Residual value Time [c.t] Time [c.t] PSI Example LYSO Signal with Fit Signal - Fit Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) Range = ~16 = 4 bits j.carlton@uky.edu IV. PIONEER DAQ Development (Slide 30/37) Template Fitting - Applied \u25cfData from PSI test beam \u25cfEach vertical slice corresponds to pdf \u25cfTemplate fit drastically reduces spread of data Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) Template fitting time [c.t.] Time [c.t] Probability Probability ADC value ADC value j.carlton@uky.edu IV. PIONEER DAQ Development (Slide 31/37) Theoretical Best Compression \u25cfFor lossless compression, the best possible compression rate is the entropy rate \u25cfEntropy rate of pedestal part of signal is 3.4 bits per ADC sample \u25cbA perfect fit would reduce signal to pedestal noise \u25cfBest possible data storage rate 3.5 GB/s \u2192 ~1 GB/s \u25cbAssumes similar noise to PSI test beam data \u25cfRealistically the data storage rate depends how good our fit is \u25cbAssuming entropy rate of ~5 bits/sample 3.5 GB/s \u2192 ~1.5 GB/s Time [c.t] Entropy/sample [bits] Entropy Rate Formula Entropy Rate of PSI Test Beam Data After Fitting Signal entropy Pedestal entropy Pedestal entropy j.carlton@uky.edu IV. PIONEER DAQ Development (Slide 32/37) Current and Future Work j.carlton@uky.edu V. Current and Future Work (Slide 33/37) ATAR Teststand DAQ (Naludaq) \u25cfIntegrate Nalu\u2019s HDSoC digitizer output with MIDAS for synchronized, multi-detector event construction \u25cbAlso utilize existing custom MIDAS-linked software \u25cfUse Nalu's Python library for integration \u25cbCurrent readout via UART interface \u25cbIncorporate Nalu library into MIDAS frontend Nexys A7 Video Board with Nalu\u2019s HDSoC Digitizer Attached as an FMC module NaluScope Program Screenshot with Noise Traces j.carlton@uky.edu V. Current and Future Work (Slide 34/37) FPGA Firmware Additions \u25cfAdded MicroBlaze IP Block \u25cfAllows the FPGA to run C++ code to edit onboard DDR3 RAM \u25cbCan code data generation simulators Block diagram for PCIe DMA transfer with microblaze j.carlton@uky.edu V. Current and Future Work (Slide 35/37) Generalizing and Optimizing Software \u25cfWrite modular software \u25cbWill make experiment DAQ code much more manageable in the future \u25cfOptimize and adjust readout, compression, and other libraries (as needed) \u25cfWrite simple and scalable midas frontends \u25cbImplement libraries above Other Libraries Compression Library MIDAS Readout Library Frontend 1 Frontend 2 \u2026 Frontend 3 \u2026 Dependency Diagram j.carlton@uky.edu V. Current and Future Work (Slide 36/37) PIONEER Demonstrator \u25cf\u201cFull\u201d experiment demonstrator \u25cfPrototypes for all detectors \u25cbSmall number of ATAR Layers (16 layers) \u25cbSmall spherical segment of tapered LYSO crystals (12 crystals) \u25cbSome spherical \u201cshell\u201d segment of tracker \u25cfDAQ handles event construction Tapered LYSO Array ATAR Layers Curved Tracker Section Beam Different Digitization Systems DAQ Computer(s) j.carlton@uky.edu V. Current and Future Work (Slide 37/37) Auxiliary Slides j.carlton@uky.edu Title (Slide 0/xx) Background Physics j.carlton@uky.edu \u03c0 \u2192 e \u03bde and \u03c0 \u2192 \u00b5 \u03bd\u00b5 \u25cfCorresponding diagrams for \u03c0- \u25cfTau decay forbidden \u25cbtau too massive ~ 1000 MeV/c2 \u25cbPion ~ 100 MeV/c2 \u25cfMuon decay more likely \u25cbbranching fraction of 0.999877 \u03bde e+\u00b5+\u03bd\u00b5 u du d\u03c0+ \u03c0+W W Citation: Particle Data Group (https://pdg.lbl.gov/2014/listings/rpp2014-list-pi-plus-minus.pdf) j.carlton@uky.edu Helicity Suppression (Why is Muon Decay Most Likely?) \u25cfNaively, \u0393 \u221d p\u2019 \u2192 electron decay more likely \u25cfWeak force only affects left-handed (LH) chiral particle states and right-handed (RH) chiral anti-particle states \u25cfNeutrinos are all LH chirality \u25cfm\u03bd << E means LH neutrino chirality \u2192 LH (negative) neutrino helicity \u25cfConservation of momentum \u2192 anti-lepton is LH (negative) helicity \u03bdl l+u d\u03c0+W \u03c0+ \u03bdll+ Citation: Modern Particle Physics, Mark Thomson (Ch. 11.6 pg. 299) j.carlton@uky.edu Helicity Suppression (Why is Muon Decay Most Likely?) \u25cfWe can write the LH (negative) helicity anti-particle state in the chiral basis: \u25cfWe ignore the LH term (weak force only acts on the RH term), anti-particle\u2019s matrix element contribution: \u25cfThis effect ends up making the matrix element smaller \u2192 decay rate smaller \u03bdl l+u d\u03c0+W \u03c0+ \u03bdll+ Citation: Modern Particle Physics, Mark Thomson (Ch. 11.6 pg. 300, Ch. 6.4 pg. 143) j.carlton@uky.edu Lepton Universality \u25cfStates coupling strengths (vertices) ge = g\u00b5 = g\u03c4 \u25cfUsing the Feynman rules for the weak interaction, we can approximate the matrix element \u03bdee-\u00b5- \u03bd\u00b5d ud u\u03c0- \u03c0-W W ge g\u00b5 f\u03c0f\u03c0 Pion vertex Lepton vertex W-boson propagator Citation: Modern Particle Physics, Mark Thomson (Ch. 11.6 pg. 301) j.carlton@uky.edu Lepton Universality \u25cfAfter some \u201cmassaging\u201d we can find the matrix element to be \u25cfPion spin zero \u2192 no spin averaging needed, i.e.: \u25cfWe can use the general formula for 2-body decay to to find the decay rate \u25cfFinally, we compute the branching ratio Citation: Modern Particle Physics, Mark Thomson (Ch. 11.6 pg. 302-303) j.carlton@uky.edu Lepton Universality \u25cfLepton universality assumes ge = g\u00b5, so the first factor disappears \u25cfImproving the branching ratio measurement and comparing to the theoretical value acts as a test of lepton universality \u25cfAnother test would consider pure leptonic decays, but such decays involving taus are too rare for high precision measurements j.carlton@uky.edu Branching Ratio Re/\u00b5 \u25cfWe can measure the branching ratio by measuring # of decays e and \u00b5 decays \u25cfTheoretical prediction is simple in first (and second) order \u25cbNo f\u03c0 or CKM element Vud \u25cf3rd order correction and beyond the pion structure becomes relevant = 1 [in theory] Citation: Dynamic of the Standard Model, Donoghue et. al (Ch. 6.1 pg. 163) j.carlton@uky.edu Current state of Re/\u00b5 \u25cfConsistent with each other \u25cfExpect factor of ~10 precision improvement on experimental value from PIONEER \u25cb\u201cCatches up\u201d with theoretical uncertainty Re/\u03bcexp = 1.2327(23) x 10-4 (PIENU collab) Rtheo = 1.23524(15) x 10-4 Citation: Testing Lepton Flavor Universality and CKM Unitarity with Rare Pion Decays in the PIONEER experiment, PIONEER collab (pg. 6, arxiv: 2203.05505) j.carlton@uky.edu Past Experimental Approach (PIENU) \u25cfNaI has a long primary decay time \u25cb~ 250 ns \u25cfEvent pileup forces the experiment to run at a low rate \u25cb~70 kHz \u25cf\u201cinactive target\u201d, muons aren\u2019t tracked \u25cfCsI Rings for shower leakage detection Citation: Status of the TRIUMF PIENU Experiment, PIENU collab, (arxiv 1509.08437) https://pienu.triumf.ca/ j.carlton@uky.edu Common Pion Decay Channels \u25cf\u03c0+ \u2192 e+ + \u03bde \u25cf\u03c0- \u2192 e- + \u03bde \u25cf\u03c0+ \u2192 \u00b5+ + \u03bd\u00b5 \u25cf\u03c0- \u2192 \u00b5- + \u03bd\u00b5 \u25cf\u03c0+ \u2192 \u03c00 + e+ + \u03bde \u25cf\u03c0- \u2192 \u03c00 + e- + \u03bde\u25cf\u03c00 \u2192 \u03b3 + \u03b3 \u25cf\u03c00 \u2192 \u03b3 + e- + e+ \u25cf\u03c00 \u2192 e- + e+ + e- + e+ \u25cf\u03c00 \u2192 e- + e+ Leptonic Decay Beta Decay = Most Common Photon Decay Dalitz Decay Double-Dalitz Decay Electrons [Note: Dalitz Decays are like photon decays, except the photon(s) are virtual and immediately decay into electron/positron pairs] Citation: Wikipedia (https://en.wikipedia.org/wiki/Pion) j.carlton@uky.edu Naive Pion Decay, 2-body decay \u25cfWithout getting into details of QCD, we can treat this as a 3 particle decay \u25cfWe can use Fermi\u2019s golden rule: \u25cfAfter integration in the COM frame we find: \u25cf\u2192 \u0393 \u221d p (not correct) \u25cbDetails hidden in matrix element AB C Citation: Introduction to Elementary Particles, Griffiths (Ch. 6.2 pg. 196-198) j.carlton@uky.edu Why Massless \u2192 Chirality States ~ Helicity States \u25cfMassless \u2192 moves at c \u25cfMoves at c \u2192 cannot reverse particle direction with Lorentz boost \u2192 helicity is Lorentz Invariant \u25cfChirality is a property of a particle, always Lorentz invariant! \u2192 helicity and chirality agree in direction in all inertial reference frames [Dirac Equation] [Chiral States] [Helicity operator] [Chiral states are eigenstates of helicity operator] Citation: Lecture Notes, Quantum Field Theory, Michael Eides (PHY616, Lecture #25) j.carlton@uky.edu LH (negative) helicity spinor to chiral components An negative helicity antiparticle can be written as Where (\u03b8,\u03c6) define the direction of the momentum. Without loss of generality, assume the momentum is in the z direction Citation: Modern Particle Physics, Mark Thomson (Ch. 6.4 pg. 143) j.carlton@uky.edu LH (negative) helicity spinor to chiral components We can use the chiral projection operations to project this helicity state to chiral state Where the left and right chiral anti-particle states are defined by Citation: Modern Particle Physics, Mark Thomson (Ch. 6.4 pg. 141,143) j.carlton@uky.edu LH (negative) helicity spinor to chiral components Looking at the chiral projection of a negative helicity state, we can see in general there are left and right chiral components, so the weak force can act on a LH (negative) anti-particle helicity state It should also be clear as m\u21920, the LH (negative) helicity state coincides with the LH chiral state. This means W boson decay to two massless leptons is forbidden! One of the particles must have the wrong chirality, and thus low mass decays will be suppressed. Citation: Modern Particle Physics, Mark Thomson (Ch. 6.4 pg. 143) j.carlton@uky.edu Matrix Element Details Move to pion rest frame so only p0 = m\u03c0 remains: Using the identity: Citation: Modern Particle Physics, Mark Thomson (Ch. 11.6 pg. 301) j.carlton@uky.edu Matrix Element Details For a neutrino m << E so helicity eigenstate is essentially the chiral eigenstate: By letting the lepton go in the z-direction we can write: and Negative helicity lepton down state disappears when \u201cdotted\u201d with the neutrino state: Citation: Modern Particle Physics, Mark Thomson (Ch. 11.6 pg. 301-302) j.carlton@uky.edu Matrix Element Details We can re-write El and p in the limit where the neutrino mass is zero: Citation: Modern Particle Physics, Mark Thomson (Ch. 11.6 pg. 302) j.carlton@uky.edu Lepton Universality j.carlton@uky.edu Small discrepency in ge/g\u00b5 and 1 can cause twice as big discrepency in measured Re/\u00b5 and theory Re/\u00b5 Another Test for Lepton Universality Citation: PIONEER Seminar, Tim Gorringe (Slide 9) Fermi constant and new physics, Marciano, Phys Rev. D 60, 093006 j.carlton@uky.edu CKM Unitary Test Citation: Testing Lepton Flavor Universality and CKM Unitarity with Rare Pion Decays in the PIONEER experiment, PIONEER collab (pg. 21) PIONEER Seminar, Tim Gorringe (Slide 12) arXiv:2203.05505 \u25cfPion beta decay gives a precision measurement of Vud \u25cfThese decays are lower rate than \u03c0 \u2192 e\u03bde and \u03c0 \u2192 \u00b5\u03bd\u00b5 \u25cfExperimental measurements do not agree j.carlton@uky.edu Some Information about LXe and NaI \u25cfLXe has singlet and triplet state decay constants: \u25cb\u03c4S = 4.3 \u00b1 0.6 ns \u25cb\u03c4T = 26.9+0.7 \u22121.1 ns \u25cfLXe light yield: \u25cb~29 photons/keV at room temp \u25cfNaI decay constant: \u25cb~ 250 ns \u25cfNaI light yield: \u25cb38 photons/keV at room temp Citations: A measurement of the scintillation decay time constant of nuclear recoils in liquid xenon with the XMASS-I detector, XMASS collab, arxiv 1809.05988 Scintillation yield of liquid xenon at room temperature , XMASS collab, arxiv 0803.2888 Berkeley Nucleonics (https://www.berkeleynucleonics.com/nai-sodium-iodide) Scintillation from excited Xe (Xe*): Scintillation from ionized Xe (Xe+): j.carlton@uky.edu PEN \u25cfSimilar to PIENU \u25cbSegmented \u25cbBetter timing \u25cfMany channels of pure CSI \u25cb240 channels \u25cfActive target Citation:PEN: a low energy test of lepton universality , PENcollab, (arxiv: 1701.05254) j.carlton@uky.edu More ATAR details \u25cfPion and muon decays deposit energy into ATAR \u25cfAllow event types to be distinguished \u25cfMuons decaying in flight can boost positron energy past 53 MeV (big issue!) \u25cbATAR can give information to rebuild event, and correctly classify a muon decay arxiv: 2203.01981 Citation: PSI Ring Cyclotron Proposal R-22-01.1 PIONEER: Studies of Rare Pion Decays, PIONEER collab, (pg. 19 arxiv: 2203.01981) j.carlton@uky.edu Another Calorimeter 3D Render (Liquid Xenon) Citations: PIONeer A next-generation rare pion decay experiment, David Hertzog, (https://pioneer.npl.washington.edu/docdb/0002/000281/001/PIONEER%20Orientation%20an d%20Status%20June%202024.pdf) j.carlton@uky.edu Electronics and Data Rates j.carlton@uky.edu j.carlton@uky.edu Initialism Meaning Example 10GbE 10 Gigabit Ethernet FPGA Field Programmable Gate Array FMC FPGA Mezzanine Card FC7 SFP Interface CPU Central Processing Unit Intel Core i7-12700K GPU Graphics Processing Unit NVIDIA A5000 \u00b5TCA (uTCA) Micro Telecommunications Computing Architecture WFD Waveform Digitizer WFD5 FC Flexible Controller FC7 AMC Advanced Mezzanine Card AMC13 (also FC7 and WFD5) MCH MicroTCA Carrier Hub DDR Double Data Rate DDR3, DDR4 (RAM) PCIe Peripheral Component Interconnect Express PCIe2, PCIe3, ... TTC Timing, Trigger, and Control UART Universal Asynchronous Receiver-Transmitter Initialism Cheatsheet Hardware - Conceptual Diagram \u25cfDifferential signal into WFD5 (Waveform Digitizer) \u25cfTrigger signal into FC7 (Flexible Controller) \u25cfAMC13 (Advanced Mezzanine Card) gathers data, sends over 10GbE (10 Gigabit Ethernet) to desktop \u25cfMCH (MicroTCA Carrier Hub) facilitates Desktop\u2194Crate communication over 1GbE \u25cfDesktop CPU handles event processing \u25cfMeinberg gives trigger timestamp to computer Differential Signal(s) Trigger WFD5(s) FC7 AMC13(s) MCH Desktop Ribbon Cable Optical Pentabus Cable Crate Optical Crate Crate Crate 1GbE Ethernet Red - Data Blue - Trigger Gray - Control Crate Bank Meinberg SMA SMA to D9 To storage Crate components PCIe j.carlton@uky.edu Hardware - Unlabeled Picture j.carlton@uky.edu PIONEER DAQ (in a nascent state) \u25cfPIONEER DAQ \u25cbIn nascent development state \u25cbDesign catered to PIONEER full experiment necessities PIONEER ADC schematic drawings Citation: DAQ electronics status, Lawrence Gibbons (Slide 1) https://pioneer.npl.washington.edu/cgi-bin/private/ShowDocument?docid=245 j.carlton@uky.edu \u201cOlder\u201d PCIe DMA Transfer Rates are Better \u25cfTransfer rates using block ram in a computer with an older OS (CentOS7) \u25cfThere is a leveling off effect at high transfer sizes \u25cfXDMA driver by Xilinx seems to changes with kernel version, causing performance differences j.carlton@uky.edu Average Transfer Rate [MB/s] Transfer Size Transfer Speed Vs. Transfer Size Data Rates (CALO data rates LXe/LYSO dependant) arXiv:2203.01981 \u25cfPIONEER DAQ expects data rate of ~ 3.5GB/s \u25cfConsidering running time, this is ~ 35,000 TB/year \u25cfHow do we compress this in real time? \u25cbFit data, store fit parameters \u25cbCompress and store residuals, throw some out \u25cbGraphics Processing Units (GPUs) used for this operation Citation: PSI Ring Cyclotron Proposal R-22-01.1 PIONEER: Studies of Rare Pion Decays, PIONEER collab (pg. 33) j.carlton@uky.edu PSI Data j.carlton@uky.edu LYSO Information \u25cfLYSO \u2013 lutetium\u2013yttrium oxyorthosilicate \u25cbLutetium (73%), Oxygen (18%), Silicon (6%), Yttrium (3%), and a Cerium scintillation dopant ( \u223c 0%) \u25cfDensity = 7.4 g/cm3 \u25cfX0 = 1.14 cm = \u201cRadiation length\u201d = distance for an electron's energy to be reduced by a factor of 1/e \u25cfRM = 2.07 cm = \u201cMoli\u00e9re radius\u201d = radius of a cylinder containing on average 90% of the shower's energy deposition \u25cfLight Yield = 30,000 photons/MeV \u25cfScintillating decay time = 40 ns j.carlton@uky.edu Citation: Measurements of a LYSO crystal array from threshold to 100 MeV, PIONEER collab (arxiv: 2409.14691) Energy Resolution Definition \u25cfEnergy resolution = \u0394E/E \u25cbE is the peak energy \u25cb\u0394E is the width of the peak \u25cfGaussian fit around the peak \u25cba \u201ccrystal ball\u201d fit is used here \u25cbGaussian around center, x-n on \u201csides\u201d where n is a parameter \u25cbGaussian parameter \u03c3 used for \u0394E \u25cfIn this case, p4 = E = 70.80 \u00b1 0.02 MeV \u25cfp3 = \u0394E = 1.098 \u00b1 0.014 MeV \u25cf\u0394E/E = 0.0155 = 1.55% j.carlton@uky.edu Citation: Omar Beesley, LYSO Updates/Answer https://pioneer.npl.washington.edu/docdb/0003/000312/001/LYSO%20Updates _Answers%20%28General%20Meeting%2010_22_24%29.pdf Timing Resolution Definition \u25cfUse the strongest signal in an event as reference signal. \u25cbt0 = time of peak \u25cfIn the same event find all crystal peaks ti \u25cbOnly use peaks above some energy threshold \u25cf\u0394t = t0 - ti \u25cbThe width of a gaussian fit to a histogram of all such measurements gives the timing resolution j.carlton@uky.edu Citation: Omar Beesley, LYSO Updates/Answer https://pioneer.npl.washington.edu/docdb/0003/000312/001/LYSO%20Updates _Answers%20%28General%20Meeting%2010_22_24%29.pdf Results - Timing Resolution \u25cfTiming resolution for 70 MeV events expected to be about 122.5 ps \u25cfThis measurement was largely influenced by noise from incorrect high voltage during test beam \u25cbUsing a system of synchronized LEDs, clean, simultaneous signals were generated at UW \u25cbImproved timing resolution to about 60 ps \u25cbAbout that same as LXe j.carlton@uky.edu Citation: Measurements of a LYSO crystal array from threshold to 100 MeV, PIONEER collab (arxiv: 2409.14691) Results - Energy Resolution \u25cfEnergy resolution is uniform near the center of the lyso array \u25cfTowards the edges the energy resolution decreases due to leakage \u25cbIn this case, into the NaI array j.carlton@uky.edu Citation: Measurements of a LYSO crystal array from threshold to 100 MeV, PIONEER collab (arxiv: 2409.14691) Vertical (y-axis) Horizontal (x-axis) Compression and Entropy j.carlton@uky.edu Data Set Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) \u25cfPSI Test beam, Run 1887 \u25cf70 MeV/c centered on LYSO crystal 4. \u25cfThe data only includes lyso channels (no NaI for instance) \u25cf More details on that run are in this elog (https://maxwell.npl.washington.edu/ elog/pienuxe/R23/124 )0 1 2 3 4 5 9 86 7j.carlton@uky.edu Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) j.carlton@uky.edu Entropy and Lossless Compression \u25cfFor lossless compression, the best possible compression rate is the entropy rate \u25cfTo first order, the entropy of an entire trace is: \u25cf is the random variable for the ADC value of the ith sample in the trace with n samples \u25cfIf we assume independent, then \u25cfBy transforming ( \u2192 fit residuals), becomes approximately independent Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) j.carlton@uky.edu Higher Order Entropy Estimations \u25cfAssume we have N characters (traces) in our alphabet (data set) \u25cfZero order: each character in alphabet is statistically independent \u25cfFirst order: each character in alphabet is statistically independent, pi is the probability of that character to occur \u25cfSecond order: Pj|i is correlation between subsequent characters \u25cfGeneral Model (impractical): Bn represents the first n characters Citation: Coding and Information Theory Class Notes, Dr. Jay Weitzen, University of Massachusetts Lowell https://faculty.uml.edu/jweitzen/16.548/classnotes/Theory%20of%20Data%20Compression.htm#:~:text=When%20the%20 compression%20is%20lossless,rate%20is%20the%20entropy%20rate j.carlton@uky.edu Joint Entropy, Mutual Information Equality only holds if This means if Then we must have and be statistically independent Citation: Joint Entropy, Wikipedia https://en.wikipedia.org/wiki/Joint_entropy j.carlton@uky.edu Joint entropy for Independent Variables Proof Statement: Proof (part 1): (Note: I am lazy, each P(xi) represents a different pdf in general) Citation: Proof from stackexchange https://math.stackexchange.com/questions/3519345/joint-entropy-of-2-independent-random-variables j.carlton@uky.edu Joint entropy for Independent Variables Proof Proof (part 2): Citation: Proof from stackexchange https://math.stackexchange.com/questions/3519345/joint-entropy-of-2-independent-random-variables j.carlton@uky.edu Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) j.carlton@uky.edu Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) j.carlton@uky.edu Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) j.carlton@uky.edu Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) j.carlton@uky.edu Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) j.carlton@uky.edu Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) j.carlton@uky.edu Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) j.carlton@uky.edu Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) j.carlton@uky.edu Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) j.carlton@uky.edu Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) j.carlton@uky.edu Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) j.carlton@uky.edu Mutual Information Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) \u25cfMutual Information: \u25cf no correlation \u25cfTemplate fitting reduces correlations between subsequent samples Sample # Sample # Sample # Sample # Mutual Info Mutual Info Template fitting j.carlton@uky.edu Entropy Estimation Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) \u25cfAverage entropy: \u25cfIn this case N = 800 \u25cfBefore: Havg = 5.22 bits/sample \u25cfAfter: Havg = 3.55 bits/sample \u25cfSome room for improvement(?) Time [c.t] Time [c.t] Template fitting Entropy/sample [bits] Entropy/sample [bits] j.carlton@uky.edu Explanation of Entropy Plot \u25cfThe pedestal is easy to fit, so the variance of the pedestal part of the signal is is just the noise of the WFD5s. \u25cbThis is the minimum possible entropy when using this equipment \u25cfThe signal is harder to fit and therefore has more variance \u25cbEntropy of this part of the trace is therefore larger Time [c.t] Entropy/sample [bits] Entropy Rate of PSI Test Beam Data After Fitting Signal entropy Pedestal entropy Pedestal entropy j.carlton@uky.edu Theoretical Best Compression Calculation Assuming data is sent as 12 bit ADC samples over PCIe at a data rate of 3.5 GB/s: Entropy rate = 3.4 \u2192 New Data Rate \u2248 0.99 GB/s Entropy rate = 5 \u2192 New Data Rate \u2248 1.46 GB/s j.carlton@uky.edu Continuing Support for Test Stand DAQ \u25cfInstitutions that currently use or plan to use the test stand DAQ in some capacity: \u25cbCENPA at University of Washington \u25cbTRIUMF, Canada \u25cbPSI, Switzerland \u25cfMaintaining and developing software to fit specific needs of each institution j.carlton@uky.edu Signal Conditioning \u25cfWant a narrow distribution for compression. Let ri be the numbers we compress \u25cfMethods tried: \u25cbNo conditioning \u25cbDelta encoding: ri = yi+1-yi \u25cbTwice Delta Encoding: ri = yi+2-2yi+1+yi \u25cbDouble Exponential Fit: ri= yi - (A \u22c5exp(ati)+ B \u22c5exp(bti)) \u25cbShape Fit : ri =yi- (A \u22c5T(ti-t0) + B) No Conditioning Shape Fit Frequency Frequency Voltage [Arbitrary Units] Voltage [Arbitrary Units] j.carlton@uky.edu Shape Fitting Algorithm 1.Construct a discrete template from sample pulses 2.Interpolate template to form a continuous Template, T(t) 3.\u201cStretch\u201d and \u201cshift\u201d template to match signal: [Note: a and b can be calculated explicitly given t0] 4.Compute \u03c72 (assuming equal uncertainty on each channel i) 5.Use Euler\u2019s method to minimize \u03c72 j.carlton@uky.edu Lossless Compression Algorithm \u25cfRice-Golomb Encoding \u25cbLet x be number to encode y = \u201cs\u201d+\u201cq\u201d+\u201dr\u201d \u25a0q = x/M (unary) \u25a0r = x%M (binary) \u25a0s = sign(x) \u25cbAny distribution \u25cbClose to optimal for valid choice of M \u25cbOne extra bit to encode negative sign \u25cbSelf-delimiting \u25cbIf quotient too large, we \u201cgive up\u201d and write x in binary with a \u201cgive up\u201d signal in front Value Encoding -1 011 0 000 1 001 2 1000Rice-Golomb Encoding (M=2) Red = sign bit Blue = quotient bit(s) (Unary) Yellow = remainder bit (binary) j.carlton@uky.edu How to choose Rice-Golomb parameter M \u25cfGenerated fake Gaussian data (centered at zero) with variance \u03c32 \u25cfFor random variable X, M \u2248 median(|X|)/2 is a good choice \u25cbThis is the close to the diagonal on the plot \u25cf\u03c3 \u2248 32 for residuals of shape on wavedream data \u2192 M = 16 is a good choice Gaussian Noise \u03c3 MCompression Ratio Determining Optimal M waveDREAM test j.carlton@uky.edu Compression Ratio from Rice-Golomb Encoding \u25cfLossless compression factor of ~2 \u25cfIn agreement with plot from simulated data on last slide \u25cfBest compression ratio we achieved Rice-Golomb Compression on Residuals (M = 16) Compression Ratio Sample Index j.carlton@uky.edu Real Time Compression Algorithm \u25cfWe choose to let the FE\u2019s GPU and CPU handle compression for flexibility CPU GPU Copy initial guess, Y(t0) Allocate memory for X,Y(t0),t0*,t,r,r\u2019c timeCompute initial guess fit Y(t0)Initialization (one time) Data loop (many times) Copy many traces, X (Overwrite) Wait for enough traces\u2026 Launch 1 thread per trace Compute t0*, via \u03c72 minimization, r = X-Y(t0*)Copy r\u2019c, t0*Use header info from r\u2019c to allocate memory for rcAllocate memory for X,Y,t,r\u2019c Golomb encode r \u2192 r\u2019cStitch together rc from r\u2019c Store rc, t0*j.carlton@uky.edu GPU Benchmarking (Timings) \u25cfBlock Size: \u25cbA GPU parameter, number of threads per multiprocessor \u25cfCan compress 226 integers (32-bit) in roughly \u2153 of a second. \u2192 ~ 0.8 GB/s compression rate Time [s] # of 32-bit Integers Fit + Compression Time using A5000 in PCIe4 (Batch Size = 1024) j.carlton@uky.edu GPU Benchmarking (Timings) \u25cfBatch Size: \u25cbHow many integers are compressed by a single GPU thread \u25cfData must be sent to GPU in batches (not a continuous flow) to take full advantage of parallel computation j.carlton@uky.edu FPGA Firmware Design j.carlton@uky.edu FPGA Firmware Ideas \u25cfVivado allows creating custom AXI IP blocks \u25cfThis could allow for periodically editing registers in the on board RAM by using a AXI IP block to communicate between FPGA and RAM \u25cbAllows for simulating data acquisition and reading in data based on \u201ccontrol\u201d registers j.carlton@uky.edu Block diagram for PCIe DMA transfer with proposed custom IP block connection Custom IP block Master AXI 2nd Slave AXI Clock input",
    "textLength": 5885
  },
  {
    "kind": "presentation",
    "title": "DAQ Progress Report 08_15_2023_2023-08-15_15-53-50.pdf",
    "fileName": "DAQ Progress Report 08_15_2023_2023-08-15_15-53-50.pdf",
    "url": "resources/presentations/DAQ Progress Report 08_15_2023_2023-08-15_15-53-50.pdf",
    "createdDate": "2023-08-15",
    "text": "Addressing Some Questions \u25cfFront end (FE) Computer plan: \u25cbFermilab to return three FE computers to UKy that have 2x10GB links and 2xK40 GPUs. \u25cbOne to go to UW then go to PSI as the readout frontend \u25cfData Rate \u25cfHigher trigger rate (>10 kHz) additional preparation will need to be made \u25cbThrow out portion of data \u25cbUse GPU compression \u25cbAdditional storage (~100TB) Assumptions: \u25cf1 kHz trigger rate \u25cf50 digitizer channels \u25cf100 16-bit samples per digitizer sample ~10 MB/s \u2248 1 TB/day Current Progress Hardware and Frontend code: \u25cfAll necessary frontends initialize \u25cfChanging logic in AMC1300 frontend \u201cbegin run\u201d code to expect one crate system \u25cfNo meaningful data readout yet Backend code: \u25cfBegan taking steps towards event reconstruction \u25cbPoking through g-2 midas files, Cornell teststand generated files to understand data structure \u25cbOffline read-in using python Development Steps (Rough Outline) \u25cfCompiled UKY g-2 teststand DAQ (software only) \u25cbUses more recent midas version \u25cfModified AMC13xx frontend code to edit ODB to match configuration file \u25cfCompiled modified g-2 DAQ on Cornell teststand \u25cbConnected and communicated with frontend hardware (AMC13s with FC7s or WFDs) \u25cfSwap out hardware to one crate system \u25cfRemove/replace hard coded references to FC7 crate from frontends \u25cfGenerate data, check \u201cintegrity\u201d of files \u25cfClean up DAQ for easier user control, package with modified midas, distribute Example crate contents configuration file",
    "textLength": 224
  },
  {
    "kind": "presentation",
    "title": "UKY Group Report 02_04_2026_2026-02-04_05-26-37.pdf",
    "fileName": "UKY Group Report 02_04_2026_2026-02-04_05-26-37.pdf",
    "url": "resources/presentations/UKY Group Report 02_04_2026_2026-02-04_05-26-37.pdf",
    "createdDate": "2026-02-04",
    "text": "PIONEER ML Based Reconstruction Status Jack Carlton University of Kentucky PIONEER Simulation Framework \u25cfSeries of software steps to simulate the PIONEER experiment \u25cb Work in progress \u25cb Adapts as we develop our detectors/strategy \u25cfReconstruction designed to be used on simulated and real detector data \u25cb Current goal: proof of concept \u25cb Future goal: reconstruction of experimental data \u25cfMost effort at UKy has been on the event reconstruction stage \u25cb Particular for the ATAR \u25a0 Pattern finding \u25a0 More recently: AI Reconstruction approach Citations: PIONEER Slides from ACTS Workshop, Patrick Schwendimann Simulation and Analysis Presentation, Quentin Buat Monte Carlo (Geant4 Based) Detector Response (Gaudi Based) Event Reconstruction (Gaudi Based) Reconstructed Data Truth level physics interaction data in space of detectors Realistic detector output data Physical events reconstructed from detector data Why Reconstruction Can be an AI task \u25cfSimulation provides all needed information \u25cbGeant4 simulation gives truth targets (ex. Positron angle, true pion stop) \u25cbDetector response gives inputs (ex. ATAR strip hit 5D information) \u25cfThe simulation can produce large quantities of data needed for training Monte Carlo Detector Response Traditional Reconstruction Truth Data Detector Data Model Training AI Reconstruction Reconstructed Data Reconstructed Data Trained Models One time training cost Current Status: Data Flow \u25cfModels ultimately will run in the simulation framework, options: \u25cbTorchScripts run in C++ \u25a0Least friction with current development efforts \u25cbGaudi python stages \u25a0Likely too slow \u25cbPybinds running model \u25a0Likely too slow \u25cfTraining must remains in Python \u25cbML ecosystem is much more mature in python \u25cfLogic should be shared until division is necessary \u25cbNatural division is right before creating torch objects Monte Carlo + Detector Response Parquet Arrow C++ Data Loaders PyTorch DataLoader PyTorch Model Once, offline file generation Disk \u2192 RAM Copy Zero-copy views of data Torch DataLoader TorchScript Model Export TorchScript Model C++ Python Current Status: Training \u25cfPyTorch \u25cbProvides a standard base abstraction classes for many model types (ex. nn.Module ) \u25cbEnforces a consistent model interface (ex. forward method) \u25cfZenML \u25cbEncodes pipelines as composable, declarative units and orchestrates execution \u25cbAllows pipelines to grow by adding or reordering steps; easy to add new pipelines \u25cbManages pipeline state, artifacts, and execution metadata outside user code \u25cfOptuna \u25cbIsolates hyperparameter search code \u25cbEnables experimentation without modifying core implementations \u25cbReally a package for black box searching, by default uses Tree-Structured Parzen Estimator (TPE) Simplified Example Pipeline for Training Models Data Construction Optuna Optimization Model Training Evaluation Pipeline Parameters Trained Model ZenML Pipeline Load shard data Build graph inputs Sample hyperparameters Decide next trial Train our model implementation Compute metrics Inform hyperparameter search Finished when hyperparameter search ends Task: Running Models in Simulation Framework \u25cfGoal: Implement ML reco stages that are \u201chot-swappable\u201d with traditional reco stages \u25cbIdeal scenario for benchmarking performance of ML models in terms of physics goals \u25cfProblem: Models need to operate on batched data for performance, Gaudi framework designed for event by event reconstruction \u25cbHow to optimally interface traditional stage \u2192 ML stage \u2192 traditional stage is unclear \u25cbML stage speed performances must be on par with traditional reco speed performances Reco Stage 1A Reco Stage 2A Reco Stage 3A AI Reco Stage 2A . . .Gaudi Reconstruction Pipeline AI Reco Stage 2B Reco Stage 2B . . .Hot-swappable stages Task: Optimizing Accuracy of Models \u25cfUse graph transformers for every task currently \u25cb These are among the most expressive AI models \u25a0 Particularly effective for high-context, relational tasks (i.e. the ATAR reconstruction) \u25cb Computation expensive \u25a0 Are they necessary for every task? \u25a0 Can we achieve similar accuracy on some tasks with simpler models? \u25cfAre there more ways we can give the model \u201chints\u201d at relevant features to improve accuracy? \u25cb Similarly can we reduce computational expense by removing unneeded information? direction in detector coordinate system with uncertainty Graph Input Graph Transformer based ML Model Model Predictions Mental model that every ML model in our pipeline currently follows Task: Training on Multiple Compute Nodes \u25cfGoal: be able to run training on arbitrary sized computing clusters \u25cfIdea: Use Kubernetes to schedule Dockerized training pipelines orchestrated with ZenML \u25cbDesigned the codebase to support it, but haven\u2019t deployed the Kubernetes backend yet \u25a0What will be in each pod? How many resources for each pod? \u25cbAre other technologies useful for this task? \u25a0PyTorch DDP? Simplified \u201cScope\u201d Of Technologies Outer Technologies Manage Inner Technologies Kubernetes Distributes pipeline containers as black boxes Pipeline Container (ZenML) Pipeline logic, I/O, bookkeeping, etc. PyTorch Model semantics CUDA Kernels, threads, overall GPU execution Auxiliary Slides Why use Graph Transformers? \u25cfThese are among the most expressive modern ML models \u25cbCan solve a wider class of problems than most models \u25cfFairly easy to construct with torch geometric \u25cfAttention based transformers allow models to learn how event information is related, as opposed to having to be more explicitly \u201ctold\u201d in a traditional GNN approach Repositories \u25cfPIONEER simulation (private, need access) \u25cbYou can follow these instructions to get started in a docker container \u25cbDetReponse and shared branches with ML dataset generation code \u25a0Caveat: the docker container does not yet have Apache Arrow installed \u25cfThis is needed for creating parquet files for training/running ML models \u25a0I typically create a static container then install Apache Arrow myself \u25cfpioneerML (public) \u25cbWIP \u25a0use branch refactor/parquet-dataset-boundary for now \u25cbYou can build a docker image with ./scripts/docker/build.sh \u25cbYou can run the built docker image with ./scripts/docker/run.sh --static --gpu -p 8888:8888 \u25cbMuch of the codebase is \u201cout of whack\u201d right now, but it in principle contains tools to create data loaders, training pipelines, inference tests, etc.",
    "textLength": 903
  },
  {
    "kind": "presentation",
    "title": "Simulation Progress Report 4_23_2025_2025-04-23_21-34-41.pdf",
    "fileName": "Simulation Progress Report 4_23_2025_2025-04-23_21-34-41.pdf",
    "url": "resources/presentations/Simulation Progress Report 4_23_2025_2025-04-23_21-34-41.pdf",
    "createdDate": "2025-04-23",
    "text": "Pattern Finding Performance Using Current Tracklet Finding Algorithm Jack Carlton University of Kentucky Short Overview \u25cfTracklet finding reconstruction data can be used in python pattern finding test playground \u25cbUse it to see how pattern reconstruction performs using reconstructed tracklets as opposed to truth \u25cfOverall performance worse compared to previous plots \u25cbBefore we used truth information from tracklets, so this is unsurprising \u25cfPerformance of vertex finding algorithm improved using the new tracklet reco\u2019s endpoints \u25cbBefore, we were using Sean\u2019s fitting algorithm to determine endpoints of tracklets \u03c0\u2192\u03bc\u2192e Performance Difference using x-z info only \u03c0\u2192e Performance Difference using x-z info only Auxiliary Slides \u03c0\u2192\u03bc\u2192e (Reconstructed Tracklet Evaluation, x-z info only) \u03c0\u2192\u03bc\u2192e (Truth Tracklet Evaluation, x-z info only) \u03c0\u2192e (Reconstructed Tracklet Evaluation, x-z info only) \u03c0\u2192e (Truth Tracklet Evaluation, x-z info only) \u03c0\u2192\u03bc\u2192e (x-z info only) Validation Using True Tracklets \u2192 True Patterns Vs. Reco Tracklets \u2192 True Patterns vs \u03c0\u2192e (x-z info only) Validation Using True Tracklets \u2192 True Patterns Vs. Reco Tracklets \u2192 True Patterns vs",
    "textLength": 183
  },
  {
    "kind": "presentation",
    "title": "DAQ Progress Report 07_11_2023_2023-07-11_16-57-35.pdf",
    "fileName": "DAQ Progress Report 07_11_2023_2023-07-11_16-57-35.pdf",
    "url": "resources/presentations/DAQ Progress Report 07_11_2023_2023-07-11_16-57-35.pdf",
    "createdDate": "2023-07-11",
    "text": "Basic Development Goals \u25cfDevelop a DAQ capable of handling a single crate system \u25cbWFDs and FC7s in same crate \u25cfDo this by modifying g-2 DAQ \u25cbMaintains analysis software \u25cbSame hardware used Crate(s) of FC7s and WFDs ...Array of FEs, BE, Midas server ... Rest of Experiment Simplified DAQ Diagram Development Steps (Rough Outline) \u25cfCompiled UKY g-2 teststand DAQ (software only) \u25cbUses more recent midas version \u25cfModified AMC13xx frontend code to edit ODB to match configuration file \u25cfCompiled modified g-2 DAQ on Cornell teststand \u25cbConnected and communicated with frontend hardware (AMC13s with FC7s or WFDs) \u25cfSwap out hardware to one crate system \u25cfRemove/replace hard coded references to FC7 crate from frontends \u25cfGenerate data, check \u201cintegrity\u201d of files \u25cfClean up DAQ for easier user control, package with modified midas, distribute Example crate contents configuration file",
    "textLength": 137
  },
  {
    "kind": "presentation",
    "title": "DAQ Presentation Collaboration Meeting October 2025_2025-10-07_07-01-21.pdf",
    "fileName": "DAQ Presentation Collaboration Meeting October 2025_2025-10-07_07-01-21.pdf",
    "url": "resources/presentations/DAQ Presentation Collaboration Meeting October 2025_2025-10-07_07-01-21.pdf",
    "createdDate": "2025-10-07",
    "text": "PIONEER DAQ Development Jack Carlton University of Kentucky October 16th, 2025 j.carlton@uky.edu 1/10 g-2 DAQ modified - Usage for LYSO testbeam \u25cfIteration on previous LYSO test beam \u25cfRate limited by HDD write speed ~250 MB/s \u25cbFor small scale experiments, could be solved by writing directly to SSDs (>1GB/s write speed) \u25a0Limited by SSD space (\u22648TB for consumer electronics) \u25cfDesyncs between crate data caused (mostly) recoverable issues \u25cb ~2% of events across all data runs are desynced j.carlton@uky.edu 2/10 Two crate setup used at PSI LYSO Testbeam Run Crates Channels Used Event Rate (Hz) Data Rate (MB/s) 2023 PSI LYSO Test Beam 1 ~50 ~400 ~30 2025 PSI LYSO Test Beam 2 ~60 ~2500 ~200 g-2 DAQ modified - Desync Issues \u25cfDesync issues should be fixed \u25cbReplicated the issue on the UKy teststand \u25a0Caused by internal ring buffer overflows (\u201c GPU_BUFFER \u201d) \u25cbFixed software bug preventing trigger throttling from working properly \u25a0Trigger throttles apply back pressure to prevent ring buffer overflows \u25cfFor the testbeam we used a \u201cband-aid\u201d solution \u25cbEvent builder stops run on desync detected \u25cbRun is restarted immediately \u25cbGives the crates time to recover \u25cbDownsides: splits data runs, likely not scalable for many crates j.carlton@uky.edu 3/10 All desynced subruns in 2025 PSI LYSO Testbeam HDSoC DAQ - Status \u25cfHDSoC is (was?) a candidate ATAR digitization system \u25cfMidas frontend working \u25cbSupports internal and external trigger settings \u25cbHandles HDSoCv1 rev2 max data rate of ~55 MB/s \u25cfDocumentation (manual) available \u25cbDetails setup, configuration, etc. \u25cfUnpacker app available \u25cbUnpacks midas data into ROOT tree, stores in analyzable .root files j.carlton@uky.edu 4/10 Nalu\u2019s HDSoC FMC attached to a Nexys A7 Video Card HDSoC DAQ - Next Steps \u25cfLow priority for the time being \u25cbNot actively working on development \u25cbDevelopment focus shifted to to SAMPic system \u25cfUndergraduate Brennan Edwards doing studies on HDSoC digitized data \u25cbTiming resolution studies \u25a0Constructs \u201cpseudo time\u201d of leading and trailing edge \u25a0Then constructs true time differences between events \u25a0Similar to g-2 analysis j.carlton@uky.edu 5/10 Distribution of true time differences between consecutive events [preliminary analysis] Two consecutive events used to create time difference SAMPic DAQ - Status \u25cfWorking midas integration \u25cbConverts ODB params \u2192 Sampic settings for most settings \u25cb1 thread to collect \u201cSAMPic Events\u201d \u25cb1 thread to form \u201cSAMPic Events\u201d into \u201cFrontend Events\u201d \u25a0Frontend events may span multiple sections of \u201cSAMPic Events\u201d \u25cb1 thread to handle midas state machine \u25cfEvent formation logic is hot swappable for ease of development j.carlton@uky.edu 6/10 Data flow diagram for SAMPic Data SAMPic DAQ - Next Steps \u25cfRates tests \u25cbOnly tested using simple cases so far (~KB/s rates) \u25cbNeed to test more realistic rates (~10kHz/~100 MB/s) \u25cfImplement more realistic event formation \u25cbTrigger architecture details needed to finalize event formation design \u25cfWrite an unpacker to analyze/debug midas data \u25cbCan adapt Midas file unpacker app to do this jobj.carlton@uky.edu 7/10 Example Digitized trace from SAMPic System Supplementary Software - Flexible DQM \u25cfUsed in PSI 2025 LYSO Testbeam \u25cbWorked okay, needed some live bugfixes \u25cbConfigurable to any experiment (with some boilerplate additions) \u25cfManual , wikis, tutorials, and repos available j.carlton@uky.edu 8/10 Data flow diagram for DQM Example DQM webapp page view Supplementary Software - Unpacker Application \u25cfApplication to convert midas files to ROOT Trees \u25cbWork in progress \u25cbCurrently on works for HDSoC midas data \u25cbPlans to add SAMPic midas data support \u25cbAdaptable to event structure changes \u25cbCurrent does not support g-2 modified DAQ midas data, can use sean\u2019s unpacker \u25cfAdding new unpackers simplified \u25cbBoils down to adding new plugins in the analysis pipeline framework j.carlton@uky.edu 9/10 Example HDSoC data ROOT tree formed by the application Supplementary Software - Analysis Pipeline Framework \u25cfLightweight, configurable pipeline framework for ROOT data \u25cbInspired by Gaudi, but simpler and faster to deploy \u25cbBuilt on ROOT, leveraging: \u25a0Plugin system for modularity \u25a0Reflection for flexible configuration \u25a0Custom data products \u25cf\u201cBackbone\u201d of apps: \u25cbZMQ publisher (part of DQM framework) \u25cbMidas file unpacker app \u25cfDocumentation available \u25cbWiki \u25cbRepo j.carlton@uky.edu 10/10 Example data flow diagram for an analysis pipeline Auxiliary Slides Study on desynced data \u25cfElog available \u25cfClock signal fanned out out into both crates \u25cfShowed the DAQ \u201crecovered\u201d from desyncs properly j.carlton@uky.edu x/14 Cross correlated of time offset between both crate clock signals Clock signal fanned out in both crates for synced event More on desyncs \u25cfDesyncs occurred in multiples of the GPU buffer size (512) \u25cfSaw periods of \u201cinstability\u201d and periods of recovery j.carlton@uky.edu x/14 Trigger index for each module across subruns Trigger index for each module across one subrun g-2 DAQ modified - Next steps \u25cfPolish the code for trigger throttling before pushing \u25cfFind a solution to HDD bottleneck \u25cbNo bottleneck for: \u25a0Low rate (<~250MB/s) applications \u25a0Low storage (<~2TB) applications \u25cbPotential solution if usage case is under ~16 TB \u25a0Buy large SSDs (ex. 8TB ~ 500$) \u25cbNeed to revisit g-2 solution for larger applications HDSoC DAQ - Hardware \u25cfDAQ is functional and integrated into MIDAS \u25cfCan digitize data rates up to 55 MB/s, event rates up to 30 kHz* *For specific parameters Nexys A7 Video Board with Nalu\u2019s HDSoC Digitizer Attached as an FMC Module Conceptual Hardware Diagram for the HDSoC Readout HDSoC DAQ - Software \u25cfWrote a midas frontend that leverages custom libraries created for readout \u25cbNalu Board Controller \u25cbNalu Event Collector \u25cfSeparate branch for rate testing , leveraging custom RP Pico W libraries created for automatic rate testing \u25cbRP Pico W remote controller \u25cbRP Pico W board interface Conceptual Software Diagram for the HDSoC Readout HDSoC DAQ - Rate Tests \u25cfMajority of input parameters \u2192 performance as expected \u25cfOutliers where we underperform \u25cbExpect good performance under 55 MB/s \u25cbLooking for cause of performance drops Expected Data Rate vs. Actual Data Rate Actual Data Rate (KB/s) Expected Data Rate (KB/s) HDSoC DAQ - Rate Tests \u25cfFor 32 channels (all active) \u25cf1 window = 32 12-bit ADC samples \u25cf1 Gsps \u25cfCan take 32 traces length 64 ns at rates ~20kHz reliably \u25cfEvents begin dropping near 55 MB/s threshold Normalized Event Rate vs. Frequency (32 channels) External Trigger Rate (Hz) Event Rate / External Trigger Rate ZeroMQ Publisher Application \u25cfConfigurable software to publish data over ZeroMQ \u25cfMain branched configured to use midas \u25cbNot technically necessary, data source can be anything \u25cbUses my midas receiver library \u25cfUses C++ Package Manager (CPM) to clone (most) dependencies from gitub and build them \u25cbLess work setting up environments for user Midas Receiver Library \u25cfLibrary gives methods to launch a thread that listens for midas events in an embedded, configurable way. \u25cfUsed by ZeroMQ receiver to receive events \u25cfSettings for how to receive data \u25cfDraw back: \u25cbSingleton, cannot have two receivers in one application (midas doesn\u2019t like this) Field Meaning / Function hostHostname or IP of the MIDAS experiment server; empty string (\"\") connects to the local host. experiment Name of the MIDAS experiment; empty string uses the default experiment for the host. bufferName Name of the shared memory event buffer (e.g., \"SYSTEM\", \"BUF001\"); determines which event stream is read. clientName Logical name for this receiver client; appears in the MIDAS client list (/mhttpd). eventID Event ID filter; EVENTID_ALL subscribes to all event types in the buffer. getAllEvents True receives all events blocking, false is nonblocking maxBufferSize Maximum number of events in circular buffer managed by receiver thread cmYieldTimeout Yield interval (ms) for midas communication manager. Smaller means it \u201ctalks\u201d to midas more transitionRegistrations List of (Transition, Priority) pairs registering interest in specific MIDAS state transitions. Receiver updates run # and errors on transitions. TR_START Run start transition; fired when a data-taking run begins. TR_STOP Run stop transition; fired when a run is stopped normally. TR_PAUSE Run pause transition; data taking temporarily halted without ending run. TR_RESUME Run resume transition; resumes data-taking after a pause. TR_STARTABORT Triggered on aborted start or initialization failure",
    "textLength": 1322
  },
  {
    "kind": "presentation",
    "title": "ATAR ML Based PIONEER Reconstruction as of 01_07_2026_2026-01-07_11-33-41.pdf",
    "fileName": "ATAR ML Based PIONEER Reconstruction as of 01_07_2026_2026-01-07_11-33-41.pdf",
    "url": "resources/presentations/ATAR ML Based PIONEER Reconstruction as of 01_07_2026_2026-01-07_11-33-41.pdf",
    "createdDate": "2026-01-07",
    "text": "ATAR ML Based PIONEER Reconstruction as of 01/07/2026 Jack Carlton University of Kentucky Monte Carlo \u2192 ATAR ML Reconstruction Division 0 Samples = Truth Events Division 1 \u201cupstream\u201d Samples = Time Groups G4Pioneer Monte Carlo + Detector Response Time Group Former Group Classifier Group Splitter Endpoint Regressor Event Builder (~Pattern Finder) Pion Stop Regressor Positron Angle Finder Truth level descriptions of entire events; optional event mixing Redefines a sample 1 sample = truth information about time grouped hits This is a \u201crealistic\u201d starting point from the ATAR raw output Adds group level particle class Adds hit level particle classes Adds endpoint (x,y,z) estimates Redefines a sample 1 sample = grouped time groups by event_id Adds pion stop (x,y,z) estimates Adds positron angle (sin\u03b8 cos\u03c6, sin\u03b8 sin\u03c6, cos\u03b8) estimates = Not an ML stage = An ML (trained) stage Event Grouper Division 2 \u201cdownstream\u201d Samples = Grouped Time Groups by event_id Redefines a sample 1 sample = graph where nodes are pooled/encoded summaries of a time group, edges are \u201caffinities\u201d between them; Division 3 \u201cdownstream\u201d Samples = Event level summarized graph G4Pioneer Monte Carlo + Detector Response \u25cfG4Pioneer Monte Carlo simulates the underlying physics \u25cbGeant4 Fork \u25cfDetector Response converts truth into detector-level signals \u25cbDepends on detector geometry \u25cbHandles event mixing \u25cfML training requires both detector-level outputs and truth-level information \u25cbCurrent Detector Response does not expose all required quantities cleanly \u25cbTODO: Add a Detector Response mode that writes all required detector + truth data to an RNTuple, forming a stable input for ML dataset construction Cartoon example of detector response with truth information added to hits Time Group Former \u25cfDetector response events are split into time-based clusters \u25cbThis stage determines the method we use to cluster the hits \u25cfTruth-level information (e.g. particle labels) is retained for ML targets \u25cfEach time group is one ML sample \u25cfA time group contains: \u25cbVariable-length hit-level features \u25cbFixed group-level summary features Cartoon example of time group spikes in energy deposition Group Classifier \u25cfMulti \u2011label GNN classifier \u25cfInputs: \u25cbDetector response information represented as a graph \u25cfTargets: \u25cbTruth level representation of what particles are in the group \u25cbParticularly: [pionInGroup, muonInGroup, MIPinGroup] \u25cfOutputs: \u25cbPredicted probability that the time group belongs to each class [prob_pionInGroup, prob_muonInGroup, prob_MIPinGroup] Cartoon example of time group spikes in energy deposition, now labeled by group classifier Group Splitter \u25cfMulti \u2011label GNN classifier \u25cfInputs: \u25cbDetector response information represented as a graph \u25cbPredicted time group level particle class \u25cfTargets: \u25cbTruth level representation of the particle type for each hit \u25cbParticularly, for each hit in the graph: [[is_pion, is_muon, is_mip], [is_pion, is_muon, is_mip], \u2026] \u25cfOutputs: \u25cbPredicted probability that each hit belongs to each class [[prob_pion, prob_muon, prob_mip], [prob_pion, prob_muon, prob_mip], \u2026] Cartoon example of how a time group may be split into multiple particle classifications \u03c0 \u03c0 \u03bc Endpoint Regressor \u25cfQuantile GNN Regressor \u25cfInputs: \u25cbDetector response information represented as a graph \u25cbPredicted time group level particle class \u25cbPredicted hit level particle classes \u25cfTargets: \u25cbTruth level endpoints \u25cbParticularly: [[x_start, y_start, z_start], [x_end, y_end, z_end]] \u25cfOutputs: \u25cbPredicted endpoints with quantiles [[[x_start_q1, y_start_q1, z_start_q1], [x_end_q1, y_end_q1, z_end_q1]], \u2026] Cartoon example of how we estimate endpoints with uncertainties given by the quantiles = Median endpoint estimate = Error range determined from quantiles Event Grouper \u25cfRe-groups time groups into events by event_id \u25cfForms a list of graphs \u25cfSide effect: \u25cbThe ML reconstruction is sensitive to how we define an ATAR event \u25cbThe traditional reconstruction has this same problem (?, need to check if the traditional reco uses event_id at all) Time group 0 Time group 1 Time group 2 Time group 3 All time groups with a given event_id Cartoon example of an event, or group of time groups Event Builder \u25cfAffinity GNN classifier \u25cfInputs: \u25cb Detector response information represented as a graph \u25cb Predicted time group level particle class \u25cb Predicted hit level particle classes \u25cb Predicted endpoint quantiles \u25cfTargets: \u25cb Agreement between truth level event origins between nodes; i.e. \u201care these two nodes from the same event\u201d. Explicitly: target_affinity[i][j] = 1 if origin_id[i] == origin_id[j] \u25cfOutputs: \u25cb Predicted \u201caffinities\u201d (0,1) \u25cb We construct a graph using this information, letting Nodes = pooled/encoded group summary \u25cfNote: \u25cb This module will NOT work if there are no mixed events in the data set, it effectively trains a null-op Time group 0 Time group 1 Time group 2 Time group 3 Node labels: On per time group graph, pooled/encoded summary of that group Edges: Learned affinity between groups (i.e. are two time groups from the same event?) Pion Stop Regressor \u25cfGNN Regressor \u25cfInputs: \u25cbGraph produced by event builder \u25cfTargets: \u25cbTruth level pion stop \u25cbParticularly: [x_stop,y_stop,z_stop] \u25cfOutputs: \u25cbPredicted pion stop [x_stop,y_stop,z_stop] = Pion stop estimate Cartoon example of pion stop estimate Positron Angle Regressor \u25cfGNN Regressor \u25cfInputs: \u25cbGraph produced by event builder \u25cfTargets: \u25cbTruth level direction vector for positron angle \u25cbParticularly: [sin \u03b8 cos\u03c6, sin \u03b8 sin\u03c6, cos \u03b8] \u25cfOutputs: \u25cbPredicted direction vector for positron angle [sin\u03b8 cos\u03c6, sin \u03b8 sin\u03c6, cos \u03b8] Cartoon example of positron angle estimate direction in detector coordinate system Auxiliary Slides Omar\u2019s Diagram \u25cfConceptually, all the same stages \u25cfI\u2019ve just added \u201cboundaries\u201d to my diagram; between each phase the definition of the dataset we train our models on changes \u25cfMuch better explained in Omar\u2019s presentation Current Discrepancies \u25cfWe have the following discrepancies from what I described in the current framework, but these will be changed: 1.Event mixing is done right before event building, so the \u201cphase 1\u201d stages don\u2019t see mixed event right now 2.There\u2019s no \u201cinfrastructure\u201d code that takes us from monte carlo to workable ML training data currently, Omar has his own \u201cspecial\u201d data conversion we\u2019ve been using Why Have Divisions? \u25cfEach pipeline stage operates on a well-defined \u201csample\u201d \u25cbEach division defines a dataset boundary \u25a0A dataset boundary is the point at which the meaning of a row is fixed and written to storage, so downstream stages can rely on it without knowing how it was produced \u25a0It\u2019s okay to create appending files or masks, \u25a0If you must mutate data (i.e. change your definition of a \u201csample\u201d then you create another dataset boundary), then you should create a new dataset boundary or \u201cdivision\u201d \u25cfIf we don\u2019t create clear divisions \u25cbHidden coupling between stages can occur \u25a0I.e. you change one stage, an unrelated stage no longer works \u25cbBatching becomes unclear \u25a0Your definition of a batch changes between data boundaries \u25a0Memory and performance become less predictable \u25cfIn short, each division should scale separately GraphRecord Former \u25cfWe don\u2019t store data as their graphs, we store them as the minimal information needed to build the graph \u25cfAs a result we have a \u201cdata loading stage\u201d before running any model where we construct a graph from the data Pion Stop Prediction \u25cfOne additional processing step before the event builder runs is the pion stop prediction is computed \u25cfThis is a minor step used to help downstream models \u25cfPion stop predicted as just the median of the endpoint predicted by the endpoint regressor model Example cartoon of the pion stop \u201cinitial guess\u201d used to help division 2 models = Median endpoint estimate Stereoscopic View \u25cfBefore each \u201cDivision 1\u201d model \u201cdoes it\u2019s job\u201d, it first construct a \u201cstereoscopic\u201d view of the data \u25cb Hits are split by view: \u25a0 0 = X plane, 1 = Y plane \u25cb Each view is embedded independently, then fused: [emb_view0, emb_view1, mask0, mask1] \u25a0 mask_i = 1 if view i has hits, else 0 \u25cb This process is learned for each model \u25cfWhy this helps: \u25cb Treats view ID as discrete routing \u25cb Explicitly encodes that intermediate views (e.g. \u201c0.5\u201d) do not exist \u25cfWhy we want this stage learnable: \u25cb weight each view \u25cb rescale per-view features \u25cb handle missing or weak views \u25cfWhy it\u2019s model-specific \u25cb Different tasks rely on views differently \u25a0 e.g. missing Y view matters more for endpoint finding than for particle classification View of x and y planes View of x plane View of y plane X plane contains all the hits Y plane does not contains any hits, the model learns to treat the case of an empty view differently than a standard \u201cfull\u201d view (empty) Exaggerated cartoon example of how a stereoscopic view can help in the case of missing views [emb_view0, 00\u2026000, 1, 0] + Quantiles \u25cfFor regressions, quantiles are useful to extract uncertainties \u25cfUses a quantile regression loss function \u25cfWe can use quantile regression to have our models target a specific quantiles \u25cbUsually we select \u25a0Lower quantile = 16 ~ 1\u03c3 \u25a0Mid quantile = 50 ~ median \u25a0Upper quantile = 84 ~ +1\u03c3 Wikipedia example of Quantile Regression. Notice how it forms confidence bands around the best fit (or median) Event Mixing \u25cfEvent mixing is already handled in the pioneer simulation framework in the detector response \u25cbEffectively piles up simulated events into one event. The number of simulated events and probability of pileup are parameterized. \u25cfCurrently, the ML reconstruction has its own version of event mixing that runs before division 2; this is",
    "textLength": 1481
  },
  {
    "kind": "presentation",
    "title": "UKY Group Report 12_10_2025_2025-12-10_14-26-15.pdf",
    "fileName": "UKY Group Report 12_10_2025_2025-12-10_14-26-15.pdf",
    "url": "resources/presentations/UKY Group Report 12_10_2025_2025-12-10_14-26-15.pdf",
    "createdDate": "2025-12-10",
    "text": "Training and Validation Details For Classification Models for PIONEER Reconstruction Jack Carlton University of Kentucky Time Group Classifier \u25cfI\u2019ll mostly be talking about Omar\u2019s \u201ctime group classifier model\u201d \u25cfInput: \u25cbTime grouped hit graph \u25a0Nodes: [x (or y), z, energy, view, group_energy] \u25a0Edges: [dx (or dy), dz, dE, same_view] \u25cbGroups split by time (could potentially contain multiple particle types) \u25cfOutput \u25cbClass labels: [muon, pion, mip] \u25cfMuch better explained in Omar\u2019s presentation Performance of Model \u25cfClosely matches performance of Omar\u2019s work \u25cfDifferences from Omar\u2019s work \u25cbUsed my machine to train \u25cbDid a hyperparameter search using Optuna \u25cbIncorporated into ZenML framework for creating pipelines in python \u25cfUnsure how this compares to the traditional reco values(?) \u25cfUnsure exact parameters in Omar\u2019s data set Performance of Model \u25cfHistograms below shows the models \u201csureness\u201d of each class \u25cfWant to see large peaks at 0 and 1 \u25cb0 \u2192 this is definitely not this class \u25cb1 \u2192 this is definitely this class \u25cfThe muon groups are the biggest struggle Preventing Overtraining (Early Stopping) \u25cfCan set early stopping when training loss curves \u25cbIf no meaningful (> \u03b4) improvement within N epochs, stop training \u25cbN := \u201cpatience\u201d usually set to ~5% of expected training epochs \u25cfPotential improvements: \u25cbLoss curve smoothing \u25cb\u201cNoise\u201d estimations, only continue training if smoothed improvement > noise of previous iterations \u25cfSee documentation *NOTE: This particular model is overtrained because N set to 6 (too high) Meaningful improvement in validation loss stops Reaches patience threshold (N=6) No improvement in 6 iterations Preventing Overtraining (PCA) \u25cfNeed a way to visualize many dimensions \u25cfPrincipal Component Analysis (PCA) good candidate for this \u25cfCompare clusters in embedding space vs. input space \u25cbInput space shows data driven groupings \u25cbEmbedding space shows learned groupings \u25cb# of groupings should match! Well-trained Over-trained Average vector of all nodes in graph: [coord, z_pos, energy, view, group_energy] 5D \u2192 2D 512D \u2192 2D 512D \u2192 2D Preventing Overtraining (PCA) \u25cfNeed a way to visualize many dimensions \u25cfPrincipal Component Analysis (PCA) good candidate for this \u25cbChoose to project down to d = 2 dimensions this way \u25cfCompare clusters in embedding space vs. input space \u25cbInput space shows data driven groupings \u25cbEmbedding space shows learned groupings \u25cb# of groupings should match! Well-trained Over-trained mipmuon pion 1 pion 2 muon mippion 1 pion 2 512D \u2192 2D pion 1 pion 2 muon muon 2? muon 3? mip 512D \u2192 2D Average vector of all nodes in graph: [coord, z_pos, energy, view, group_energy] 5D \u2192 2D Preventing Overtraining (t-SNE) \u25cfProblem with PCA \u25cbGlobal linear may not preserve local neighborhoods \u25a0May not show groups! \u25cft-distributed stochastic neighbor embedding (t-SNE) is designed to preserve local clusters \u25cbMaps N dims \u2192 d dims \u25a0We choose d = 2 for visualization ease \u25cfSame ideas as PCA \u25cbcompare input space and embedding space Well-trained Over-trained 512D \u2192 2D 512D \u2192 2D Average vector of all nodes in graph: [coord, z_pos, energy, view, group_energy] 5D \u2192 2D Preventing Overtraining (t-SNE) \u25cfProblem with PCA \u25cbGlobal linear may not preserve local neighborhoods \u25a0May not show groups! \u25cft-distributed stochastic neighbor embedding (t-SNE) is designed to preserve local clusters \u25cbMaps N dims \u2192 d dims \u25a0We choose d = 2 for visualization ease \u25cfSame ideas as PCA \u25cbcompare input space and embedding space Well-trained Over-trained 512D \u2192 2D 512D \u2192 2D mipmuon pion 1 pion 2 pion 1 pion 2 mip muon muon muon 2? muon 3? mip mip 2? mip 3? pion 1 pion 2 Average vector of all nodes in graph: [coord, z_pos, energy, view, group_energy] 5D \u2192 2D Preventing Overtraining (UMAP) \u25cfProblem with t-SNE \u25cb Depends on a \u201cPerplexity\u201d \u25a0 Parameter, ~how many neighbors a point can have \u25cb May artificially split or group clusters \u25cfUniform Manifold Approximation and Projection (UMAP) is designed to preserve the underlying manifold structure \u25cb Tries to preserve both local neighborhoods and their global relationships \u25cb Maps N dims \u2192 d dims \u25a0 We choose d = 2 for visualization ease \u25cfComputational expensive \u25cb Use as a \u201ctie breaker\u201d if PCA and t-SNE disagree Well-trained Over-trained 512D \u2192 2D 512D \u2192 2D Sorry! I don\u2019t have an example for this!Average vector of all nodes in graph: [coord, z_pos, energy, view, group_energy] 5D \u2192 2D Preventing Overtraining (UMAP) \u25cfProblem with t-SNE \u25cb Depends on a \u201cPerplexity\u201d \u25a0 Parameter, ~how many neighbors a point can have \u25cb May artificially split or group clusters \u25cfUniform Manifold Approximation and Projection (UMAP) is designed to preserve the underlying manifold structure \u25cb Tries to preserve both local neighborhoods and their global relationships \u25cb Maps N dims \u2192 d dims \u25a0 We choose d = 2 for visualization ease \u25cfComputational expensive \u25cb Use as a \u201ctie breaker\u201d if PCA and t-SNE disagree Well-trained Over-trained 512D \u2192 2D 512D \u2192 2D Sorry! I don\u2019t have an example for this!pion 1 pion 2 muon mip muon mip pion 2 pion 1 Average vector of all nodes in graph: [coord, z_pos, energy, view, group_energy] 5D \u2192 2D Auxiliary Slides",
    "textLength": 801
  },
  {
    "kind": "presentation",
    "title": "DAQ Progress Report 03_12_2024_2024-03-12_01-15-02.pdf",
    "fileName": "DAQ Progress Report 03_12_2024_2024-03-12_01-15-02.pdf",
    "url": "resources/presentations/DAQ Progress Report 03_12_2024_2024-03-12_01-15-02.pdf",
    "createdDate": "2024-03-12",
    "text": "PIONEER DAQ Development Progress \u25cfWorking with a few FPGA boards, mostly Nereid Kintex-7 \u25cfCan read and write configuration registers over PCIe \u25cfCan generate and read fake data over UART \u25cfWant to generate and read fake data over PCIe Nereid K7 PCI Express FPGA Development Board PIONEER DAQ Development Outline \u25cfRead and write FPGA configuration registers over PCIe \u25cfIncorporate Microblaze processor, generate and transmit fake data over UART \u25cfGenerate and transmit fake data from FPGA over PCIe \u25cfCreate a C++ API for interfacing with FPGA over PCIe \u25cfAdd FMC ADC module to FPGA system \u25cfCreate Midas frontend incorporating PCIe FPGA communication \u25cfCreate similar design with HTG-K700 PCIe FPGA Microblaze with UART output Block Diagram g-2 Modified DAQ Development Progress \u25cfIn the process of building a \u201cfull\u201d UKY teststand \u25cfAfter some debugging, we have: \u25cbEstablished communication with our MCH module via 1GbE \u25cbEstablished communication with other modules via IPMI \u25cbAssigned IPs to other modules (AMC13, FC7, WFD5s) \u25cfWaiting on ribbon cables for full setup Testbeam setup that we want to \u201cduplicate\u201d g-2 Modified DAQ Development Outline \u25cfEstablish communication with all crate modules \u25cfFinish hardware assembly \u25cfGet frontend code running \u25cfDebug (increase) rate capabilities by optimizing frontend code \u25cfAdd second crate to teststand Crate(s) of FC7s and WFDs ...Array of FEs, BE, Midas server ... Rest of Experiment Simplified DAQ Diagram",
    "textLength": 222
  },
  {
    "kind": "presentation",
    "title": "PIONEER AI Reconstruction PGSC Talk_2026-01-20_18-12-33.pdf",
    "fileName": "PIONEER AI Reconstruction PGSC Talk_2026-01-20_18-12-33.pdf",
    "url": "resources/presentations/PIONEER AI Reconstruction PGSC Talk_2026-01-20_18-12-33.pdf",
    "createdDate": "2026-01-20",
    "text": "Building an AI Reconstruction Framework for the PIONEER Experiment Jack Carlton University of Kentucky Outline I.What is PIONEER? A. Physics background B. Experimental design C. Simulation framework II.The Active Target (ATAR) A. General design philosophy B. Why a \u201ctraditional\u201d reconstruction is hard III. Principles of Neural Networks and Machine Learning A. Neural networks and back propagation (what the machine learns) B. Hyperparameters and tuning (what the human learns) C. Graph Neural Networks (GNNs) D. Graph Transformers IV. AI Reconstruction Pipeline A. Layout B. Data preprocessing/loading C. AI stages You can find this presentation in my notes Links: https://jaca230.github.io/joplin_notes_page/ or https://tinyurl.com/jack-uky-notes How to Train an AI Model from Scratch How to Train an AI Model from Scratch 1.Harvest some silicon from the beach How to Train an AI Model from Scratch 1.Harvest some silicon from the beach 2.Use whatever this thing is to carve some runes How to Train an AI Model from Scratch 1.Harvest some silicon from the beach 2.Use whatever this thing is to carve some runes 3.Collect training data via legal and accepted practices How to Train an AI Model from Scratch 1.Harvest some silicon from the beach 2.Use whatever this thing is to carve some runes 3.Collect training data via legal and accepted practices 4.Temporarily repurpose the entire power output of a rural town How to Train an AI Model from Scratch 1.Harvest some silicon from the beach 2.Use whatever this thing is to carve some runes 3.Collect training data via legal and accepted practices 4.Temporarily repurpose the entire power output of a rural town 5.Design a loss function forgetting that the end DOES NOT justify the means How to Train an AI Model from Scratch 1.Harvest some silicon from the beach 2.Use whatever this thing is to carve some runes 3.Collect training data via legal and accepted practices 4.Temporarily repurpose the entire power output of a rural town 5.Design a loss function forgetting that the end DOES NOT justify the means 6.Teach your sand to think against its will What is PIONEER? \u03c0\u2192e \u03bde and \u03c0\u2192\u00b5 \u03bd\u00b5 (\u03c0\u2192e and \u03c0\u2192\u00b5\u2192e) \u25cfCorresponding diagrams for \u03c0- \u25cfTau decay forbidden \u25cbTau too massive ~ 1000 MeV/c2 \u25cbPion ~ 100 MeV/c2 \u25cfMuon decay more likely \u25cbDue to helicity suppression \u25cbBranching fraction of 0.999877 \u25cbQuickly decays into positron \u03bde e+\u00b5+\u03bd\u00b5 u du d\u03c0+ \u03c0+W W Citation: Particle Data Group (https://pdg.lbl.gov/2014/listings/rpp2014-list-pi-plus-minus.pdf) Lepton Universality \u25cfStates coupling strengths (vertices) ge = g\u00b5 = g\u03c4 \u25cfUsing the Feynman rules for the weak interaction, we can approximate the matrix element \u03bdee-\u00b5- \u03bd\u00b5d ud u\u03c0- \u03c0-W W ge g\u00b5 f\u03c0f\u03c0 Pion vertex Lepton vertex W-boson propagator Citation: Modern Particle Physics, Mark Thomson (Ch. 11.6 pg. 301) Lepton Universality \u25cfAfter some \u201cmassaging\u201d we can find the matrix element to be \u25cfPion spin zero \u2192 no spin averaging needed, i.e.: \u25cfWe can use the general formula for 2-body decay to to find the decay rate \u25cfFinally, we compute the branching ratio Citation: Modern Particle Physics, Mark Thomson (Ch. 11.6 pg. 302-303) Branching Ratio Re/\u00b5 \u25cfWe can measure the branching ratio by measuring # of decays e and \u00b5 decays \u25cfTheoretical prediction is simple in first (and second) order \u25cbNo f\u03c0 or CKM element Vud \u25cf3rd order correction and beyond the pion structure becomes relevant = 1 [in theory] Citation: Dynamic of the Standard Model, Donoghue et. al (Ch. 6.1 pg. 163) Current state of Re/\u00b5 \u25cfConsistent with each other \u25cfExpect factor of ~10 precision improvement on experimental value from PIONEER \u25cb\u201cCatches up\u201d with theoretical uncertainty Re/\u03bcexp = 1.2327(23) x 10-4 (PIENU collab) Rtheo = 1.23524(15) x 10-4 Citation: Testing Lepton Flavor Universality and CKM Unitarity with Rare Pion Decays in the PIONEER experiment, PIONEER collab (pg. 6, arxiv: 2203.05505) PIONEER Experimental Proposal Citations: PIONEER Slides from ACTS Workshop, Patrick Schwendimann (Slide 4) \u25cfLXe (or LYSO) as a calorimeter material has short decay time and good energy resolution \u25cb\u03c3t \u2248 25 ns (timing resolution) \u25cb\u0394E/E \u2248 2% (energy resolution) \u25cfAllows experiment to run at much higher rate than previous experiments \u25cb~300kHz (phase 1) \u25cb~2000kHz (phase 2 and 3) \u25cf\u201cactive target\u201d, muons and pions are \u201ctracked\u201d while being stopped 3D Render Experiment Citations: PIONeer A next-generation rare pion decay experiment, David Hertzog, (https://pioneer.npl.washington.edu/docdb/0002/000281/001/PIONEER%20Orientation%20an d%20Status%20June%202024.pdf) Digitization Electronics Spherical Calorimeter Design Not Pictured: \u25cfATAR (inside Calo) \u25cfTracker (a shell around ATAR, inside Calo) \u25cfVETOs, T0, etc. \u25cfDAQ Computers PIONEER Strategy \u25cfCalorimeter measures just positron energy \u25cbMuon stopped by target \u25cbNeutrinos invisible \u25cfPrompt 70 MeV = \u03c0\u2192e \u25cfDelayed <53 MeV = \u03c0\u2192\u00b5\u2192e \u25cfPlots are for idealized, perfect detectors (in a \u201csimple world\u201d) Citations: PIONEER Slides from ACTS Workshop, Patrick Schwendimann (Slide 3) PIONEER Strategy \u25cfAt a glance the experiment is simple \u25cfJust look at energy deposited on the calorimeter and count events above and below Ethr \u2261 56 MeV \u25cfIn reality, not so simple\u2026 Citations: PIONEER Slides from ACTS Workshop, Patrick Schwendimann (Slide 6) PIONEER Strategy \u25cfFinite resolution and incomplete energy collection in the calorimeter result in a tail \u25cfTo compete with theoretical uncertainty, we need to characterize this tail to ~1 part in 10,000 ( ) Citations: PIONEER Slides from ACTS Workshop, Patrick Schwendimann (Slide 7) Calorimeter (CALO) Purpose \u25cfMuon\u2019s intrinsically follow a Michelle Spectrum \u25cbAdditionally width comes from energy resolution \u25cfPositrons follow monoenergetic spectrum \u25cb\u201cBack\u201d and \u201cFront\u201d tail due to radiative decays and bremsstrahlung \u25cfGood energy resolution is crucial for event reconstruction Muon Michelle Electron Monoenergetic Citation: PSI Ring Cyclotron Proposal R-22-01.1 PIONEER: Studies of Rare Pion Decays, PIONEER collab, (pg. 19 arxiv: 2203.01981) Active Target (ATAR) Purpose arxiv: 2203.01981 Citation: PSI Ring Cyclotron Proposal R-22-01.1 PIONEER: Studies of Rare Pion Decays, PIONEER collab, (pg. 19 arxiv: 2203.01981) \u25cfATAR allows classifying between \u03c0\u2192e and \u03c0\u2192\u00b5\u2192e based on 5D (x,y,z,t,E) information \u25cbWorse energy resolution than calorimeter, cannot do experiment on it\u2019s own \u25cfCase 5. \u03c0 and \u00b5 decay in flight negligible \u25cbATAR designed to stop heavy \u201cslow\u201d particles within their decay time; decay in flights are are PIONEER Simulation Framework \u25cfSeries of software steps to simulate the PIONEER experiment \u25cbWork in progress \u25cbAdapts as we develop our detectors/strategy \u25cfDesigned as a proof of concept \u25cbExperiment should work in simulation before real experiment is run \u25cfReconstruction designed to be used on simulated and real detector data Citations: PIONEER Slides from ACTS Workshop, Patrick Schwendimann Simulation and Analysis Presentation, Quentin Buat Monte Carlo (Geant4 Based) Detector Response (Gaudi Based) Event Reconstruction (Gaudi Based) Reconstructed Data Truth level physics interaction data in space of detectors Realistic detector output data Physical events reconstructed from detector data The Active Target (ATAR) Why Do We Need an ATAR? \u25cfEnergy information alone is insufficient to chracterizethe \u03c0\u2192e positron tail at the 10-8 level in Re/\u03bc \u25cfATAR topology and timing are required to identify intermediate muons and correct for this effect Citations: PIONEER Slides from ACTS Workshop, Patrick Schwendimann (Slide 22) Example of pristine \u03c0\u2192\u03bc\u2192e event data in ATAR ATAR Design \u25cfHighly segmented and instrumented pion stopping target made of silicon low gain avalanche diodes (LGADs) \u25cfEach sensitive strip has a size of 20 mm x 200 \u03bcm x 120 \u03bcm \u25cfTotal of 4800 channels arranged in criss-crossing pattern \u25cf5D track information: \u25cbTransverse positions x,y ~ O(200 \u03bcm) \u25cbLongitudinal position z ~ O(120 \u03bcm) \u25cbTime t ~ O(100 ps) per single hit \u25cbEnergy E, \u0394E/E ~ O(10%) Citations: PIONEER Slides from ACTS Workshop, Patrick Schwendimann (Slide 10) ATAR in Simulation \u25cfGeometric descriptions of ATAR in files fed to Geant4 based simulation \u25cbGeant4 provides simulation of particles interacting with the detector \u25cbDetector response code turns those interactions into data we\u2019d imagine seeing from the detector \u25cf24 layers of what\u2019s in the yellow dashed lines in the figure \u25cbPairs of x y layers in dashed lines, meaning 48 sensor layers Citations: Update on ATAR region supports, Adam Molnar (Slide 2) Why ATAR Events Are Hard to Reconstruct Traditionally Citations: PIONEER Slides from ACTS Workshop, Patrick Schwendimann (Slide 25) \u25cfPrecise pion stop location and positron direction are essential for rebuilding events in our detector geometry \u25cfMust be very efficient at rejecting \u03c0\u2192e events that are actually \u03c0\u2192\u03bc\u2192e \u25cb \u03c0\u2192\u03bc\u2192e decays are \u223c104 times more frequent than \u03c0\u2192e, and Re/\u03bc must be measured to \u223c10-4 relative precision, the probability for a \u03c0\u2192\u03bc\u2192e event to be misidentified as \u03c0\u2192e must be suppressed to the \u223c10-8 level \u25cb Timing and energy information help us so we need \u223c10-7 suppression from tagging Why Reconstruction Can be an AI task \u25cfSimulation provides all needed information \u25cbGeant4 simulation gives truth targets (ex. Positron angle, true pion stop) \u25cbDetector response gives inputs (ex. ATAR strip hit 5D information) \u25cfThe simulation can produce large quantities of data needed for training Monte Carlo Detector Response Traditional Reconstruction Truth Data Detector Data Model Training AI Reconstruction Reconstructed Data Reconstructed Data Trained Models One time training cost Principles of Neural Networks and Machine Learning What is a Neural Network? \u25cfA neural network is a parameterized function that approximates non-linear mappings through stacked linear transformations and nonlinear activations. \u25cfA composition of function layers \u25cfParameters (weights and biases) varied to optimize arbitrary loss function i.e. \u201clearned\u201d Example annotated multi layered neural network used to classify images of dogs This is a specific type of neural network called a multi layer perceptron (MLP), the simplest neural network Backpropagation (Overview) \u25cfMuch more detail in this article , and wikipedia \u25cfBackpropagation computes gradients of the loss with respect to all model parameters by applying the chain rule backward through the network \u25cfCompute the gradient of the loss in the space of weights \u25cbOptimal weight updates for the next iteration What are Hyperparameters \u25cf\u201cA Hyperparameter is a parameter that can be set in order to define any configurable part of a model's learning process\u201d \u25cbThese are parameters that are not learned by the model \u25cbChosen before the model is trained \u25cfExamples of what they control \u25cbOptimization dynamics (learning rate, batch size, optimizer) \u25cbModel capacity (hidden size, depth, heads) \u25cbRegularization (dropout, weight decay) Example: Moving average window size is a hyperparameter. It can be over, or under tuned. Hyperparameter Example (Batch Size) \u25cfMore detail in this article \u25cfBatch size is how many training data points are processed before updating the model \u25cbMakes predictions on batch, uses error to inform gradient descent algorithm \u25cfLarger batch size \u25cbMore accurate gradient descent \u25cbFewer updates per epoch \u25cbLess noisy gradient \u25cbLess general, can get stuck in local minima \u25cfSmall batch size \u25cbLess accurate gradient descent \u25cbMore updates per epoch \u25cbNoiser gradient \u25cbCan escape local minima What is a Graph Neural Network (GNN)? \u25cfA graph neural network is a neural network defined on graph-structured data \u25cfData represented by \u25cbNodes (objects, e.g. particle hits in detector) \u25cbEdges (relationships, e.g. spatial proximity of two hits in detector) \u25cbGlobals (property of group, e.g. total energy) \u25cfMuch better explained in this article Citation: https://distill.pub/2021/gnn-intro/ Example of data turned into a graph input What is a Graph Neural Network (GNN)? \u25cfWe input a graph through GNN layers which define how information flows \u25cfExample GNN layer strategies are: \u25cb Independent updates (no connectivity) \u25a0 Apply learned functions to nodes, edges, globals independently \u25cb Message passing (most common, many versions) \u25a0 Edges gather information from connecting nodes \u25a0 Edges compute a \u201cmessage\u201d for each neighboring node \u25a0 Nodes gather messages from edges \u25a0 Graph is updated \u25cfGNN Models have 3 basic type of predictions: \u25cb Node level predictions \u25cb Edge level predictions \u25cb Graph level predictions \u25cfUpdate functions are MLPs Citation: https://distill.pub/2021/gnn-intro/ Simple message passing example (annotated) GNN Layer GNN Block Example of full GNN model What is a Transformer Encoder Block? \u25cfA transformer encoder block is a neural network layer that \u25cbA neural network block that operates on a set of feature vectors \u25cbUpdates each vector using information from related vectors \u25cbProduces context-aware features of the same shape \u25cbCan be stacked to build progressively larger context \u25a0This is because the model computes residuals or \u201ccorrections\u201d, not replacements \u25cfIn the context of graphs \u25cbupdates node embeddings using information from neighboring nodes and edges \u25cfAnalogy: \u25cbMHSA = \u201cTalk to other nodes\u201d \u25cbFFN = \u201cReflect privately\u201d What is Multi-Head Self-Attention (MHSA)? \u25cfSelf-attention lets each element decide which other elements matter and how strongly to combine them \u25cfMultiple heads let the model learn different interaction patterns at the same time What is a Feed Forward Network (FFN)? \u25cfA position-wise feed-forward network applied to each element independently \u25cfUses the same two-layer MLP for all elements (shared weights) \u25cfNo communication between elements occurs in this layer \u25cfAdds nonlinear feature refinement after self-attention \u25cfAside: \u25cbFeed Forward Networks are more general than position wise FFNs . . .xi x\u2019i Example FFN for node with 2 features. Same FFN is applied to all nodes independently What is a Graph Transformer? \u25cfA graph transformer is a GNN that generalizes message passing using transformer-style attention \u25cfThese are among the most expressive modern ML models \u25cbCan solve a wider class of problems than most models \u25cfGNN \u25cbEdges define where information flows \u25cbMessage passing same \u201cstrength\u201d for all edges \u25cfGraph transformers \u25cbAttention learns how strongly information flows along those edges. \u25cbMessage passing differs in learned \u201cstrength\u201d for different edges Comparison of GNNs and Transformers in terms of message passing over different structures Citation: https://towardsdatascience.com/how-to-build-graph-transformers-with-o -n-complexity-d507e103d30a/ AI Reconstruction Pipeline Monte Carlo \u2192 ATAR ML Reconstruction Division 0 Simulation Data Monte Carlo + Detector Response ML Ready Dataset Gaudi Pipeline Truth level descriptions of entire events + detector response; optional event mixing = Not an ML stage = An ML (trained) stage Forms ML ready (fixed size row) dataset from dynamic sized data and applies preprocessing stages to derive additional feature columns (ex. Time group labels) Division 1 Samples = Full event (detector data + truth data) Group Classifier Group Splitter Endpoint Regressor Pattern Finder Pion Stop Regressor Positron Angle Finder Adds group level particle classes Adds hit level particle classes Adds endpoint (x,y,z) estimates Adds time group affinities Adds positron angles (sin\u03b8 cos\u03c6, sin\u03b8 sin\u03c6, cos\u03b8) estimates Adds pion stops (x,y,z) estimates G4Pioneer Monte Carlo + Detector Response \u25cfG4Pioneer Monte Carlo simulates the underlying physics \u25cbGeant4 Fork \u25cfDetector Response converts truth into detector-level signals \u25cbDepends on detector geometry \u25cbHandles event mixing \u25cfML training requires both detector-level outputs and truth-level information Cartoon example of detector response with truth information added to hits ML Ready Dataset Gaudi Pipeline (Time Group Forming) \u25cfGaudi pipeline does simple traditional labeling and reconstruction \u25cfExample time group forming : \u25cbDetector response events are \u201csplit\u201d into time-based clusters \u25a0Really, we just label hits with a time group they belong to \u25cbMost the time one time group == one particle \u25a0This helps the later ML stages reconcile particle specific features Cartoon example of time group spikes in energy deposition Representing Information as a Graph \u25cfOur final step before feeding the data into the model is constructing a fully connected graph \u25cfNodes contain hit specific information \u25cbEx. position, deposited energy, etc. \u25cfEdges contain related information between hits \u25cbEx. difference in positions \u25cfGlobal information for event level inputs \u25cbEx. Total Energy \u25cfWe can append information to these graphs as downstream models make predictions Graph representation of base detector information Graph level feature example: \u25cfTotal energy Group Classifier \u25cfMulti \u2011label graph transformer classifier \u25cbSubgraph level task \u25cfInputs (represented as a graph): \u25cbDetector response event information \u25cbTime grouping labels \u25cfTargets: \u25cbTruth level representation of what particles are in the group \u25cbParticularly: [pionInGroup, muonInGroup, MIPinGroup] \u25cfOutputs: \u25cbPredicted probability that the time group belongs to each class [prob_pionInGroup, prob_muonInGroup, prob_MIPinGroup] Cartoon example of time group spikes in energy deposition, now labeled by group classifier Group Splitter \u25cfMulti \u2011label graph transformer classifier \u25cbNode level task \u25cfInputs (represented as a graph): \u25cbDetector response event information \u25cbTime grouping labels \u25cbPredicted time group level particle class \u25cfTargets: \u25cbTruth level representation of the particle type for each hit \u25cbParticularly, for each hit in the graph: [[is_pion, is_muon, is_mip], [is_pion, is_muon, is_mip], \u2026] \u25cfOutputs: \u25cbPredicted probability that each hit belongs to each class [[prob_pion, prob_muon, prob_mip], [prob_pion, prob_muon, prob_mip], \u2026] Cartoon example of how a time group may be split into multiple particle classifications \u03c0 \u03c0 \u03bc Pattern Finder \u25cfAffinity graph transformer classifier \u25cbEdge level task \u25cfInputs (represented as a graph): \u25cbDetector response event information \u25cbTime grouping labels \u25cbPredicted time group level particle class \u25cbPredicted hit level particle classes \u25cfTargets: \u25cbAgreement between truth level event origins between nodes; i.e. \u201care these two nodes from the same monte carlo truth event\u201d. Explicitly: target_affinity[i][j] = 1 if origin_id[i] == origin_id[j] \u25cfOutputs: \u25cbPredicted \u201caffinities\u201d (0,1) between time groups Time group 0 Time group 1 Time group 2 Time group 3 Node labels: On per time group graph Edges: Learned affinity between groups (i.e. are two time groups from the same event?) Pion Stop Regressor \u25cfQuantile graph transformer regressor \u25cbGraph level task \u25cfInputs (represented as a graph): \u25cbDetector response event information \u25cbTime grouping labels \u25cbPredicted time group level particle class \u25cbPredicted hit level particle classes \u25cbPredicted affinities \u25cfTargets: \u25cbTruth level pion stop \u25cbParticularly: [x_stop,y_stop,z_stop] \u25cfOutputs: \u25cbPredicted pion stop [[[x_stop_q1, y_stop_q1, z_stop_q1], \u2026] \u25cfNotes: \u25cbQuantiles effectively give uncertainties if chosen to be top 84%, top 50%, and top 16% quartiles = median \u00b1 1 standard deviation = Pion stop estimate Cartoon example of pion stop estimate = Error range determined from quantiles Citation: Physics Reconstruction BVR Talk, Omar Beesley https://indico.psi.ch/event/18441/contributions/61425/attachments/3283 0/66309/Reconstruction-Final.pdf Positron Angle Regressor \u25cfQuantile graph transformer regressor \u25cbGraph level task \u25cfInputs (represented as a graph): \u25cbDetector response event information \u25cbTime grouping labels \u25cbPredicted time group level particle class \u25cbPredicted hit level particle classes \u25cbPredicted affinities \u25cfTargets: \u25cbTruth level direction vector for positron angle \u25cbParticularly: [(sin \u03b8cos\u03c6), (sin \u03b8sin\u03c6), (cos \u03b8)] \u25cfOutputs: \u25cbPredicted direction vector for positron angle [[(sin\u03b8cos\u03c6)_q1, (sin \u03b8sin\u03c6)_q1, (cos \u03b8)_q1], \u2026] Cartoon example of positron angle estimate direction in detector coordinate system with uncertainty Citation: Physics Reconstruction BVR Talk, Omar Beesley https://indico.psi.ch/event/18441/contributions/61425/attachments/3283 0/66309/Reconstruction-Final.pdf Auxiliary Slides Background Physics Common Pion Decay Channels \u25cf\u03c0+ \u2192 e+ + \u03bde \u25cf\u03c0- \u2192 e- + \u03bde \u25cf\u03c0+ \u2192 \u00b5+ + \u03bd\u00b5 \u25cf\u03c0- \u2192 \u00b5- + \u03bd\u00b5 \u25cf\u03c0+ \u2192 \u03c00 + e+ + \u03bde \u25cf\u03c0- \u2192 \u03c00 + e- + \u03bde\u25cf\u03c00 \u2192 \u03b3 + \u03b3 \u25cf\u03c00 \u2192 \u03b3 + e- + e+ \u25cf\u03c00 \u2192 e- + e+ + e- + e+ \u25cf\u03c00 \u2192 e- + e+ Leptonic Decay Beta Decay = Most Common Photon Decay Dalitz Decay Double-Dalitz Decay Electrons [Note: Dalitz Decays are like photon decays, except the photon(s) are virtual and immediately decay into electron/positron pairs] Citation: Wikipedia (https://en.wikipedia.org/wiki/Pion) j.carlton@uky.edu Naive Pion Decay, 2-body decay \u25cfWithout getting into details of QCD, we can treat this as a 3 particle decay \u25cfWe can use Fermi\u2019s golden rule: \u25cfAfter integration in the COM frame we find: \u25cf\u2192 \u0393 \u221d p (not correct) \u25cbDetails hidden in matrix element AB C Citation: Introduction to Elementary Particles, Griffiths (Ch. 6.2 pg. 196-198) j.carlton@uky.edu Why Massless \u2192 Chirality States ~ Helicity States \u25cfMassless \u2192 moves at c \u25cfMoves at c \u2192 cannot reverse particle direction with Lorentz boost \u2192 helicity is Lorentz Invariant \u25cfChirality is a property of a particle, always Lorentz invariant! \u2192 helicity and chirality agree in direction in all inertial reference frames [Dirac Equation] [Chiral States] [Helicity operator] [Chiral states are eigenstates of helicity operator] Citation: Lecture Notes, Quantum Field Theory, Michael Eides (PHY616, Lecture #25) j.carlton@uky.edu Helicity Suppression (Why is Muon Decay Most Likely?) \u25cfNaively, \u0393 \u221d p\u2019 \u2192 electron decay more likely \u25cfWeak force only affects left-handed (LH) chiral particle states and right-handed (RH) chiral anti-particle states \u25cfNeutrinos are all LH chirality \u25cfm\u03bd << E means LH neutrino chirality \u2192 LH (negative) neutrino helicity \u25cfConservation of momentum \u2192 anti-lepton is LH (negative) helicity \u03bdl l+u d\u03c0+W \u03c0+ \u03bdll+ Citation: Modern Particle Physics, Mark Thomson (Ch. 11.6 pg. 299) j.carlton@uky.edu I. What is PIONEER? (Slide 5/46) Helicity Suppression (Why is Muon Decay Most Likely?) \u25cfWe can write the LH (negative) helicity anti-particle state in the chiral basis: \u25cfWe ignore the LH term (weak force only acts on the RH term), anti-particle\u2019s matrix element contribution: \u25cfThis effect ends up making the matrix element smaller \u2192 decay rate smaller \u03bdl l+u d\u03c0+W \u03c0+ \u03bdll+ Citation: Modern Particle Physics, Mark Thomson (Ch. 11.6 pg. 300, Ch. 6.4 pg. 143) j.carlton@uky.edu I. What is PIONEER? (Slide 6/46) LH (negative) helicity spinor to chiral components An negative helicity antiparticle can be written as Where (\u03b8,\u03c6) define the direction of the momentum. Without loss of generality, assume the momentum is in the z direction Citation: Modern Particle Physics, Mark Thomson (Ch. 6.4 pg. 143) j.carlton@uky.edu LH (negative) helicity spinor to chiral components We can use the chiral projection operations to project this helicity state to chiral state Where the left and right chiral anti-particle states are defined by Citation: Modern Particle Physics, Mark Thomson (Ch. 6.4 pg. 141,143) j.carlton@uky.edu LH (negative) helicity spinor to chiral components Looking at the chiral projection of a negative helicity state, we can see in general there are left and right chiral components, so the weak force can act on a LH (negative) anti-particle helicity state It should also be clear as m\u21920, the LH (negative) helicity state coincides with the LH chiral state. This means W boson decay to two massless leptons is forbidden! One of the particles must have the wrong chirality, and thus low mass decays will be suppressed. Citation: Modern Particle Physics, Mark Thomson (Ch. 6.4 pg. 143) j.carlton@uky.edu Matrix Element Details Move to pion rest frame so only p0 = m\u03c0 remains: Using the identity: Citation: Modern Particle Physics, Mark Thomson (Ch. 11.6 pg. 301) j.carlton@uky.edu Matrix Element Details For a neutrino m << E so helicity eigenstate is essentially the chiral eigenstate: By letting the lepton go in the z-direction we can write: and Negative helicity lepton down state disappears when \u201cdotted\u201d with the neutrino state: Citation: Modern Particle Physics, Mark Thomson (Ch. 11.6 pg. 301-302) j.carlton@uky.edu Matrix Element Details We can re-write El and p in the limit where the neutrino mass is zero: Citation: Modern Particle Physics, Mark Thomson (Ch. 11.6 pg. 302) j.carlton@uky.edu Lepton Universality j.carlton@uky.edu Small discrepency in ge/g\u00b5 and 1 can cause twice as big discrepency in measured Re/\u00b5 and theory Re/\u00b5 Lepton Universality \u25cfLepton universality assumes ge = g\u00b5, so the first factor disappears \u25cfImproving the branching ratio measurement and comparing to the theoretical value acts as a test of lepton universality \u25cfAnother test would consider pure leptonic decays, but such decays involving taus are too rare for high precision measurements j.carlton@uky.edu I. What is PIONEER? (Slide 9/46) Another Test for Lepton Universality Citation: PIONEER Seminar, Tim Gorringe (Slide 9) Fermi constant and new physics, Marciano, Phys Rev. D 60, 093006 j.carlton@uky.edu CKM Unitary Test Citation: Testing Lepton Flavor Universality and CKM Unitarity with Rare Pion Decays in the PIONEER experiment, PIONEER collab (pg. 21) PIONEER Seminar, Tim Gorringe (Slide 12) arXiv:2203.05505 \u25cfPion beta decay gives a precision measurement of Vud \u25cfThese decays are lower rate than \u03c0 \u2192 e\u03bde and \u03c0 \u2192 \u00b5\u03bd\u00b5 \u25cfExperimental measurements do not agree j.carlton@uky.edu Some Information about LXe and NaI \u25cfLXe has singlet and triplet state decay constants: \u25cb\u03c4S = 4.3 \u00b1 0.6 ns \u25cb\u03c4T = 26.9+0.7 \u22121.1 ns \u25cfLXe light yield: \u25cb~29 photons/keV at room temp \u25cfNaI decay constant: \u25cb~ 250 ns \u25cfNaI light yield: \u25cb38 photons/keV at room temp Citations: A measurement of the scintillation decay time constant of nuclear recoils in liquid xenon with the XMASS-I detector, XMASS collab, arxiv 1809.05988 Scintillation yield of liquid xenon at room temperature , XMASS collab, arxiv 0803.2888 Berkeley Nucleonics (https://www.berkeleynucleonics.com/nai-sodium-iodide) Scintillation from excited Xe (Xe*): Scintillation from ionized Xe (Xe+): j.carlton@uky.edu Past Experimental Approach (PIENU) \u25cfNaI has a long primary decay time \u25cb~ 250 ns \u25cfEvent pileup forces the experiment to run at a low rate \u25cb~70 kHz \u25cf\u201cinactive target\u201d, muons aren\u2019t tracked \u25cfCsI Rings for shower leakage detection Citation: Status of the TRIUMF PIENU Experiment, PIENU collab, (arxiv 1509.08437) https://pienu.triumf.ca/ j.carlton@uky.edu I. What is PIONEER? (Slide 12/46) PEN \u25cfSimilar to PIENU \u25cbSegmented \u25cbBetter timing \u25cfMany channels of pure CSI \u25cb240 channels \u25cfActive target Citation:PEN: a low energy test of lepton universality , PENcollab, (arxiv: 1701.05254) j.carlton@uky.edu PIONEER Strategy (Tail Fraction Uncertainty) j.carlton@uky.edu I. What is PIONEER? (Slide 4/46) More ATAR details \u25cfPion and muon decays deposit energy into ATAR \u25cfAllow event types to be distinguished \u25cfMuons decaying in flight can boost positron energy past 53 MeV (big issue!) \u25cbATAR can give information to rebuild event, and correctly classify a muon decay arxiv: 2203.01981 Citation: PSI Ring Cyclotron Proposal R-22-01.1 PIONEER: Studies of Rare Pion Decays, PIONEER collab, (pg. 19 arxiv: 2203.01981) j.carlton@uky.edu Another Calorimeter 3D Render (Liquid Xenon) Citations: PIONeer A next-generation rare pion decay experiment, David Hertzog, (https://pioneer.npl.washington.edu/docdb/0002/000281/001/PIONEER%20Orientation%20an d%20Status%20June%202024.pdf) j.carlton@uky.edu PIONEER Simulation Monte Carlo (Geant4 Fork) \u25cfForked from Geant4 \u25cbGeant4 is a general-purpose particle transport toolkit. Standard simulation engine for high energy particle, nuclear, and medical physics \u25cfBuilt to simulate pion decays in an arbitrary input detector geometry \u25cfModular \u201cphysics lists\u201d for interactions, physics models, etc. \u25cfProvides \u201ctruth\u201d data for downstream software Citation: j.carlton@uky.edu I. _ (Slide 00/46) Example of particle tracks through a physical object in an (unrelated) Geant4 simulation PIONEER Simulation Detector Response \u25cfA Gaudi based pipeline for detector response to physical interactions in simulated truth data \u25cbGaudi is a modular event processing framework commonly used for high energy physics software pipelines \u25cfSimulates what information we expect to see out of the detectors so we can blind reconstruction to truth j.carlton@uky.edu I. _ (Slide 00/46) Example raw detector data (with some truth overlaid) PIONEER Simulation Reconstruction \u25cfAlso a Gaudi based pipeline \u25cfA series of steps to ultimately classify event types (ex. as \u03c0\u2192e or \u03c0\u2192\u00b5\u2192e) \u25cfDesigned to operate on simulated and real detector data \u25cfThis is the stage where machine learning/AI approaches can work well \u25cbLarge quantities of detector data with truth targets available from simulation Citation: Simulation and Analysis Presentation, Quentin Buat j.carlton@uky.edu I. _ (Slide 00/46) The Activate Target (ATAR) j.carlton@uky.edu Active Target (ATAR) Purpose Citations: PIONEER Slides from ACTS Workshop, Patrick Schwendimann (Slide 17) j.carlton@uky.edu I. What is PIONEER? (Slide 16/46) Low Gain Avalanche Diodes (LGAD) \u25cfSilicon detector with a thin gain-layer \u25cfGain required to reliably detect minimally ionising positrons. \u25cfLarge dynamic range from 40 keV (MIP) to 4 MeV (Muon Stop) \u25cfExcellent timing resolution \u25cfGain suppression for large energy deposits (stopping pion/muon) \u25cfDegraded energy resolution \u25cfIntroduce angular dependency Citations: PIONEER Slides from ACTS Workshop, Patrick Schwendimann (Slide 12) j.carlton@uky.edu I. _ (Slide 00/46) Principles of Neural Networks and Machine Learning j.carlton@uky.edu Backpropagation (Explicit, Part I) \u25cfDiagram with some labels to conceptualize the variables Backpropagation (Explicit, Part II) \u25cfEquations for how to update weights from back propagation 1. Backpropagate activation gradients: 2. Weight gradient via local chain rule: 3. Gradient descent update to weights: Backpropagation (Explicit, Part III) \u25cfThe back propagation step is a recursive step The backpropagation step: This formula is recursive, so for N layers you have explicitly: Or more commonly you can write in Jacobian form, which cleans up the notation Backpropagation (Explicit, Part IV) \u25cfThe actual values of xl,i are architecture dependent \u25cfIn this simple example, you can compute them by defining a bias and activation function (eg. softmax) We can define zl,i for the raw computed \u201cresponse\u201d from the previous layer: Then we apply some activation, usually to constrain values between 0 and 1 to prevent exponential blowup. This allows to (finally) formally compute all needed partial derivatives: Hyperparameters Need to be Tuned Appropriately \u25cfImproper hyperparameter choices can lead to \u25cbOvertraining \u25cbSlower convergence \u25cbVanishing or exploding gradients \u25a0Impossible to find true solution at this point \u25cfTuning hyperparameters can be hard \u25cbThey interact with each other (often non-linearly) \u25cbOptimal choice varies with each dataset/model Example: Fitting data with a polynomial. The degree of the polynomial, d, is a hyperparameter Hyperparameters (Learning Rate) \u25cfMore detail in this article \u25cfLearning Rate controls how large each parameter update is in the direction of the gradient \u25cfLarger learning rate: \u25cb Bigger, more exploratory steps \u25cb Less likely to get stuck in local minima \u25cb Harder to settle precisely at the optimum \u25cfSmaller learning rate: \u25cb Smaller, more precise steps \u25cb More likely to get trapped in local minima \u25cb Better at fine-tuning near the optimum Hyperparameters Example (# of layers) \u25cfMore detail in this article \u25cfHidden dimension sets the size of the model\u2019s internal feature representations at each layer. \u25cfMore layers: \u25cbLearns more \u201chierarchical\u201d/ \u201cabstract\u201d features \u25cbHigher risk of overfitting or training instability (higher loss fluctuations) \u25cbHigher memory and compute cost \u25cfLess layers: \u25cbLearns \u201csimpler\u201d/\u201cshallow\u201d features \u25cbLower risk of overfitting \u25cbLower memory/compute cost Hyperparameters (Dropout) \u25cfMore detail in this article \u25cfDropout randomly disables a fraction of activations during training to reduce overfitting \u25cfHigher dropout: \u25cbBetter for noisy datasets \u25cbLess risk of overfitting \u25cbHigher risk of underfitting \u25cfLower dropout: \u25cbBetter for less noisy datasets \u25cbLess risk of underfitting \u25cbHigher risk of overfitting Hyperparameters (Hidden dim) \u25cfMore detail in this article \u25cfHidden dimension sets the size of the model\u2019s internal feature representations at each layer. \u25cfLarger hidden dim: \u25cbCan represent more complex patterns \u25cbHigher risk of overfitting \u25cbHigher memory and compute cost \u25cfSmaller hidden dim: \u25cbLimited ability to model complex patterns \u25cbLower risk of overfitting \u25cbLower memory/compute cost Hyperparameters (weight decay) \u25cfMore detail in this article \u25cfWeight decay adds a penalty on large weights to the loss, encouraging simpler models. Similar to dropout. \u25cfHigher weight Decay: \u25cbBetter for noisy datasets, stronger regularization \u25cbLower risk of overfitting \u25cbHigher risk of underfitting \u25cfLower weight decay: \u25cbBetter for less noisy datasets, less regularization \u25cbLower risk of underfitting \u25cbHigher risk of overfitting Hyperparameters (# of attention heads) \u25cfMore detail in this article \u25cfThe number of attention heads controls how many independent subspaces the model attends to in parallel within each attention layer \u25cfMore attention heads: \u25cb Learns multiple attention patterns in parallel \u25cb Higher memory/compute cost \u25cb Diminishing returns if per-head dimension is too small \u25cb Can overfit and destabilize training \u25cfFewer attention heads: \u25cb Learns fewer attention patterns \u25cb Lower memory/compute cost \u25cb May miss distinct relationships \u25cb Can underfit if data is very heterogeneous Hyperparameters (activation functions) \u25cfMore detail in this article \u25cfThe activation function controls the nonlinearity applied at each layer Examples: \u25cfReLU \u25cbSimple, piecewise-linear activation \u25cbFast training; can form sharp, noisy boundaries \u25cfTanh \u25cbSmooth, bounded activation \u25cbProduces smoother boundaries; may saturate \u25cfGELU \u25cbSmooth, probabilistic gating \u25cbBalances smoothness and expressiveness Hyperparameters (optimizers) \u25cfMore detail in this article \u25cfOptimizers control how gradients are transformed into parameter updates during training Examples: \u25cfStochastic Gradient Descent (SGD) with momentum \u25cb Simple, stable updates \u25cb Often performs well on unseen data, not just the training set \u25cb Sensitive to learning rate and scaling \u25cfAdaptive Moment Estimation (Adam) \u25cb Adaptive learning rates per parameter \u25cb Fast convergence, less sensitive to hyperparameter choice \u25cb Can overfit or generalize worse than SGD \u25cfAdamW \u25cb Adam with decoupled weight decay \u25cb More reliable regularization behavior \u25cb Standard choice for modern deep models Hyperparameters (Gradient Descents) \u25cfMuch more detail in this article \u25cfBatch Gradient Descent (BGD): \u25cbUses the entire dataset in one iteration. The batch size is equal to the total number of training samples. \u25cfMini-Batch Gradient Descent (MBGD): \u25cbUses a predefined number of samples from the dataset for each update. This method lies between batch and stochastic gradient descent (SGD). \u25cfStochastic Gradient Descent (SGD): \u25cbProcesses only one sample at a time for each update, making the batch size equal to 1. Hyperparameters (why are more layers harder to train) \u25cfMore layers \u2192 more loss instability \u25cb Due to back propagation \u25cb The size of your step becomes more \u201cuntrainable\u201d the more layers you add \u25cfCases: \u25cb \u03bb \u2248 1 \u25a0 Gradients stable as model layers increase \u25cb \u03bb < 1 \u25a0 Gradients vanish as model layers increase \u25a0 No more learning occurs! \u25cb \u03bb > 1 \u25a0 Gradients blow up as model layers increase \u25a0 Cannot converge on solution \u25cfOne goal of model architecture choice is to get \u03bb \u2248 1 What is a Tree-Structured Parzen Estimator (TPE) (Part I) \u25cfGiven a (possibly stochastic) black box function you want to minimize (ex. model loss) \u25cfHyperparams \u2261 \u03b8 \u25cfDefine the following: \u25cfThen, for any given theta we can define expected improvement \u25cfGoal: Maximize expected improvement Note: See paper on arxiv What is a Tree-Structured Parzen Estimator (TPE) (Part II) \u25cfFor a 1 dimensional y, it turns out to be easier to work with , we can invert using Bayes\u2019 rule: \u25cfAnd substitute \u25cfSince we don\u2019t know every value of y this becomes an impossible task. We must make an approximation by dividing into \u201cgood\u201d and \u201cbad\u201d distributions Note: See paper on arxiv What is a Tree-Structured Parzen Estimator (TPE) (Part III) \u25cfThe integral, by construction, only cares about the \u201cgood\u201d region, so the integral simplifies to \u25cfBut the integral is now constant in theta! So we have: \u25cfWhere so we can write: Note: See paper on arxiv What is a Tree-Structured Parzen Estimator (TPE) (Part IV) \u25cfBut \u03b3 is fixed, so \u25cfWhere the final step is because x/(bx+c) is monotonic in x for x >0 ,let x = l/g \u25cfIn other words, we just need to find which is doable via algorithm! Note: See paper on arxiv What is a Tree-Structured Parzen Estimator (TPE) (Part V) \u25cfNow to define the algorithm, first we observe T (~10) trials randomly: \u25cfFrom this data, we want to build: \u25cfSo we define \u25cfAnd assume: Note: See paper on arxiv What is a Tree-Structured Parzen Estimator (TPE) (Part VI) \u25cfThis allows us to write: \u25cfWe can fit to our samples to get a continuous distribution spaces for each param \u25cfThen we sample from the \u201cgood\u201d spaces for M candidates index by m \u25cfAnd finally, choose our next theta, add it to the data set, and repeat Note: See paper on arxiv What is a Tree-Structured Parzen Estimator (TPE) (Part VII) \u25cfHow do we obtain our fits from the data? \u25cfUses Kernel Density Estimation (KDE) \u25cbThe actual fit is done when determining each \u201cgaussian kernel\u201d (or sigma) \u25cbLikelihood-optimal is expensive ~O(n2d) \u25a0n = # samples \u25a0d = # hyperparameters \u25cbOptuna uses the \u201cheuristic\u201d version, which requires choosing some value for c. Note: See paper on arxiv Why use Graph Transformers? \u25cf Example Graph Transformer Layer Building a Framework that Scales j.carlton@uky.edu Breaking down \u201cScalability\u201d I choose to break down scalability into three categories: 1.Data a. ML pipeline does not change behavior as data set grows i.Still scales in execution time 2.Compute a. ML pipeline does not change behavior as compute power is changed i.Still scales in execution time ii.Ex. Pipeline runs on developer\u2019s laptop or a CPU/GPU cluster 3.Codebase a. ML pipeline does not (greatly) change behavior as complexity grows i.New models, stages, or data products require additional code, not (major) code rewrites ii.Iteration speed does not (greatly) degrade with system size (i.e. keep things modular!) What Do We Mean by \u201cScaling\u201d (Data) \u25cfData volume should be able to grow without changing how the pipeline behaves \u25cfAdding the following should not cause pipeline behavior changes: \u25cbMore events \u25cbMore derived data products \u25a0predictions, masks, regressions, etc. \u25cbMore passes over the same data \u25cbLarger event representations \u25cfImplications: \u25cbMemory usage must not grow with dataset sizeIdeal Behavior for Different Sized Datasets ML Pipeline Output A Output B Small Dataset Large Dataset Short processing time Long processing time Small number of batches Large number of batches Techniques to Ensure Scalability (Data) \u25cfStream data in bounded batches \u25cbRAM usage should not scale with data set size \u25cbAllows RAM usage to be \u201ctunable\u201d \u25cfBase data should be immutable \u25cbNo modifications or extensions to ML pipeline input data files \u25cfSeparate derived data products \u25cbPredictions, masks, and regressions are produced as independent datasets \u25cfReference data by IDs, not by object \u25cbWhen passing data modules, use file paths or map IDs not in memory collections \u25cbSimilar to why we use pointers in C++ Simple Example Pipeline Including Derived Datasets Base Dataset Stage A Stage B Output Batch i Derived Data i Derived Dataset Storage Batch i + Derived Data i ML Pipeline Technologies for Scalability (Data) \u25cfApache Parquet (columnar, on disk) \u25cbML-native working datasets, append-only, shardable (aka \u201cbatchable\u201d) \u25cbCan key rows by event ID, enabling batch-scoped joins for derived data products \u25cfApache Arrow \u25cbSingle copy from disk into RAM, then zero-copy views all the way to Torch \u25cfPolars \u25cbDataset shaping: filtering, joins, feature derivation \u25cbLazy, columnar execution on Arrow-backed data \u25cbPrepares batchable views for PyTorch ingestion \u25cfPyTorch tensors \u25cbExecution format for models \u25cfPytorch DataLoader \u25cbHandles batching, shuffling, parallel loading, prefetching, enforcing memory bounds Flow of Data From Monte Carlo to a Model in the ML pipeline Monte Carlo Parquet Arrow Polars PyTorch DataLoader Model Once, offline file generation Disk \u2192 RAM Copy Zero-copy views of data What Do We Mean by \u201cScaling\u201d (Compute) \u25cfComputation resources should be able to grow without changing how the pipeline behaves \u25cfAdding the following should not cause pipeline behavior changes: \u25cbNumber of GPUs \u25cbNumber of CPU cores/threads \u25cbNode count \u25cbMemory Capacity \u25cfImplications: \u25cbAlgorithms must be agnostic to resources \u25a0Caveat: PyTorch and other frameworks may change their behavior for different devices/device counts for efficiency Ideal Behavior for Different Amounts of Computing Resources ML Pipeline Output Output Dataset Dataset Long processing time Shorter processing time Low resource (ex. Laptop) High resource (ex. GPU cluster) Techniques to Ensure Scalability (Compute) \u25cfMake algorithms resource-agnostic \u25cbNo logic branches based on GPU count, core count, node count, or memory size, etc. \u25cfMake algorithms easily parallelizable \u25cbDecompose computation into independent, composable units \u25cbAvoid global state dependencies in pipeline stages \u25cbAvoid \u201csynchronization points\u201d; i.e. points where models must make inferences on whole datasets Parallelized View of Simplified Pipeline Big Dataset Batch 0 N outputs Batch 1 Batch M N events Output 1 Output 2 Output N N outputs N events \u2026 N outputs \u2026N events Stage A Stage B Compute Node 0 Stage A Stage B Compute Node 1 Stage A Stage B Compute Node M ML Pipeline Technologies for Scalability (Compute) \u25cfPyTorch \u25cbStandard framework for modern ML models \u25cbResource-agnostic execution model \u25cfCUDA \u25cbOperates purely at the level of memory, kernels, and execution, independent of algorithm or pipeline semantics \u25cbProvides an API for launching and coordinating large numbers of parallel threads on GPUs \u25cfKubernetes \u25cbSchedules identical pipeline executions onto available compute nodes \u25cbScales how many pipelines run concurrently, not what they do \u25cbHandles retry logic and resource limits Simplified \u201cScope\u201d Of Technologies Outer Technologies Manage Inner Technologies Kubernetes Distributes pipeline containers as black boxes Pipeline Container (ZenML) Pipeline logic, I/O, bookkeeping, etc. PyTorch Model semantics CUDA Kernels, threads, overall GPU execution What Do We Mean by \u201cScaling\u201d (Codebase) \u25cfCodebase complexity should be able to grow without changing how the system behaves \u25cfAdding the following should not cause system wide behavioral changes: \u25cbMore pipeline stages \u25cbMore models / algorithms \u25cbMore configuration options \u25cfImplications: \u25cbNew functionality should be added by extensions, not modification \u25cbSystem behavior should be locally understood (modularity) \u25cbExisting code should not require global refactoring to evolve The \u201cGlobal\u201d Structure Should Not Change As Complexity Increases Output B Dataset \u201cSimple\u201d pipeline with few stages \u201cComplex \u201cPipeline with many stages Stage A Stage B Stage C Stage E Stage D Stage F Output B Dataset Stage A Stage B Techniques to Ensure Scalability (Codebase) \u25cfUse abstraction where appropriate \u25cbDefine stable base interfaces / abstract classes \u25cbAdd new functionality by extending, not rewriting \u25cfAvoid global coupling \u25cbModules depend only on explicit inputs \u25cbEach module manages its own immutable local state \u25cfIsolate responsibilities to achieve modularity \u25cbEach module has a single, well-defined responsibility \u25cbChanges remain local to the owning module Simple Example of Abstraction For Adding New Models torch.nn.Module pioneerml.GraphModel pioneerml.GroupClassifier pioneerml.PionStopFinder Framework level contract Project level Contract Project level contract New file with implementation New file with implementation Technologies for Scalability (Codebase) \u25cfPyTorch \u25cbProvides a standard base abstraction classes for many model types (ex. nn.Module ) \u25cbEnforces a consistent model interface (ex. forward method) \u25cfZenML \u25cbEncodes pipelines as composable, declarative units and orchestrates execution \u25cbAllows pipelines to grow by adding or reordering steps; easy to add new pipelines \u25cbManages pipeline state, artifacts, and execution metadata outside user code \u25cfOptuna \u25cbIsolates hyperparameter search code \u25cbEnables experimentation without modifying core implementations \u25cbReally a package for black box searching, by default uses Tree-Structured Parzen Estimator (TPE) Simplified Example Pipeline for Training Models Data Construction Optuna Optimization Model Training Evaluation Pipeline Parameters Trained Model ZenML Pipeline Load shard data Build graph inputs Sample hyperparameters Decide next trial Train our model implementation Compute metrics Inform hyperparameter search Finished when hyperparameter search ends What is Apache Parquet? \u25cfApache Parquet is a columnar, on-disk data format that is widely used in ML workloads \u25cfWhat parquet does \u25cbColumnar storage \u2192 read only the columns (features) your model needs \u25a0Allows one to efficiently assign a subset of columns as inputs and another subset of columns as targets \u25cbSupports nested and variable-length fields \u25cbData schema is embedded in the file, not inferred by code (ex. Not like numpy, where code defines dtype parameter) \u25cfWhy this matters for scalability \u25cbEfficient I/O for large datasets through compression and encoding \u25cbNew models using different subsets of the data becomes trivial Example time_groups.parquet file structure What is Batching? \u25cfBatching means processing a fixed-size subset of events at a time, rather than the full dataset \u25cfWhat batching does \u25cbGroups individual events into batches of size N \u25cbEach batch is processed independently \u25cbBatches are discarded after use \u25cfWhy this matters for scalability \u25cbMemory usage is bounded by batch size (for single batch process) \u25cbDataset size does not affect RAM usage \u25cbEnables streaming over arbitrarily large datasets Big Dataset Batch 0 Batch 1 Batch M Model Output 1 Output 2 Output N \u2026 \u2026N events N outputs Diagram that Shows how Batching Splits Data N events N events N outputs N outputs What is Shuffling? \u25cfShuffling changes the order in which events are seen, without changing the data itself \u25cfWhat shuffling does \u25cbRandomizes event order before forming batches \u25cbEnsures batches contain a mix of events \u25cbChanges between epochs (or passes over the data) \u25cfWhy this matters for scalability \u25cbPrevents bias from data ordering \u25cbImproves statistical independence between batches \u25cbAllows repeated passes over large datasets without correlation artifacts Dataset [A,A,A,A,B,B] Simplified Example of Shuffling vs. Not Shuffling a Dataset with Distinct Event Types A and B Without Shuffling With Shuffling Batch 1 [A,A] Batch 0 [A,A] Batch 2 [B,B] Dataset [A,A,A,A,B,B] Batch 1 [A,B] Batch 0 [A,B] Batch 2 [A,B] Batches may have biases in event types, which hinders training Batches are a better representation of the whole dataset; no ordering correlations What is Parallel Loading? \u25cfParallel loading means loading multiple batches concurrently, using multiple workers \u25cfWhat parallel loading does \u25cbMultiple workers read and prepare batches simultaneously \u25cbThe model always has a batch ready to process \u25cbData loading is decoupled from model execution \u25cfWhy this matters for scalability \u25cbHelps prevent the model from waiting on disk I/O \u25cbImproves hardware utilization (especially GPUs) Big Dataset Loader 0 (Batch 0) Loader 1 (Batch 1) Loader 2 (Batch 2) Model \u2026Data Loaded in Parallel Note: Parallel loading does not necessarily mean parallel model execution Parallel Data Loading Diagram What is Prefetching? \u25cfPrefetching means loading future batches while the current batch is being processed \u25cfWhat prefetching does \u25cbWhile the model computes on batch N the next batch (N+1) is loaded in the background \u25cbWhen computation finishes, the next batch is already ready \u25cfWhy this matters for scalability \u25cbHelps prevent the model from waiting on disk I/O Simplified Prefetching Example Diagram Without Prefetching With Prefetching Load Batch N Compute Batch NLoad Batch N+1 Compute Batch N+1Load Batch N Compute Batch N Load Batch N+1 Compute Batch N+1Time Time Subsequent batches loaded in parallel with compute of previous batch. Effectively utilizing different hardwares What is Enforcing Memory Bounds? \u25cfEnforcing memory bounds means placing a hard limit on how much data can be in memory at once \u25cfWhat enforcing memory bounds does \u25cbMaximum in-flight data size is fixed \u25cbBatch creation is throttled when memory is full \u25cbMakes memory usage predictable and stable \u25cfWhy this matters for scalability \u25cbDataset size does not affect RAM usage \u25cbEnables streaming over arbitrarily large datasets Batch 0Batch 1 Model \u2026 Diagram Showing How Memory Bounds Enforce a Limited Number of Batches Loaded in RAM Batch 2Batch 3Batch MBig Dataset Memory bound fixes limit of data in RAM, which effectively fixes the number of batches that can be in RAM at one time. As one batch finishes, more batches load into RAM What is Kubernetes (K8s)? \u25cfA system for running and managing containerized workloads across shared compute resources \u25cfWhat Kubernetes does \u25cbSchedules containers onto available compute nodes \u25cbEnforces resource limits (CPU, GPU, memory) per container \u25cbIsolates workloads from one another \u25cbHandles restarts and retries on failure \u25cfWhy this matters for scalability \u25cbEnables concurrent execution of many independent workloads \u25cbPrevents resource contention between workloads Kubernetes Control Plane Cluster of Compute Resources Compute Node A Compute Node B Schedules and distributes workload Pod PodPod Application 0 Application 1 Application 2 Note: A pod is the smallest schedulable unit Simplified Diagram of How Kubernetes Orchestrates Applications Across a Compute Cluster What is ZenML? \u25cfA framework for defining, orchestrating, and executing machine-learning pipelines with explicit steps, artifacts, and metadata \u25cfWhat ZenML does \u25cbEncodes workflows as composable, declarative pipelines \u25cbOrchestrates execution order and dependencies \u25cbIntegrates with execution backends (local, containers, clusters) without changing user code \u25cfWhy this matters for scalability \u25cbPipelines grow by adding or rearranging stages, not rewriting logic \u25cbEnables reproducibility, versioning, and parallel development \u25cbState and artifacts are managed outside user code Example ZenML pipeline diagram Stage A Stage B Stage C Pipeline Parameters Pipeline Output ZenML Pipeline Artifacts and Metadata Storage (external or local database) What is Optuna? \u25cfMany hyper parameters means manual tuning is bad \u25cbToo slow \u25cbSuboptimal tuning means you spend more resources (time, computing power, etc.) training unused models \u25cfOptuna is a python package that solves this problem \u25cbFramework for optimization black box objective functions \u25cbTechnically not an ML package, but rather a package that supports many optimized sampling strategies Example Optuna workflow diagram How Optuna Works \u25cfOptuna supports many sampling algorithms , examples: \u25cbGrid search \u25cbRandom search \u25cbGaussian process-based Bayesian optimization \u25cfFor single object functions, the default for Optuna is Tree-Structured Parzen Estimator (TPE) TPE flow diagram (in a nutshell) AI Reconstruction Pipeline j.carlton@uky.edu Endpoint Regressor \u25cfQuantile graph transformer regressor \u25cfInputs: \u25cbDetector response event information represented as a graph \u25cbPredicted time group level particle class \u25cbPredicted hit level particle classes \u25cfTargets: \u25cbTruth level endpoints \u25cbParticularly: [[x_start, y_start, z_start], [x_end, y_end, z_end]] \u25cfOutputs: \u25cbPredicted endpoints with quantiles [[[x_start_q1, y_start_q1, z_start_q1], [x_end_q1, y_end_q1, z_end_q1]], \u2026] Cartoon example of how we estimate endpoints with uncertainties given by the quantiles = Median endpoint estimate = Error range determined from quantiles Full Reconstruction Diagram \u25cfConceptually, all the same stages \u25cfThe idea is the ML models are \u201cimplementations\u201d of a stage \u25cbIn principle they can be swapped out with a traditional reconstruction (non-machine learning) \u25cbAllows for benchmarking of different implementations Why Have Divisions? \u25cfEach pipeline stage operates on a well-defined \u201csample\u201d \u25cbEach division defines a dataset boundary \u25a0A dataset boundary is the point at which the meaning of a row is fixed and written to storage, so downstream stages can rely on it without knowing how it was produced \u25a0It\u2019s okay to create appending files or masks, \u25a0If you must mutate data (i.e. change your definition of a \u201csample\u201d then you create another dataset boundary), then you should create a new dataset boundary or \u201cdivision\u201d \u25cfIf we don\u2019t create clear divisions \u25cbHidden coupling between stages can occur \u25a0I.e. you change one stage, an unrelated stage no longer works \u25cbBatching becomes unclear \u25a0Your definition of a batch changes between data boundaries \u25a0Memory and performance become less predictable \u25cfIn short, each division should scale separately GraphRecord Former \u25cfWe don\u2019t store data as their graphs, we store them as the minimal information needed to build the graph \u25cfAs a result we have a \u201cdata loading stage\u201d before running any model where we construct a graph from the data Stereoscopic View \u25cfBefore each \u201cDivision 1\u201d model \u201cdoes it\u2019s job\u201d, it first construct a \u201cstereoscopic\u201d view of the data \u25cb Hits are split by view: \u25a0 0 = X plane, 1 = Y plane \u25cb Each view is embedded independently, then fused: [emb_view0, emb_view1, mask0, mask1] \u25a0 mask_i = 1 if view i has hits, else 0 \u25cb This process is learned for each model \u25cfWhy this helps: \u25cb Treats view ID as discrete routing \u25cb Explicitly encodes that intermediate views (e.g. \u201c0.5\u201d) do not exist \u25cfWhy we want this stage learnable: \u25cb weight each view \u25cb rescale per-view features \u25cb handle missing or weak views \u25cfWhy it\u2019s model-specific \u25cb Different tasks rely on views differently \u25a0 e.g. missing Y view matters more for endpoint finding than for particle classification View of x and y planes View of x plane View of y plane X plane contains all the hits Y plane does not contains any hits, the model learns to treat the case of an empty view differently than a standard \u201cfull\u201d view (empty) Exaggerated cartoon example of how a stereoscopic view can help in the case of missing views [emb_view0, 00\u2026000, 1, 0] + Quantiles \u25cfFor regressions, quantiles are useful to extract uncertainties \u25cfUses a quantile regression loss function \u25cfWe can use quantile regression to have our models target a specific quantiles \u25cbUsually we select \u25a0Lower quantile = 16 ~ 1\u03c3 \u25a0Mid quantile = 50 ~ median \u25a0Upper quantile = 84 ~ +1\u03c3 Wikipedia example of Quantile Regression. Notice how it forms confidence bands around the best fit (or median) Event Mixing \u25cfEvent mixing is handled in the pioneer simulation framework in the detector response \u25cbEffectively piles up simulated events into one \u201cdetector\u201d event. The number of simulated events and probability of pileup are parameterized.",
    "textLength": 8539
  },
  {
    "kind": "presentation",
    "title": "DAQ Progress Report 04_01_2025_2025-04-01_05-14-40.pdf",
    "fileName": "DAQ Progress Report 04_01_2025_2025-04-01_05-14-40.pdf",
    "url": "resources/presentations/DAQ Progress Report 04_01_2025_2025-04-01_05-14-40.pdf",
    "createdDate": "2025-04-01",
    "text": "ATAR DAQ - Hardware \u25cfDAQ is functional and integrated into MIDAS \u25cfCan digitize data rates up to 55 MB/s, event rates up to 30 kHz* *For specific parameters Nexys A7 Video Board with Nalu\u2019s HDSoC Digitizer Attached as an FMC Module Conceptual Hardware Diagram for the HDSoC Readout ATAR DAQ - Software \u25cfWrote a midas frontend that leverages custom libraries created for readout \u25cbNalu Board Controller \u25cbNalu Event Collector \u25cfSeparate branch for rate testing , leveraging custom RP Pico W libraries created for automatic rate testing \u25cbRP Pico W remote controller \u25cbRP Pico W board interface Conceptual Software Diagram for the HDSoC Readout ATAR DAQ - Rate Tests \u25cfMajority of input parameters \u2192 performance as expected \u25cfOutliers where we underperform \u25cbExpect good performance under 55 MB/s \u25cbLooking for cause of performance drops Expected Data Rate vs. Actual Data Rate Actual Data Rate (KB/s) Expected Data Rate (KB/s) ATAR DAQ - Rate Tests \u25cfFor 32 channels (all active) \u25cf1 window = 32 12-bit ADC samples \u25cf1 Gsps \u25cfCan take 32 traces length 64 ns at rates ~20kHz reliably \u25cfEvents begin dropping near 55 MB/s threshold \u25cfNeed to test self/internal triggering mode still \u25cbIn these plots every channel is digitized on every trigger Normalized Event Rate vs. Frequency (32 channels) External Trigger Rate (Hz) Event Rate / External Trigger Rate ATAR DAQ - Useful Documents \u25cfATAR DAQ manual hosted on github pages \u25cbHardware setup guides \u25cbSoftware setup guides \u25cbODB configuration and usage \u25cbEtc. \u25cfMore rate testing plots available \u25cbSee my notes page \u25cfDocumentation and examples available in project README.md files A screenshot of a page on the ATAR DAQ Manual",
    "textLength": 268
  },
  {
    "kind": "presentation",
    "title": "Simulation Progress Report 11_26_2025_2025-11-26_22-27-08.pdf",
    "fileName": "Simulation Progress Report 11_26_2025_2025-11-26_22-27-08.pdf",
    "url": "resources/presentations/Simulation Progress Report 11_26_2025_2025-11-26_22-27-08.pdf",
    "createdDate": "2025-11-26",
    "text": "HDSoC Deadtime Studies Jack Carlton University of Kentucky HDSoC Deadtime (Methods) \u25cfUsed Raspberry Pi Pico W + NIM modules to generated configurable double pulse signal \u25cfUsed HDSoC DAQ to observe event rate for varying parameters \u25cfSee spike corresponding to deadtime Example Double pulse on Oscilloscope Example Rate Response to Double Pulse Separation HDSoC Deadtime (Parameter Scan) \u25cfThe deadtime depends on: \u25cb Digitization window length \u25cb Number of channels actively receiving pulses \u25cfIt does not depend on: \u25cb Number of inactive channels \u25cb Rate of events (up to some threshold, likely corresponding to ~55 MB/s) \u25cfWe tested the parameter space defined by \u25cb Windows = [1,2,4,8,16,32,61] \u25cb Channels = [1,2,4,8,16,32] \u25cb Input Signal Rate = [10 Hz, 100 Hz] \u25cfSpace defined as: \u25cb Windows \u2297 Channels \u2297 Input Signal Rate \u25cfNote: \u25cb Signals were fanned out to channels 0-15, no signals were in channels 16-31 Examples showing channels and windows affect on deadtime HDSoC Deadtime (Results) \u25cfDeadtime increases (~linearly) with \u25cb# of active channels \u25cb# of windows (# of samples, 1 window == 32 samples, this is nalu\u2019s terminology) \u25cfDeadtime unaffected by: \u25cbRate \u25a010Hz and 100Hz input signal curves overlap \u25cbInactive channels \u25a0Curve flattens when channels 16-31 (no input) are enabled in software \u25cfJSON file of deadtime upper bounds available Auxiliary Slides More information \u25cfMore plots in jupyter notebook (can view on github) \u25cbhttps://github.com/jaca230/nalu_deadtim e_tests/blob/main/notebooks/deadtime_ vs_separation.ipynb \u25cfMore information documented in Josh\u2019s demonstration simulation upgrade google doc \u25cbhttps://docs.google.com/document/d/18L Lyw50G9MPmdMN1EXKJsDdKYHJieB N8n_xYpL8UGR0/edit?pli=1&tab=t.0",
    "textLength": 257
  },
  {
    "kind": "presentation",
    "title": "DAQ Progress Report 08_22_2023_2023-08-22_20-05-10.pdf",
    "fileName": "DAQ Progress Report 08_22_2023_2023-08-22_20-05-10.pdf",
    "url": "resources/presentations/DAQ Progress Report 08_22_2023_2023-08-22_20-05-10.pdf",
    "createdDate": "2023-08-22",
    "text": "Current Progress Hardware and Frontend code: \u25cfEvent triggers \u25cbCan see data being transferred through tcp thread \u25cfCan see header/trailer information using mdump \u25cbMissing actual data payload \u25cfData not currently being logged Development Steps (Rough Outline) \u25cfCompiled UKY g-2 teststand DAQ (software only) \u25cbUses more recent midas version \u25cfModified AMC13xx frontend code to edit ODB to match configuration file \u25cfCompiled modified g-2 DAQ on Cornell teststand \u25cbConnected and communicated with frontend hardware (AMC13s with FC7s or WFDs) \u25cfSwap out hardware to one crate system \u25cfRemove/replace hard coded references to FC7 crate from frontends \u25cfGenerate data, check \u201cintegrity\u201d of files \u25cfClean up DAQ for easier user control, package with modified midas, distribute Example crate contents configuration file",
    "textLength": 119
  },
  {
    "kind": "presentation",
    "title": "DAQ Progress Report 06_10_2025_2025-06-09_17-04-09.pdf",
    "fileName": "DAQ Progress Report 06_10_2025_2025-06-09_17-04-09.pdf",
    "url": "resources/presentations/DAQ Progress Report 06_10_2025_2025-06-09_17-04-09.pdf",
    "createdDate": "2025-06-09",
    "text": "HDSoC DAQ - Updates \u25cfInternal or \u201cself\u201d trigger mode implemented into MIDAS frontend \u25cbRate testing soon \u25cfHDSoC midas event unpacker created by Sean \u25cbAllows for easy analysis by converting midas file \u2192 root tree Example Digitized Pulses From Multiple Events Flexible DQM \u25cfSimilar to what was done for g-2 \u25cfEach dashed box can be \u201cseparated\u201d if need be \u25cbI.e. hosted on its own dedicated machine \u25cbBuilt in redundancy for separation of concerns \u25a0Ex: could support multiple webservers for one experiment \u25cfWorks for any midas experiment* \u25cb*Needs custom unpackers to match equipment \u25cbAnalyzers/Unpackers can be hotswapped/configured \u25cfWeb frontend done \u25cbCan \u201cplugin\u201d new figure types \u25cbDemo available Midas Experiment [C++ or python] ZMQ Publisher [C++] Midas Receiver ZMQ Publisher ZMQ Receiver [python or C++] ZMQ Receiver Event Buffer Backend Webserver [python, C++, JavaScript, etc.] GET/POST Endpoints Web Frontend [JavaScript] Configurable Plot Displays Event Unpacker(s) Data Analyzer(s) Unpacked Data JSON Data for Plots Unpacked Data/Management Raw Midas Data Auxiliary Slides Reference Clock vs. Event Index Threshold Times for two time coincident signals Good vs. Bad events \u25cf\u201cGood\u201d means threshold crossing in expected time location on digitized islands \u25cf\u201cBad\u201d events have the threshold crossing outside that time window g-2 DQM system \u25cfNew DQM is conceptually similar \u25cbNo \u201cmidas-to-art\u201d since we aren\u2019t using art framework \u25cbnode.js (webserver) can still be used, but I prefer using FASTAPI in python \u25cbPlotly still used for all the figures (can use other tools as well) \u25cfWhy start from scratch? \u25cbUpdate to modern software \u25cbAbility to make more flexible by leveraging \u25a0\u201cReflection\u201d via rootcling (unpackers/analyzers) \u25a0Modular plot implementation via modern React Webapp",
    "textLength": 274
  },
  {
    "kind": "presentation",
    "title": "DAQ Progress Report 09_10_2024_2024-09-10_06-08-39.pdf",
    "fileName": "DAQ Progress Report 09_10_2024_2024-09-10_06-08-39.pdf",
    "url": "resources/presentations/DAQ Progress Report 09_10_2024_2024-09-10_06-08-39.pdf",
    "createdDate": "2024-09-10",
    "text": "g-2 modified DAQ updates \u25cfManual created for DAQ usage hosted on github \u25cbLiving document \u25cfMeinberg card no longer needed \u25cb\u201cMaster\u201d triggers replaced by FC7 internal trigger count \u25cfCurrent rate limitations at UKY: \u25cb~ 10kHz event rate \u25cb~ 120 MB/s uncompressed data rate \u25cbOther programs can cause slowdown on some system \u25cfCentOS7 reached EOL June 2024 \u25cbMigrate to ALMA9 Linux when possible PIONEER DAQ Updates \u25cfImprovements in transfer speed with RAM change (Block RAM \u2192 DDR3) \u25cfWorking on C++ library for reading and writing via PCIe DMA \u25cbWill work for Xilinx XDMA IP core \u25cbMay need adapting for PIONEER electronics Nalu Scientific HDSoC chip DAQ (NaluDAQ) \u25cfATAR readout uses Nalu Scientific HDSoC chip \u25cbHave python package for readout already made \u25cbExamples here \u25cfIntegrate into midas with a python frontend \u25cfRate tested python frontends \u25cbMax data rate ~90MB/s (per frontend, not concurrent with max event rate) \u25cbMax event rate ~10kHz (per frontend, not concurrent with max data rate)",
    "textLength": 156
  },
  {
    "kind": "presentation",
    "title": "UKY Group Report 02_11_2026_2026-02-10_21-56-00.pdf",
    "fileName": "UKY Group Report 02_11_2026_2026-02-10_21-56-00.pdf",
    "url": "resources/presentations/UKY Group Report 02_11_2026_2026-02-10_21-56-00.pdf",
    "createdDate": "2026-02-10",
    "text": "Asymmetric Numeral Systems (ANS) for Compression of Template Fit Data Jack Carlton University of Kentucky Template Fitting \u25cfCan construct a continuous template for our traces \u25cfCan fit traces using template: \u25cfStoring unfit traces takes ~12 bits per ADC sample \u25cfStoring residuals takes ~4 bits per ADC sample \u25cfBy fitting and compressing, we can expect compress the data by a factor of ~3 for \u201cperfect\u201d fits \u25cbEffective compressing random noise ADC value Residual value Time [c.t] Time [c.t] PSI Example LYSO Signal with Fit Signal - Fit Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) j.carlton@uky.edu 5/13 Range = ~16 = 4 bits Theoretical Best Compression \u25cfFor lossless compression, the best possible compression rate is the entropy rate \u25cfEntropy rate of pedestal part of signal is 3.4 bits per ADC sample \u25cbA perfect fit would reduce signal to pedestal noise \u25cfThus with perfect fit + compression true perfect compression factor is ~3.5 \u25cbHighly dependent on size of noise Time [c.t] Entropy/sample [bits] Entropy Rate Formula (First order, exact for independent residuals) Entropy Rate of PSI Test Beam Data After Fitting Signal entropy Pedestal entropy Pedestal entropy j.carlton@uky.edu 7/13 What is Asymmetric Numeral Systems (ANS)? \u25cfEntropy encoding compression method \u25cfManages a state that represents encoded data \u25cbCan separate into many states for GPU parallelization \u25cbBetter at encoding \u201cfractional bits\u201d than other methods like Huffman or Rice-Golomb \u25cfWikipedia Link What is Table Asymmetric Numeral Systems (tANS)? \u25cfYou can define the behavior of ANS (for fixed parameter choices) in a lookup table \u25cfThis removes the need for operations, rather each stage is a table lookup \u25cbDivision expensive on GPU \u25cfThe cost is needing to store a table \u25cbThis can be built one time based on measured probabilities of samples Why ANS is good at being parallelized \u25cfTwo example approaches: \u25cbBlock parallelism \u25cbInterleaved parallelism \u25cfBoth make it so: \u25cbOne thread holds one state \u25cbEach state has an identical update rule \u25cbNo synchronization is required across threads \u25cfThese make parallelization much more natural than other methods \u25cbEx. Rice-Golomb, Huffman Things to test/research questions \u25cfAt some point Sean had a template fitter for 2023 PSI LYSO waveforms \u25cbCan we easily get a sample of LYSO data to template fit to produce compressible integer residuals? \u25cfAssuming we have integer residuals, these are the things we want to compress with ANS \u25cbWhat data throughput (in GB/s) can we expect using tANS? \u25cbWhat compression factor can we expect using tANS? \u25cbHow do the above depend on choice of parameters (ex. Total frequency size F, which is related to the size of the table) \u25a0Expectation: as F goes up, compression factor improves but performance suffers \u25cbCompare compression factor to Shannon Entropy , which is the theoretical limit Sean computed for 2023 PSI LYSO data \u25a0Other useful metrics? Auxiliary Slides Should we delta encode? \u25cfProbably not \u25cfDelta encoding hurts compression if data has small covariance \u25cfAs a result, you should only delta encode if there is a positive correlation Delta encoded expectation non-delta encoded expectation Alternatively, look at the correlation coefficient to see \u201chow much\u201d delta encoding will help or hurt Template Fitting - How to store residuals Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) j.carlton@uky.edu 5/13 No Conditioning Shape Fit Frequency Frequency Voltage [Arbitrary Units] Voltage [Arbitrary Units] Rounding residuals is still lossless! Fit\u2019s job: 1. Compute fit params + residuals 2. Store fit params 3. send integer residuals to compression algorithm Rounding avoids messy binary float representations of the data Higher Order Entropy Estimations \u25cfAssume we have N characters (traces) in our alphabet (data set) \u25cfZero order: each character in alphabet is statistically independent \u25cfFirst order: each character in alphabet is statistically independent, pi is the probability of that character to occur \u25cfSecond order: Pj|i is correlation between subsequent characters \u25cfGeneral Model (impractical): Bn represents the first n characters Citation: Coding and Information Theory Class Notes, Dr. Jay Weitzen, University of Massachusetts Lowell https://faculty.uml.edu/jweitzen/16.548/classnotes/Theory%20of%20Data%20Compression.htm#:~:text=When%20the%20 compression%20is%20lossless,rate%20is%20the%20entropy%20rate What is Asymmetric Numeral Systems (ANS)? This is like a \u201cbuffer\u201d between bitstream and the state. Your state, likely encoded in a 64 bit integer, will overflow when encoding or decoding. So you need to \u201cemit\u201d or \u201cconsume\u201d bits to an arbitrary long bitstream as that happens.",
    "textLength": 740
  },
  {
    "kind": "presentation",
    "title": "Deadtime Estimate Updates for HDSoC and SAMPic as of 01_07_2026_2026-01-07_18-50-39.pdf",
    "fileName": "Deadtime Estimate Updates for HDSoC and SAMPic as of 01_07_2026_2026-01-07_18-50-39.pdf",
    "url": "resources/presentations/Deadtime Estimate Updates for HDSoC and SAMPic as of 01_07_2026_2026-01-07_18-50-39.pdf",
    "createdDate": "2026-01-07",
    "text": "Deadtime Estimate Updates for HDSoC and SAMPic Jack Carlton University of Kentucky HDSoC HDSoC Deadtime Scan (Results) Parameter Space (793 combinations): Channels = [1,2,...,13] Windows = [1,2,3,...61] Parameter Space (91 combinations): Channels = [1,2,...,13] Windows = [1,2,4,8,16,32,61] HDSoC Deadtime Scan (Fits) \u25cfIdea: deadtime should scale linearly with payload size \u25cfWorks well for >2 channels \u25cfFails for 1 and 2 channel cases HDSoC Deadtime Scan (Fits) \u25cfIdea: \u25cbFit y = a + b*windows +c*(channels*windows) \u25cbAdd a \u201cdigitization\u201d cost term \u25cbProduct is the \u201cconjestion\u201d cost term \u25cfAgain, works well for >2 channels \u25cfAgain, fails for 1 and 2 channel cases \u25cfCould try more complex fits but not sure how to motivate them \u2026 SAMPic SAMPiC Deadtime Scan (Results) Parameter Space (330 combinations): Channels = [1,2,...,13,14,15] Amplitude = [3.0,3.2, \u2026 5.0] Auto_conversion = [False, True] \u25cfSome runs failed (likely a communication error), the scan was programmed to move on in this case \u25cfThere\u2019s some scaling between Lecroy input voltage and SAMPic read voltage (ex. 5V lecroy input digitizes as ~0.5V(?) pulse on SAMPic) SAMPiC Deadtime Scan (Results) \u25cfAs expected with auto conversion off deadtime performance is worse, but consistent \u25cfAlso as expected, deadtime scales with voltage if auto conversion is on \u25cbI may want to try parameterizing the baseline, here it\u2019s set to default 0.5 V \u25cbAlso could try negative signals \u25cfDeadtime somehow influenced by whether both channels of lecroy were used or not \u25cbOutside of this, it appeared each channel has its own independent deadtime \u25a0Deadtime does not scale with number of channels Auxiliary Slides HDSoC Deadtime Scan (Fits) Example SAMPic digitization of lecroy signal Lecroy Module B Lecroy Module A",
    "textLength": 286
  },
  {
    "kind": "presentation",
    "title": "DAQ Progress Report 09_19_2023_2023-09-19_20-11-24.pdf",
    "fileName": "DAQ Progress Report 09_19_2023_2023-09-19_20-11-24.pdf",
    "url": "resources/presentations/DAQ Progress Report 09_19_2023_2023-09-19_20-11-24.pdf",
    "createdDate": "2023-09-19",
    "text": "Frontend code: \u25cfWorking on installation script for RHEL7.9 machines \u25cb Installs and makes midas-modified from github \u25cb Working on installing and making gm2daq-modified from github Current Progress Backend code: \u25cfSean Foster working on output analysis \u25cb Almost completely decoded midas data banks \u25cb Working of \u201coffline\u201d analysis for now \u25cb Plans for \u201conline\u201d/DQM work Development Steps (Rough Outline) Frontend code: \u25cfClean up DAQ for easier user control, package with modified midas, distribute Backend code: \u25cfCorrectly \u201cbin\u201d all header information, trailer information, ADC data, etc. \u25cfHistogram/data reconstruction (offline) \u25cfEstablish Data Quality Monitor (DQM) that links with midas experiment (online) Example crate contents configuration file",
    "textLength": 103
  },
  {
    "kind": "presentation",
    "title": "OralQualifyingExam_2023-06-29_21-46-02.pdf",
    "fileName": "OralQualifyingExam_2023-06-29_21-46-02.pdf",
    "url": "resources/presentations/OralQualifyingExam_2023-06-29_21-46-02.pdf",
    "createdDate": "2023-06-29",
    "text": "PIONEER Data Acquisition Development Jack Carlton Advisor: Tim Gorringe j.carlton@uky.edu Title (Slide 0/34) Outline I.[3-14] Physics Background/PIONEER goals A. \u03c0 \u2192 e\u03bd, \u03c0 \u2192 \u00b5\u03bd B. Lepton Universality C. Branching Ratio Re/\u00b5 D. Detector Design II.[15-21] Frontend Development A. Proposed DAQ framework B. Midas Framework C. Wavedream UKY teststand D. g-2 Cornell teststand \u2192 more versatile frontend III. [22-30] Fitting and Compression A. Algorithm B. Bottleneck C. Benchmarking IV. [32-34] Future Endeavors A. FPGAs B. November PSI beam time j.carlton@uky.edu Outline (Slide 2/34) \u03c0 \u2192 e \u03bde and \u03c0 \u2192 \u00b5 \u03bd\u00b5 \u25cfCorresponding diagrams for \u03c0- \u25cfTau decay forbidden \u25cbtau too massive ~ 1000 MeV/c2 \u25cbPion ~ 100 MeV/c2 \u25cfMuon decay more likely \u25cbbranching fraction of 0.999877 \u03bde e+\u00b5+\u03bd\u00b5 u du d\u03c0+ \u03c0+W W Citation: Particle Data Group (https://pdg.lbl.gov/2014/listings/rpp2014-list-pi-plus-minus.pdf) j.carlton@uky.edu I. Physics Background (Slide 3/34) Helicity Suppression (Why is Muon Decay Most Likely?) \u25cfNaively, \u0393 \u221d p\u2019 \u2192 electron decay more likely \u25cfWeak force only affects left-handed (LH) chiral particle states and right-handed (RH) chiral anti-particle states \u25cfNeutrinos are all LH chirality \u25cfm\u03bd << E means LH neutrino chirality \u2192 LH (negative) neutrino helicity \u25cfConservation of momentum \u2192 anti-lepton is LH (negative) helicity \u03bdl l+u d\u03c0+W \u03c0+ \u03bdll+ Citation: Modern Particle Physics, Mark Thomson (Ch. 11.6 pg. 299) j.carlton@uky.edu I. Physics Background (Slide 4/34) Helicity Suppression (Why is Muon Decay Most Likely?) \u25cfWe can write the LH (negative) helicity anti-particle state in the chiral basis: \u25cfWe ignore the LH term (weak force only acts on the RH term), anti-particle\u2019s matrix element contribution: \u25cfThis effect ends up making the matrix element smaller \u2192 decay rate smaller \u03bdl l+u d\u03c0+W \u03c0+ \u03bdll+ Citation: Modern Particle Physics, Mark Thomson (Ch. 11.6 pg. 300, Ch. 6.4 pg. 143) j.carlton@uky.edu I. Physics Background (Slide 5/34) Lepton Universality \u25cfStates coupling strengths (vertices) ge = g\u00b5 = g\u03c4 \u25cfUsing the Feynman rules for the weak interaction, we can approximate the matrix element \u03bdee-\u00b5- \u03bd\u00b5d ud u\u03c0- \u03c0-W W ge g\u00b5 f\u03c0f\u03c0 Pion vertex Lepton vertex W-boson propagator Citation: Modern Particle Physics, Mark Thomson (Ch. 11.6 pg. 301) j.carlton@uky.edu I. Physics Background (Slide 6/34) Lepton Universality \u25cfAfter some \u201cmassaging\u201d we can find the matrix element to be \u25cfPion spin zero \u2192 no spin averaging needed, i.e.: \u25cfWe can use the general formula for 2-body decay to to find the decay rate \u25cfFinally, we compute the branching ratio Citation: Modern Particle Physics, Mark Thomson (Ch. 11.6 pg. 302-303) j.carlton@uky.edu I. Physics Background (Slide 7/34) Lepton Universality \u25cfLepton universality assumes ge = g\u00b5, so the first factor disappears \u25cfImproving the branching ratio measurement and comparing to the theoretical value acts as a test of lepton universality \u25cfAnother test would consider pure leptonic decays, but such decays involving taus are too rare for high precision measurements j.carlton@uky.edu I. Physics Background (Slide 8/34) Branching Ratio Re/\u00b5 \u25cfWe can measure the branching ratio by measuring # of decays e and \u00b5 decays \u25cfTheoretical prediction is simple in first (and second) order \u25cbNo f\u03c0 or CKM element Vud \u25cf3rd order correction and beyond the pion structure becomes relevant = 1 [in theory] Citation: Dynamic of the Standard Model, Donoghue et. al (Ch. 6.1 pg. 163) j.carlton@uky.edu I. Physics Background (Slide 9/34) Current state of Re/\u00b5 \u25cfConsistent with each other \u25cfExpect factor of ~10 precision improvement on experimental value from PIONEER \u25cb\u201cCatches up\u201d with theoretical uncertainty Re/\u03bcexp = 1.2327(23) x 10-4 (PIENU collab) Rtheo = 1.23524(15) x 10-4 Citation: Testing Lepton Flavor Universality and CKM Unitarity with Rare Pion Decays in the PIONEER experiment, PIONEER collab (pg. 6, arxiv: 2203.05505) j.carlton@uky.edu I. Physics Background (Slide 10/34) Past Experimental Approach (PIENU) \u25cfNaI has a long primary decay time \u25cb~ 250 ns \u25cfEvent pileup forces the experiment to run at a low rate \u25cb~70 kHz \u25cf\u201cinactive target\u201d, muons aren\u2019t tracked \u25cfCsI Rings for shower leakage detection Citation: Status of the TRIUMF PIENU Experiment, PIENU collab, (arxiv 1509.08437) https://pienu.triumf.ca/ j.carlton@uky.edu I. Physics Background (Slide 11/34) PIONEER Experimental Proposal Citations: PIONEER Seminar, Tim Gorringe (Slide 20) PSI Ring Cyclotron Proposal R-22-01.1 PIONEER: Studies of Rare Pion Decays, PIONEER collab, (pg. 19 arxiv: 2203.01981) \u25cfLXe (or LYSO) has smaller decay time \u25cb~ 25 ns \u25cfAllows experiment to run at much higher rate \u25cb~300kHz (phase 1) \u25cb~2000kHz (phase 2 and 3) \u25cf\u201cactive target\u201d, muons and pions are \u201ctracked\u201d j.carlton@uky.edu I. Physics Background (Slide 12/34) Active Target (ATAR) Purpose arxiv: 2203.01981 Citation: PSI Ring Cyclotron Proposal R-22-01.1 PIONEER: Studies of Rare Pion Decays, PIONEER collab, (pg. 19 arxiv: 2203.01981) j.carlton@uky.edu I. Physics Background (Slide 13/34) How PIONEER Will Improve the Re/\u00b5 Measurement \u25cf4D space-time active pion stopping target (ATAR) \u25cb Reduce e+ energy tail, identify beam pileup, identify \u03c0 \u2192 \u00b5 \u03bd\u00b5 decays \u25cfLarge acceptance, deep radiation length calorimeter \u25cb LXE or LYSO for high resolution, fast response, small tail \u25cfFast electronics, high-speed acquisition \u25cb Giga sample/second digitizers, new gen PCIe readout \u25cfPSI high intensity pion beams \u25cb 2 mA proton beam, large acceptance beamline Citation: PIONEER Seminar, Tim Gorringe (Slide 22) j.carlton@uky.edu I. Physics Background (Slide 14/34) Proposed Data Acquisition (DAQ) Framework arXiv:2203.05505 Citation: Testing Lepton Flavor Universality and CKM Unitarity with Rare Pion Decays in the PIONEER experiment, PIONEER collab (pg. 20, arxiv: 2203.05505) j.carlton@uky.edu II. DAQ Framework (Slide 15/34) Proposed Data Acquisition (DAQ) Framework arXiv:2203.05505 Citation: Testing Lepton Flavor Universality and CKM Unitarity with Rare Pion Decays in the PIONEER experiment, PIONEER collab (pg. 21) j.carlton@uky.edu II. DAQ Framework (Slide 16/34) Midas Framework \u25cfPackage of modules for \u25cbrun control, \u25cbexpt. configuration \u25cbdata readout \u25cbevent building \u25cbdata storage \u25cbslow control \u25cbalarm systems \u25cbetc. Citation: Rare Pion Decay Workshop, Tim Gorringe (Slide 6) j.carlton@uky.edu II. DAQ Framework (Slide 17/34) WaveDREAM Teststand WaveDREAM board CAEN Digital Detection Emulator Frontend (FE) computer Backend (BE) computer BNC-SMA 10GbE 1GbE \u25cfCreates fake analog signals \u25cfConfigurable rate \u25cfConfigurable triggers on signals \u25cfDigitizes data \u25cfExecutes frontend code \u25cfPackages Data \u25cfUses GPU and CPU for real time data compression \u25cfHost midas server \u25cfStores data 1GbE UKY Network \u25cfAllows for remote connection j.carlton@uky.edu II. DAQ Framework (Slide 18/34) Example Signal \u25cfCAEN module produces and sends \u201cfake\u201d double exponential signal \u25cfWaveDREAM triggers on low voltage signal, sends time window of data \u25cfFE receives data, packages, and compresses it, sends to be stored \u25cfBE stores data, can be remotely accessed j.carlton@uky.edu II. DAQ Framework (Slide 19/34) g-2 DAQ set-up FC7s Crate WFDs Crates ...Array of FEs, BE, Midas server ... Rest of Experiment \u25cfFE expects a crate of just FC7s (hard-coded in) \u25cbSend timing information, triggers, etc, to FEs \u25cfCan have as many WFD crates as we want \u25cbDigitize data to be processed by FE code j.carlton@uky.edu II. DAQ Framework (Slide 20/34) g-2 DAQ Modified for November Beam Time Crate(s) of FC7s and WFDs ...Array of FEs, BE, Midas server ... Rest of Experiment \u25cfFE code modified to allow crates with FC7s and WFDs \u25cfMore versatile \u25cbAllows for one crate setups \u25cfUseful for: \u25cbBeamtime test DAQ \u25cbStony Brook DAQ \u25cbWashington DAQ j.carlton@uky.edu II. DAQ Framework (Slide 21/34) Data Rates Citation: PSI Ring Cyclotron Proposal R-22-01.1 PIONEER: Studies of Rare Pion Decays, PIONEER collab (pg. 33) j.carlton@uky.edu III. Fitting and Compression (Slide 22/34) arXiv:2203.01981 \u25cfPIONEER expects data rate of ~ 3.5GB/s \u25cfThis is ~ 100,000 TB/year Signal Conditioning \u25cfWant a narrow distribution for compression. Let ri be the numbers we compress \u25cfMethods tried: \u25cbNo conditioning \u25cbDelta encoding: ri = yi+1-yi \u25cbTwice Delta Encoding: ri = yi+2-2yi+1+yi \u25cbDouble Exponential Fit: ri= yi - (A \u22c5exp(ati)+ B \u22c5exp(bti)) \u25cbShape Fit : ri =yi- (A \u22c5T(ti-t0) + B) No Conditioning Shape Fit Frequency Frequency Voltage [Arbitrary Units] Voltage [Arbitrary Units] j.carlton@uky.edu III. Fitting and Compression (Slide 23/34) Shape Fitting Algorithm 1.Construct a discrete template from sample pulses 2.Interpolate template to form a continuous Template, T(t) 3.\u201cStretch\u201d and \u201cshift\u201d template to match signal: [Note: a and b can be calculated explicitly given t0] 4.Compute \u03c72 (assuming equal uncertainty on each channel i) 5.Use Euler\u2019s method to minimize \u03c72 j.carlton@uky.edu III. Fitting and Compression (Slide 24/34) Lossless Compression Algorithm \u25cfRice-Golomb Encoding \u25cbLet x be number to encode y = \u201cs\u201d+\u201cq\u201d+\u201dr\u201d \u25a0q = x/M (unary) \u25a0r = x%M (binary) \u25a0s = sign(x) \u25cbAny distribution \u25cbClose to optimal for valid choice of M \u25cbOne extra bit to encode negative sign \u25cbSelf-delimiting \u25cbIf quotient too large, we \u201cgive up\u201d and write x in binary with a \u201cgive up\u201d signal in front Value Encoding -1 011 0 000 1 001 2 1000Rice-Golomb Encoding (M=2) Red = sign bit Blue = quotient bit(s) (Unary) Yellow = remainder bit (binary) j.carlton@uky.edu III. Fitting and Compression (Slide 25/34) How to choose Rice-Golomb parameter M \u25cfGenerated fake Gaussian data (centered at zero) with variance \u03c32 \u25cfFor random variable X, M \u2248 median(|X|)/2 is a good choice \u25cbThis is the close to the diagonal on the plot \u25cf\u03c3 \u2248 32 for residuals of shape on wavedream data \u2192 M = 16 is a good choice Gaussian Noise \u03c3 MCompression Ratio Determining Optimal M waveDREAM test j.carlton@uky.edu III. Fitting and Compression (Slide 26/34) Compression Ratio from Rice-Golomb Encoding \u25cfLossless compression factor of ~2 \u25cfIn agreement with plot from simulated data on last slide \u25cfBest compression ratio we achieved Rice-Golomb Compression on Residuals (M = 16) Compression Ratio Sample Index j.carlton@uky.edu III. Fitting and Compression (Slide 27/34) Real Time Compression Algorithm \u25cfWe choose to let the FE\u2019s GPU and CPU handle compression for flexibility CPU GPU Copy initial guess, Y(t0) Allocate memory for X,Y(t0),t0*,t,r,r\u2019c timeCompute initial guess fit Y(t0)Initialization (one time) Data loop (many times) Copy many traces, X (Overwrite) Wait for enough traces\u2026 Launch 1 thread per trace Compute t0*, via \u03c72 minimization, r = X-Y(t0*)Copy r\u2019c, t0*Use header info from r\u2019c to allocate memory for rcAllocate memory for X,Y,t,r\u2019c Golomb encode r \u2192 r\u2019cStitch together rc from r\u2019c Store rc, t0*j.carlton@uky.edu III. Fitting and Compression (Slide 28/34) GPU Benchmarking (Timings) \u25cfBlock Size: \u25cbA GPU parameter, number of threads per multiprocessor \u25cfCan compress 226 integers (32-bit) in roughly \u2153 of a second. \u2192 ~ 0.8 GB/s compression rate Time [s] # of 32-bit Integers Fit + Compression Time using A5000 in PCIe4 (Batch Size = 1024) j.carlton@uky.edu III. Fitting and Compression (Slide 29/34) GPU Benchmarking (Timings) \u25cfBatch Size: \u25cbHow many integers are compressed by a single GPU thread \u25cfData must be sent to GPU in batches (not a continuous flow) to take full advantage of parallel computation j.carlton@uky.edu III. Fitting and Compression (Slide 30/34) Handling the data rate \u25cfAgain, data rate ~3.5GB/s \u25cfWe expect to achieve this using the following method(s) \u25cbMultiple GPUs/CPUs \u25cbNewer PCIe versions available by start of experiment j.carlton@uky.edu III. Fitting and Compression (Slide 31/34) Future Projects (Things I\u2019m Working On) j.carlton@uky.edu IV. Future Projects (Slide 32/34) FPGA Use \u25cfFor the PIONEER DAQ, we plan to use FPGAs to digitize data \u25cfA PCIe card with an FPGA will replace the waveDREAM in our test stand picture \u25cfWhy? \u25cbCan use PCIe for fast data transfer \u25cbAble to transfer data directly to GPU \u25cbMore flexible signal triggers j.carlton@uky.edu IV. Future Projects (Slide 33/34) November PSI beam time \u25cfNeed a functioning one crate DAQ by November in order to test equipment \u25cfEquipment tests (Calo, ATAR, etc.) \u25cfWill have to \u201cbuild\u201d DAQ onsite j.carlton@uky.edu IV. Future Projects (Slide 34/34) Auxiliary Slides j.carlton@uky.edu Auxiliary Slides (Slide 35/66) Common Pion Decay Channels \u25cf\u03c0+ \u2192 e+ + \u03bde \u25cf\u03c0- \u2192 e- + \u03bde \u25cf\u03c0+ \u2192 \u00b5+ + \u03bd\u00b5 \u25cf\u03c0- \u2192 \u00b5- + \u03bd\u00b5 \u25cf\u03c0+ \u2192 \u03c00 + e+ + \u03bde \u25cf\u03c0- \u2192 \u03c00 + e- + \u03bde\u25cf\u03c00 \u2192 \u03b3 + \u03b3 \u25cf\u03c00 \u2192 \u03b3 + e- + e+ \u25cf\u03c00 \u2192 e- + e+ + e- + e+ \u25cf\u03c00 \u2192 e- + e+ Leptonic Decay Beta Decay = Most Common Photon Decay Dalitz Decay Double-Dalitz Decay Electrons [Note: Dalitz Decays are like photon decays, except the photon(s) are virtual and immediately decay into electron/positron pairs] Citation: Wikipedia (https://en.wikipedia.org/wiki/Pion) j.carlton@uky.edu Auxiliary Slides (Slide 36/66) Naive Pion Decay, 2-body decay \u25cfWithout getting into details of QCD, we can treat this as a 3 particle decay \u25cfWe can use Fermi\u2019s golden rule: \u25cfAfter integration in the COM frame we find: \u25cf\u2192 \u0393 \u221d p (not correct) \u25cbDetails hidden in matrix element AB C Citation: Introduction to Elementary Particles, Griffiths (Ch. 6.2 pg. 196-198) j.carlton@uky.edu Auxiliary Slides (Slide 37/66) Why Massless \u2192 Chirality States ~ Helicity States \u25cfMassless \u2192 moves at c \u25cfMoves at c \u2192 cannot reverse particle direction with Lorentz boost \u2192 helicity is Lorentz Invariant \u25cfChirality is a property of a particle, always Lorentz invariant! \u2192 helicity and chirality agree in direction in all inertial reference frames [Dirac Equation] [Chiral States] [Helicity operator] [Chiral states are eigenstates of helicity operator] Citation: Lecture Notes, Quantum Field Theory, Michael Eides (PHY616, Lecture #25) j.carlton@uky.edu Auxiliary Slides (Slide 38/66) LH (negative) helicity spinor to chiral components An negative helicity antiparticle can be written as Where (\u03b8,\u03c6) define the direction of the momentum. Without loss of generality, assume the momentum is in the z direction Citation: Modern Particle Physics, Mark Thomson (Ch. 6.4 pg. 143) j.carlton@uky.edu Auxiliary Slides (Slide 39/66) LH (negative) helicity spinor to chiral components We can use the chiral projection operations to project this helicity state to chiral state Where the left and right chiral anti-particle states are defined by Citation: Modern Particle Physics, Mark Thomson (Ch. 6.4 pg. 141,143) j.carlton@uky.edu Auxiliary Slides (Slide 40/66) LH (negative) helicity spinor to chiral components Looking at the chiral projection of a negative helicity state, we can see in general there are left and right chiral components, so the weak force can act on a LH (negative) anti-particle helicity state It should also be clear as m\u21920, the LH (negative) helicity state coincides with the LH chiral state. This means W boson decay to two massless leptons is forbidden! One of the particles must have the wrong chirality, and thus low mass decays will be suppressed. Citation: Modern Particle Physics, Mark Thomson (Ch. 6.4 pg. 143) j.carlton@uky.edu Auxiliary Slides (Slide 41/66) Matrix Element Details Move to pion rest frame so only p0 = m\u03c0 remains: Using the identity: Citation: Modern Particle Physics, Mark Thomson (Ch. 11.6 pg. 301) j.carlton@uky.edu Auxiliary Slides (Slide 42/66) Matrix Element Details For a neutrino m << E so helicity eigenstate is essentially the chiral eigenstate: By letting the lepton go in the z-direction we can write: and Negative helicity lepton down state disappears when \u201cdotted\u201d with the neutrino state: Citation: Modern Particle Physics, Mark Thomson (Ch. 11.6 pg. 301-302) j.carlton@uky.edu Auxiliary Slides (Slide 43/66) Matrix Element Details We can re-write El and p in the limit where the neutrino mass is zero: Citation: Modern Particle Physics, Mark Thomson (Ch. 11.6 pg. 302) j.carlton@uky.edu Auxiliary Slides (Slide 44/66) Another Test for Lepton Universality Citation: PIONEER Seminar, Tim Gorringe (Slide 9) Fermi constant and new physics, Marciano, Phys Rev. D 60, 093006 j.carlton@uky.edu Auxiliary Slides (Slide 45/66) CKM Unitary Test Citation: Testing Lepton Flavor Universality and CKM Unitarity with Rare Pion Decays in the PIONEER experiment, PIONEER collab (pg. 21) PIONEER Seminar, Tim Gorringe (Slide 12) arXiv:2203.05505 \u25cfPion beta decay gives a precision measurement of Vud \u25cfThese decays are lower rate than \u03c0 \u2192 e\u03bde and \u03c0 \u2192 \u00b5\u03bd\u00b5 \u25cfExperimental measurements do not agree j.carlton@uky.edu Auxiliary Slides (Slide 46/66) Some Information about LXe and NaI \u25cfLXe has singlet and triplet state decay constants: \u25cb\u03c4S = 4.3 \u00b1 0.6 ns \u25cb\u03c4T = 26.9+0.7 \u22121.1 ns \u25cfLXe light yield: \u25cb~29 photons/keV at room temp \u25cfNaI decay constant: \u25cb~ 250 ns \u25cfNaI light yield: \u25cb38 photons/keV at room temp Citations: A measurement of the scintillation decay time constant of nuclear recoils in liquid xenon with the XMASS-I detector, XMASS collab, arxiv 1809.05988 Scintillation yield of liquid xenon at room temperature , XMASS collab, arxiv 0803.2888 Berkeley Nucleonics (https://www.berkeleynucleonics.com/nai-sodium-iodide) Scintillation from excited Xe (Xe*): Scintillation from ionized Xe (Xe+): j.carlton@uky.edu Auxiliary Slides (Slide 47/66) PEN \u25cfSimilar to PIENU \u25cbSegmented \u25cbBetter timing \u25cfMany channels of pure CSI \u25cb240 channels \u25cfActive target Citation:PEN: a low energy test of lepton universality , PENcollab, (arxiv: 1701.05254) j.carlton@uky.edu Auxiliary Slides (Slide 48/66) More ATAR details \u25cfPion and muon decays deposit energy into ATAR \u25cfAllow event types to be distinguished \u25cfMuons decaying in flight can boost positron energy past 53 MeV (big issue!) \u25cbATAR can give information to rebuild event, and correctly classify a muon decay arxiv: 2203.01981 Citation: PSI Ring Cyclotron Proposal R-22-01.1 PIONEER: Studies of Rare Pion Decays, PIONEER collab, (pg. 19 arxiv: 2203.01981) j.carlton@uky.edu Auxiliary Slides (Slide 49/66) Why two computers? \u25cfReally just for practice \u25cfReal experiment will likely have multiple FE computers, which will all communicate with one BE computer \u25cfIn real experiment, one computer is impractical \u2026Frontend Computers Backend Computer Network j.carlton@uky.edu Auxiliary Slides (Slide 50/66) Networking Machines Together 1.LAN connection a. dhcp b. ssh 2.Remote connection a. Kerberos b. ssh UKY Network Cornell Network Remote device Kerberos Authentication dhcp j.carlton@uky.edu Auxiliary Slides (Slide 51/66) Edits to MIDAS code \u25cfSome edits were made to the MIDAS source code to make our frontends \u201cwork\u201d \u25cbIncreasing online database (ODB) maximum number of hotlink \u25cbVarious \u201cbug fixes\u201d (i.e. things that made it so the g-2 daq would no longer compile) j.carlton@uky.edu Auxiliary Slides (Slide 52/66) Other Conditioning Distributions Delta Encoding Twice Delta Encoding Double Exponential Fit j.carlton@uky.edu Auxiliary Slides (Slide 53/66) Shape Fitting Details Fit Function Explicit a(t0) calc Explicit b(t0) calc Explicit \u03c72 calc Newton\u2019s method Threshold requirement j.carlton@uky.edu Auxiliary Slides (Slide 54/66) Golomb Encoding \u25cfIn general, M is an arbitrary choice \u25cfSince computers work with binary, M = 2x such that x is an integer is a \u201cfast\u201d choice \u25cbThis is called Rice-Golomb Encoding \u25cfSelf delimiting so long as the information M is provided Encoding of quotient part q output bits 00 110 2110 31110 411110 5111110 61111110 \u22ee \u22ee N111 \u22ef1110Golomb Encoding Example Encoding of remainder part r offset binary output bits 00 0000 000 11 0001 001 22 0010 010 33 0011 011 44 0100 100 55 0101 101 612 1100 1100 713 1101 1101 814 11101110 915 11111111Choose M = 10, b = log2(M) = 3 2b+1 - M = 16 - 10 = 6 r < 6 \u2192 r encoded in b=3 bits r \u2265 6 \u2192 r encoded in b+1=4 bits Citation: Wikipedia (https://en.wikipedia.org/wiki/Golomb_coding) j.carlton@uky.edu Auxiliary Slides (Slide 55/66) Huffman Encoding \u25cfRequires finite distribution \u25cfValues treated as \u201csymbols\u201d \u25cfSelf-delimiting (sometimes called \u201cgreedy\u201d) Value Frequency Encoding -1 \u2261 a 1 000 0 \u2261 b 10 1 1 \u2261 c 5 01 2 \u2261 d 3 001Huffman Encoding Example db ac10 10 10 d a1 0b c \u2026\u201cCombine\u201d two lowest frequencies into tree, Frequency z = 1+3 = 4 zRepeat for set {z,c,b} d ac0 101y bCitation: Wikipedia (https://en.wikipedia.org/wiki/Huffman_coding) j.carlton@uky.edu Auxiliary Slides (Slide 56/66) Theoretical Uncertainty in Compression Ratio from Gaussian Noise \u25cf~ 0.1% relative error j.carlton@uky.edu Auxiliary Slides (Slide 57/66) Uniform Distribution of Noise effect on Compression Ratio \u25cfHere instead we use a uniform distribution to generate the noise \u25cfNot much different than gaussian noise, same conclusions really j.carlton@uky.edu Auxiliary Slides (Slide 58/66) Residuals Distribution and Optimal M M Compression Ratio 1 1.04721105 2 1.21287474 4 1.53114598 8 1.92616642 16 2.09307249 32 2.02975311 64 1.86037914 128 1.66627451 ... ...j.carlton@uky.edu Auxiliary Slides (Slide 59/66) Lossy Compression Idea \u25cfIn lossless compression, Rice-Golomb encodes: 1.Fit parameters 2.Residuals \u25cfIf the residuals meet some criteria, we may choose to threw them out just keeping our fit of the signal. Example Criteria: j.carlton@uky.edu Auxiliary Slides (Slide 60/66) GPU Timing Breakdown \u25cfBottleneck is at the transfer between GPU and CPU \u25cfThis data transfer time decreases with PCIe gen \u25cfInterfacing and Initialization should be 1 time operations j.carlton@uky.edu Auxiliary Slides (Slide 61/66) PCIe Gen Speedup \u25cfPCIe3 \u2192 PCIe4 gives a roughly factor of 2 speedup (expected) \u25cfWhat\u2019s puzzling is that PCIe2 is faster than PCIe3 \u25cf PCIe2 test was done on different computer and OS, may be the cause j.carlton@uky.edu Auxiliary Slides (Slide 62/66) Does the GPU Quality Matter? \u25cfPCIe bus data transfer rate matters much more \u25cfTesla K20c (Released: November 12th, 2012) \u25cfA5000 (Released: April 12th, 2021) \u25cfNearly a decade of improvement gives ~1.2x speedup. Not cost efficient to use newest GPUs. j.carlton@uky.edu Auxiliary Slides (Slide 63/66) Programing FPGAs \u25cfTo code our FPGAs, we will likely use V ivado and write our code in V erilog \u25cfTo the right is an example thermometer project I did to learn about programming FPGAs j.carlton@uky.edu Auxiliary Slides (Slide 64/66) Computation Time scales O(n) \u25cfSame plot as before, without x axis in log scale \u25cfFor sufficient N, the computational time scales linearly \u25cfN too large, GPU runs out of memory \u25cfN too small, GPU parallel computation not fully utilized j.carlton@uky.edu Auxiliary Slides (Slide 65/66) Optimal Batching Choice \u25cfThere appears to be an optimal batching choice \u25cfSmall optimization, may not be worth worrying about \u25cfSmall batch sizes \u2192 CPU must do more \u201csewing\u201d data back together. \u25cfLarge batch sizes \u2192 fewer GPU threads are utilized during compression j.carlton@uky.edu Auxiliary Slides (Slide 66/66)",
    "textLength": 3839
  },
  {
    "kind": "presentation",
    "title": "Simulation Progress Report 4_9_2025_2025-04-07_06-20-21.pdf",
    "fileName": "Simulation Progress Report 4_9_2025_2025-04-07_06-20-21.pdf",
    "url": "resources/presentations/Simulation Progress Report 4_9_2025_2025-04-07_06-20-21.pdf",
    "createdDate": "2025-04-07",
    "text": "Proposed Pattern Finding Framework Jack Carlton University of Kentucky Information Framework EventPatterns Member Variables: - Set of Pattern classes Methods: - Anything for event level pattern info, examples: - getPatterns() Notes: This is effectively just a wrapper around a set of patterns but provides structure to add more (ex. Write to fRecEvent method) \u03c0\u03bce \u03c0 e Pattern Member Variables: - Set of Vertex classes Methods: - Anything for pattern level info, example: - getVertices() Notes: This is effectively just a wrapper around a set of vertices but provides structure to add more \u03c0\u03bce Vertex Member Variables: - Set of Tracklet\u2020 classes - PatternCreator tags (json map or similar) Methods: - Anything for vertex level info, examples: - getTracklets() Notes: This is effectively just a wrapper around a set of tracklets but provides structure to add more \u03c0\u03bc Tracklet\u2020 Member Variables: - Hits (or endpoints only?) - Fitter function (or abstract class?) - Fit results (json map or similar) - In/out tracklet boolean? - VertexCreator tags (json map or similar) Methods: - Anything for tracklet level pattern info, examples: - getEndpoints() - fit() Notes: We may need a \u201cPatternFinderTracklet\u201d object or similar to wrap around what Jessie gives us. \u2020 This will likely be a wrapper around what comes out of the tracklet finding algorithm, not the actual tracklet from tracklet finding \u03c0 Algorithm Framework PatternFindingHelpers (Helper class) Member Variables: - VertexCreator abstract class - PatternCreator abstract class Methods: - formVertices(set<Tracklets>) - formPatterns(set<Vertices>) Notes: More or less just a container for logic to create patterns. Has member variables to \u201chot swap\u201d algorithms. \u03c0\u03bc e \u03c0 eformVertices(set<Tracklets>) formPatterns(set<Vertices>) VertexCreator Member Variables: - \u2026 Methods: - Virtual formVertices(set<Tracklets>) Notes: Can implement any algorithm with any parameters needed by creating a class derived from VertexCreator. formVertices(set<Tracklets>) PatternCreator Member Variables: - \u2026 Methods: - Virtual formPatterns(set<Vertex>) Notes: Can implement any algorithm with any parameters needed by creating a class derived from PatternCreator. \u03c0\u03bc e \u03c0 eformPatterns(set<Vertices>) Pattern Finding Playground \u25cfStarted creating python framework for testing algorithms \u25cbGithub repo \u25cbUsing python allows for quicker testing, switching, and validation of algorithms we design (from a development perspective) \u25cfNext steps: \u25cbTest and develop algorithm in python \u25cbPort into C++ simulation framework Auxiliary Slides formVerticies Method (vague) Ideas \u25cfCould treat it as clustering of endpoints. Let endpoints have form: (x,y,z,E,t, \u2026 whatever else \u2026) \u25cbKmeans? See how endpoints get grouped? \u25cfSimilarly, could define some \u201cmeasure\u201d Kmeans groupings k=3 for endpoints (x,y,z)",
    "textLength": 395
  },
  {
    "kind": "presentation",
    "title": "Annual postqualifiying update 2_2026-02-11_18-07-54.pdf",
    "fileName": "Annual postqualifiying update 2_2026-02-11_18-07-54.pdf",
    "url": "resources/presentations/Annual postqualifiying update 2_2026-02-11_18-07-54.pdf",
    "createdDate": "2026-02-11",
    "text": "PIONEER Software Development Update Jack Carlton University of Kentucky j.carlton@uky.edu Title (Slide 1/44) Outline I.PIONEER Refresher A. Strategy B. Experimental Design II.DAQ Software Development A. Calorimeter Teststand DAQ B. ATAR Candidate DAQ: HDSoC C. ATAR Candidate DAQ: SAMPic D. Deadtime Tests for ATAR DAQ Candidates E. Example Supplementary Software: Flexible Data Quality Monitor III. Simulation Software Development A. ATAR Pattern Finding B. ATAR AI Reconstruction IV. PSI 2025 Testbeam A. \u201cSoccer Ball\u201d Design B. Energy Resolution Measurement V.Graduation Planned Timeline You can find this presentation in my notes Links: https://jaca230.github.io/joplin_notes_page/ or https://tinyurl.com/jack-uky-notes j.carlton@uky.edu Outline (Slide 2/44) PIONEER Refresher j.carlton@uky.edu PIONEER Refresher (Slide 3/44) Primary PIONEER Goal Citations: PIONEER Slides from ACTS Workshop, Patrick Schwendimann (Slide 1) j.carlton@uky.edu PIONEER Refresher (Slide 4/44) PIONEER Strategy \u25cfCalorimeter measures just positron energy \u25cbMuon stopped by target \u25cbNeutrinos invisible \u25cfPrompt 70 MeV = \u03c0\u2192e \u25cfDelayed <53 MeV = \u03c0\u2192\u00b5\u2192e \u25cfPlots are for idealized, perfect detectors (in a \u201csimple world\u201d) Citations: PIONEER Slides from ACTS Workshop, Patrick Schwendimann (Slide 3) j.carlton@uky.edu PIONEER Refresher (Slide 5/44) PIONEER Strategy \u25cfAt a glance the experiment is simple \u25cfJust look at energy deposited on the calorimeter and count events above and below Ethr \u2261 56 MeV \u25cfIn reality, not so simple\u2026 Citations: PIONEER Slides from ACTS Workshop, Patrick Schwendimann (Slide 6) j.carlton@uky.edu PIONEER Refresher (Slide 6/44) PIONEER Strategy \u25cfFinite resolution and incomplete energy collection in the calorimeter result in a tail \u25cfTo compete with theoretical uncertainty, we need to characterize this tail to ~1 part in 10,000 ( ) Citations: PIONEER Slides from ACTS Workshop, Patrick Schwendimann (Slide 7) j.carlton@uky.edu PIONEER Refresher (Slide 7/44) PIONEER Experimental Proposal Citations: PIONEER Slides from ACTS Workshop, Patrick Schwendimann (Slide 4) \u25cfLYSO (or LXe) as a calorimeter material has short decay time and good energy resolution \u25cb\u03c3t \u2248 100 ps (timing resolution) \u25cb\u0394E/E \u2248 2% (energy resolution) \u25cfExperiment to run at much higher beam rate than PIENU \u25cb~300kHz (phase 1) \u25cb~2000kHz (phase 2 and 3) \u25cf\u201cactive target\u201d, muons and pions are \u201ctracked\u201d while being stopped j.carlton@uky.edu PIONEER Refresher (Slide 8/44) Calorimeter (CALO) Purpose \u25cfMuon\u2019s intrinsically follow a Michel Spectrum \u25cbAdditionally width comes from energy resolution \u25cfPositrons follow monoenergetic spectrum \u25cbDeviation from 69.8 MeV mostly due to radiative decays \u25cfGood energy resolution is crucial for event reconstruction \u25cbThe less likely muons decays are to contaminated the electron tail, the lower we can set the energy threshold. Therefore, the tail correction becomes smaller and the ATAR can afford to characterize it with worse relative precision Muon Michel Electron Monoenergetic Citation: PSI Ring Cyclotron Proposal R-22-01.1 PIONEER: Studies of Rare Pion Decays, PIONEER collab, (pg. 19 arxiv: 2203.01981) j.carlton@uky.edu PIONEER Refresher (Slide 9/44) Active Target (ATAR) Purpose arxiv: 2203.01981 Citation: PSI Ring Cyclotron Proposal R-22-01.1 PIONEER: Studies of Rare Pion Decays, PIONEER collab, (pg. 19 arxiv: 2203.01981) \u25cfATAR allows classifying between \u03c0\u2192e and \u03c0\u2192\u00b5\u2192e based on 5D (x,y,z,t,E) information \u25cb Worse energy resolution than calorimeter, cannot do experiment on it\u2019s own \u25cfCase 5. \u03c0 and \u00b5 decay in flight negligible \u25cb ATAR designed to stop heavy \u201cslow\u201d particles within their decay time; decay in flights are are rare thus \u03c0 and \u00b5 decays in flight within the same event are negligible. j.carlton@uky.edu PIONEER Refresher (Slide 10/44) 3D Render Experiment Citations: PIONeer A next-generation rare pion decay experiment, David Hertzog, (https://pioneer.npl.washington.edu/docdb/0002/000281/001/PIONEER%20Orientation%20an d%20Status%20June%202024.pdf) Digitization Electronics (6,0) Goldberg-Polyhedron Calorimeter Design (\u201cSoccer Ball\u201d Geometry) Approximately spherical Not Pictured: \u25cfATAR (inside Calo) \u25cfTracker (a shell around ATAR, inside Calo) \u25cfVETOs, T0, etc. \u25cfDAQ Computers j.carlton@uky.edu PIONEER Refresher (Slide 11/44) ATAR Design \u25cfHighly segmented and instrumented pion stopping target made of silicon low gain avalanche diodes (LGADs) \u25cfEach sensitive strip has a size of 20 mm x 200 \u03bcm x 120 \u03bcm \u25cfTotal of 4800 channels arranged in pattern alternating x and y planes \u25cf5D track information: \u25cbTransverse positions x,y ~ O(200 \u03bcm) \u25cbLongitudinal position z ~ O(120 \u03bcm) \u25cbTime t ~ O(100 ps) per single hit \u25cbEnergy E, \u0394E/E ~ O(10%) Citations: PIONEER Slides from ACTS Workshop, Patrick Schwendimann (Slide 10) j.carlton@uky.edu PIONEER Refresher (Slide 12/44) PIONEER Simulation Framework \u25cfSeries of software steps to simulate the PIONEER experiment \u25cbWork in progress \u25cbAdapts as we develop our detectors/strategy \u25cfDesigned as a proof of concept \u25cbExperiment should work in simulation before real experiment is run \u25cfReconstruction designed to be used on simulated and real detector data Citations: PIONEER Slides from ACTS Workshop, Patrick Schwendimann Simulation and Analysis Presentation, Quentin Buat Monte Carlo (Geant4 Based) Detector Response (Gaudi Based) Event Reconstruction (Gaudi Based) Reconstructed Data Truth level physics interaction data in space of detectors Realistic detector output data Physical events reconstructed from detector data j.carlton@uky.edu PIONEER Refresher (Slide 13/44) DAQ Software Development j.carlton@uky.edu DAQ Software Development (Slide 14/44) Calo teststand DAQ \u25cfIteration on previous LYSO test beam \u25cfUses the same hardware as the g-2 experiment \u25cb 10 GbE based readout system \u25cb 800 MSPS Cornell digitizers \u25cfModified g-2 MIDAS readout software for broader test-stand use \u25cb LYSO calorimeter test stands \u25a0 Used at PSI in November 2023 rectilinear LYSO crystal array test beam \u25a0 Used at PSI in August 2025 tapered LYSO crystal array test beam \u25cb LXe calorimeter test stands Two crate setup used at PSI LYSO Testbeam Run Crates Channels Used Event Rate (Hz) Data Rate (MB/s) 2023 PSI LYSO Test Beam 1 ~50 ~400 ~30 2025 PSI LYSO Test Beam 2 ~60 ~2500 ~200 j.carlton@uky.edu DAQ Software Development (Slide 15/44) ATAR Candidate Digitizer: HDSoC DAQ \u25cfHDSoC is a candidate ATAR digitization system \u25cb 1 GbE based readout system \u25cb 32 channel HDSoC digitizer board in UKy \u25cb Produces \u201cevents\u201d \u25a0 32 to 1984 samples per triggered channel \u25cfMidas frontend \u25cb Handles configuration and readout \u25a0 Self triggering/External triggering modes supported \u25a0 Built on existing naludaq python library \u25cb Handles HDSoCv1 rev2 max data rate of ~55 MB/s \u25cfDocumentation (manual) available \u25cb Details setup, configuration, etc. \u25cfUnpacker app available \u25cb Unpacks midas data into ROOT tree, stores in analyzable .root files Nalu\u2019s HDSoC FMC attached to a Nexys A7 Video Card j.carlton@uky.edu DAQ Software Development (Slide 16/44) ATAR Candidate Digitizer: HDSoC DAQ - Strategy \u03bc\u25cfGiven a trigger on positron hit in calo, readout last ~2\u03bcs in ATAR \u25cfChallenges: \u25cb HDSoC needs to zero suppress (currently cannot) or data rate is too large (~10 MB/event or ~100 GB/s) \u25cb Becomes analysis task to properly construct decay sequences/\u201dpatterns\u201d \u25cb Lookback limited to HDSoC storage ~2\u03bcs Example Readout Ranges (not to scale) e \u03c0 \u03bc e \u03c0\u03bc e \u03c0 \u2026Digitization window ~2 \u03bcs Deadtime Time Outside digitization window Trigger Trigger j.carlton@uky.edu DAQ Software Development (Slide 17/44) ATAR Candidate Digitizer: SAMPic DAQ \u25cfHDSoC is a candidate ATAR digitization system \u25cb1 GbE based readout system \u25cb256 channel digitizer crate teststand in LPNHE, Paris \u25cbProduces \u201chits\u201d \u25a032 samples from a triggered channel \u25cfMidas frontend \u25cbHandles configuration and readout \u25a0Built on existing SAMPic-256ch C library and all it\u2019s different configuration modes \u25cfUnpacker app available \u25cbUnpacks midas data into ROOT tree, stores in analyzable .root files SAMPic Boards j.carlton@uky.edu DAQ Software Development (Slide 18/44) ATAR Candidate Digitizer: SAMPic DAQ - Strategy \u03bc\u25cfGiven a trigger on positron hit in calo, readout last ~10 \u03bcs with signals over threshold in ATAR \u25cfChannels self trigger and store last ~10 \u03bcs \u25cfChallenges: \u25cb Each channel has an individual deadtime ~ 2 \u03bcs \u25cb Deadtime mitigation: use \u201cping-pong\u201d mapping (1 ATAR channel \u2192 2 SAMPic channels) to \u201cremove\u201d deadtime \u25a0 Readout channel count doubles 4800 \u2192 9600 Example Readout Ranges (not to scale) e \u03c0 \u03bc e \u03c0\u03bc e \u03c0 \u2026Outside digitization window Digitization window ~10 \u03bcs Time Trigger Trigger j.carlton@uky.edu DAQ Software Development (Slide 19/44) HDSoC Deadtime Scan \u25cfUsed Raspberry Pi Pico W + NIM modules to generated configurable double pulse signal \u25cfUsed HDSoC DAQ to observe event rate for varying parameters \u25cfSee spike corresponding to deadtime Example Double pulse on Oscilloscope Example Rate Response to Double Pulse Separation j.carlton@uky.edu DAQ Software Development (Slide 20/44) HDSoC Deadtime Scan Parameter Space (91 combinations): Channels = [1,2,...,13] Windows = [1,2,4,8,16,32,61] \u25cf\u201cSimultaneous\u201d input pulses on each channel, self triggered \u25cfDeadtime scales with number of channels and digitization window \u25cb1 window == 32 samples \u25cb1 Gsps sampling rate \u25cfConclusions: \u25cbCannot operate experiment in SAMPic style strategy \u25a0deadtime too long \u25a0No \u201cping-pong\u201d mode \u25a0Deadtime appears to be \u201cchip wide\u201d, i.e. not channel independent \u25cbOnly valid strategy is long (~2us) readout windows per event \u25a0Long deadtimes make running at high rates a challenge j.carlton@uky.edu DAQ Software Development (Slide 21/44) SAMPic Deadtime Scan \u25cfUsed Lecroy 9210 Pulse Generator to create a configurable double pulse signal \u25cfUsed sampic_256ch_lib observe hit rate for varying parameters \u25cfSee spike corresponding to deadtime Example rate response to double pulse separation j.carlton@uky.edu DAQ Software Development (Slide 22/44) SAMPic Deadtime Scan Parameter Space (330 combinations): Channels = [1,2,...,13,14,15] Amplitude = [3.0,3.2, \u2026 5.0] Auto_conversion = [False, True] \u25cf\u201cSimultaneous\u201d input pulses on each channel, self triggered \u25cfDeadtime doesn\u2019t scale with # of channels (independent channel deadtimes) \u25cb Channel digitizes 32 samples at specified sample rate, around 1-10 Gsps \u25cfSAMPic has a fixed digitization window of 32 samples \u25cfUnknown Lecroy channel specific behavior causes difference in deadtime \u25cb Channel count 1-8 is just lecroy channel A \u25cb Channel count 9-15 includes both lecroy channel A and B j.carlton@uky.edu DAQ Software Development (Slide 23/44) Supplementary Software - Flexible DQM \u25cfUsed in PSI 2025 LYSO Testbeam \u25cbPlugins system for configurability to a variety of experiments (with boilerplate additions) \u25a0Customizable plot layouts \u25a0Customizable preliminary \u201clive\u201d processing \u25cfManual , wikis, tutorials, and repos available Data flow diagram for DQM Example DQM webapp page view j.carlton@uky.edu DAQ Software Development (Slide 24/44) Reconstruction Software Development j.carlton@uky.edu Reconstruction Software Development (Slide 25/44) Why ATAR Events Are Hard to Reconstruct Traditionally Citations: PIONEER Slides from ACTS Workshop, Patrick Schwendimann (Slide 25) \u25cfPrecise pion stop location and positron direction are essential for rebuilding events in our detector geometry \u25cfMust be very efficient at rejecting \u03c0\u2192e events that are actually \u03c0\u2192\u03bc\u2192e \u25cb \u03c0\u2192\u03bc\u2192e decays are \u223c104 times more frequent than \u03c0\u2192e, and Re/\u03bc must be measured to \u223c10-4 relative precision, the probability for a \u03c0\u2192\u03bc\u2192e event to be misidentified as \u03c0\u2192e must be suppressed to the \u223c10-8 level \u25cb Timing and energy information help us so we need \u223c10-7 suppression from tagging j.carlton@uky.edu Reconstruction Software Development (Slide 26/44) PIONEER Simulation Reconstruction \u25cfTraditional reconstruction is a Gaudi based pipeline \u25cfA series of steps to ultimately classify event types (ex. as \u03c0\u2192e or \u03c0\u2192\u00b5\u2192e) \u25cfDesigned to operate on simulated and real detector data \u25cfThis is the stage where machine learning/AI approaches can work well \u25cbLarge quantities of detector data with truth targets available from simulation Citation: Simulation and Analysis Presentation, Quentin Buat j.carlton@uky.edu Reconstruction Software Development (Slide 27/44) PIONEER Rules Based Reconstruction: Pattern Finding Citation: Simulation and Analysis Presentation, Quentin Buat \u25cfFocused work particularly on last step \u25cbCollaborative effort with (former) UKy postdoc Sean Foster \u25cfIterative process involving: \u25cbPattern finding algorithm prototyping in custom pattern finding playground framework \u25a0Python based, allowing for more rapid development \u25cbBenchmarking performance of pattern finding against truth information from simulation \u25cbIntegrating tested algorithms into simulation framework \u25a0C++ based (Gaudi Pipeline) j.carlton@uky.edu Reconstruction Software Development (Slide 28/44) PIONEER Rules Based Reconstruction: Pattern Finding \u03c0\u03bc e \u03c0 eformVertices(set<Tracklets>) formPatterns(set<Vertices>) \u25cfGoal: Given tracklet objects, form them into physics patterns \u25cfIdea split into two main steps: 1.Form \u201cVertices\u201d 2.Form \u201cPatterns\u201d j.carlton@uky.edu Reconstruction Software Development (Slide 29/44) PIONEER Rules Based Reconstruction: Pattern Finding \u25cfVertex forming is the real challenge \u25cbPattern forming reduces to depth first search (DFS) on the small (usually <10 nodes) vertex graph \u25cfVertex Finding Algorithm: \u25cbStarting from pion and then muon tracklets, endpoint overlaps with other tracklets are evaluated independently in the XZ and YZ projections \u25cbOverlaps are scored using distance between endpoints, the shortest distance is selected to form a vertex Example Event (\u03c0 -> \u03bc -> e): Tracklets stitched together into vertices based on distance between tracklet endpoints j.carlton@uky.edu Reconstruction Software Development (Slide 30/44) Example Reconstruction Accuracy \u25cfFind the correct pattern ~92% of time \u25cb\u201cPattern finding\u201d is heavily dependent on previous stage \u201ctracklet finding\u201d \u25a0If tracklet finding fails to appropriate tag particles, pattern finder often fails \u25cbThese statistics are for events without pile-up \u25cbThis statistic is only correlated with pattern finding performance \u25a0Need work to define better physics based metrics to evaluate pattern finding performance in isolation \u25cfTakeaway: still work to be done to refine the edge cases of the pattern finding and tracklet finding algorithms j.carlton@uky.edu Reconstruction Software Development (Slide 31/44) Where AI/ML Reconstruction Falls in the Pipeline \u25cfSimulation provides all needed information \u25cb Geant4 simulation gives truth targets (ex. Positron angle, true pion stop) \u25cb Detector response gives inputs (ex. ATAR strip hit 5D information) \u25cfThe simulation can produce large quantities of data needed for training \u25cfProject where training and inference is handled in a scalable way \u25cb Designed to stream data to arbitrary number of compute nodes (ex. GPU cluster) Monte Carlo Detector Response Traditional Reconstruction Truth Data Detector Data Model Training AI Reconstruction Reconstructed Data Reconstructed Data Trained Models One time training cost j.carlton@uky.edu Reconstruction Software Development (Slide 32/44) CMS Results Motivate Graph-Transformer Reconstruction \u25cfAmong the most expressive ML architectures \u25cbSolve a broader class of reconstruction problems \u25cfStraightforward to implement with PyG \u25cfAttention based transformers allow models to learn how event information is related \u25cbStandard GNNs rely on predefined neighborhood aggregation, whereas attention-based models learn which nodes should communicate Citation: Physics Reconstruction for PIONEER BVR Report, Omar Beesley https://indico.psi.ch/event/18441/#6-physics-reconstruction j.carlton@uky.edu Reconstruction Software Development (Slide 33/44) Example time grouping Example node and edge labeling Representing the Data as a graph \u25cfStart with an detector level event \u25cbSet of ATAR hits over ~2-10 \u03bcs before trigger \u25cfSplit into time groups \u25cbSequences of hits separated by at most 1ns \u25cfFrom each time group, create a fully connected graph from hits \u25cbNodes contain detector info: \u25a0(x or y, z, E, strip dim) \u25cbEdges: \u25a0(dx or dy, dz, dE, same strip type?) \u25cfLabeled fully connected graphs are inputs to AI models Citation: Machine Learning Approach to ATAR Reconstruction, Omar Beesley https://indico.psi.ch/event/17600/contributions/59198/ Example of model input and output Predictions: Node Level, Edge Level, and/or Graph Level j.carlton@uky.edu Reconstruction Software Development (Slide 34/44) Current AI/ML ATAR Reconstruction Pipeline Simulation Pipeline: Create ML Ready Dataset Monte Carlo + Detector Response ML Ready Dataset Gaudi Pipeline Truth level descriptions of entire events + detector response; optional event mixing = Not an ML stage = An ML (trained) stage Forms ML ready dataset (parquet files, efficient columnar storage) Applies preprocessing stages to derive additional feature columns (ex. Time group labels) AI/ML Pipeline: Append predictions to events, each stage follows the following prescription: Event Data \u2192 Graphs \u2192 Model \u2192 Graph Level Predictions \u2192 Event Level Predictions Group Classifier Group Splitter Endpoint Regressor Pattern Finder Pion Stop Regressor Positron Angle Finder Adds group level particle classes Adds hit level particle classes Adds endpoint (x,y,z) estimates Adds affinities between time group Adds positron angles (sin\u03b8 cos\u03c6, sin\u03b8 sin\u03c6, cos\u03b8) estimates Adds pion stops (x,y,z) estimates Final Goal: Unify all stages into a single end-to-end ML model j.carlton@uky.edu Reconstruction Software Development (Slide 35/44) Pion Stop Regressor \u25cfQuantile graph transformer regressor \u25cbGraph level task \u25cfInputs (represented as a graph): \u25cbDetector response event information \u25cbTime grouping labels \u25cbPredicted time group level particle class \u25cbPredicted hit level particle classes \u25cbPredicted affinities \u25cfTargets: \u25cbTruth level pion stop \u25cbParticularly: [x_stop,y_stop,z_stop] \u25cfOutputs: \u25cbPredicted pion stop [[[x_stop_q1, y_stop_q1, z_stop_q1], \u2026] \u25cfNotes: \u25cbQuantiles effectively give uncertainties if chosen to be top 84%, top 50%, and top 16% quantiles = median \u00b1 1 standard deviation = Pion stop estimate Cartoon example of pion stop estimate = Error range determined from quantiles Citation: Physics Reconstruction BVR Talk, Omar Beesley https://indico.psi.ch/event/18441/contributions/61425/attachments/3283 0/66309/Reconstruction-Final.pdf j.carlton@uky.edu Reconstruction Software Development (Slide 36/44) Positron Angle Regressor \u25cfQuantile graph transformer regressor \u25cbGraph level task \u25cfInputs (represented as a graph): \u25cbDetector response event information \u25cbTime grouping labels \u25cbPredicted time group level particle class \u25cbPredicted hit level particle classes \u25cbPredicted affinities \u25cfTargets: \u25cbTruth level direction vector for positron angle \u25cbParticularly: [(sin \u03b8cos\u03c6), (sin \u03b8sin\u03c6), (cos \u03b8)] \u25cfOutputs: \u25cbPredicted direction vector for positron angle [[(sin\u03b8cos\u03c6)_q1, (sin \u03b8sin\u03c6)_q1, (cos \u03b8)_q1], \u2026] Cartoon example of positron angle estimate direction in detector coordinate system with uncertainty Citation: Physics Reconstruction BVR Talk, Omar Beesley https://indico.psi.ch/event/18441/contributions/61425/attachments/3283 0/66309/Reconstruction-Final.pdf j.carlton@uky.edu Reconstruction Software Development (Slide 37/44) 2025 PSI Test Beam j.carlton@uky.edu 2025 PSI Test Beam (Slide 38/44) Motivation \u25cfPIONEER LYSO Calorimeter design is a (6,0) Goldberg-Polyhedron with an opening \u25cb8 different crystal shapes \u25a01 class of pentagon \u25a07 classes of hexagons \u25cb311 crystals for full calo (362 for full sphere) \u25cfGoal: Show a LYSO \u201cdemonstrator\u201d i.e. segment of a (6,0) Goldberg-Polyhedron meets our key performance parameters (KPPs) \u25cbEnergy Resolution \u25cbTiming Resolution \u25cbPosition Resolution Citation: Physics Reconstruction BVR Talk, Stefan Hochrein https://indico.psi.ch/event/18441/contributions/61422/attachments/3284 1/66376/Stefan_LYSO_Slides_final.pdf LYSO Calorimeter: (6,0) Goldberg-Polyhedron with opening. Shape classes color coded Key performance parameters (KPPs) targets to meet PIONEER target precision j.carlton@uky.edu 2025 PSI Test Beam (Slide 39/44) Beamtime Setup \u25cfpiE1 beamline \u25cb Used to steer 20 - 80 MeV positrons towards our detectors \u25cb Located at PSI, Switzerland \u25cfCore components of our detector setup: \u25cb T0: Defines event start time \u25cb Veto : Used to reject events outside our detector volume \u25cb Si-strips : \u201cHodoscope\u201d detector used to make more refined spatial cuts on the beam \u25cb LYSO array + PMTs : Used to reconstruct energy of the event \u25cb NaI crystals +PMTs : Used to make light leakage cuts Citation: Physics Reconstruction BVR Talk, Stefan Hochrein https://indico.psi.ch/event/18441/contributions/61422/attachments/3284 1/66376/Stefan_LYSO_Slides_final.pdf Our test beam experimental setup j.carlton@uky.edu 2025 PSI Test Beam (Slide 40/44) Energy Resolution Measurement \u25cf< 2% Energy resolution above 50 MeV \u25cbMeets KPP target for PIONEER precision \u25cfSimilar results to 2023 testbeam \u25cbMore or less expected Citation: Physics Reconstruction BVR Talk, Stefan Hochrein https://indico.psi.ch/event/18441/contributions/61422/attachments/3284 1/66376/Stefan_LYSO_Slides_final.pdf Energy resolution as a function of beam energy Energy reconstruction fit at 70MeV j.carlton@uky.edu 2025 PSI Test Beam (Slide 41/44) Graduation Planned Timeline j.carlton@uky.edu Graduation Planned Timeline (Slide 42/44) Graduation Timeline \u25cfATAR Demonstrator planned near end of 2026 \u25cbProvide data to run atar reconstruction code on and evaluate performance \u25cbThis can act as the capstone analysis project for the Ph.D. \u25cfDefend spring semester 2027 \u25cbGives 4-6 months for dissertation writing and analysis Research timeline with milestones and testbeams j.carlton@uky.edu Graduation Planned Timeline (Slide 43/44) PIONEER ATAR Demonstrator \u25cfPrototype ATAR demonstrator hardware \u25cbSmaller number of ATAR layers (16 layers) \u25cfDAQ handles event construction \u25cfIdeas to test both HDSoC and SAMPic in this testbeam \u25cbUp in the air \u25cfPlan: \u25cbRun reconstruction (traditional and ML based) on this data for dissertation Layers for SAMPic Tests Beam DAQ Computer(s) SAMPic Digitizers HDSoC Digitizers (?) ATAR Layers Layers for HDSoC Tests (?) j.carlton@uky.edu Graduation Planned Timeline (Slide 44/44) Auxiliary Slides j.carlton@uky.edu Title (Slide 0/xx) Background Physics j.carlton@uky.edu \u03c0 \u2192 e \u03bde and \u03c0 \u2192 \u00b5 \u03bd\u00b5 \u25cfCorresponding diagrams for \u03c0- \u25cfTau decay forbidden \u25cbtau too massive ~ 1000 MeV/c2 \u25cbPion ~ 100 MeV/c2 \u25cfMuon decay more likely \u25cbbranching fraction of 0.999877 \u03bde e+\u00b5+\u03bd\u00b5 u du d\u03c0+ \u03c0+W W Citation: Particle Data Group (https://pdg.lbl.gov/2014/listings/rpp2014-list-pi-plus-minus.pdf) j.carlton@uky.edu Helicity Suppression (Why is Muon Decay Most Likely?) \u25cfNaively, \u0393 \u221d p\u2019 \u2192 electron decay more likely \u25cfWeak force only affects left-handed (LH) chiral particle states and right-handed (RH) chiral anti-particle states \u25cfNeutrinos are all LH chirality \u25cfm\u03bd << E means LH neutrino chirality \u2192 LH (negative) neutrino helicity \u25cfConservation of momentum \u2192 anti-lepton is LH (negative) helicity \u03bdl l+u d\u03c0+W \u03c0+ \u03bdll+ Citation: Modern Particle Physics, Mark Thomson (Ch. 11.6 pg. 299) j.carlton@uky.edu Helicity Suppression (Why is Muon Decay Most Likely?) \u25cfWe can write the LH (negative) helicity anti-particle state in the chiral basis: \u25cfWe ignore the LH term (weak force only acts on the RH term), anti-particle\u2019s matrix element contribution: \u25cfThis effect ends up making the matrix element smaller \u2192 decay rate smaller \u03bdl l+u d\u03c0+W \u03c0+ \u03bdll+ Citation: Modern Particle Physics, Mark Thomson (Ch. 11.6 pg. 300, Ch. 6.4 pg. 143) j.carlton@uky.edu Lepton Universality \u25cfStates coupling strengths (vertices) ge = g\u00b5 = g\u03c4 \u25cfUsing the Feynman rules for the weak interaction, we can approximate the matrix element \u03bdee-\u00b5- \u03bd\u00b5d ud u\u03c0- \u03c0-W W ge g\u00b5 f\u03c0f\u03c0 Pion vertex Lepton vertex W-boson propagator Citation: Modern Particle Physics, Mark Thomson (Ch. 11.6 pg. 301) j.carlton@uky.edu Lepton Universality \u25cfAfter some \u201cmassaging\u201d we can find the matrix element to be \u25cfPion spin zero \u2192 no spin averaging needed, i.e.: \u25cfWe can use the general formula for 2-body decay to to find the decay rate \u25cfFinally, we compute the branching ratio Citation: Modern Particle Physics, Mark Thomson (Ch. 11.6 pg. 302-303) j.carlton@uky.edu Lepton Universality \u25cfLepton universality assumes ge = g\u00b5, so the first factor disappears \u25cfImproving the branching ratio measurement and comparing to the theoretical value acts as a test of lepton universality \u25cfAnother test would consider pure leptonic decays, but such decays involving taus are too rare for high precision measurements j.carlton@uky.edu Branching Ratio Re/\u00b5 \u25cfWe can measure the branching ratio by measuring # of decays e and \u00b5 decays \u25cfTheoretical prediction is simple in first (and second) order \u25cbNo f\u03c0 or CKM element Vud \u25cf3rd order correction and beyond the pion structure becomes relevant = 1 [in theory] Citation: Dynamic of the Standard Model, Donoghue et. al (Ch. 6.1 pg. 163) j.carlton@uky.edu Current state of Re/\u00b5 \u25cfConsistent with each other \u25cfExpect factor of ~10 precision improvement on experimental value from PIONEER \u25cb\u201cCatches up\u201d with theoretical uncertainty Re/\u03bcexp = 1.2327(23) x 10-4 (PIENU collab) Rtheo = 1.23524(15) x 10-4 Citation: Testing Lepton Flavor Universality and CKM Unitarity with Rare Pion Decays in the PIONEER experiment, PIONEER collab (pg. 6, arxiv: 2203.05505) j.carlton@uky.edu Common Pion Decay Channels \u25cf\u03c0+ \u2192 e+ + \u03bde \u25cf\u03c0- \u2192 e- + \u03bde \u25cf\u03c0+ \u2192 \u00b5+ + \u03bd\u00b5 \u25cf\u03c0- \u2192 \u00b5- + \u03bd\u00b5 \u25cf\u03c0+ \u2192 \u03c00 + e+ + \u03bde \u25cf\u03c0- \u2192 \u03c00 + e- + \u03bde\u25cf\u03c00 \u2192 \u03b3 + \u03b3 \u25cf\u03c00 \u2192 \u03b3 + e- + e+ \u25cf\u03c00 \u2192 e- + e+ + e- + e+ \u25cf\u03c00 \u2192 e- + e+ Leptonic Decay Beta Decay = Most Common Photon Decay Dalitz Decay Double-Dalitz Decay Electrons [Note: Dalitz Decays are like photon decays, except the photon(s) are virtual and immediately decay into electron/positron pairs] Citation: Wikipedia (https://en.wikipedia.org/wiki/Pion) j.carlton@uky.edu Naive Pion Decay, 2-body decay \u25cfWithout getting into details of QCD, we can treat this as a 3 particle decay \u25cfWe can use Fermi\u2019s golden rule: \u25cfAfter integration in the COM frame we find: \u25cf\u2192 \u0393 \u221d p (not correct) \u25cbDetails hidden in matrix element AB C Citation: Introduction to Elementary Particles, Griffiths (Ch. 6.2 pg. 196-198) j.carlton@uky.edu Why Massless \u2192 Chirality States ~ Helicity States \u25cfMassless \u2192 moves at c \u25cfMoves at c \u2192 cannot reverse particle direction with Lorentz boost \u2192 helicity is Lorentz Invariant \u25cfChirality is a property of a particle, always Lorentz invariant! \u2192 helicity and chirality agree in direction in all inertial reference frames [Dirac Equation] [Chiral States] [Helicity operator] [Chiral states are eigenstates of helicity operator] Citation: Lecture Notes, Quantum Field Theory, Michael Eides (PHY616, Lecture #25) j.carlton@uky.edu LH (negative) helicity spinor to chiral components An negative helicity antiparticle can be written as Where (\u03b8,\u03c6) define the direction of the momentum. Without loss of generality, assume the momentum is in the z direction Citation: Modern Particle Physics, Mark Thomson (Ch. 6.4 pg. 143) j.carlton@uky.edu LH (negative) helicity spinor to chiral components We can use the chiral projection operations to project this helicity state to chiral state Where the left and right chiral anti-particle states are defined by Citation: Modern Particle Physics, Mark Thomson (Ch. 6.4 pg. 141,143) j.carlton@uky.edu LH (negative) helicity spinor to chiral components Looking at the chiral projection of a negative helicity state, we can see in general there are left and right chiral components, so the weak force can act on a LH (negative) anti-particle helicity state It should also be clear as m\u21920, the LH (negative) helicity state coincides with the LH chiral state. This means W boson decay to two massless leptons is forbidden! One of the particles must have the wrong chirality, and thus low mass decays will be suppressed. Citation: Modern Particle Physics, Mark Thomson (Ch. 6.4 pg. 143) j.carlton@uky.edu Matrix Element Details Move to pion rest frame so only p0 = m\u03c0 remains: Using the identity: Citation: Modern Particle Physics, Mark Thomson (Ch. 11.6 pg. 301) j.carlton@uky.edu Matrix Element Details For a neutrino m << E so helicity eigenstate is essentially the chiral eigenstate: By letting the lepton go in the z-direction we can write: and Negative helicity lepton down state disappears when \u201cdotted\u201d with the neutrino state: Citation: Modern Particle Physics, Mark Thomson (Ch. 11.6 pg. 301-302) j.carlton@uky.edu Matrix Element Details We can re-write El and p in the limit where the neutrino mass is zero: Citation: Modern Particle Physics, Mark Thomson (Ch. 11.6 pg. 302) j.carlton@uky.edu Lepton Universality j.carlton@uky.edu Small discrepency in ge/g\u00b5 and 1 can cause twice as big discrepency in measured Re/\u00b5 and theory Re/\u00b5 Another Test for Lepton Universality Citation: PIONEER Seminar, Tim Gorringe (Slide 9) Fermi constant and new physics, Marciano, Phys Rev. D 60, 093006 j.carlton@uky.edu CKM Unitary Test Citation: Testing Lepton Flavor Universality and CKM Unitarity with Rare Pion Decays in the PIONEER experiment, PIONEER collab (pg. 21) PIONEER Seminar, Tim Gorringe (Slide 12) arXiv:2203.05505 \u25cfPion beta decay gives a precision measurement of Vud \u25cfThese decays are lower rate than \u03c0 \u2192 e\u03bde and \u03c0 \u2192 \u00b5\u03bd\u00b5 \u25cfExperimental measurements do not agree j.carlton@uky.edu Some Information about LXe and NaI \u25cfLXe has singlet and triplet state decay constants: \u25cb\u03c4S = 4.3 \u00b1 0.6 ns \u25cb\u03c4T = 26.9+0.7 \u22121.1 ns \u25cfLXe light yield: \u25cb~29 photons/keV at room temp \u25cfNaI decay constant: \u25cb~ 250 ns \u25cfNaI light yield: \u25cb38 photons/keV at room temp Citations: A measurement of the scintillation decay time constant of nuclear recoils in liquid xenon with the XMASS-I detector, XMASS collab, arxiv 1809.05988 Scintillation yield of liquid xenon at room temperature , XMASS collab, arxiv 0803.2888 Berkeley Nucleonics (https://www.berkeleynucleonics.com/nai-sodium-iodide) Scintillation from excited Xe (Xe*): Scintillation from ionized Xe (Xe+): j.carlton@uky.edu LYSO Information \u25cfLYSO \u2013 lutetium\u2013yttrium oxyorthosilicate \u25cbLutetium (73%), Oxygen (18%), Silicon (6%), Yttrium (3%), and a Cerium scintillation dopant ( \u223c 0%) \u25cfDensity = 7.4 g/cm3 \u25cfX0 = 1.14 cm = \u201cRadiation length\u201d = distance for an electron's energy to be reduced by a factor of 1/e \u25cfRM = 2.07 cm = \u201cMoli\u00e9re radius\u201d = radius of a cylinder containing on average 90% of the shower's energy deposition \u25cfLight Yield = 30,000 photons/MeV \u25cfScintillating decay time = 40 ns j.carlton@uky.edu Citation: Measurements of a LYSO crystal array from threshold to 100 MeV, PIONEER collab (arxiv: 2409.14691) PIONEER Experiment j.carlton@uky.edu Past Experimental Approach (PIENU) \u25cfNaI has a long primary decay time \u25cb~ 250 ns \u25cfEvent pileup forces the experiment to run at a low rate \u25cb~70 kHz \u25cf\u201cinactive target\u201d, muons aren\u2019t tracked \u25cfCsI Rings for shower leakage detection Citation: Status of the TRIUMF PIENU Experiment, PIENU collab, (arxiv 1509.08437) https://pienu.triumf.ca/ j.carlton@uky.edu PEN \u25cfSimilar to PIENU \u25cbSegmented \u25cbBetter timing \u25cfMany channels of pure CSI \u25cb240 channels \u25cfActive target Citation:PEN: a low energy test of lepton universality , PENcollab, (arxiv: 1701.05254) j.carlton@uky.edu Another Calorimeter 3D Render (Liquid Xenon) Citations: PIONeer A next-generation rare pion decay experiment, David Hertzog, (https://pioneer.npl.washington.edu/docdb/0002/000281/001/PIONEER%20Orientation%20an d%20Status%20June%202024.pdf) j.carlton@uky.edu PIONEER Strategy Tail Correction Citations: PIONEER Slides from ACTS Workshop, Patrick Schwendimann (Slide 7) Removed terms ~10-8 relative precision, far beyond goal of ~10-4Assume negligible leakage of muon decays above threshold PIONEER Strategy Acceptance Correction \u25cfIn reality, our efficiency for high and low energy are not the same, requiring another correction term Citations: PIONEER Slides from ACTS Workshop, Patrick Schwendimann (Slide 7) Acceptance Correction More ATAR details \u25cfPion and muon decays deposit energy into ATAR \u25cfAllow event types to be distinguished \u25cfMuons decaying in flight can boost positron energy past 53 MeV (big issue!) \u25cbATAR can give information to rebuild event, and correctly classify a muon decay arxiv: 2203.01981 Citation: PSI Ring Cyclotron Proposal R-22-01.1 PIONEER: Studies of Rare Pion Decays, PIONEER collab, (pg. 19 arxiv: 2203.01981) j.carlton@uky.edu How PIONEER Will Improve the Re/\u00b5 Measurement \u25cf5D space-time-energy active pion stopping target (ATAR) \u25cb Reduce e+ energy tail, identify beam pileup, identify \u03c0 \u2192 \u00b5 \u03bd\u00b5 decays \u25cfLarge acceptance, deep radiation length calorimeter \u25cb LXE or LYSO for high resolution, fast response, small tail \u25cfFast electronics, high-speed acquisition \u25cb Giga sample/second digitizers, new gen PCIe readout \u25cfPSI high intensity pion beams \u25cb 2 mA proton beam, large acceptance beamline Citation: PIONEER Seminar, Tim Gorringe (Slide 22) j.carlton@uky.edu I. PIONEER Refresher (Slide 6/37) Midas Framework \u25cfC/C++ (mostly) package of modules for \u25cbrun control, \u25cbexpt. configuration \u25cbdata readout \u25cbevent building \u25cbdata storage \u25cbslow control \u25cbalarm systems \u25cbEtc. \u25cfCan link with custom software Example g-2 Midas Webpage j.carlton@uky.edu I. PIONEER Refresher (Slide 7/37) Why Do We Need an ATAR? \u25cfEnergy information alone is insufficient to chracterizethe \u03c0\u2192e positron tail at the 10-8 level in Re/\u03bc \u25cfATAR topology and timing are required to identify intermediate muons and correct for this effect Citations: PIONEER Slides from ACTS Workshop, Patrick Schwendimann (Slide 22) Example of pristine \u03c0\u2192\u03bc\u2192e event data in ATAR ATAR in Simulation \u25cfGeometric descriptions of ATAR in files fed to Geant4 based simulation \u25cbGeant4 provides simulation of particles interacting with the detector \u25cbDetector response code turns those interactions into data we\u2019d imagine seeing from the detector \u25cf24 layers of what\u2019s in the yellow dashed lines in the figure \u25cbPairs of x y layers in dashed lines, meaning 48 sensor layers Citations: Update on ATAR region supports, Adam Molnar (Slide 2) Why ATAR Events Are Hard to Reconstruct Traditionally Citations: PIONEER Slides from ACTS Workshop, Patrick Schwendimann (Slide 25) \u25cfPrecise pion stop location and positron direction are essential for rebuilding events in our detector geometry \u25cfMust be very efficient at rejecting \u03c0\u2192e events that are actually \u03c0\u2192\u03bc\u2192e \u25cb \u03c0\u2192\u03bc\u2192e decays are \u223c104 times more frequent than \u03c0\u2192e, and Re/\u03bc must be measured to \u223c10-4 relative precision, the probability for a \u03c0\u2192\u03bc\u2192e event to be misidentified as \u03c0\u2192e must be suppressed to the \u223c10-8 level \u25cb Timing and energy information help us so we need \u223c10-7 suppression from tagging Why Reconstruction Can be an AI task \u25cfSimulation provides all needed information \u25cbGeant4 simulation gives truth targets (ex. Positron angle, true pion stop) \u25cbDetector response gives inputs (ex. ATAR strip hit 5D information) \u25cfThe simulation can produce large quantities of data needed for training Monte Carlo Detector Response Traditional Reconstruction Truth Data Detector Data Model Training AI Reconstruction Reconstructed Data Reconstructed Data Trained Models One time training cost Electronics and Data Rates j.carlton@uky.edu j.carlton@uky.edu Initialism Meaning Example 10GbE 10 Gigabit Ethernet FPGA Field Programmable Gate Array FMC FPGA Mezzanine Card FC7 SFP Interface CPU Central Processing Unit Intel Core i7-12700K GPU Graphics Processing Unit NVIDIA A5000 \u00b5TCA (uTCA) Micro Telecommunications Computing Architecture WFD Waveform Digitizer WFD5 FC Flexible Controller FC7 AMC Advanced Mezzanine Card AMC13 (also FC7 and WFD5) MCH MicroTCA Carrier Hub DDR Double Data Rate DDR3, DDR4 (RAM) PCIe Peripheral Component Interconnect Express PCIe2, PCIe3, ... TTC Timing, Trigger, and Control UART Universal Asynchronous Receiver-Transmitter Initialism Cheatsheet Hardware - Conceptual Diagram \u25cfDifferential signal into WFD5 (Waveform Digitizer) \u25cfTrigger signal into FC7 (Flexible Controller) \u25cfAMC13 (Advanced Mezzanine Card) gathers data, sends over 10GbE (10 Gigabit Ethernet) to desktop \u25cfMCH (MicroTCA Carrier Hub) facilitates Desktop\u2194Crate communication over 1GbE \u25cfDesktop CPU handles event processing \u25cfMeinberg gives trigger timestamp to computer Differential Signal(s) Trigger WFD5(s) FC7 AMC13(s) MCH Desktop Ribbon Cable Optical Pentabus Cable Crate Optical Crate Crate Crate 1GbE Ethernet Red - Data Blue - Trigger Gray - Control Crate Bank Meinberg SMA SMA to D9 To storage Crate components PCIe j.carlton@uky.edu Hardware - Unlabeled Picture j.carlton@uky.edu PIONEER DAQ (in a nascent state) \u25cfPIONEER DAQ \u25cbIn nascent development state \u25cbDesign catered to PIONEER full experiment necessities PIONEER ADC schematic drawings Citation: DAQ electronics status, Lawrence Gibbons (Slide 1) https://pioneer.npl.washington.edu/cgi-bin/private/ShowDocument?docid=245 j.carlton@uky.edu Data Rates (CALO data rates LXe/LYSO dependant) arXiv:2203.01981 \u25cfPIONEER DAQ expects data rate of ~ 3.5GB/s \u25cfConsidering running time, this is ~ 35,000 TB/year \u25cfHow do we compress this in real time? \u25cbFit data, store fit parameters \u25cbCompress and store residuals, throw some out \u25cbGraphics Processing Units (GPUs) used for this operation Citation: PSI Ring Cyclotron Proposal R-22-01.1 PIONEER: Studies of Rare Pion Decays, PIONEER collab (pg. 33) j.carlton@uky.edu DAQ Software Development Calorimeter Teststand DAQ \u25cfThe test stand DAQ is used throughout the PIONEER collaboration \u25cbMain uses are for calorimeter development \u25a0LXe \u25a0LYSO \u25cfBuilt on top of g-2 DAQ hardware and software Digitizers & trigger processors ...Array of readout computers, Midas server ... Detectors Hardware Side Software Side j.carlton@uky.edu II. Test Stand DAQ Development (Slide 9/37) Hardware - Labeled Crate 10GbE out (data) AMC13\u2192desktop Trigger in AMC13 Trigger out FC7 1GbE MCH in/out (comm.) FC7 Trigger in WFD5 5-channel, differential signal in (no connection in this picture) WFD5s M C HA M C 1 3 F C 7Note: AMC13 and MCH are half slot modules W F D 5W F D 5Crate Power Supply j.carlton@uky.edu II. Test Stand DAQ Development (Slide 10/37) Readout Systems for ATAR DAQ Candidates \u25cfSAMPic \u25cb1 GbE based readout system \u25cbMIDAS frontend handles configuration and readout, built on existing SAMPic-256ch C library \u25cb256 channel digitizer crate teststand in LPNHE, Paris \u25cfHDSoC \u25cb1 GbE based readout system \u25cbMIDAS frontend handles configuration and readout built on existing naludaq python library \u25cb32 channel HDSoC digitizer board in UKy \u25cfComparative studies of rate, triggering, and deadtime performance are currently underway Nalu Scientific\u2019s HDSoC FMC attached to a Nexys A7 video card SAMPic teststand with remote access capabilities HDSoC DAQ - Hardware \u25cfDAQ is functional and integrated into MIDAS \u25cfCan digitize data rates up to 55 MB/s, event rates up to 30 kHz* *For specific parameters Nexys A7 Video Board with Nalu\u2019s HDSoC Digitizer Attached as an FMC Module Conceptual Hardware Diagram for the HDSoC Readout HDSoC DAQ - Software \u25cfWrote a midas frontend that leverages custom libraries created for readout \u25cbNalu Board Controller \u25cbNalu Event Collector \u25cfSeparate branch for rate testing , leveraging custom RP Pico W libraries created for automatic rate testing \u25cbRP Pico W remote controller \u25cbRP Pico W board interface Conceptual Software Diagram for the HDSoC Readout HDSoC DAQ - Next Steps \u25cfLow priority for the time being \u25cbNot actively working on development \u25cbDevelopment focus shifted to to SAMPic system \u25cfUndergraduate Brennan Edwards doing studies on HDSoC digitized data \u25cbTiming resolution studies \u25a0Constructs \u201cpseudo time\u201d of leading and trailing edge \u25a0Then constructs true time differences between events \u25a0Similar to g-2 analysis j.carlton@uky.edu 5/10 Distribution of true time differences between consecutive events [preliminary analysis] Two consecutive events used to create time difference HDSoC DAQ - Rate Tests \u25cfMajority of input parameters \u2192 performance as expected \u25cfOutliers where we underperform \u25cbExpect good performance under 55 MB/s \u25cbLooking for cause of performance drops Expected Data Rate vs. Actual Data Rate Actual Data Rate (KB/s) Expected Data Rate (KB/s) HDSoC DAQ - Rate Tests \u25cfFor 32 channels (all active) \u25cf1 window = 32 12-bit ADC samples \u25cf1 Gsps \u25cfCan take 32 traces length 64 ns at rates ~20kHz reliably \u25cfEvents begin dropping near 55 MB/s threshold Normalized Event Rate vs. Frequency (32 channels) External Trigger Rate (Hz) Event Rate / External Trigger Rate SAMPic DAQ - Status \u25cfWorking midas integration \u25cbConverts ODB params \u2192 Sampic settings for most settings \u25cb1 thread to collect \u201cSAMPic Events\u201d \u25cb1 thread to form \u201cSAMPic Events\u201d into \u201cFrontend Events\u201d \u25a0Frontend events may span multiple sections of \u201cSAMPic Events\u201d \u25cb1 thread to handle midas state machine \u25cfEvent formation logic is hot swappable for ease of development j.carlton@uky.edu 6/10 Data flow diagram for SAMPic Data SAMPic DAQ - Ping Pong Mode \u25cfIn HDSoC approach, you see all activity on any given channel in the past ~2 \u03bcs \u25cfFor SAMPic, only short readout (~32ns) then channel is dead (~2 \u03bcs) \u25cbProblem: We become blind to pile-up \u25cbSolution: Ping pong mode \u25cfPing ping mode: \u25cbCopy input across 2 SAMPic channels A and B \u25cbChannel B can still trigger during Channel A deadtime \u25cfFor heavy pile-up we may need ping pong mode for across 4 channels \u25cb4800 ATAR channels\u2192 9600 SAMPic channels (ping pong) \u25cb4800 ATAR channels\u2192 19200 SAMPic channels (double ping pong) A BATAR Strip A BATAR Strip A BATAR Strip A BATAR Strip 1. Pile-up pulse arrives; pulse #1 and pulse #2 2. SAMPic channel A triggers on pulse #1 3. SAMPic channel A is dead; SAMPic channel B triggers on pulse #2 4. SAMPic channel A has recovered; SAMPic channel B is dead HDSoC Deadtime Scan Parameter Space (793 combinations): Channels = [1,2,...,13] Windows = [1,2,3,...61] Parameter Space (91 combinations): Channels = [1,2,...,13] Windows = [1,2,4,8,16,32,61] SAMPic Deadtime Scan Parameter Space (330 combinations): Channels = [1,2,...,13,14,15] Amplitude = [3.0,3.2, \u2026 5.0] Auto_conversion = [False, True] \u25cfSome runs failed (likely a communication error), the scan was programmed to move on in this case \u25cfThere\u2019s some scaling between Lecroy input voltage and SAMPic read voltage (ex. 5V lecroy input digitizes as ~0.5V pulse on SAMPic) \u25cfUnknown Lecroy channel specific behavior causes difference in deadtime \u25cb Channel count 1-8 is just lecroy channel A \u25cb Channel count 9-15 includes both lecroy channel A and B ZeroMQ Publisher Application \u25cfConfigurable software to publish data over ZeroMQ \u25cfMain branched configured to use midas \u25cbNot technically necessary, data source can be anything \u25cbUses my midas receiver library \u25cfUses C++ Package Manager (CPM) to clone (most) dependencies from gitub and build them \u25cbLess work setting up environments for user Supplementary Software - Analysis Pipeline Framework \u25cfLightweight, configurable pipeline framework for ROOT data \u25cbInspired by Gaudi, but simpler and faster to deploy \u25cbBuilt on ROOT, leveraging: \u25a0Plugin system for modularity \u25a0Reflection for flexible configuration \u25a0Custom data products \u25cf\u201cBackbone\u201d of apps: \u25cbZMQ publisher (part of DQM framework) \u25cbMidas file unpacker app \u25cfDocumentation available \u25cbWiki \u25cbRepo Example data flow diagram for an analysis pipeline Supplementary Software - Unpacker Application \u25cfApplication to convert midas files to ROOT Trees \u25cbCurrently on works for HDSoC and SAMPic MIDAS files \u25cbAdaptable to event structure changes \u25cfAdding new unpackers simplified \u25cbBoils down to adding new plugins in the analysis pipeline framework Example HDSoC data ROOT tree formed by the application Example Digitized SAMPic Waveform Simulation Software Development Vertex Finding Algorithm \u25cfUse PID to select pion, muon, and positron tracklets \u25cfStart with the pion tracklets \u25cb For each pion tracklet, search for an overlap with any of the muon and positron tracklets (candidate tracklets); search is in each orientation (XZ and YZ) separately \u25cb For each candidate, an overlap type is determined using the tracklet\u2019s endpoints \u25cb From the candidates, the \u201cbest\u201d (closest) overlap is selected \u25cfOverlap types \u25cb Distance between endpoints is below a threshold \u25cb Extrapolated distance to an endpoint is below a threshold \u25cb Missing hits in this orientation, so no overlap possible \u25cb No overlap \u25cb \u2026 \u25cf \u25cfA vertex is formed if a valid overlap is found in each orientation \u25cfMove onto the muon tracklet \u25cb For each muon tracklet, search for any overlaps with positron tracklets \u25cb Overlaps (and vertices) are determined in the same way as for the pion tracklet \u25cfForm single-endpoint vertices for all remaining endpoints \u25cb Algorithm expects all endpoints to be assigned a vertex \u25cb All remaining endpoints are made into their own vertices Citations: ATAR Pattern Finding Presentation, Sean Foster (Slides 5-6) https://indico.psi.ch/event/17600/contributions/59200/attachments/31908/63829/Pattern%20Finding%20-%20CM%20Oct%202025.pdf Pattern Finder Implementation into Simulation Framework \u25cfPattern finder leverages Gaudi Tools to organize standard utilities \u25cbAllows for easily hotswapping \u201cstages\u201d to benchmark different approaches against each other \u25cfPattern finding playground for development in python Another Pattern Finding Approach \u25cfDefine \u201cexpected\u201d vertex types \u25cbEx: pi->e, pi->mu \u25cfEach tracklet gets \u201cscored\u201d based on what vertex it belongs to \u25cbEx. pi tracklet looks for e or mu tracklet to connect to, whichever is closer is scored higher \u25cfBiased \u25cbOnly finds vertices it\u2019s \u201ctold\u201d to look for \u25cfScoring comparisons need to be tuned \u25cbInherently subjective Example list of vertex types Failure Modes for full reconstruction Citations: Status of the full simulation chain and R_emu measurement, Patrick Schwendimann https://indico.psi.ch/event/17600/contributions/59206/attachments/31950/63841/Schwendimann_FrameworkStatus.pdf Example Reconstruction Accuracy (New Approach) \u25cfPerforms better \u25cbReverse engineered, so it \u201ccheats\u201d \u25cbInaccuracy solely due to Tracklet Finding inaccuracy Tracklet finding biggest source of inaccuracy \u25cfSlightly modified algorithm \u25cbSee \u201cnew approach\u201d slide \u25cfAll inaccuracies are in the tracklet finding stage \u25cbTest: Run pattern reconstruction using reconstructed tracklets vs. truth tracklets \u25cbResult: Pattern reconstruction has perfect performance \u25cfNo pileup in this study Reconstruction Performance: Reco Tracklets -> Reco Patterns Reconstruction Performance: Truth Tracklets -> Reco Patterns What is a Neural Network? \u25cfA neural network is a parameterized function that approximates non-linear mappings through stacked linear transformations and nonlinear activations. \u25cfA composition of function layers \u25cfParameters (weights and biases) varied to optimize arbitrary loss function i.e. \u201clearned\u201d Example annotated multi layered neural network used to classify images of dogs This is a specific type of neural network called a multi layer perceptron (MLP), the simplest neural network Backpropagation (Overview) \u25cfMuch more detail in this article , and wikipedia \u25cfBackpropagation computes gradients of the loss with respect to all model parameters by applying the chain rule backward through the network \u25cfCompute the gradient of the loss in the space of weights \u25cbOptimal weight updates for the next iteration What are Hyperparameters \u25cf\u201cA Hyperparameter is a parameter that can be set in order to define any configurable part of a model's learning process\u201d \u25cbThese are parameters that are not learned by the model \u25cbChosen before the model is trained \u25cfExamples of what they control \u25cbOptimization dynamics (learning rate, batch size, optimizer) \u25cbModel capacity (hidden size, depth, heads) \u25cbRegularization (dropout, weight decay) Example: Moving average window size is a hyperparameter. It can be over, or under tuned. Hyperparameter Example (Batch Size) \u25cfMore detail in this article \u25cfBatch size is how many training data points are processed before updating the model \u25cbMakes predictions on batch, uses error to inform gradient descent algorithm \u25cfLarger batch size \u25cbMore accurate gradient descent \u25cbFewer updates per epoch \u25cbLess noisy gradient \u25cbLess general, can get stuck in local minima \u25cfSmall batch size \u25cbLess accurate gradient descent \u25cbMore updates per epoch \u25cbNoiser gradient \u25cbCan escape local minima What is a Graph Neural Network (GNN)? \u25cfA graph neural network is a neural network defined on graph-structured data \u25cfData represented by \u25cbNodes (objects, e.g. particle hits in detector) \u25cbEdges (relationships, e.g. spatial proximity of two hits in detector) \u25cbGlobals (property of group, e.g. total energy) \u25cfMuch better explained in this article Citation: https://distill.pub/2021/gnn-intro/ Example of data turned into a graph input What is a Graph Neural Network (GNN)? \u25cfWe input a graph through GNN layers which define how information flows \u25cfExample GNN layer strategies are: \u25cb Independent updates (no connectivity) \u25a0 Apply learned functions to nodes, edges, globals independently \u25cb Message passing (most common, many versions) \u25a0 Edges gather information from connecting nodes \u25a0 Edges compute a \u201cmessage\u201d for each neighboring node \u25a0 Nodes gather messages from edges \u25a0 Graph is updated \u25cfGNN Models have 3 basic type of predictions: \u25cb Node level predictions \u25cb Edge level predictions \u25cb Graph level predictions \u25cfUpdate functions are MLPs Citation: https://distill.pub/2021/gnn-intro/ Simple message passing example (annotated) GNN Layer GNN Block Example of full GNN model What is a Transformer Encoder Block? \u25cfA transformer encoder block is a neural network layer that \u25cbA neural network block that operates on a set of feature vectors \u25cbUpdates each vector using information from related vectors \u25cbProduces context-aware features of the same shape \u25cbCan be stacked to build progressively larger context \u25a0This is because the model computes residuals or \u201ccorrections\u201d, not replacements \u25cfIn the context of graphs \u25cbupdates node embeddings using information from neighboring nodes and edges \u25cfAnalogy: \u25cbMHSA = \u201cTalk to other nodes\u201d \u25cbFFN = \u201cReflect privately\u201d What is Multi-Head Self-Attention (MHSA)? \u25cfSelf-attention lets each element decide which other elements matter and how strongly to combine them \u25cfMultiple heads let the model learn different interaction patterns at the same time What is a Feed Forward Network (FFN)? \u25cfA position-wise feed-forward network applied to each element independently \u25cfUses the same two-layer MLP for all elements (shared weights) \u25cfNo communication between elements occurs in this layer \u25cfAdds nonlinear feature refinement after self-attention \u25cfAside: \u25cbFeed Forward Networks are more general than position wise FFNs . . .xi x\u2019i Example FFN for node with 2 features. Same FFN is applied to all nodes independently What is a Graph Transformer? \u25cfA graph transformer is a GNN that generalizes message passing using transformer-style attention \u25cfThese are among the most expressive modern ML models \u25cbCan solve a wider class of problems than most models \u25cfGNN \u25cbEdges define where information flows \u25cbMessage passing same \u201cstrength\u201d for all edges \u25cfGraph transformers \u25cbAttention learns how strongly information flows along those edges. \u25cbMessage passing differs in learned \u201cstrength\u201d for different edges Comparison of GNNs and Transformers in terms of message passing over different structures Citation: https://towardsdatascience.com/how-to-build-graph-transformers-with-o -n-complexity-d507e103d30a/ G4Pioneer Monte Carlo + Detector Response \u25cfG4Pioneer Monte Carlo simulates the underlying physics \u25cbGeant4 Fork \u25cfDetector Response converts truth into detector-level signals \u25cbDepends on detector geometry \u25cbHandles event mixing \u25cfML training requires both detector-level outputs and truth-level information Cartoon example of detector response with truth information added to hits ML Ready Dataset Gaudi Pipeline (Time Group Forming) \u25cfGaudi pipeline does simple traditional labeling and reconstruction \u25cfExample time group forming : \u25cbDetector response events are \u201csplit\u201d into time-based clusters \u25a0Really, we just label hits with a time group they belong to \u25cbMost the time one time group == one particle \u25a0This helps the later ML stages reconcile particle specific features Cartoon example of time group spikes in energy deposition Representing Information as a Graph \u25cfOur final step before feeding the data into the model is constructing a fully connected graph \u25cfNodes contain hit specific information \u25cbEx. position, deposited energy, etc. \u25cfEdges contain related information between hits \u25cbEx. difference in positions \u25cfGlobal information for event level inputs \u25cbEx. Total Energy \u25cfWe can append information to these graphs as downstream models make predictions Graph representation of base detector information Graph level feature example: \u25cfTotal energy Group Classifier \u25cfMulti \u2011label graph transformer classifier \u25cbSubgraph level task \u25cfInputs (represented as a graph): \u25cbDetector response event information \u25cbTime grouping labels \u25cfTargets: \u25cbTruth level representation of what particles are in the group \u25cbParticularly: [pionInGroup, muonInGroup, MIPinGroup] \u25cfOutputs: \u25cbPredicted probability that the time group belongs to each class [prob_pionInGroup, prob_muonInGroup, prob_MIPinGroup] Cartoon example of time group spikes in energy deposition, now labeled by group classifier Group Splitter \u25cfMulti \u2011label graph transformer classifier \u25cbNode level task \u25cfInputs (represented as a graph): \u25cbDetector response event information \u25cbTime grouping labels \u25cbPredicted time group level particle class \u25cfTargets: \u25cbTruth level representation of the particle type for each hit \u25cbParticularly, for each hit in the graph: [[is_pion, is_muon, is_mip], [is_pion, is_muon, is_mip], \u2026] \u25cfOutputs: \u25cbPredicted probability that each hit belongs to each class [[prob_pion, prob_muon, prob_mip], [prob_pion, prob_muon, prob_mip], \u2026] Cartoon example of how a time group may be split into multiple particle classifications \u03c0 \u03c0 \u03bc Endpoint Regressor \u25cfQuantile graph transformer regressor \u25cfInputs: \u25cbDetector response event information represented as a graph \u25cbPredicted time group level particle class \u25cbPredicted hit level particle classes \u25cfTargets: \u25cbTruth level endpoints \u25cbParticularly: [[x_start, y_start, z_start], [x_end, y_end, z_end]] \u25cfOutputs: \u25cbPredicted endpoints with quantiles [[[x_start_q1, y_start_q1, z_start_q1], [x_end_q1, y_end_q1, z_end_q1]], \u2026] Cartoon example of how we estimate endpoints with uncertainties given by the quantiles = Median endpoint estimate = Error range determined from quantiles Pattern Finder \u25cfAffinity graph transformer classifier \u25cbEdge level task \u25cfInputs (represented as a graph): \u25cbDetector response event information \u25cbTime grouping labels \u25cbPredicted time group level particle class \u25cbPredicted hit level particle classes \u25cfTargets: \u25cbAgreement between truth level event origins between nodes; i.e. \u201care these two nodes from the same monte carlo truth event\u201d. Explicitly: target_affinity[i][j] = 1 if origin_id[i] == origin_id[j] \u25cfOutputs: \u25cbPredicted \u201caffinities\u201d (0,1) between time groups Time group 0 Time group 1 Time group 2 Time group 3 Node labels: On per time group graph Edges: Learned affinity between groups (i.e. are two time groups from the same event?) Pion Stop Regressor \u25cfQuantile graph transformer regressor \u25cbGraph level task \u25cfInputs (represented as a graph): \u25cbDetector response event information \u25cbTime grouping labels \u25cbPredicted time group level particle class \u25cbPredicted hit level particle classes \u25cbPredicted affinities \u25cfTargets: \u25cbTruth level pion stop \u25cbParticularly: [x_stop,y_stop,z_stop] \u25cfOutputs: \u25cbPredicted pion stop [[[x_stop_q1, y_stop_q1, z_stop_q1], \u2026] \u25cfNotes: \u25cbQuantiles effectively give uncertainties if chosen to be top 84%, top 50%, and top 16% quartiles = median \u00b1 1 standard deviation = Pion stop estimate Cartoon example of pion stop estimate = Error range determined from quantiles Citation: Physics Reconstruction BVR Talk, Omar Beesley https://indico.psi.ch/event/18441/contributions/61425/attachments/3283 0/66309/Reconstruction-Final.pdf Positron Angle Regressor \u25cfQuantile graph transformer regressor \u25cbGraph level task \u25cfInputs (represented as a graph): \u25cbDetector response event information \u25cbTime grouping labels \u25cbPredicted time group level particle class \u25cbPredicted hit level particle classes \u25cbPredicted affinities \u25cfTargets: \u25cbTruth level direction vector for positron angle \u25cbParticularly: [(sin \u03b8cos\u03c6), (sin \u03b8sin\u03c6), (cos \u03b8)] \u25cfOutputs: \u25cbPredicted direction vector for positron angle [[(sin\u03b8cos\u03c6)_q1, (sin \u03b8sin\u03c6)_q1, (cos \u03b8)_q1], \u2026] Cartoon example of positron angle estimate direction in detector coordinate system with uncertainty Citation: Physics Reconstruction BVR Talk, Omar Beesley https://indico.psi.ch/event/18441/contributions/61425/attachments/3283 0/66309/Reconstruction-Final.pdf Full Reconstruction Diagram \u25cfConceptually, all the same stages \u25cfThe idea is the ML models are \u201cimplementations\u201d of a stage \u25cbIn principle they can be swapped out with a traditional reconstruction (non-machine learning) \u25cbAllows for benchmarking of different implementations Why Have Divisions? \u25cfEach pipeline stage operates on a well-defined \u201csample\u201d \u25cbEach division defines a dataset boundary \u25a0A dataset boundary is the point at which the meaning of a row is fixed and written to storage, so downstream stages can rely on it without knowing how it was produced \u25a0It\u2019s okay to create appending files or masks, \u25a0If you must mutate data (i.e. change your definition of a \u201csample\u201d then you create another dataset boundary), then you should create a new dataset boundary or \u201cdivision\u201d \u25cfIf we don\u2019t create clear divisions \u25cbHidden coupling between stages can occur \u25a0I.e. you change one stage, an unrelated stage no longer works \u25cbBatching becomes unclear \u25a0Your definition of a batch changes between data boundaries \u25a0Memory and performance become less predictable \u25cfIn short, each division should scale separately GraphRecord Former \u25cfWe don\u2019t store data as their graphs, we store them as the minimal information needed to build the graph \u25cfAs a result we have a \u201cdata loading stage\u201d before running any model where we construct a graph from the data Stereoscopic View \u25cfBefore each \u201cDivision 1\u201d model \u201cdoes it\u2019s job\u201d, it first construct a \u201cstereoscopic\u201d view of the data \u25cb Hits are split by view: \u25a0 0 = X plane, 1 = Y plane \u25cb Each view is embedded independently, then fused: [emb_view0, emb_view1, mask0, mask1] \u25a0 mask_i = 1 if view i has hits, else 0 \u25cb This process is learned for each model \u25cfWhy this helps: \u25cb Treats view ID as discrete routing \u25cb Explicitly encodes that intermediate views (e.g. \u201c0.5\u201d) do not exist \u25cfWhy we want this stage learnable: \u25cb weight each view \u25cb rescale per-view features \u25cb handle missing or weak views \u25cfWhy it\u2019s model-specific \u25cb Different tasks rely on views differently \u25a0 e.g. missing Y view matters more for endpoint finding than for particle classification View of x and y planes View of x plane View of y plane X plane contains all the hits Y plane does not contains any hits, the model learns to treat the case of an empty view differently than a standard \u201cfull\u201d view (empty) Exaggerated cartoon example of how a stereoscopic view can help in the case of missing views [emb_view0, 00\u2026000, 1, 0] + Quantiles \u25cfFor regressions, quantiles are useful to extract uncertainties \u25cfUses a quantile regression loss function \u25cfWe can use quantile regression to have our models target a specific quantiles \u25cbUsually we select \u25a0Lower quantile = 16 ~ 1\u03c3 \u25a0Mid quantile = 50 ~ median \u25a0Upper quantile = 84 ~ +1\u03c3 Wikipedia example of Quantile Regression. Notice how it forms confidence bands around the best fit (or median) Backpropagation (Explicit, Part I) \u25cfDiagram with some labels to conceptualize the variables Backpropagation (Explicit, Part II) \u25cfEquations for how to update weights from back propagation 1. Backpropagate activation gradients: 2. Weight gradient via local chain rule: 3. Gradient descent update to weights: Backpropagation (Explicit, Part III) \u25cfThe back propagation step is a recursive step The backpropagation step: This formula is recursive, so for N layers you have explicitly: Or more commonly you can write in Jacobian form, which cleans up the notation Backpropagation (Explicit, Part IV) \u25cfThe actual values of xl,i are architecture dependent \u25cfIn this simple example, you can compute them by defining a bias and activation function (eg. softmax) We can define zl,i for the raw computed \u201cresponse\u201d from the previous layer: Then we apply some activation, usually to constrain values between 0 and 1 to prevent exponential blowup. This allows to (finally) formally compute all needed partial derivatives: Hyperparameters Need to be Tuned Appropriately \u25cfImproper hyperparameter choices can lead to \u25cbOvertraining \u25cbSlower convergence \u25cbVanishing or exploding gradients \u25a0Impossible to find true solution at this point \u25cfTuning hyperparameters can be hard \u25cbThey interact with each other (often non-linearly) \u25cbOptimal choice varies with each dataset/model Example: Fitting data with a polynomial. The degree of the polynomial, d, is a hyperparameter Hyperparameters (Learning Rate) \u25cfMore detail in this article \u25cfLearning Rate controls how large each parameter update is in the direction of the gradient \u25cfLarger learning rate: \u25cb Bigger, more exploratory steps \u25cb Less likely to get stuck in local minima \u25cb Harder to settle precisely at the optimum \u25cfSmaller learning rate: \u25cb Smaller, more precise steps \u25cb More likely to get trapped in local minima \u25cb Better at fine-tuning near the optimum Hyperparameters Example (# of layers) \u25cfMore detail in this article \u25cfHidden dimension sets the size of the model\u2019s internal feature representations at each layer. \u25cfMore layers: \u25cbLearns more \u201chierarchical\u201d/ \u201cabstract\u201d features \u25cbHigher risk of overfitting or training instability (higher loss fluctuations) \u25cbHigher memory and compute cost \u25cfLess layers: \u25cbLearns \u201csimpler\u201d/\u201cshallow\u201d features \u25cbLower risk of overfitting \u25cbLower memory/compute cost Hyperparameters (Dropout) \u25cfMore detail in this article \u25cfDropout randomly disables a fraction of activations during training to reduce overfitting \u25cfHigher dropout: \u25cbBetter for noisy datasets \u25cbLess risk of overfitting \u25cbHigher risk of underfitting \u25cfLower dropout: \u25cbBetter for less noisy datasets \u25cbLess risk of underfitting \u25cbHigher risk of overfitting Hyperparameters (Hidden dim) \u25cfMore detail in this article \u25cfHidden dimension sets the size of the model\u2019s internal feature representations at each layer. \u25cfLarger hidden dim: \u25cbCan represent more complex patterns \u25cbHigher risk of overfitting \u25cbHigher memory and compute cost \u25cfSmaller hidden dim: \u25cbLimited ability to model complex patterns \u25cbLower risk of overfitting \u25cbLower memory/compute cost Hyperparameters (weight decay) \u25cfMore detail in this article \u25cfWeight decay adds a penalty on large weights to the loss, encouraging simpler models. Similar to dropout. \u25cfHigher weight Decay: \u25cbBetter for noisy datasets, stronger regularization \u25cbLower risk of overfitting \u25cbHigher risk of underfitting \u25cfLower weight decay: \u25cbBetter for less noisy datasets, less regularization \u25cbLower risk of underfitting \u25cbHigher risk of overfitting Hyperparameters (# of attention heads) \u25cfMore detail in this article \u25cfThe number of attention heads controls how many independent subspaces the model attends to in parallel within each attention layer \u25cfMore attention heads: \u25cb Learns multiple attention patterns in parallel \u25cb Higher memory/compute cost \u25cb Diminishing returns if per-head dimension is too small \u25cb Can overfit and destabilize training \u25cfFewer attention heads: \u25cb Learns fewer attention patterns \u25cb Lower memory/compute cost \u25cb May miss distinct relationships \u25cb Can underfit if data is very heterogeneous Hyperparameters (activation functions) \u25cfMore detail in this article \u25cfThe activation function controls the nonlinearity applied at each layer Examples: \u25cfReLU \u25cbSimple, piecewise-linear activation \u25cbFast training; can form sharp, noisy boundaries \u25cfTanh \u25cbSmooth, bounded activation \u25cbProduces smoother boundaries; may saturate \u25cfGELU \u25cbSmooth, probabilistic gating \u25cbBalances smoothness and expressiveness Hyperparameters (optimizers) \u25cfMore detail in this article \u25cfOptimizers control how gradients are transformed into parameter updates during training Examples: \u25cfStochastic Gradient Descent (SGD) with momentum \u25cb Simple, stable updates \u25cb Often performs well on unseen data, not just the training set \u25cb Sensitive to learning rate and scaling \u25cfAdaptive Moment Estimation (Adam) \u25cb Adaptive learning rates per parameter \u25cb Fast convergence, less sensitive to hyperparameter choice \u25cb Can overfit or generalize worse than SGD \u25cfAdamW \u25cb Adam with decoupled weight decay \u25cb More reliable regularization behavior \u25cb Standard choice for modern deep models Hyperparameters (Gradient Descents) \u25cfMuch more detail in this article \u25cfBatch Gradient Descent (BGD): \u25cbUses the entire dataset in one iteration. The batch size is equal to the total number of training samples. \u25cfMini-Batch Gradient Descent (MBGD): \u25cbUses a predefined number of samples from the dataset for each update. This method lies between batch and stochastic gradient descent (SGD). \u25cfStochastic Gradient Descent (SGD): \u25cbProcesses only one sample at a time for each update, making the batch size equal to 1. Hyperparameters (why are more layers harder to train) \u25cfMore layers \u2192 more loss instability \u25cb Due to back propagation \u25cb The size of your step becomes more \u201cuntrainable\u201d the more layers you add \u25cfCases: \u25cb \u03bb \u2248 1 \u25a0 Gradients stable as model layers increase \u25cb \u03bb < 1 \u25a0 Gradients vanish as model layers increase \u25a0 No more learning occurs! \u25cb \u03bb > 1 \u25a0 Gradients blow up as model layers increase \u25a0 Cannot converge on solution \u25cfOne goal of model architecture choice is to get \u03bb \u2248 1 What is a Tree-Structured Parzen Estimator (TPE) (Part I) \u25cfGiven a (possibly stochastic) black box function you want to minimize (ex. model loss) \u25cfHyperparams \u2261 \u03b8 \u25cfDefine the following: \u25cfThen, for any given theta we can define expected improvement \u25cfGoal: Maximize expected improvement Note: See paper on arxiv What is a Tree-Structured Parzen Estimator (TPE) (Part II) \u25cfFor a 1 dimensional y, it turns out to be easier to work with , we can invert using Bayes\u2019 rule: \u25cfAnd substitute \u25cfSince we don\u2019t know every value of y this becomes an impossible task. We must make an approximation by dividing into \u201cgood\u201d and \u201cbad\u201d distributions Note: See paper on arxiv What is a Tree-Structured Parzen Estimator (TPE) (Part III) \u25cfThe integral, by construction, only cares about the \u201cgood\u201d region, so the integral simplifies to \u25cfBut the integral is now constant in theta! So we have: \u25cfWhere so we can write: Note: See paper on arxiv What is a Tree-Structured Parzen Estimator (TPE) (Part IV) \u25cfBut \u03b3 is fixed, so \u25cfWhere the final step is because x/(bx+c) is monotonic in x for x >0 ,let x = l/g \u25cfIn other words, we just need to find which is doable via algorithm! Note: See paper on arxiv What is a Tree-Structured Parzen Estimator (TPE) (Part V) \u25cfNow to define the algorithm, first we observe T (~10) trials randomly: \u25cfFrom this data, we want to build: \u25cfSo we define \u25cfAnd assume: Note: See paper on arxiv What is a Tree-Structured Parzen Estimator (TPE) (Part VI) \u25cfThis allows us to write: \u25cfWe can fit to our samples to get a continuous distribution spaces for each param \u25cfThen we sample from the \u201cgood\u201d spaces for M candidates index by m \u25cfAnd finally, choose our next theta, add it to the data set, and repeat Note: See paper on arxiv What is a Tree-Structured Parzen Estimator (TPE) (Part VII) \u25cfHow do we obtain our fits from the data? \u25cfUses Kernel Density Estimation (KDE) \u25cbThe actual fit is done when determining each \u201cgaussian kernel\u201d (or sigma) \u25cbLikelihood-optimal is expensive ~O(n2d) \u25a0n = # samples \u25a0d = # hyperparameters \u25cbOptuna uses the \u201cheuristic\u201d version, which requires choosing some value for c. Note: See paper on arxiv Example Graph Transformer Layer Why use Graph Transformers? \u25cfThese are among the most expressive modern ML models \u25cbCan solve a wider class of problems than most models \u25cfFairly easy to construct with torch geometric \u25cfAttention based transformers allow models to learn how event information is related, as opposed to having to be more explicitly \u201ctold\u201d in a traditional GNN approach Breaking down \u201cScalability\u201d I choose to break down scalability into three categories: 1.Data a. ML pipeline does not change behavior as data set grows i.Still scales in execution time 2.Compute a. ML pipeline does not change behavior as compute power is changed i.Still scales in execution time ii.Ex. Pipeline runs on developer\u2019s laptop or a CPU/GPU cluster 3.Codebase a. ML pipeline does not (greatly) change behavior as complexity grows i.New models, stages, or data products require additional code, not (major) code rewrites ii.Iteration speed does not (greatly) degrade with system size (i.e. keep things modular!) What Do We Mean by \u201cScaling\u201d (Data) \u25cfData volume should be able to grow without changing how the pipeline behaves \u25cfAdding the following should not cause pipeline behavior changes: \u25cbMore events \u25cbMore derived data products \u25a0predictions, masks, regressions, etc. \u25cbMore passes over the same data \u25cbLarger event representations \u25cfImplications: \u25cbMemory usage must not grow with dataset sizeIdeal Behavior for Different Sized Datasets ML Pipeline Output A Output B Small Dataset Large Dataset Short processing time Long processing time Small number of batches Large number of batches Techniques to Ensure Scalability (Data) \u25cfStream data in bounded batches \u25cbRAM usage should not scale with data set size \u25cbAllows RAM usage to be \u201ctunable\u201d \u25cfBase data should be immutable \u25cbNo modifications or extensions to ML pipeline input data files \u25cfSeparate derived data products \u25cbPredictions, masks, and regressions are produced as independent datasets \u25cfReference data by IDs, not by object \u25cbWhen passing data modules, use file paths or map IDs not in memory collections \u25cbSimilar to why we use pointers in C++ Simple Example Pipeline Including Derived Datasets Base Dataset Stage A Stage B Output Batch i Derived Data i Derived Dataset Storage Batch i + Derived Data i ML Pipeline Technologies for Scalability (Data) \u25cfApache Parquet (columnar, on disk) \u25cbML-native working datasets, append-only, shardable (aka \u201cbatchable\u201d) \u25cbCan key rows by event ID, enabling batch-scoped joins for derived data products \u25cfApache Arrow \u25cbSingle copy from disk into RAM, then zero-copy views all the way to Torch \u25cfPolars \u25cbDataset shaping: filtering, joins, feature derivation \u25cbLazy, columnar execution on Arrow-backed data \u25cbPrepares batchable views for PyTorch ingestion \u25cfPyTorch tensors \u25cbExecution format for models \u25cfPytorch DataLoader \u25cbHandles batching, shuffling, parallel loading, prefetching, enforcing memory bounds Flow of Data From Monte Carlo to a Model in the ML pipeline Monte Carlo Parquet Arrow Polars PyTorch DataLoader Model Once, offline file generation Disk \u2192 RAM Copy Zero-copy views of data What Do We Mean by \u201cScaling\u201d (Compute) \u25cfComputation resources should be able to grow without changing how the pipeline behaves \u25cfAdding the following should not cause pipeline behavior changes: \u25cbNumber of GPUs \u25cbNumber of CPU cores/threads \u25cbNode count \u25cbMemory Capacity \u25cfImplications: \u25cbAlgorithms must be agnostic to resources \u25a0Caveat: PyTorch and other frameworks may change their behavior for different devices/device counts for efficiency Ideal Behavior for Different Amounts of Computing Resources ML Pipeline Output Output Dataset Dataset Long processing time Shorter processing time Low resource (ex. Laptop) High resource (ex. GPU cluster) Techniques to Ensure Scalability (Compute) \u25cfMake algorithms resource-agnostic \u25cbNo logic branches based on GPU count, core count, node count, or memory size, etc. \u25cfMake algorithms easily parallelizable \u25cbDecompose computation into independent, composable units \u25cbAvoid global state dependencies in pipeline stages \u25cbAvoid \u201csynchronization points\u201d; i.e. points where models must make inferences on whole datasets Parallelized View of Simplified Pipeline Big Dataset Batch 0 N outputs Batch 1 Batch M N events Output 1 Output 2 Output N N outputs N events \u2026 N outputs \u2026N events Stage A Stage B Compute Node 0 Stage A Stage B Compute Node 1 Stage A Stage B Compute Node M ML Pipeline Technologies for Scalability (Compute) \u25cfPyTorch \u25cbStandard framework for modern ML models \u25cbResource-agnostic execution model \u25cfCUDA \u25cbOperates purely at the level of memory, kernels, and execution, independent of algorithm or pipeline semantics \u25cbProvides an API for launching and coordinating large numbers of parallel threads on GPUs \u25cfKubernetes \u25cbSchedules identical pipeline executions onto available compute nodes \u25cbScales how many pipelines run concurrently, not what they do \u25cbHandles retry logic and resource limits Simplified \u201cScope\u201d Of Technologies Outer Technologies Manage Inner Technologies Kubernetes Distributes pipeline containers as black boxes Pipeline Container (ZenML) Pipeline logic, I/O, bookkeeping, etc. PyTorch Model semantics CUDA Kernels, threads, overall GPU execution What Do We Mean by \u201cScaling\u201d (Codebase) \u25cfCodebase complexity should be able to grow without changing how the system behaves \u25cfAdding the following should not cause system wide behavioral changes: \u25cbMore pipeline stages \u25cbMore models / algorithms \u25cbMore configuration options \u25cfImplications: \u25cbNew functionality should be added by extensions, not modification \u25cbSystem behavior should be locally understood (modularity) \u25cbExisting code should not require global refactoring to evolve The \u201cGlobal\u201d Structure Should Not Change As Complexity Increases Output B Dataset \u201cSimple\u201d pipeline with few stages \u201cComplex \u201cPipeline with many stages Stage A Stage B Stage C Stage E Stage D Stage F Output B Dataset Stage A Stage B Techniques to Ensure Scalability (Codebase) \u25cfUse abstraction where appropriate \u25cbDefine stable base interfaces / abstract classes \u25cbAdd new functionality by extending, not rewriting \u25cfAvoid global coupling \u25cbModules depend only on explicit inputs \u25cbEach module manages its own immutable local state \u25cfIsolate responsibilities to achieve modularity \u25cbEach module has a single, well-defined responsibility \u25cbChanges remain local to the owning module Simple Example of Abstraction For Adding New Models torch.nn.Module pioneerml.GraphModel pioneerml.GroupClassifier pioneerml.PionStopFinder Framework level contract Project level Contract Project level contract New file with implementation New file with implementation Technologies for Scalability (Codebase) \u25cfPyTorch \u25cbProvides a standard base abstraction classes for many model types (ex. nn.Module ) \u25cbEnforces a consistent model interface (ex. forward method) \u25cfZenML \u25cbEncodes pipelines as composable, declarative units and orchestrates execution \u25cbAllows pipelines to grow by adding or reordering steps; easy to add new pipelines \u25cbManages pipeline state, artifacts, and execution metadata outside user code \u25cfOptuna \u25cbIsolates hyperparameter search code \u25cbEnables experimentation without modifying core implementations \u25cbReally a package for black box searching, by default uses Tree-Structured Parzen Estimator (TPE) Simplified Example Pipeline for Training Models Data Construction Optuna Optimization Model Training Evaluation Pipeline Parameters Trained Model ZenML Pipeline Load shard data Build graph inputs Sample hyperparameters Decide next trial Train our model implementation Compute metrics Inform hyperparameter search Finished when hyperparameter search ends What is Apache Parquet? \u25cfApache Parquet is a columnar, on-disk data format that is widely used in ML workloads \u25cfWhat parquet does \u25cbColumnar storage \u2192 read only the columns (features) your model needs \u25a0Allows one to efficiently assign a subset of columns as inputs and another subset of columns as targets \u25cbSupports nested and variable-length fields \u25cbData schema is embedded in the file, not inferred by code (ex. Not like numpy, where code defines dtype parameter) \u25cfWhy this matters for scalability \u25cbEfficient I/O for large datasets through compression and encoding \u25cbNew models using different subsets of the data becomes trivial Example time_groups.parquet file structure What is Batching? \u25cfBatching means processing a fixed-size subset of events at a time, rather than the full dataset \u25cfWhat batching does \u25cbGroups individual events into batches of size N \u25cbEach batch is processed independently \u25cbBatches are discarded after use \u25cfWhy this matters for scalability \u25cbMemory usage is bounded by batch size (for single batch process) \u25cbDataset size does not affect RAM usage \u25cbEnables streaming over arbitrarily large datasets Big Dataset Batch 0 Batch 1 Batch M Model Output 1 Output 2 Output N \u2026 \u2026N events N outputs Diagram that Shows how Batching Splits Data N events N events N outputs N outputs What is Shuffling? \u25cfShuffling changes the order in which events are seen, without changing the data itself \u25cfWhat shuffling does \u25cbRandomizes event order before forming batches \u25cbEnsures batches contain a mix of events \u25cbChanges between epochs (or passes over the data) \u25cfWhy this matters for scalability \u25cbPrevents bias from data ordering \u25cbImproves statistical independence between batches \u25cbAllows repeated passes over large datasets without correlation artifacts Dataset [A,A,A,A,B,B] Simplified Example of Shuffling vs. Not Shuffling a Dataset with Distinct Event Types A and B Without Shuffling With Shuffling Batch 1 [A,A] Batch 0 [A,A] Batch 2 [B,B] Dataset [A,A,A,A,B,B] Batch 1 [A,B] Batch 0 [A,B] Batch 2 [A,B] Batches may have biases in event types, which hinders training Batches are a better representation of the whole dataset; no ordering correlations What is Parallel Loading? \u25cfParallel loading means loading multiple batches concurrently, using multiple workers \u25cfWhat parallel loading does \u25cbMultiple workers read and prepare batches simultaneously \u25cbThe model always has a batch ready to process \u25cbData loading is decoupled from model execution \u25cfWhy this matters for scalability \u25cbHelps prevent the model from waiting on disk I/O \u25cbImproves hardware utilization (especially GPUs) Big Dataset Loader 0 (Batch 0) Loader 1 (Batch 1) Loader 2 (Batch 2) Model \u2026Data Loaded in Parallel Note: Parallel loading does not necessarily mean parallel model execution Parallel Data Loading Diagram What is Prefetching? \u25cfPrefetching means loading future batches while the current batch is being processed \u25cfWhat prefetching does \u25cbWhile the model computes on batch N the next batch (N+1) is loaded in the background \u25cbWhen computation finishes, the next batch is already ready \u25cfWhy this matters for scalability \u25cbHelps prevent the model from waiting on disk I/O Simplified Prefetching Example Diagram Without Prefetching With Prefetching Load Batch N Compute Batch NLoad Batch N+1 Compute Batch N+1Load Batch N Compute Batch N Load Batch N+1 Compute Batch N+1Time Time Subsequent batches loaded in parallel with compute of previous batch. Effectively utilizing different hardwares What is Enforcing Memory Bounds? \u25cfEnforcing memory bounds means placing a hard limit on how much data can be in memory at once \u25cfWhat enforcing memory bounds does \u25cbMaximum in-flight data size is fixed \u25cbBatch creation is throttled when memory is full \u25cbMakes memory usage predictable and stable \u25cfWhy this matters for scalability \u25cbDataset size does not affect RAM usage \u25cbEnables streaming over arbitrarily large datasets Batch 0Batch 1 Model \u2026 Diagram Showing How Memory Bounds Enforce a Limited Number of Batches Loaded in RAM Batch 2Batch 3Batch MBig Dataset Memory bound fixes limit of data in RAM, which effectively fixes the number of batches that can be in RAM at one time. As one batch finishes, more batches load into RAM What is Kubernetes (K8s)? \u25cfA system for running and managing containerized workloads across shared compute resources \u25cfWhat Kubernetes does \u25cbSchedules containers onto available compute nodes \u25cbEnforces resource limits (CPU, GPU, memory) per container \u25cbIsolates workloads from one another \u25cbHandles restarts and retries on failure \u25cfWhy this matters for scalability \u25cbEnables concurrent execution of many independent workloads \u25cbPrevents resource contention between workloads Kubernetes Control Plane Cluster of Compute Resources Compute Node A Compute Node B Schedules and distributes workload Pod PodPod Application 0 Application 1 Application 2 Note: A pod is the smallest schedulable unit Simplified Diagram of How Kubernetes Orchestrates Applications Across a Compute Cluster What is ZenML? \u25cfA framework for defining, orchestrating, and executing machine-learning pipelines with explicit steps, artifacts, and metadata \u25cfWhat ZenML does \u25cbEncodes workflows as composable, declarative pipelines \u25cbOrchestrates execution order and dependencies \u25cbIntegrates with execution backends (local, containers, clusters) without changing user code \u25cfWhy this matters for scalability \u25cbPipelines grow by adding or rearranging stages, not rewriting logic \u25cbEnables reproducibility, versioning, and parallel development \u25cbState and artifacts are managed outside user code Example ZenML pipeline diagram Stage A Stage B Stage C Pipeline Parameters Pipeline Output ZenML Pipeline Artifacts and Metadata Storage (external or local database) What is Optuna? \u25cfMany hyper parameters means manual tuning is bad \u25cbToo slow \u25cbSuboptimal tuning means you spend more resources (time, computing power, etc.) training unused models \u25cfOptuna is a python package that solves this problem \u25cbFramework for optimization black box objective functions \u25cbTechnically not an ML package, but rather a package that supports many optimized sampling strategies Example Optuna workflow diagram How Optuna Works \u25cfOptuna supports many sampling algorithms , examples: \u25cbGrid search \u25cbRandom search \u25cbGaussian process-based Bayesian optimization \u25cfFor single object functions, the default for Optuna is Tree-Structured Parzen Estimator (TPE) TPE flow diagram (in a nutshell) Time Group Classifier \u25cfI\u2019ll mostly be talking about Omar\u2019s \u201ctime group classifier model\u201d \u25cfInput: \u25cbTime grouped hit graph \u25a0Nodes: [x (or y), z, energy, view, group_energy] \u25a0Edges: [dx (or dy), dz, dE, same_view] \u25cbGroups split by time (could potentially contain multiple particle types) \u25cfOutput \u25cbClass labels: [muon, pion, mip] \u25cfMuch better explained in Omar\u2019s presentation Performance of Model \u25cfClosely matches performance of Omar\u2019s work \u25cfDifferences from Omar\u2019s work \u25cbUsed my machine to train \u25cbDid a hyperparameter search using Optuna \u25cbIncorporated into ZenML framework for creating pipelines in python \u25cfUnsure how this compares to the traditional reco values(?) \u25cfUnsure exact parameters in Omar\u2019s data set Performance of Model \u25cfHistograms below shows the models \u201csureness\u201d of each class \u25cfWant to see large peaks at 0 and 1 \u25cb0 \u2192 this is definitely not this class \u25cb1 \u2192 this is definitely this class \u25cfThe muon groups are the biggest struggle Preventing Overtraining (Early Stopping) \u25cfCan set early stopping when training loss curves \u25cbIf no meaningful (> \u03b4) improvement within N epochs, stop training \u25cbN := \u201cpatience\u201d usually set to ~5% of expected training epochs \u25cfPotential improvements: \u25cbLoss curve smoothing \u25cb\u201cNoise\u201d estimations, only continue training if smoothed improvement > noise of previous iterations \u25cfSee documentation *NOTE: This particular model is overtrained because N set to 6 (too high) Meaningful improvement in validation loss stops Reaches patience threshold (N=6) No improvement in 6 iterations Preventing Overtraining (PCA) \u25cfNeed a way to visualize many dimensions \u25cfPrincipal Component Analysis (PCA) good candidate for this \u25cfCompare clusters in embedding space vs. input space \u25cbInput space shows data driven groupings \u25cbEmbedding space shows learned groupings \u25cb# of groupings should match! Well-trained Over-trained Average vector of all nodes in graph: [coord, z_pos, energy, view, group_energy] 5D \u2192 2D 512D \u2192 2D 512D \u2192 2D Preventing Overtraining (PCA) \u25cfNeed a way to visualize many dimensions \u25cfPrincipal Component Analysis (PCA) good candidate for this \u25cbChoose to project down to d = 2 dimensions this way \u25cfCompare clusters in embedding space vs. input space \u25cbInput space shows data driven groupings \u25cbEmbedding space shows learned groupings \u25cb# of groupings should match! Well-trained Over-trained mipmuon pion 1 pion 2 muon mippion 1 pion 2 512D \u2192 2D pion 1 pion 2 muon muon 2? muon 3? mip 512D \u2192 2D Average vector of all nodes in graph: [coord, z_pos, energy, view, group_energy] 5D \u2192 2D Preventing Overtraining (t-SNE) \u25cfProblem with PCA \u25cbGlobal linear may not preserve local neighborhoods \u25a0May not show groups! \u25cft-distributed stochastic neighbor embedding (t-SNE) is designed to preserve local clusters \u25cbMaps N dims \u2192 d dims \u25a0We choose d = 2 for visualization ease \u25cfSame ideas as PCA \u25cbcompare input space and embedding space Well-trained Over-trained 512D \u2192 2D 512D \u2192 2D Average vector of all nodes in graph: [coord, z_pos, energy, view, group_energy] 5D \u2192 2D Preventing Overtraining (t-SNE) \u25cfProblem with PCA \u25cbGlobal linear may not preserve local neighborhoods \u25a0May not show groups! \u25cft-distributed stochastic neighbor embedding (t-SNE) is designed to preserve local clusters \u25cbMaps N dims \u2192 d dims \u25a0We choose d = 2 for visualization ease \u25cfSame ideas as PCA \u25cbcompare input space and embedding space Well-trained Over-trained 512D \u2192 2D 512D \u2192 2D mipmuon pion 1 pion 2 pion 1 pion 2 mip muon muon muon 2? muon 3? mip mip 2? mip 3? pion 1 pion 2 Average vector of all nodes in graph: [coord, z_pos, energy, view, group_energy] 5D \u2192 2D Preventing Overtraining (UMAP) \u25cfProblem with t-SNE \u25cb Depends on a \u201cPerplexity\u201d \u25a0 Parameter, ~how many neighbors a point can have \u25cb May artificially split or group clusters \u25cfUniform Manifold Approximation and Projection (UMAP) is designed to preserve the underlying manifold structure \u25cb Tries to preserve both local neighborhoods and their global relationships \u25cb Maps N dims \u2192 d dims \u25a0 We choose d = 2 for visualization ease \u25cfComputational expensive \u25cb Use as a \u201ctie breaker\u201d if PCA and t-SNE disagree Well-trained Over-trained 512D \u2192 2D 512D \u2192 2D Sorry! I don\u2019t have an example for this!Average vector of all nodes in graph: [coord, z_pos, energy, view, group_energy] 5D \u2192 2D Preventing Overtraining (UMAP) \u25cfProblem with t-SNE \u25cb Depends on a \u201cPerplexity\u201d \u25a0 Parameter, ~how many neighbors a point can have \u25cb May artificially split or group clusters \u25cfUniform Manifold Approximation and Projection (UMAP) is designed to preserve the underlying manifold structure \u25cb Tries to preserve both local neighborhoods and their global relationships \u25cb Maps N dims \u2192 d dims \u25a0 We choose d = 2 for visualization ease \u25cfComputational expensive \u25cb Use as a \u201ctie breaker\u201d if PCA and t-SNE disagree Well-trained Over-trained 512D \u2192 2D 512D \u2192 2D Sorry! I don\u2019t have an example for this!pion 1 pion 2 muon mip muon mip pion 2 pion 1 Average vector of all nodes in graph: [coord, z_pos, energy, view, group_energy] 5D \u2192 2D PSI Data j.carlton@uky.edu 2025 PSI Test Beam j.carlton@uky.edu III. 2023 PSI Test Beam (Slide 14/37) Overview \u25cfPIONEER LYSO Tapered Array calorimeter test \u25cbAugust 18 - September 1, 2025 \u25cfMade measurements using LYSO scintillator crystals \u25cb2023 Rectilinear \u25a0Rectangle shaped segment, does not match our calorimeter geometry \u25cb2025 Tapered Array \u25a0\u201cSoccer ball\u201d segment shaped, true segment of our calorimeter geometry \u25cfProved tapered LYSO can be used for PIONEER\u2019s calorimeter by measuring: \u25cbEnergy resolution \u25cbTiming resolution \u25cbSpatial resolution g-2 DAQ modified - Usage for LYSO testbeam \u25cfIteration on previous LYSO test beam \u25cfRate limited by HDD write speed ~250 MB/s \u25cbFor small scale experiments, could be solved by writing directly to SSDs (>1GB/s write speed) \u25a0Limited by SSD space (\u22648TB for consumer electronics) \u25cfDesyncs between crate data caused (mostly) recoverable issues \u25cb ~2% of events across all data runs are desynced j.carlton@uky.edu 2/10 Two crate setup used at PSI LYSO Testbeam Run Crates Channels Used Event Rate (Hz) Data Rate (MB/s) 2023 PSI LYSO Test Beam 1 ~50 ~400 ~30 2025 PSI LYSO Test Beam 2 ~60 ~2500 ~200 g-2 DAQ modified - Desync Issues \u25cfDesync issues should be fixed \u25cbReplicated the issue on the UKy teststand \u25a0Caused by internal ring buffer overflows (\u201c GPU_BUFFER \u201d) \u25cbFixed software bug preventing trigger throttling from working properly \u25a0Trigger throttles apply back pressure to prevent ring buffer overflows \u25cfFor the testbeam we used a \u201cband-aid\u201d solution \u25cbEvent builder stops run on desync detected \u25cbRun is restarted immediately \u25cbGives the crates time to recover \u25cbDownsides: splits data runs, likely not scalable for many crates j.carlton@uky.edu 3/10 All desynced subruns in 2025 PSI LYSO Testbeam Study on desynced data \u25cfElog available \u25cfClock signal fanned out out into both crates \u25cfShowed the DAQ \u201crecovered\u201d from desyncs properly j.carlton@uky.edu x/14 Cross correlated of time offset between both crate clock signals Clock signal fanned out in both crates for synced event More on desyncs \u25cfDesyncs occurred in multiples of the GPU buffer size (512) \u25cfSaw periods of \u201cinstability\u201d and periods of recovery j.carlton@uky.edu x/14 Trigger index for each module across subruns Trigger index for each module across one subrun Energy Resolution Citation: Physics Reconstruction BVR Talk, Stefan Hochrein https://indico.psi.ch/event/18441/contributions/61422/attachments/3284 1/66376/Stefan_LYSO_Slides_final.pdf Timing Resolution Citation: Physics Reconstruction BVR Talk, Stefan Hochrein https://indico.psi.ch/event/18441/contributions/61422/attachments/3284 1/66376/Stefan_LYSO_Slides_final.pdf Timing Resolution Citation: Physics Reconstruction BVR Talk, Stefan Hochrein https://indico.psi.ch/event/18441/contributions/61422/attachments/3284 1/66376/Stefan_LYSO_Slides_final.pdf Position Resolution Citation: Physics Reconstruction BVR Talk, Stefan Hochrein https://indico.psi.ch/event/18441/contributions/61422/attachments/3284 1/66376/Stefan_LYSO_Slides_final.pdf 2023 PSI Test Beam j.carlton@uky.edu III. 2023 PSI Test Beam (Slide 14/37) Overview \u25cfPIONEER LYSO Calorimeter test \u25cbNovember 15 - 29, 2023 \u25cfMade measurements using LYSO scintillator crystals to determine if they are an adequate candidate for PIONEER\u2019s calorimeter \u25cbEnergy resolution \u25cbTiming resolution \u25cbSpatial resolution j.carlton@uky.edu III. 2023 PSI Test Beam (Slide 15/37) Contributions \u25cfRepurposing g-2 DAQ Software \u25cfFlexible Pipeline for Data Quality Monitor \u25cfBeamtime \u201cLive\u201d DAQ Maintenance \u25cfOnsite preliminary data analysis Examples of preliminary analysis work done at PSI j.carlton@uky.edu III. 2023 PSI Test Beam (Slide 16/37) Experiment Diagram - Conceptual Picture Last Quadrupole Magnet on beamline NaI (Leakage Detector) Photomultiplier Tubes (PMTS) NaI (Leakage Detector) Array of LYSO Crystals Data Acquisition System Beam Veto T0 XY Hodoscope Calorimeter on movable XY table j.carlton@uky.edu III. 2023 PSI Test Beam (Slide 17/37) Experiment Diagram - Labeled Picture A full view of the detector setup during the PSI test beam (a) and a close-up of the calorimeter front-face during laser alignment (b). Positrons from the last quadrupole magnet \u2460 pass through the VETO counter \u2461, T0 \u2462, and beam hodoscope \u2463 before depositing energy in the LYSO array \u2464. The LYSO crystals, along with the surrounding NaI detectors \u2465, are mounted on a movable XY table \u2466.Citation: Testing Lepton Flavor Universality and CKM Unitarity with Rare Pion Decays in the PIONEER experiment, PIONEER collab (pg. 20, arxiv: 2203.05505) j.carlton@uky.edu III. 2023 PSI Test Beam (Slide 18/37) Hodoscope \u25cf2 Layers of 12 scintillator strips \u25cbLayers offset by 90 degrees \u25cf1 mm x 1 mm \u201cpixels\u201d created by strip intersections \u25cbAllows for finer positioning data Citation: Measurements of a LYSO crystal array from threshold to 100 MeV, PIONEER collab (arxiv: 2409.14691) Upstream detector analysis, Stefan Hochrein, https://pioneer.npl.washington.edu/docdb/0002/000254/005/Upstream%20detectors.pdf 1 Hodoscope layer, 12 SiPMs connecting to 12 BC404 plastic scintillator 2mm wide bars Beam Profile: Red - positrons, Blue - muons j.carlton@uky.edu III. 2023 PSI Test Beam (Slide 19/37) LYSO Calorimeter \u25cfConstructed from an array of 10 LYSO crystals \u25cbNaI for leakage detection \u25cfX0 = 1.14 cm \u25cfRM= 2.07 cm Citation: Measurements of a LYSO crystal array from threshold to 100 MeV, PIONEER collab (arxiv: 2409.14691) Front-facing image of LYSO calorimeter j.carlton@uky.edu III. 2023 PSI Test Beam (Slide 20/37) Results - Energy Resolution \u25cfMeasured an energy resolution of \u0394E/E = 1.55 \u00b1 0.05% \u25cbPublished as 1.80, recently improved with better integration strategy \u25cb70 MeV \u2248 e energy in \u03c0 \u2192 e\u03bde \u25cfOver two times better than reported results for previous generation LYSO crystals \u25cfSimilar to liquid xenon energy resolution Citation: Measurements of a LYSO crystal array from threshold to 100 MeV, PIONEER collab (arxiv: 2409.14691) j.carlton@uky.edu III. 2023 PSI Test Beam (Slide 21/37) Energy Resolution Definition \u25cfEnergy resolution = \u0394E/E \u25cbE is the peak energy \u25cb\u0394E is the width of the peak \u25cfGaussian fit around the peak \u25cba \u201ccrystal ball\u201d fit is used here \u25cbGaussian around center, x-n on \u201csides\u201d where n is a parameter \u25cbGaussian parameter \u03c3 used for \u0394E \u25cfIn this case, p4 = E = 70.80 \u00b1 0.02 MeV \u25cfp3 = \u0394E = 1.098 \u00b1 0.014 MeV \u25cf\u0394E/E = 0.0155 = 1.55% j.carlton@uky.edu Citation: Omar Beesley, LYSO Updates/Answer https://pioneer.npl.washington.edu/docdb/0003/000312/001/LYSO%20Updates _Answers%20%28General%20Meeting%2010_22_24%29.pdf Timing Resolution Definition \u25cfUse the strongest signal in an event as reference signal. \u25cbt0 = time of peak \u25cfIn the same event find all crystal peaks ti \u25cbOnly use peaks above some energy threshold \u25cf\u0394t = t0 - ti \u25cbThe width of a gaussian fit to a histogram of all such measurements gives the timing resolution j.carlton@uky.edu Citation: Omar Beesley, LYSO Updates/Answer https://pioneer.npl.washington.edu/docdb/0003/000312/001/LYSO%20Updates _Answers%20%28General%20Meeting%2010_22_24%29.pdf Results - Timing Resolution \u25cfTiming resolution for 70 MeV events expected to be about 122.5 ps \u25cfThis measurement was largely influenced by noise from incorrect high voltage during test beam \u25cbUsing a system of synchronized LEDs, clean, simultaneous signals were generated at UW \u25cbImproved timing resolution to about 60 ps \u25cbAbout that same as LXe j.carlton@uky.edu Citation: Measurements of a LYSO crystal array from threshold to 100 MeV, PIONEER collab (arxiv: 2409.14691) Results - Energy Resolution \u25cfEnergy resolution is uniform near the center of the lyso array \u25cfTowards the edges the energy resolution decreases due to leakage \u25cbIn this case, into the NaI array j.carlton@uky.edu Citation: Measurements of a LYSO crystal array from threshold to 100 MeV, PIONEER collab (arxiv: 2409.14691) Vertical (y-axis) Horizontal (x-axis) Graduation Planned Timeline PIONEER Demonstrator (Now after planned defense date) \u25cf\u201cFull\u201d experiment demonstrator \u25cbPSI shutdown delayed, demonstrator moved back to take advantage \u25cfPrototypes for all detectors \u25cbSmall number of ATAR Layers (16 layers) \u25cbSmall spherical segment of tapered LYSO crystals (12 crystals) \u25cbSome spherical \u201cshell\u201d segment of tracker \u25cfDAQ handles event construction Tapered LYSO Array ATAR Layers Curved Tracker Section Beam Different Digitization Systems DAQ Computer(s) j.carlton@uky.edu V. Current and Future Work (Slide 37/37)",
    "textLength": 14641
  },
  {
    "kind": "presentation",
    "title": "DAQ Progress Report 12_17_2025_2025-12-16_18-48-34.pdf",
    "fileName": "DAQ Progress Report 12_17_2025_2025-12-16_18-48-34.pdf",
    "url": "resources/presentations/DAQ Progress Report 12_17_2025_2025-12-16_18-48-34.pdf",
    "createdDate": "2025-12-16",
    "text": "HDSoC and SAMPic Deadtime Studies Update Jack Carlton University of Kentucky HDSoC Deadtime (Methods) \u25cfUsed Raspberry Pi Pico W + NIM modules to generated configurable double pulse signal \u25cbLater extended this to 3 and 4 \u201cburst\u201d pulses \u25cfUsed HDSoC DAQ to observe event rate for varying parameters \u25cfSee spike corresponding to deadtime Example Double pulse on Oscilloscope Example Rate Response to Double Pulse Separation HDSoC Deadtime (Parameter Scan) \u25cfVary separation of pulses until each pulse is digitized \u25cbBinary search around expect event rate \u25cfWe tested the parameter space defined by \u25cbWindows = [1,2,4,8,16,32,61] \u25cbChannels = [1,2,4,8,16,32] \u25cbInput signal rate = [10 Hz, 100 Hz] \u25cbNumber of pulses = [2,3,4] \u25cfSpace defined as: \u25cbWindows \u2297 Channels \u2297 Input signal rate \u2297 Number of pulses \u25cfNotes: \u25cbSignals were fanned out to channels 0-15, no signals were in channels 16-31 Examples showing channels and windows affect on deadtime HDSoC Deadtime (Results) \u25cfDeadtime increases with \u25cb# of active channels \u25cb# of windows (# of samples, 1 window == 32 samples, this is nalu\u2019s terminology) \u25cfDeadtime unaffected by: \u25cbRate \u25a010Hz and 100Hz input signal curves overlap \u25cbInactive channels \u25a0Curve flattens when channels 16-31 (no input) are enabled in software \u25cfNotes: \u25cbJSON file of deadtime upper and lower bounds available \u25cbSystematically lower deadtime than reality \u25a0Need to re-run scans binary searching around expected data rate, not event rate HDSoC Deadtime (Results) \u25cfDeadtime unaffected by: \u25cbNumber of pulses (\u201ccongestion\u201d) \u25cfRepeated double pulse tests with 3 and 4 pulses \u25cbSeparation between pulses changed with binary search \u25cbNo meaningful change outside a few isolated bugs in the 4 pulse test SAMPic Deadtime (Methods) \u25cfUsed Lecroy 9210 Pulse Generator to create a configurable double pulse signal \u25cfUsed sampic_256ch_lib observe hit rate for varying parameters \u25cfSee spike corresponding to deadtime Example rate response to double pulse separation SAMPic Deadtime (Parameter Scan) \u25cfVary separation of pulses until each pulse is digitized \u25cbBinary search around expect hit rate \u25cfWe tested the parameter space defined by \u25cbSampic digitization rate = [1600, 2133, 3200, 4252, 6400] MHz \u25cbInput signal rate = [10, 100] Hz \u25cfSpace defined as: \u25cbInput signal rate \u2297 Sampic digitization rate \u25cfNotes: \u25cbFor this scan only one channel was connected to the Lecroy module Examples showing the effect of digitizer rate on deadtime SAMPic Deadtime (Results) \u25cfDeadtime unaffected by: \u25cbRate \u25a010Hz and 100Hz input signal curves overlap \u25cbDigitization Rate \u25a0No significant change in deadtime with digitization rate \u25cfNeed to do more scans to see how things scale with number of channels. For one channel, best estimate is ~2\u03bcs deadtime . Effect of digitization rate on measured deadtime. Lower bound based on maximum pulse separation where only one pulse was seen. TODO \u25cfRerun HDSoC deadtime scans with fixes \u25cbMake sure all 16 channels are getting signals \u25cbBinary search on data rate as opposed to event rate \u25cfRun the SAMPic deadtime scans with more parameter(s) \u25cbNumber of channels \u25cfRun more realistic deadtime scans with both systems \u25cbRight now all pulses are synchronized \u25cbSome configurable offset on pulses/groups of pulses between channels gives insight into channel level vs. chip level deadtimes Auxiliary Slides HDSoC Deadtime (Caveats) \u25cfMore plots are available in notebooks hosted on github \u25cbHDSoC \u25cbSAMPic \u25cfAll data is also hosted on github \u25cbCould pull repo, make sure you python environment has all dependencies and run interactive notebooks to explore data HDSoC Deadtime (Caveats) \u25cfProblems with the scans \u25cbSome channels inadvertently inactivate \u25a0Probably a faulty connection \u25cbBinary searches on event rate \u25a0Some events don\u2019t contain the full expected dataset \u25a0Need to binary search on data rate instead of event rate \u25cfWill re-run scans with these improvements \u25cbQuantitative results are likely in the correct \u201cballpack\u201d, just systematically underestimated \u25cbQualitative results are likely correct Channels not digitized, maybe bad connections(?) Some events missing majority of channel data HDSoC Deadtime (Caveats) \u25cfAs pulse separation increase, we begin to see data from the missing channels again HDSoC Deadtime (Caveats) \u25cfAs pulse separation increase, we begin to see data from the missing channels again \u25cbThis is a gradual effect Increasing separation between the two \u201cburst\u201d pulses Chanel occupancy plots. Organized by increasing double pulse separation. (windows = 2, enabled channels = 8, double pulse frequency = 10 Hz) HDSoC Deadtime (Caveats) \u25cfIssues using HDSoC DAQ collector for 4 pulse data \u25cfSee unexpected dips in some deadtime curves \u25cfSomehow the HDSoC DAQ collector is splitting events, causing more recorded events than actual \u25cfThis lowers the point where all 4 pulses are \u201cseen\u201d, causing deadtime to lower",
    "textLength": 739
  },
  {
    "kind": "presentation",
    "title": "DAQ Progress Report 09_26_2023_2023-09-26_19-59-55.pdf",
    "fileName": "DAQ Progress Report 09_26_2023_2023-09-26_19-59-55.pdf",
    "url": "resources/presentations/DAQ Progress Report 09_26_2023_2023-09-26_19-59-55.pdf",
    "createdDate": "2023-09-26",
    "text": "\u25cfInstallation script for RHEL7.9 machines finished \u25cbSmall adjustments to make it more robust \u25cfMidas bata bank parser finished \u25cbSmall adjustments to make it more robust \u25cfSean and I are beginning to work on \u201copposite ends\u201d of the DQM to meet in the middle \u25cbOne end: midas experiment \u2192 service api data requests \u25cbOther end: DQM histograms, oscilloscopes \u2190 make api data requests Current Progress Install.sh handling package installations with subscripts Development Steps (Rough Outline) Frontend code: \u25cfClean up DAQ for easier user control, package with modified midas, distribute Backend code: \u25cfCorrectly \u201cbin\u201d all header information, trailer information, ADC data, etc. \u25cfHistogram/data reconstruction (offline) \u25cfEstablish Data Quality Monitor (DQM) that links with midas experiment (online) Example crate contents configuration file",
    "textLength": 120
  },
  {
    "kind": "presentation",
    "title": "DAQ Progress Report 05_21_2024_2024-05-21_04-35-34.pdf",
    "fileName": "DAQ Progress Report 05_21_2024_2024-05-21_04-35-34.pdf",
    "url": "resources/presentations/DAQ Progress Report 05_21_2024_2024-05-21_04-35-34.pdf",
    "createdDate": "2024-05-21",
    "text": "g-2 Modified DAQ Development Progress \u25cfAdded second crate to UKY test stand \u25cfDebugged testbeam frontend software to handle multiple crates \u25cfCan generate midas files with events built from multiple crates UKY test stand MicroTCA crates Additional Debugging \u25cf\u201cCCC: Run abort\u201d alarm shortening runs \u25cbFC7/WFD5 \u201cperformance\u201d evaluation runs(?) \u25cfSean analyzed test beam and UKY teststand performance data. \u25cbBottlenecks are due to rare, long pauses between events \u25cbYet to determine exact reason for pauses Midas Experiment running at 2kHz with multiple crates g-2 Modified DAQ Development Outline \u25cfEstablish communication with all crate modules \u25cfFinish hardware assembly \u25cfGet frontend code and monitoring software running \u25cfAdd second crate to teststand \u25cfDebug (increase) rate capabilities by optimizing frontend code \u25cfReplace meinberg GPS trigger with parallel port triggers \u25cfWrite user manual for this DAQ Crate(s) of FC7s and WFDs ...Array of FEs, BE, Midas server ... Rest of Experiment Simplified DAQ Diagram",
    "textLength": 149
  },
  {
    "kind": "presentation",
    "title": "Simulation Progress Report 2_12_2025_2025-02-12_18-41-55.pdf",
    "fileName": "Simulation Progress Report 2_12_2025_2025-02-12_18-41-55.pdf",
    "url": "resources/presentations/Simulation Progress Report 2_12_2025_2025-02-12_18-41-55.pdf",
    "createdDate": "2025-02-12",
    "text": "Pattern Finding Update Jack Carlton University of Kentucky Pattern Finding performance by Particles in ATAR \u25cfFirst order failure modes are: \u25cbEvents with an electron \u25cbLarge spatial \u201cjumps\u201d in tracklets(?) \u25cfNo event mixing \u25cbTODO: test performance on mixed event \u25cfIdea to solve electron events: \u25cbNeed pattern finder to look for particles branching off middle of tracklets (not just ends) \u25cfIdea to solve spatial jumps: \u25cbUse timing information to try to group muon hits, not just spatial data \u25a0Could be problematic for mixed events? Example Failure: Electron Event T ruth: Reco: Example Failure: Large spatial Jumps T ruth: Reco: Backups Pienu decays Pattern finding on electron events",
    "textLength": 105
  },
  {
    "kind": "presentation",
    "title": "DAQ Progress Report 10_10_2023_2023-10-10_20-02-15.pdf",
    "fileName": "DAQ Progress Report 10_10_2023_2023-10-10_20-02-15.pdf",
    "url": "resources/presentations/DAQ Progress Report 10_10_2023_2023-10-10_20-02-15.pdf",
    "createdDate": "2023-10-10",
    "text": "\u25cfCreated an \u201cmidas event listener\u201d, linked with Sean\u2019s unpacking code \u25cbNeed to \u201clink\u201d this with Josh\u2019s webpage \u25cfWorking on sorting out some software issues on UW machine \u25cbPython boost issues \u25cbMhttpd issues \u25cfWorking on updating installer to include data simulator and unpacking libraries Current Progress Development Steps (Rough Outline) Frontend code: \u25cfClean up DAQ for easier user control, package with modified midas, distribute Backend code: \u25cfCorrectly \u201cbin\u201d all header information, trailer information, ADC data, etc. \u25cfHistogram/data reconstruction (offline) \u25cfEstablish Data Quality Monitor (DQM) that links with midas experiment (online) Example crate contents configuration file",
    "textLength": 97
  },
  {
    "kind": "presentation",
    "title": "PIONEER DAQ Collaboration Meeting June 2024_2024-06-10_01-27-29.pdf",
    "fileName": "PIONEER DAQ Collaboration Meeting June 2024_2024-06-10_01-27-29.pdf",
    "url": "resources/presentations/PIONEER DAQ Collaboration Meeting June 2024_2024-06-10_01-27-29.pdf",
    "createdDate": "2024-06-10",
    "text": "PIONEER DAQ Jack Carlton University of Kentucky June 19th, 2024 Hardware vs. Software Side \u25cfUsually \u201cDAQ\u201d refers to the \u201csoftware side\u201d (i.e. MIDAS and related tools) \u25cbLoosely used for hardware (electronics) side as well \u25cfI like to differentiate between the software and hardware sides Digitizers & trigger processors ...Array of readout computers, Midas server ... Detectors Hardware/ Electronics Side Software Side j.carlton@uky.edu 1/13 Proposed Data Acquisition (DAQ) Framework arXiv:2203.05505 Citation: Testing Lepton Flavor Universality and CKM Unitarity with Rare Pion Decays in the PIONEER experiment, PIONEER collab (pg. 20, arxiv: 2203.05505) Hardware Side SW Side j.carlton@uky.edu 2/13 Proposed Data Acquisition (DAQ) Framework arXiv:2203.05505 Citation: Testing Lepton Flavor Universality and CKM Unitarity with Rare Pion Decays in the PIONEER experiment, PIONEER collab (pg. 21) Software Side Receive Data over PCIe Build events in Midas j.carlton@uky.edu 3/13 Data Rates arXiv:2203.01981 \u25cfPIONEER DAQ expects data rate of ~ 3.5GB/s \u25cfThis is ~ 100,000 TB/year \u25cfHow do we compress this in real time? \u25cbFit data, store fit parameters \u25cbCompress and store residuals, throw some out \u25cbGraphics Processing Units (GPUs) used for this operation Citation: PSI Ring Cyclotron Proposal R-22-01.1 PIONEER: Studies of Rare Pion Decays, PIONEER collab (pg. 33) j.carlton@uky.edu 4/13 Template Fitting \u25cfCan construct a continuous template for our traces \u25cfCan fit traces using template: \u25cfStoring unfit traces takes ~12 bits per ADC sample \u25cfStoring residuals takes ~4 bits per ADC sample \u25cfBy fitting, we can compress the data by a factor of ~3 ADC value Residual value Time [c.t] Time [c.t] PSI Example LYSO Signal with Fit Signal - Fit Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) j.carlton@uky.edu 5/13 Range = ~16 = 4 bits Template Fitting \u25cfData from PSI test beam \u25cfEach vertical slice corresponds to pdf \u25cfTemplate fit drastically reduces spread of data Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) Template fitting time [c.t.] Time [c.t] Probability Probability ADC value ADC value j.carlton@uky.edu 6/13 Theoretical Best Compression \u25cfFor lossless compression, the best possible compression rate is the entropy rate \u25cfEntropy rate of pedestal part of signal is 3.4 bits per ADC sample \u25cbA perfect fit would reduce signal to pedestal noise \u25cfBest possible data storage rate 3.5 GB/s \u2192 ~1 GB/s \u25cbAssumes similar noise to PSI test beam data \u25cfRealistically the data storage rate depends how good our fit is \u25cbAssuming entropy rate of ~5 bits/sample 3.5 GB/s \u2192 ~1.5 GB/s Time [c.t] Entropy/sample [bits] Entropy Rate Formula Entropy Rate of PSI Test Beam Data After Fitting Signal entropy Pedestal entropy Pedestal entropy j.carlton@uky.edu 7/13 Real Time Compression Algorithm \u25cfWe choose to let the FE\u2019s GPU and CPU handle compression for flexibility CPU GPU Copy initial guess, Y(t0) Allocate memory for X,Y(t0),t0*,t,r,r\u2019c timeCompute initial guess fit Y(t0)Initialization (one time) Data loop (many times) Copy many traces, X (Overwrite) Wait for enough traces\u2026 Launch 1 thread per trace Compute t0*, via \u03c72 minimization, r = X-Y(t0*)Copy r\u2019c, t0*Use header info from r\u2019c to allocate memory for rcAllocate memory for X,Y,t,r\u2019c Golomb encode r \u2192 r\u2019cStitch together rc from r\u2019c Store rc, t0*j.carlton@uky.edu 8/13 GPU Benchmarking (Timings) \u25cfBlock Size: \u25cbA GPU parameter, number of threads per multiprocessor \u25cfCan compress 226 integers (32-bit) in roughly \u2153 of a second. \u2192 ~ 0.8 GB/s compression rate Time [s] # of 32-bit Integers Fit + Compression Time using A5000 in PCIe4 (Batch Size = 1024) j.carlton@uky.edu 9/13 PCIe DMA Data Transfer \u25cfTesting using a PCIe development board \u25cbTested on PCIe2 x4 \u25cfUsing Vivado IP blocks, we can create PCIe DMA design Example block diagram (made in Vivado) for a PCIe FPGA Nereid K7 PCI Express FPGA Development Board j.carlton@uky.edu 10/13 PCIe DMA Data Transfer \u25cfSpeeds here are limited by the board\u2019s transfer rate \u25cbBoard can only handle 5GT/s (PCIe gen 2) \u25cbExpect faster for other boards \u25cfTransfer rate ~1GB/s in ballpark of PIONEER rate (3.5 GB/s) \u25cfBetter to transfer in large packets Average Transfer Rate [MB/s] Transfer Size Transfer Speed Vs. Transfer Size j.carlton@uky.edu 11/13 Software Development \u25cfDeveloped modular software working around midas \u25cbUseful for Calo test beam DAQ \u25cbDetached from Calo test beam DAQ, can be used with PIONEER DAQ \u25cfExamples: \u25cbMidas Event Unpacker \u25cbMidas Event Publisher \u25cbGeneralized DQM \u25cbComputer System Monitor Generalized DQM Webpage j.carlton@uky.edu 12/13 Other Libraries Software Development Plan Compression Library \u25cfContinue writing modular software \u25cbWill make experiment DAQ code much more manageable in the future \u25cfWrite PCIe readout libraries usable for PIONEER \u25cfWrite compression libraries usable for PIONEER \u25cfWrite midas frontend to read data out of FPGA over PCIe \u25cbRate test, compression test MIDAS Readout Library Frontend 1 Frontend 2 \u2026 Frontend 3 \u2026j.carlton@uky.edu 13/13 Auxiliary Slides Data Set Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) \u25cfPSI Test beam, Run 1887 \u25cf70 MeV/c centered on LYSO crystal 4. \u25cfThe data only includes lyso channels (no NaI for instance) \u25cf More details on that run are in this elog (https://maxwell.npl.washington.edu/ elog/pienuxe/R23/124 )0 1 2 3 4 5 9 86 7 Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) Entropy and Lossless Compression \u25cfFor lossless compression, the best possible compression rate is the entropy rate \u25cfTo first order, the entropy of an entire trace is: \u25cf is the random variable for the ADC value of the ith sample in the trace with n samples \u25cfIf we assume independent, then \u25cfBy transforming ( \u2192 fit residuals), becomes approximately independent Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) Higher Order Entropy Estimations \u25cfAssume we have N characters (traces) in our alphabet (data set) \u25cfZero order: each character in alphabet is statistically independent \u25cfFirst order: each character in alphabet is statistically independent, pi is the probability of that character to occur \u25cfSecond order: Pj|i is correlation between subsequent characters \u25cfGeneral Model (impractical): Bn represents the first n characters Citation: Coding and Information Theory Class Notes, Dr. Jay Weitzen, University of Massachusetts Lowell https://faculty.uml.edu/jweitzen/16.548/classnotes/Theory%20of%20Data%20Compression.htm#:~:text=When%20the%20 compression%20is%20lossless,rate%20is%20the%20entropy%20rate Joint Entropy, Mutual Information Equality only holds if This means if Then we must have and be statistically independent Citation: Joint Entropy, Wikipedia https://en.wikipedia.org/wiki/Joint_entropy Joint entropy for Independent Variables Proof Statement: Proof (part 1): (Note: I am lazy, each P(xi) represents a different pdf in general) Citation: Proof from stackexchange https://math.stackexchange.com/questions/3519345/joint-entropy-of-2-independent-random-variables Joint entropy for Independent Variables Proof Proof (part 2): Citation: Proof from stackexchange https://math.stackexchange.com/questions/3519345/joint-entropy-of-2-independent-random-variables Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) Mutual Information Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) \u25cfMutual Information: \u25cf no correlation \u25cfTemplate fitting reduces correlations between subsequent samples Sample # Sample # Sample # Sample # Mutual Info Mutual Info Template fitting Entropy Estimation Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) \u25cfAverage entropy: \u25cfIn this case N = 800 \u25cfBefore: Havg = 5.22 bits/sample \u25cfAfter: Havg = 3.55 bits/sample \u25cfSome room for improvement(?) Time [c.t] Time [c.t] Template fitting Entropy/sample [bits] Entropy/sample [bits] Explanation of Entropy Plot \u25cfThe pedestal is easy to fit, so the variance of the pedestal part of the signal is is just the noise of the WFD5s. \u25cbThis is the minimum possible entropy when using this equipment \u25cfThe signal is harder to fit and therefore has more variance \u25cbEntropy of this part of the trace is therefore larger Time [c.t] Entropy/sample [bits] Entropy Rate of PSI Test Beam Data After Fitting Signal entropy Pedestal entropy Pedestal entropy Theoretical Best Compression Calculation Assuming data is sent as 12 bit ADC samples over PCIe at a data rate of 3.5 GB/s: Entropy rate = 3.4 \u2192 New Data Rate \u2248 0.99 GB/s Entropy rate = 5 \u2192 New Data Rate \u2248 1.46 GB/s Signal Conditioning \u25cfWant a narrow distribution for compression. Let ri be the numbers we compress \u25cfMethods tried: \u25cbNo conditioning \u25cbDelta encoding: ri = yi+1-yi \u25cbTwice Delta Encoding: ri = yi+2-2yi+1+yi \u25cbDouble Exponential Fit: ri= yi - (A \u22c5exp(ati)+ B \u22c5exp(bti)) \u25cbShape Fit : ri =yi- (A \u22c5T(ti-t0) + B) No Conditioning Shape Fit Frequency Frequency Voltage [Arbitrary Units] Voltage [Arbitrary Units] Shape Fitting Algorithm 1.Construct a discrete template from sample pulses 2.Interpolate template to form a continuous Template, T(t) 3.\u201cStretch\u201d and \u201cshift\u201d template to match signal: [Note: a and b can be calculated explicitly given t0] 4.Compute \u03c72 (assuming equal uncertainty on each channel i) 5.Use Euler\u2019s method to minimize \u03c72 Lossless Compression Algorithm \u25cfRice-Golomb Encoding \u25cbLet x be number to encode y = \u201cs\u201d+\u201cq\u201d+\u201dr\u201d \u25a0q = x/M (unary) \u25a0r = x%M (binary) \u25a0s = sign(x) \u25cbAny distribution \u25cbClose to optimal for valid choice of M \u25cbOne extra bit to encode negative sign \u25cbSelf-delimiting \u25cbIf quotient too large, we \u201cgive up\u201d and write x in binary with a \u201cgive up\u201d signal in front Value Encoding -1 011 0 000 1 001 2 1000Rice-Golomb Encoding (M=2) Red = sign bit Blue = quotient bit(s) (Unary) Yellow = remainder bit (binary) How to choose Rice-Golomb parameter M \u25cfGenerated fake Gaussian data (centered at zero) with variance \u03c32 \u25cfFor random variable X, M \u2248 median(|X|)/2 is a good choice \u25cbThis is the close to the diagonal on the plot \u25cf\u03c3 \u2248 32 for residuals of shape on wavedream data \u2192 M = 16 is a good choice Gaussian Noise \u03c3 MCompression Ratio Determining Optimal M waveDREAM test Compression Ratio from Rice-Golomb Encoding \u25cfLossless compression factor of ~2 \u25cfIn agreement with plot from simulated data on last slide \u25cfData is much noisier than than PSI test beam, so we get a smaller compression factor Rice-Golomb Compression on Residuals (M = 16) Compression Ratio Sample Index Other Conditioning Distributions Delta Encoding Twice Delta Encoding Double Exponential Fit Shape Fitting Details Fit Function Explicit a(t0) calc Explicit b(t0) calc Explicit \u03c72 calc Newton\u2019s method Threshold requirement Golomb Encoding \u25cfIn general, M is an arbitrary choice \u25cfSince computers work with binary, M = 2x such that x is an integer is a \u201cfast\u201d choice \u25cbThis is called Rice-Golomb Encoding \u25cfSelf delimiting so long as the information M is provided Encoding of quotient part q output bits 00 110 2110 31110 411110 5111110 61111110 \u22ee \u22ee N111 \u22ef1110Golomb Encoding Example Encoding of remainder part r offset binary output bits 00 0000 000 11 0001 001 22 0010 010 33 0011 011 44 0100 100 55 0101 101 612 1100 1100 713 1101 1101 814 11101110 915 11111111Choose M = 10, b = log2(M) = 3 2b+1 - M = 16 - 10 = 6 r < 6 \u2192 r encoded in b=3 bits r \u2265 6 \u2192 r encoded in b+1=4 bits Citation: Wikipedia (https://en.wikipedia.org/wiki/Golomb_coding) Huffman Encoding \u25cfRequires finite distribution \u25cfValues treated as \u201csymbols\u201d \u25cfSelf-delimiting (sometimes called \u201cgreedy\u201d) Value Frequency Encoding -1 \u2261 a 1 000 0 \u2261 b 10 1 1 \u2261 c 5 01 2 \u2261 d 3 001Huffman Encoding Example db ac10 10 10 d a1 0b c \u2026\u201cCombine\u201d two lowest frequencies into tree, Frequency z = 1+3 = 4 zRepeat for set {z,c,b} d ac0 101y bCitation: Wikipedia (https://en.wikipedia.org/wiki/Huffman_coding) Theoretical Uncertainty in Compression Ratio from Gaussian Noise \u25cf~ 0.1% relative error Uniform Distribution of Noise effect on Compression Ratio \u25cfHere instead we use a uniform distribution to generate the noise \u25cfNot much different than gaussian noise, same conclusions really Residuals Distribution and Optimal M M Compression Ratio 1 1.04721105 2 1.21287474 4 1.53114598 8 1.92616642 16 2.09307249 32 2.02975311 64 1.86037914 128 1.66627451 ... ... PCIe DMA Block Diagram in Vivado Example block diagram (made in Vivado) for a PCIe FPGA PCIe Transfer Speeds for Different Generations Nereid Test Citation: https://www.bostonindia.in/blog/2021/09/29/how-pci-express-can-work-for-you.aspx",
    "textLength": 2205
  },
  {
    "kind": "presentation",
    "title": "DAQ Progress Report 01_11_2026_2026-01-12_00-51-47.pdf",
    "fileName": "DAQ Progress Report 01_11_2026_2026-01-12_00-51-47.pdf",
    "url": "resources/presentations/DAQ Progress Report 01_11_2026_2026-01-12_00-51-47.pdf",
    "createdDate": "2026-01-12",
    "text": "DAQ Updates for BVR Jack Carlton University of Kentucky DMA over PCIe Prototype DAQ \u25cfUKy teststand using Nereid development board \u25cbKintex-7 FPGA \u25cbPCIe data transfer \u25cbOnboard RAM for buffering \u25cfFirmware for pcie readout using Xilinx DMA/Bridge Subsystem for PCIe Block \u25cbDevice control via Xilinx DMA driver for linux kernels \u25cfMIDAS frontend for simple event construction \u25cbUses custom C++ library for simple read/write operations Nereid K7 PCI Express FPGA development board Simplified block diagram for DMA transfer of data in the onboard RAM over PCIe Calorimeter Prototyping DAQ \u25cfUses the same hardware as the g-2 experiment \u25cb10 GbE based readout system \u25cb800 MSPS Cornell digitizers \u25cfModified g-2 MIDAS readout software for broader test-stand use \u25cbLYSO calorimeter test stands \u25a0Used at PSI in November 2023 rectilinear LYSO crystal array test beam \u25a0Used at PSI in August 2025 tapered LYSO crystal array test beam \u25cbLXe calorimeter test stands Two crate setup used at 2025 PSI LYSO testbeam Readout Systems for ATAR DAQ Candidates \u25cfSAMPic \u25cb1 GbE based readout system \u25cbMIDAS frontend handles configuration and readout, built on existing SAMPic-256ch C library \u25cb256 channel digitizer crate teststand in LPNHE, Paris \u25cfHDSoC \u25cb1 GbE based readout system \u25cbMIDAS frontend handles configuration and readout built on existing naludaq python library \u25cb32 channel HDSoC digitizer board in UKy \u25cfComparative studies of rate, triggering, and deadtime performance are currently underway Nalu Scientific\u2019s HDSoC FMC attached to a Nexys A7 video card SAMPic teststand with remote access capabilities Supplementary Software \u25cfZeroMQ based event publisher application \u25cbPulls live MIDAS events, processes them, and publishes to downstream clients \u25cfMidas event unpackers \u25cbConvert MIDAS banks into structured ROOT data products \u25cfData quality monitor webapp \u25cbReact-based, plugin-driven system for registering and displaying arbitrary figures \u25cfThese softwares are designed to be modular and flexible to support diverse PIONEER test-stand configurations Example webpage view formed by an event publisher client Auxiliary Slides HDSoC Deadtime Scan (Results) Parameter Space (793 combinations): Channels = [1,2,...,13] Windows = [1,2,3,...61] Parameter Space (91 combinations): Channels = [1,2,...,13] Windows = [1,2,4,8,16,32,61] SAMPiC Deadtime Scan (Results) Parameter Space (330 combinations): Channels = [1,2,...,13,14,15] Amplitude = [3.0,3.2, \u2026 5.0] Auto_conversion = [False, True] \u25cfSome runs failed (likely a communication error), the scan was programmed to move on in this case \u25cfThere\u2019s some scaling between Lecroy input voltage and SAMPic read voltage (ex. 5V lecroy input digitizes as ~0.5V pulse on SAMPic)",
    "textLength": 415
  },
  {
    "kind": "presentation",
    "title": "DAQ Presentation Collaboration Meeting January 2025_2024-12-25_10-19-40.pdf",
    "fileName": "DAQ Presentation Collaboration Meeting January 2025_2024-12-25_10-19-40.pdf",
    "url": "resources/presentations/DAQ Presentation Collaboration Meeting January 2025_2024-12-25_10-19-40.pdf",
    "createdDate": "2024-12-25",
    "text": "PIONEER DAQ Development Jack Carlton University of Kentucky January 7th, 2025 j.carlton@uky.edu 1/14 The Four DAQs in this Talk 1.g-2 modified (Calo Teststand) DAQ \u25cbUses g-2 hardware \u25cbUsed for calorimeters tests 2.HDSoC (Nalu) DAQ \u25cbUses Nalu Scientific\u2019s HDSoC FMC board \u25cbUsed for ATAR digitization 3.PCIe based (PIONEER) DAQ \u25cbWill use Cornell designed hardware \u25cbUKY testing with development FPGA boards \u25cbWill be used for PIONEER DAQ 4.Belle II PCIe Based DAQ \u25cbUses PCIe readout of FPGA boards \u25cbUsed in Belle II experiment \u25cbUseful design to piggyback off of for PIONEER j.carlton@uky.edu 2/14 Some hardware from each DAQ system mentioned Top left: g-2 modified electronics crate Top right: Nalu\u2019s HDSoC FMC on Nexys A7 Bottom left: PCIe based test board Bottom right: PCIe40 board g-2 modified (Calo Teststand) DAQ - Updates \u25cfUpdated operating system for the project to ALMA9 \u25cbCentOS7 reached EOL \u25cfAdded features \u25cbMultiple crates \u25cbWFD5 self triggering mode \u25cbLaser study parameters added to ODB \u25cfImproved rate capabilities \u25cbRemoved meinberg dependency \u25cbTested ~10kHz at UKY \u25cfSome quality of life scripts added \u25cfUpdated midas to a 2024 build j.carlton@uky.edu 3/14 \u03bcTCA crate with WFD5s, AMC13, FC7, and MCH g-2 modified (Calo Teststand) DAQ - Documentation \u25cfSetup of the teststand DAQ is not straightforward \u25cbCustom software and hardware \u25cbSpecific software and hardware configurations \u25cfCreated documentation to aid setup and configuration \u25cbWebsite version on github pages \u25cbIncludes explanation of relevant ODB parameters \u25cbLiving document (easy to update) A page from the manual webpage j.carlton@uky.edu 4/14 g-2 modified (Calo Teststand) DAQ - Software Add-ons \u25cfStatus webpage \u25cbTiming monitoring \u25cbData quality Monitoring \u25cbCrate content status page revived (separate webpage) \u25cfMore event level info \u25cbSystem resource monitoring \u25cfTo do \u25cbOptimize Event Publisher \u25a0Integrate my midas_receiver library , created as per a suggestion on the midas forums \u201cGeneralized\u201d Teststand DAQ DQM Webpage j.carlton@uky.edu 5/14 Integrating HDSoC into Midas (naludaq) - Current Status \u25cfCan control board via midas \u25cbInitialize board \u25cbConfigure (external) trigger and channel settings \u25cbBegin and end collections \u25cfReadout is currently unprocessed UDP packets over 1GbE j.carlton@uky.edu 6/14 Nalu\u2019s HDSoC FMC attached to a Nexys A7 Video Card Integrating HDSoC into Midas (naludaq) - Rates \u25cfHighest data rate achieved is ~55 MB/s through 32 channels at ~20kHz trigger rate \u25cbSlower in practice, no event building yet \u25cfData rate dependencies \u25cbTrigger rate \u25cbNumber of channels \u25cb\u201cIsland\u201d size \u25a0Affects max data rate j.carlton@uky.edu 7/14 Measured Trigger Rate vs. MIDAS Data Rate Measured Trigger Rate (Hz) MIDAS data rate (MB/s) Integrating HDSoC into Midas (naludaq) - Next Steps \u25cfIncorporate features from NaluScope into Midas: \u25cbConstruct events from UDP data \u25cbConfiguring internal trigger settings \u25cbThreshold scan \u25cbPedestal scan and subtraction \u25cfMarcus Luck (Nalu Software Head) has been helping j.carlton@uky.edu 8/14 Example Threshold Scan Trigger Threshold Trigger counts during scan PCIe based (PIONEER) DAQ - Status \u25cfUsing Nereid Development board \u25cbKintex-7 FPGA \u25cbMax throughput 2 GB/s over PCIe \u25cfFirmware using Xilinx intellectual property (IP) blocks in Vivado \u25cbCreates DMA link between onboard RAM and host (desktop) RAM \u25cfHave C++ library for readout \u25cbEffectively a wrapper around Xilinx XDMA driver \u25cfIntegrated C++ library in a midas frontend for rate testing j.carlton@uky.edu 9/14 Nereid K7 PCI Express FPGA Development Board Block diagram for DMA transfer between board RAM and host (desktop) RAM PCIe based (PIONEER) DAQ - Rates \u25cfMore interested in read/Card-to-host (c2h) transfer rates \u25cfTransfer rates are faster for larger data transfer sizes \u25cfHighest throughput in MIDAS was ~1.2 GB/s \u25cbUsing two c2h channels \u25cf1.2 GB/s is largely limited by nereid board hardware DMA transfer rate vs transfer size over one channel using custom C++ Library Transfer Size Average Transfer Rate [MB/s] Transfer Speed Vs. Transfer Size j.carlton@uky.edu 10/14 PCIe based (PIONEER) DAQ - Next Steps j.carlton@uky.edu 11/14 \u25cfAdded MicroBlaze IP Block \u25cfAllows the FPGA to run C++ code to edit onboard DDR3 RAM \u25cbCan code data generation simulators \u25cfWant to use this to better simulate experiment Block diagram for PCIe DMA transfer with microblaze Belle II PCIe Based DAQ - Overview \u25cfBelle II is an experiment studying B mesons at SuperKEKB in Japan \u25cbSimilar data rate needs to PIONEER \u25cbRecently (~2020) upgraded their DAQ system to be PCIe based \u25cfPCIe based upgrade involved a \u201cPCIe40\u201d FPGA board \u25cbSimilar to UKY test FPGA boards like numato\u2019s nereid development board j.carlton@uky.edu 12/14 Photo and block diagram of the PCIe40 board Citation:PCI-express based high-speed readout for the Belle II DAQ upgrade (https://arxiv.org/pdf/2010.15115) Belle II PCIe Based DAQ - Readout \u25cfBelle II design uses DMA engine to move data out of RAM buffers \u25cbUse PCIe Hard IP (Intel) \u25cbUse custom written drivers \u25cfDoing very similar at UKY \u25cbXilinx PCIe DMA engine facilitates data transfer between card and host \u25cbUsing XIlinx XDMA driver j.carlton@uky.edu 13/14 UKY block diagram for PCIe based DMA is similar to the Belle II PCIe readout system \u2248Citation:PCI-express based high-speed readout for the Belle II DAQ upgrade (https://arxiv.org/pdf/2010.15115) Belle II PCIe Based DAQ - Control and Event Processing \u25cfFPGA handles event building from multiple sources (links) \u25cbEvents constructed before PCIe transfer \u25cfTheir \u201cQsys Generated Endpoint\u201d is similar to the Xilinx IP blocks in the last slide \u25cfAllows user control of low level components via DMA transfer over PCIe j.carlton@uky.edu 14/14Citation:PCI-express based high-speed readout for the Belle II DAQ upgrade (https://arxiv.org/pdf/2010.15115) Auxiliary Slides Software Philosophy \u25cfWrite modular software \u25cbWill make experiment DAQ code much more manageable in the future \u25cfOptimize and adjust readout, compression, and other libraries (as needed) \u25cfWrite simple and scalable midas frontends \u25cbImplement libraries above Other Libraries Compression Library MIDAS Readout Library Frontend 1 Frontend 2 \u2026 Frontend 3 \u2026 Dependency Diagram j.carlton@uky.edu Older (2017) Xilinx XDMA Driver Gives Better Results \u25cfTransfer rates using block ram in a computer with an older OS (CentOS7) \u25cfXDMA driver by Xilinx changes with kernel version \u25cbDriver version causing performance difference \u25cfCan make slight edits to old driver to see compile on ALMA9 and see performance gains j.carlton@uky.edu Average Transfer Rate [MB/s] Transfer Size Transfer Speed Vs. Transfer Size DMA transfer rate vs transfer size over one channel using Xilinx XDMA tools on CentOS 7 Best Guesses for Plot Shape \u25cfRates tests are often \u201cbumpy\u201d \u25cfTiming results at the KB scale are \u201cbumpy\u201d \u25cbMay have to do with system resource management (How data transfers are optimized to DDR3 RAM(?)) \u25cbCould also be due to PCIe bus congestions DMA transfer rate vs transfer size over one channel using custom C++ Library Transfer Size Average Transfer Rate [MB/s] Transfer Speed Vs. Transfer Size j.carlton@uky.edu Xilinx XDMA Driver Issues \u25cfOn CentOS7 and ALMA9 different versions of Xilinx XDMA drivers are used \u25cbNewer tests were done on ALMA9 using a newer version \u25cfPerformance was evidently affected \u25cbUnsure on the exact reason \u25cfProblem can be remedied by using old driver (from 2017) j.carlton@uky.edu Plots to the right \u2192 DMA transfer rate vs transfer size over one channel Top: ALMA9 (newer driver) Bottom: CentOS7 (older driver) Differences Between C++ Library and Xilinx XDMA Tools \u25cfFor these plots Xilinx XDMA tools are artificially inflated by 220/106 ~ 1.05 \u25cbRate calculated differently for each program \u25cfXilinx XDMA Tools beforms \u201cbetter\u201d \u25cbHas the more \u201cexpected\u201d leveling off shape \u25cbAlso reports faster read speeds \u25cfUnsure what\u2019s causing the discrepency \u25cbBoth pieces of software interface with the boards very similarly j.carlton@uky.edu DMA transfer rate vs transfer size over one channel. Two datasets for each \u201cmethod\u201d (Custom C++ library vs Xilinx XDMA tools) Motivation for PCIe Based Readout \u25cfUsing APOLLO system (no more \u00b5TCA crates) \u25cfData received by desktop through Firefly PCIe cards \u25cbAn optical link to communicate with FPGA Firefly PCIe board Citation: DAQ backbone exploration, Lawrence Gibbons https://pioneer.npl.washington.edu/docdb/0000/000023/001/apollo.pdf j.carlton@uky.edu Belle II DAQ control signal flow j.carlton@uky.edu = Path to write to user logic controller Citation:PCI-express based high-speed readout for the Belle II DAQ upgrade (https://arxiv.org/pdf/2010.15115) How Belle II Data Flow Works \u25cfData Collection \u25cbEach Belle2link receives raw data from a sub-detector and buffers it into a FIFO memory \u25cfEvent Building \u25cbThe firmware merges fragments from 48 links into a single event, formats it, and stores it in a DMA FIFO (32 kB) \u25cfDMA Transfer \u25cbData are transferred from the FPGA's memory to the PC\u2019s memory using PCIe DMA om 8kB pages \u25cfPC Processing \u25cbData are received in 1 MB super pages in a large buffer on the PC = Have similar system working at UKY test stand = Do not have similar system working at UKY test stand j.carlton@uky.edu Citation:PCI-express based high-speed readout for the Belle II DAQ upgrade (https://arxiv.org/pdf/2010.15115) What is a PLL? (Phase Locked Loop) \u25cfA phase lock loop (PLL) is a control system that generates an output signal whose phase is fixed relative to the phase of an input signal Citation: https://en.wikipedia.org/wiki/Phase-locked_loop https://www.analog.com/en/resources/analog-dialogue/articles/phase-locked-loop-pll-fundamentals.html j.carlton@uky.edu",
    "textLength": 1590
  },
  {
    "kind": "presentation",
    "title": "DAQ Presentation Collaboration Meeting 2023_2023-10-15_20-04-12.pdf",
    "fileName": "DAQ Presentation Collaboration Meeting 2023_2023-10-15_20-04-12.pdf",
    "url": "resources/presentations/DAQ Presentation Collaboration Meeting 2023_2023-10-15_20-04-12.pdf",
    "createdDate": "2023-10-15",
    "text": "Data Acquisition (DAQ) Jack Carlton University of Kentucky Jack Carlton - University of Kentucky - j.carlton@uky.edu 0/8 g-2 DAQ (Modified for One Crate Support) Crate(s) of FC7s and WFDs ...Array of FEs, BE, Midas server ... Rest of Experiment \u25cfRetains g-2 hardware, but made more flexible \u25cfSame general process: \u25cbCommunicate with \u00b5TCA crate, initialize hardware \u25cbRead TCP packets from \u00b5TCA crate \u25cbWrite to midas data banks Jack Carlton - University of Kentucky - j.carlton@uky.edu 1/8 Midas Framework \u25cfC/C++ (mostly) package of modules for \u25cbrun control, \u25cbexpt. configuration \u25cbdata readout \u25cbevent building \u25cbdata storage \u25cbslow control \u25cbalarm systems \u25cbEtc. \u25cfCan link with custom software Jack Carlton - University of Kentucky - j.carlton@uky.edu 2/8 Hardware Requirements \u25cfMicro Telecom Computing (\u00b5TCA) crate with Modules: \u25cbWaveform Digitizers (WFD5(s)/Rider(s)) \u25cbController (FC7) \u25cbMicroTCA Carrier Hub (MCH) \u25cbAdvanced Mezzanine Card (AMC) \u25cf\u201cFrontend\u201d computer with available PCIe slots for the following\u2026 \u25cfMeinberg PCIe Clock Card \u25cbCustom connector \u25cf10 Gigabit Ethernet Network Interface Card (10GbE NIC) \u25cbSFP+ connectors Jack Carlton - University of Kentucky - j.carlton@uky.edu 3/8 Software Requirements \u25cf\u201cFrontend\u201d computer needs to be running Redhat-Enterprise Linux 7 (RHEL7) \u25cbExamples: Scientific Linux 7 (SL7), CentOS 7 \u25cfMidas \u25cfVarious other open source software libraries (root, boost, cactus, etc.) \u25cfSome custom software libraries (DAQ frontend code, unpacking libraries, etc.) \u25cfSoftware installation completely handled by installer on RHEL7 systems [1] git clone git@github.com:PIONEER-Experiment/g m2daq-installer [2] ./install.sh [3] source ./setup_environment.sh [4] ./start_midas_webpage.sh Installation, in a perfect world: patience\u2026 Open browser, localhost:8080 Jack Carlton - University of Kentucky - j.carlton@uky.edu 4/8 Data Output \u25cfData is output \u201craw\u201d in midas \u201cCR\u201d data banks \u25cbWritten to run{#}.mid.lz4 files by mlogger \u25cfUnpacked C++ data structure using unpacking library \u25cbCustom analyzers can import unpacking library \u25cbUnpacking library include in installer Jack Carlton - University of Kentucky - j.carlton@uky.edu 5/8 Online Database (ODB) \u25cfGUI on midas webpage \u25cbAlso available command line \u25cfAllows for \u201con the fly\u201d adjustments between runs \u25cfBuilt in configurations: \u25cbMidas webpage \u25cbLogger write location \u25cbWebpage update rate \u25cbEtc. \u25cfCustom configurations \u25cbConfigure hardware \u25cbetc. Jack Carlton - University of Kentucky - j.carlton@uky.edu 6/8 Custom Software \u25cfCan write \u201cclients\u201d that connect to midas experiment \u25cbPython \u25cbC++ \u25cfAllows for user to write software to fit their needs, for example: \u25cbData Quality Monitor \u25cbOffline Analysis \u25cbAutomatic ODB management Crude \u201cproof of concept\u201d DQM Jack Carlton - University of Kentucky - j.carlton@uky.edu 7/8 Future Projects (Things We\u2019re Working On) \u25cfEnsuring UW machine has running DAQ before PSI beamtime \u25cfImprove DQM framework to be more adaptable using midas, unpacking, and ZeroMQ libraries \u25cfDirect communication between WFDs/FPGAs and CPU/GPU using PCIe communication \u25cbAvoids the need for \u00b5TCA crates \u25cbSpeeds up data transfer rate (PCIe3x8 = 8GB/s = 64 Gb/s > 10 Gb/s) \u25cbPossibility for direct communication to GPU (faster data processing) Jack Carlton - University of Kentucky - j.carlton@uky.edu 8/8",
    "textLength": 497
  },
  {
    "kind": "presentation",
    "title": "UKY Group Report 5_22_2025_2025-05-19_01-59-54.pdf",
    "fileName": "UKY Group Report 5_22_2025_2025-05-19_01-59-54.pdf",
    "url": "resources/presentations/UKY Group Report 5_22_2025_2025-05-19_01-59-54.pdf",
    "createdDate": "2025-05-19",
    "text": "Data Pipeline 1 Midas Experiment [Python or C++] ZMQ Publisher [C++] Midas Receiver ZMQ Publisher ZMQ Receiver [C++] ZMQ Receiver Event Unpacker 0Event Unpacker 1 \u2026 Event Buffer Backend Webserver [C++] GET Endpoints Web Frontend [JavaScript] Configurable Plot Displays +1 Thread +1 Thread +1 Thread +1 Thread +1 Thread +1 Thread Total Threads: 6 Pros: \u25cfModular \u25cfPublisher works for any midas experiment \u25cfReceiver allows configuration/hot swapping unpackers \u25cfAllow offloading to different computers at both receiver and web frontend stage Cons: \u25cfMore threads \u25cfSomewhat redundant transfer points \u25cfMany data copies could be bottleneck Raw Midas Data \u201cJsonified\u201d Midas Data Unpacked Data Jsonified Data for Plots Note: Can have data aggregators here too Data Pipeline 2 Pros: \u25cfSmaller transfers (allows aggregating data early) \u25cfStill works for any midas experiment \u25cfStill allows hot swapping unpackers/aggregators Cons: \u25cfMore threads \u25cfMore work loaded onto DAQ computer \u25cfSomewhat redundant transfer points \u25cfLess modular Midas Experiment [Python or C++] ZMQ Publisher[C++] Midas Receiver ZMQ Publisher ZMQ Receiver [C++ or Python] ZMQ Receiver Event Buffer Backend Webserver [C++ or Python] GET Endpoints Web Frontend [JavaScript] Configurable Plot Displays Event Unpackers Data Aggregators +1 Thread +1 Thread +1 Thread +1 Thread +1 Thread Total Threads: 6 Unpacked Data Jsonified Data for Plots Unpacked Data Data Pipeline 3 Pros: \u25cfSmaller transfers (allows aggregating data early) \u25cfStill allows hot swapping \u25cfStill works for any midas experiment \u25cfReduces number of data transfers \u25cfFewer Threads Cons: \u25cfEven more work loaded onto DAQ computer \u25cbDAQ now acts as a server for all clients viewing the webpage \u25cfNot very modular \u25cfLose ZMQ features \u25cfRequires re-factoring publisher to not use ZMQ \u25cfToo many requests would slow down aggregator Midas Experiment [Python or C++] Data Aggregator [C++] Midas Receiver Event Buffer Backend Webserver [C++] GET Endpoints Web Frontend [JavaScript] Configurable Plot Displays Event Unpackers Data Aggregators +1 Thread +1 Thread +1 Thread +1 Thread +1 Thread Total Threads: 5 \u201cJsonified\u201d Unpacked Data Jsonified Data for Plots Auxiliary Slides ZMQ Publisher \u25cfPublishes Data over ZMQ \u25cfAllows for customizable \u201cProcessors\u201d that generate data to be published \u25cbData need not come from a midas experiment \u25cfCan be used to unpack data, I would rather not \u25cbMore stress on \u201cexperiment\u201d computer \u25cbLess modular \u25a0This tool works for any midas experiment if we don\u2019t unpack at this stage ZMQ Publisher[C++] Midas Receiver ZMQ Publisher ZMQ Receiver [unfinished slide] \u25cfReceives data over ZMQ \u25cfPlans: \u25cbAllow \u201cregistering\u201d of unpackers \u25a0 \u25cbZMQ Receiver[C++] ZMQ Receiver Event Unpacker 0 Event Unpacker 1 \u2026 Event Buffer",
    "textLength": 413
  },
  {
    "kind": "presentation",
    "title": "DAQ Progress Report 09_10_2025_2025-09-11_01-25-10.pdf",
    "fileName": "DAQ Progress Report 09_10_2025_2025-09-11_01-25-10.pdf",
    "url": "resources/presentations/DAQ Progress Report 09_10_2025_2025-09-11_01-25-10.pdf",
    "createdDate": "2025-09-11",
    "text": "SAMPIC Midas DAQ Status \u25cfLinked Sampic 256 channel C library into an executable MIDAS frontend \u25cbDoes the \u201cloop acquisition\u201d part of the \u201csampic_test\u201d example every second and stores number of hits in a midas bank \u25cfJust a \u201dproof of concept\u201d \u25cbNeed more input/documentation for DAQ design Example Midas Frontend debug text output (polled each second) SAMPIC Midas DAQ Questions \u25cfIs there some documentation on the event structure that gets read out by SAMPIC256CH_ReadEventBuffer SAMPIC256CH_DecodeEvent And are these actually the methods we want to use? \u25cfHow much of T2K\u2019s midas frontend code for sampic readout is still usable? Is it feasible to just copy their sampic wrapper with minimally changes? \u25cbI get the impression they had a \u201cspecial firmware\u201d setup. \u25cfWhat do these errors mean in the sampic test? [auxiliary slide] Auxiliary Slides \u201cErrors\u201d after running sampic_test \u2026\u25cfSeem to \u201cmultiply\u201d with number of reads \u25cfDon\u2019t seem to occur until SAMPIC256CH_StopRun is called \u25cfDoesn\u2019t seem to affect any of the readout (?)",
    "textLength": 163
  },
  {
    "kind": "presentation",
    "title": "UKY Group Report 6_17_2025_2025-06-17_18-41-07.pdf",
    "fileName": "UKY Group Report 6_17_2025_2025-06-17_18-41-07.pdf",
    "url": "resources/presentations/UKY Group Report 6_17_2025_2025-06-17_18-41-07.pdf",
    "createdDate": "2025-06-17",
    "text": "Nalu Hardware Simulator \u25cfAllows for simulating nalu events without hardware \u25cfCan also generate fake signals to be digitized \u25cfWorks with Sean\u2019s unpacker \u25cfUseful for developing DQM without interfering with data taking New Publisher with Analysis Pipeline \u25cfConfigurably receives midas events \u25cfMidas events gets fed into configurable pipeline \u25cfPipeline specifies \u201cunpackers\u201d which all get access to a midas event pointer \u25cfPipeline has a global ROOT tree edited at each stage in a threadsafe manner \u25cfOutput: Serialized analyzed data Auxiliary Slides",
    "textLength": 80
  },
  {
    "kind": "presentation",
    "title": "Postqual GSS_2024-10-23_16-59-35.pdf",
    "fileName": "Postqual GSS_2024-10-23_16-59-35.pdf",
    "url": "resources/presentations/Postqual GSS_2024-10-23_16-59-35.pdf",
    "createdDate": "2024-10-23",
    "text": "PIONEER Data Acquisition Development Jack Carlton University of Kentucky j.carlton@uky.edu Title (Slide 1/46) Outline I.[3-17] What is PIONEER? A. Physics Background B. Experimental Design II.[18-23] Test stand DAQ Development A. Hardware Description B. Software Adjustments III. [24-30] 2023 PSI Test Beam A. Experiment Description B. Results IV. [31-41] PIONEER DAQ Development A. Proposed Framework B. Prototyping C. Compression V.[42-46] Current and Future Work j.carlton@uky.edu Outline (Slide 2/46) What is PIONEER? j.carlton@uky.edu I. What is PIONEER? (Slide 3/46) \u03c0 \u2192 e \u03bde and \u03c0 \u2192 \u00b5 \u03bd\u00b5 \u25cfCorresponding diagrams for \u03c0- \u25cfTau decay forbidden \u25cbtau too massive ~ 1000 MeV/c2 \u25cbPion ~ 100 MeV/c2 \u25cfMuon decay more likely \u25cbbranching fraction of 0.999877 \u03bde e+\u00b5+\u03bd\u00b5 u du d\u03c0+ \u03c0+W W Citation: Particle Data Group (https://pdg.lbl.gov/2014/listings/rpp2014-list-pi-plus-minus.pdf) j.carlton@uky.edu I. What is PIONEER? (Slide 4/46) Helicity Suppression (Why is Muon Decay Most Likely?) \u25cfNaively, \u0393 \u221d p\u2019 \u2192 electron decay more likely \u25cfWeak force only affects left-handed (LH) chiral particle states and right-handed (RH) chiral anti-particle states \u25cfNeutrinos are all LH chirality \u25cfm\u03bd << E means LH neutrino chirality \u2192 LH (negative) neutrino helicity \u25cfConservation of momentum \u2192 anti-lepton is LH (negative) helicity \u03bdl l+u d\u03c0+W \u03c0+ \u03bdll+ Citation: Modern Particle Physics, Mark Thomson (Ch. 11.6 pg. 299) j.carlton@uky.edu I. What is PIONEER? (Slide 5/46) Helicity Suppression (Why is Muon Decay Most Likely?) \u25cfWe can write the LH (negative) helicity anti-particle state in the chiral basis: \u25cfWe ignore the LH term (weak force only acts on the RH term), anti-particle\u2019s matrix element contribution: \u25cfThis effect ends up making the matrix element smaller \u2192 decay rate smaller \u03bdl l+u d\u03c0+W \u03c0+ \u03bdll+ Citation: Modern Particle Physics, Mark Thomson (Ch. 11.6 pg. 300, Ch. 6.4 pg. 143) j.carlton@uky.edu I. What is PIONEER? (Slide 6/46) Lepton Universality \u25cfStates coupling strengths (vertices) ge = g\u00b5 = g\u03c4 \u25cfUsing the Feynman rules for the weak interaction, we can approximate the matrix element \u03bdee-\u00b5- \u03bd\u00b5d ud u\u03c0- \u03c0-W W ge g\u00b5 f\u03c0f\u03c0 Pion vertex Lepton vertex W-boson propagator Citation: Modern Particle Physics, Mark Thomson (Ch. 11.6 pg. 301) j.carlton@uky.edu I. What is PIONEER? (Slide 7/46) Lepton Universality \u25cfAfter some \u201cmassaging\u201d we can find the matrix element to be \u25cfPion spin zero \u2192 no spin averaging needed, i.e.: \u25cfWe can use the general formula for 2-body decay to to find the decay rate \u25cfFinally, we compute the branching ratio Citation: Modern Particle Physics, Mark Thomson (Ch. 11.6 pg. 302-303) j.carlton@uky.edu I. What is PIONEER? (Slide 8/46) Lepton Universality \u25cfLepton universality assumes ge = g\u00b5, so the first factor disappears \u25cfImproving the branching ratio measurement and comparing to the theoretical value acts as a test of lepton universality \u25cfAnother test would consider pure leptonic decays, but such decays involving taus are too rare for high precision measurements j.carlton@uky.edu I. What is PIONEER? (Slide 9/46) Branching Ratio Re/\u00b5 \u25cfWe can measure the branching ratio by measuring # of decays e and \u00b5 decays \u25cfTheoretical prediction is simple in first (and second) order \u25cbNo f\u03c0 or CKM element Vud \u25cf3rd order correction and beyond the pion structure becomes relevant = 1 [in theory] Citation: Dynamic of the Standard Model, Donoghue et. al (Ch. 6.1 pg. 163) j.carlton@uky.edu I. What is PIONEER? (Slide 10/46) Current state of Re/\u00b5 \u25cfConsistent with each other \u25cfExpect factor of ~10 precision improvement on experimental value from PIONEER \u25cb\u201cCatches up\u201d with theoretical uncertainty Re/\u03bcexp = 1.2327(23) x 10-4 (PIENU collab) Rtheo = 1.23524(15) x 10-4 Citation: Testing Lepton Flavor Universality and CKM Unitarity with Rare Pion Decays in the PIONEER experiment, PIONEER collab (pg. 6, arxiv: 2203.05505) j.carlton@uky.edu I. What is PIONEER? (Slide 11/46) Past Experimental Approach (PIENU) \u25cfNaI has a long primary decay time \u25cb~ 250 ns \u25cfEvent pileup forces the experiment to run at a low rate \u25cb~70 kHz \u25cf\u201cinactive target\u201d, muons aren\u2019t tracked \u25cfCsI Rings for shower leakage detection Citation: Status of the TRIUMF PIENU Experiment, PIENU collab, (arxiv 1509.08437) https://pienu.triumf.ca/ j.carlton@uky.edu I. What is PIONEER? (Slide 12/46) PIONEER Experimental Proposal Citations: PIONEER Seminar, Tim Gorringe (Slide 20) PSI Ring Cyclotron Proposal R-22-01.1 PIONEER: Studies of Rare Pion Decays, PIONEER collab, (pg. 19 arxiv: 2203.01981) \u25cfLXe (or LYSO) has shorter decay time \u25cb~ 25 ns \u25cfAllows experiment to run at much higher rate \u25cb~300kHz (phase 1) \u25cb~2000kHz (phase 2 and 3) \u25cf\u201cactive target\u201d, muons and pions are \u201ctracked\u201d j.carlton@uky.edu I. What is PIONEER? (Slide 13/46) 3D Render Experiment Citations: PIONeer A next-generation rare pion decay experiment, David Hertzog, (https://pioneer.npl.washington.edu/docdb/0002/000281/001/PIONEER%20Orientation%20an d%20Status%20June%202024.pdf) Digitization Electronics Spherical Calorimeter Design Not Pictured: \u25cfATAR (inside Calo) \u25cfTracker (a shell around ATAR, inside Calo) \u25cfVETOs, T0, etc. \u25cfDAQ Computers j.carlton@uky.edu I. What is PIONEER? (Slide 14/46) Calorimeter (CALO) Purpose \u25cfMuon\u2019s intrinsically follow a Michelle Spectrum \u25cbAdditionally width comes from energy resolution \u25cfPositrons follow monoenergetic spectrum \u25cb\u201cBack\u201d and \u201cFront\u201d tail due to radiative decays and bremsstrahlung \u25cfGood energy resolution is crucial for event reconstruction Muon Michelle Electron Monoenergetic Citation: PSI Ring Cyclotron Proposal R-22-01.1 PIONEER: Studies of Rare Pion Decays, PIONEER collab, (pg. 19 arxiv: 2203.01981) j.carlton@uky.edu I. What is PIONEER? (Slide 15/46) Active Target (ATAR) Purpose arxiv: 2203.01981 Citation: PSI Ring Cyclotron Proposal R-22-01.1 PIONEER: Studies of Rare Pion Decays, PIONEER collab, (pg. 19 arxiv: 2203.01981) j.carlton@uky.edu I. What is PIONEER? (Slide 16/46) Midas Framework \u25cfC/C++ (mostly) package of modules for \u25cbrun control, \u25cbexpt. configuration \u25cbdata readout \u25cbevent building \u25cbdata storage \u25cbslow control \u25cbalarm systems \u25cbEtc. \u25cfCan link with custom software Example g-2 Midas Webpage j.carlton@uky.edu I. What is PIONEER? (Slide 17/46) Test stand DAQ Development j.carlton@uky.edu II. Test stand DAQ Development (Slide 18/46) Overview \u25cfThe test stand DAQ is used throughout the PIONEER collaboration \u25cbHelps test and develop crucial experiment components \u25cfBuilt on top of g-2 DAQ hardware and software Digitizers & trigger processors ...Array of readout computers, Midas server ... Detectors Hardware Side Software Side j.carlton@uky.edu II. Test stand DAQ Development (Slide 19/46) Hardware - Labeled Crate 10GbE out (data) AMC13\u2192desktop Trigger in AMC13 Trigger out FC7 1GbE MCH in/out (comm.) FC7 Trigger in WFD5 5-channel, differential signal in (no connection in this picture) WFD5s M C HA M C 1 3 F C 7Note: AMC13 and MCH are half slot modules W F D 5W F D 5Crate Power Supply j.carlton@uky.edu II. Test stand DAQ Development (Slide 20/46) Software - Adjustment Made \u25cfGeneralized the frontend code \u25cbCrate contents no longer assumed \u25cbAdded option to remove unneeded hardware reliance (meinberg card) \u25cbAdded support for arbitrary number of crates \u25cbAdded scripts for ease of setup and use \u25cfAdded features \u25cbTiming monitoring \u25cbData quality Monitoring (DQM) \u25cbSystem resource monitoring Generalized Teststand DAQ DQM Webpage j.carlton@uky.edu II. Test stand DAQ Development (Slide 21/46) Documentation \u25cfSetup of the teststand DAQ is not straightforward \u25cbCustom software and hardware \u25cbSpecific software and hardware configurations \u25cfCreated documentation to aid users \u25cbWebsite version on github pages https://jaca230.github.io/teststand_daq_ manual/ A page from the manual webpage j.carlton@uky.edu II. Test stand DAQ Development (Slide 22/46) Use Cases \u25cfLYSO tests at CENPA \u25cf2023 PSI Test Beam \u25cfLiquid Xenon tests at TRIUMF \u25cfExperiments at PSI Setting up test stand at University of a Washington (on a rainy day) j.carlton@uky.edu II. Test stand DAQ Development (Slide 23/46) 2023 PSI Test Beam j.carlton@uky.edu III. 2023 PSI Test Beam (Slide 24/46) Overview \u25cfPIONEER LYSO Calorimeter test \u25cbNovember 15 - 29, 2023 \u25cfMade measurements using LYSO scintillator crystals to determine if they are an adequate candidate for PIONEER\u2019s calorimeter \u25cbEnergy resolution \u25cbTiming resolution \u25cbSpatial resolution j.carlton@uky.edu III. 2023 PSI Test Beam (Slide 25/46) Experiment Diagram - Conceptual Picture Last Quadrupole Magnet on beamline NaI (Leakage Detector) Photomultiplier Tubes (PMTS) NaI (Leakage Detector) Array of LYSO Crystals Data Acquisition System Beam Veto T0 XY Hodoscope Calorimeter on movable XY table j.carlton@uky.edu III. 2023 PSI Test Beam (Slide 26/46) Experiment Diagram - Labeled Picture A full view of the detector setup during the PSI test beam (a) and a close-up of the calorimeter front-face during laser alignment (b). Positrons from the last quadrupole magnet \u2460 pass through the VETO counter \u2461, T0 \u2462, and beam hodoscope \u2463 before depositing energy in the LYSO array \u2464. The LYSO crystals, along with the surrounding NaI detectors \u2465, are mounted on a movable XY table \u2466.Citation: Testing Lepton Flavor Universality and CKM Unitarity with Rare Pion Decays in the PIONEER experiment, PIONEER collab (pg. 20, arxiv: 2203.05505) j.carlton@uky.edu III. 2023 PSI Test Beam (Slide 27/46) LYSO Calorimeter \u25cfConstructed from an array of 10 LYSO crystals \u25cbNaI for leakage detection \u25cfX0 = 1.14 cm \u25cfRM= 2.07 cm Citation: Measurements of a LYSO crystal array from threshold to 100 MeV, PIONEER collab (arxiv: 2409.14691) Front-facing image of LYSO calorimeter j.carlton@uky.edu III. 2023 PSI Test Beam (Slide 28/46) Hodoscope \u25cf2 Layers of 12 scintillator strips \u25cbLayers offset by 90 degrees \u25cf2 mm x 2 mm \u201cpixels\u201d created by strip intersections \u25cbAllows for finer positioning data Citation: Measurements of a LYSO crystal array from threshold to 100 MeV, PIONEER collab (arxiv: 2409.14691) Upstream detector analysis, Stefan Hochrein, https://pioneer.npl.washington.edu/docdb/0002/000254/005/Upstream%20detectors.pdf 1 Hodoscope layer, 12 SiPMs connecting to 12 BC404 plastic scintillator 2mm wide bars Beam Profile: Red - positrons, Blue - muons j.carlton@uky.edu III. 2023 PSI Test Beam (Slide 29/46) Results - Energy Resolution \u25cfMeasured an energy resolution of \u0394E/E = 1.55 \u00b1 0.05% \u25cbPublished as 1.80, recently improved with better integration strategy \u25cb70 MeV \u2248 e energy in \u03c0 \u2192 e\u03bde \u25cfOver two times better than reported results for previous generation LYSO crystals \u25cfSimilar to liquid xenon energy resolution Citation: Measurements of a LYSO crystal array from threshold to 100 MeV, PIONEER collab (arxiv: 2409.14691) j.carlton@uky.edu III. 2023 PSI Test Beam (Slide 30/46) PIONEER DAQ Development j.carlton@uky.edu IV. PIONEER DAQ Development (Slide 31/46) Development Overview \u25cfDAQ work is split into a \u201chardware side\u201d and \u201csoftware side\u201d \u25cbCornell mostly handles the hardware side \u25cbUKY mostly handles the software side \u25cfHardware side goals: \u25cbDesign a flexible system to handle real time data processing, digitizations, and triggers \u25cbCommunication to software side over PCIe \u25cfSoftware side goals: \u25cbHandle electronics readout and communication over PCIe \u25cbHandle data processing and compression j.carlton@uky.edu IV. PIONEER DAQ Development (Slide 32/46) Proposed Framework arXiv:2203.05505 Citation: Testing Lepton Flavor Universality and CKM Unitarity with Rare Pion Decays in the PIONEER experiment, PIONEER collab (pg. 20, arxiv: 2203.05505) Hardware Side SW Side j.carlton@uky.edu IV. PIONEER DAQ Development (Slide 33/46) Proposed Framework arXiv:2203.05505 Citation: Testing Lepton Flavor Universality and CKM Unitarity with Rare Pion Decays in the PIONEER experiment, PIONEER collab (pg. 21) Software Side Receive Data over PCIe Build events in Midas \u201cNearline\u201d Tools j.carlton@uky.edu IV. PIONEER DAQ Development (Slide 34/46) Proposed Experimental Hardware \u25cfUsing APOLLO system (no more \u00b5TCA crates) \u25cfData is moved using \u201cFirefly\u201d optical flyover system \u25cb25 gb/s > 10gb/s links from g-2 \u25cfData received by desktop through Firefly PCIe cards Firefly PCIe board Citation: DAQ backbone exploration, Lawrence Gibbons https://pioneer.npl.washington.edu/docdb/0000/000023/001/apollo.pdf j.carlton@uky.edu IV. PIONEER DAQ Development (Slide 35/46) Mock Experimental Hardware - Our Development FPGA \u25cfUsing Nereid Development board \u25cbKintex-7 FPGA \u25cbData transfer over PCIe \u25cbOnboard RAM (data buffers) \u25cbFMC module input \u25cfWhy this board? \u25cbMore learning resources \u25cbHas components to simulate real experimental hardware \u25cfLimitations: \u25cbOnly supports 5 GT/s (equivalent to PCIe 2) \u25cbOnly 4 lanes (max throughput 2 GB/s) Nereid K7 PCI Express FPGA Development Board j.carlton@uky.edu IV. PIONEER DAQ Development (Slide 36/46) Mock Experimental Hardware - FPGA Firmware \u25cfUsing Xilinx intellectual property (IP) blocks in Vivado \u25cbIP blocks configured by development board settings \u25cfAllows for direct memory access (DMA) transfer over PCIe between card and host Block diagram for DMA transfer between board RAM and host (desktop) RAM j.carlton@uky.edu IV. PIONEER DAQ Development (Slide 37/46) Data Rates Achieved \u25cfMore interested in read/Card-to-host (c2h) transfer rates \u25cfTransfer rates are faster for larger data transfer sizes \u25cfUsing multiple channels, highest data throughput through midas was 1GB/s \u25cfThis number is largely limited by the Nereid development board\u2019s hardware DMA transfer rate vs transfer size over one channel Transfer Size Average Transfer Rate [MB/s] Transfer Speed Vs. Transfer Size j.carlton@uky.edu IV. PIONEER DAQ Development (Slide 38/46) Template Fitting - Example \u25cfCan construct a continuous template for our traces \u25cfCan fit traces using template: \u25cfStoring unfit traces takes ~12 bits per ADC sample \u25cfStoring residuals takes ~4 bits per ADC sample \u25cfBy fitting, we can compress the data by a factor of ~3 ADC value Residual value Time [c.t] Time [c.t] PSI Example LYSO Signal with Fit Signal - Fit Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) Range = ~16 = 4 bits j.carlton@uky.edu IV. PIONEER DAQ Development (Slide 39/46) Template Fitting - Applied \u25cfData from PSI test beam \u25cfEach vertical slice corresponds to pdf \u25cfTemplate fit drastically reduces spread of data Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) Template fitting time [c.t.] Time [c.t] Probability Probability ADC value ADC value j.carlton@uky.edu IV. PIONEER DAQ Development (Slide 40/46) Theoretical Best Compression \u25cfFor lossless compression, the best possible compression rate is the entropy rate \u25cfEntropy rate of pedestal part of signal is 3.4 bits per ADC sample \u25cbA perfect fit would reduce signal to pedestal noise \u25cfBest possible data storage rate 3.5 GB/s \u2192 ~1 GB/s \u25cbAssumes similar noise to PSI test beam data \u25cfRealistically the data storage rate depends how good our fit is \u25cbAssuming entropy rate of ~5 bits/sample 3.5 GB/s \u2192 ~1.5 GB/s Time [c.t] Entropy/sample [bits] Entropy Rate Formula Entropy Rate of PSI Test Beam Data After Fitting Signal entropy Pedestal entropy Pedestal entropy j.carlton@uky.edu IV. PIONEER DAQ Development (Slide 41/46) Current and Future Work j.carlton@uky.edu V. Current and Future Work (Slide 42/46) ATAR Teststand DAQ (Naludaq) \u25cfIntegrate Nalu\u2019s HDSoC digitizer output with MIDAS for synchronized, multi-detector event construction \u25cbAlso utilize existing custom MIDAS-linked software \u25cfUse Nalu's Python library for integration \u25cbCurrent readout via UART interface \u25cbIncorporate Nalu library into MIDAS frontend Nexys A7 Video Board with Nalu\u2019s HDSoC Digitizer Attached as an FMC module NaluScope Program Screenshot with Noise Traces j.carlton@uky.edu V. Current and Future Work (Slide 43/46) FPGA Firmware Additions \u25cfAdded MicroBlaze IP Block \u25cfAllows the FPGA to run C++ code to edit onboard DDR3 RAM \u25cbCan code data generation simulators Block diagram for PCIe DMA transfer with microblaze j.carlton@uky.edu V. Current and Future Work (Slide 44/46) Generalizing and Optimizing Software \u25cfWrite modular software \u25cbWill make experiment DAQ code much more manageable in the future \u25cfOptimize and adjust readout, compression, and other libraries (as needed) \u25cfWrite simple and scalable midas frontends \u25cbImplement libraries above Other Libraries Compression Library MIDAS Readout Library Frontend 1 Frontend 2 \u2026 Frontend 3 \u2026 Dependency Diagram j.carlton@uky.edu V. Current and Future Work (Slide 45/46) PIONEER Demonstrator \u25cf\u201cFull\u201d experiment demonstrator \u25cfPrototypes for all detectors \u25cbSmall number of ATAR Layers (16 layers) \u25cbSmall spherical segment of tapered LYSO crystals (12 crystals) \u25cbSome spherical \u201cshell\u201d segment of tracker \u25cfDAQ handles event construction Tapered LYSO Array ATAR Layers Curved Tracker Section Beam Different Digitization Systems DAQ Computer(s) j.carlton@uky.edu V. Current and Future Work (Slide 46/46) Auxiliary Slides j.carlton@uky.edu Background Physics j.carlton@uky.edu Common Pion Decay Channels \u25cf\u03c0+ \u2192 e+ + \u03bde \u25cf\u03c0- \u2192 e- + \u03bde \u25cf\u03c0+ \u2192 \u00b5+ + \u03bd\u00b5 \u25cf\u03c0- \u2192 \u00b5- + \u03bd\u00b5 \u25cf\u03c0+ \u2192 \u03c00 + e+ + \u03bde \u25cf\u03c0- \u2192 \u03c00 + e- + \u03bde\u25cf\u03c00 \u2192 \u03b3 + \u03b3 \u25cf\u03c00 \u2192 \u03b3 + e- + e+ \u25cf\u03c00 \u2192 e- + e+ + e- + e+ \u25cf\u03c00 \u2192 e- + e+ Leptonic Decay Beta Decay = Most Common Photon Decay Dalitz Decay Double-Dalitz Decay Electrons [Note: Dalitz Decays are like photon decays, except the photon(s) are virtual and immediately decay into electron/positron pairs] Citation: Wikipedia (https://en.wikipedia.org/wiki/Pion) j.carlton@uky.edu Naive Pion Decay, 2-body decay \u25cfWithout getting into details of QCD, we can treat this as a 3 particle decay \u25cfWe can use Fermi\u2019s golden rule: \u25cfAfter integration in the COM frame we find: \u25cf\u2192 \u0393 \u221d p (not correct) \u25cbDetails hidden in matrix element AB C Citation: Introduction to Elementary Particles, Griffiths (Ch. 6.2 pg. 196-198) j.carlton@uky.edu Why Massless \u2192 Chirality States ~ Helicity States \u25cfMassless \u2192 moves at c \u25cfMoves at c \u2192 cannot reverse particle direction with Lorentz boost \u2192 helicity is Lorentz Invariant \u25cfChirality is a property of a particle, always Lorentz invariant! \u2192 helicity and chirality agree in direction in all inertial reference frames [Dirac Equation] [Chiral States] [Helicity operator] [Chiral states are eigenstates of helicity operator] Citation: Lecture Notes, Quantum Field Theory, Michael Eides (PHY616, Lecture #25) j.carlton@uky.edu LH (negative) helicity spinor to chiral components An negative helicity antiparticle can be written as Where (\u03b8,\u03c6) define the direction of the momentum. Without loss of generality, assume the momentum is in the z direction Citation: Modern Particle Physics, Mark Thomson (Ch. 6.4 pg. 143) j.carlton@uky.edu LH (negative) helicity spinor to chiral components We can use the chiral projection operations to project this helicity state to chiral state Where the left and right chiral anti-particle states are defined by Citation: Modern Particle Physics, Mark Thomson (Ch. 6.4 pg. 141,143) j.carlton@uky.edu LH (negative) helicity spinor to chiral components Looking at the chiral projection of a negative helicity state, we can see in general there are left and right chiral components, so the weak force can act on a LH (negative) anti-particle helicity state It should also be clear as m\u21920, the LH (negative) helicity state coincides with the LH chiral state. This means W boson decay to two massless leptons is forbidden! One of the particles must have the wrong chirality, and thus low mass decays will be suppressed. Citation: Modern Particle Physics, Mark Thomson (Ch. 6.4 pg. 143) j.carlton@uky.edu Matrix Element Details Move to pion rest frame so only p0 = m\u03c0 remains: Using the identity: Citation: Modern Particle Physics, Mark Thomson (Ch. 11.6 pg. 301) j.carlton@uky.edu Matrix Element Details For a neutrino m << E so helicity eigenstate is essentially the chiral eigenstate: By letting the lepton go in the z-direction we can write: and Negative helicity lepton down state disappears when \u201cdotted\u201d with the neutrino state: Citation: Modern Particle Physics, Mark Thomson (Ch. 11.6 pg. 301-302) j.carlton@uky.edu Matrix Element Details We can re-write El and p in the limit where the neutrino mass is zero: Citation: Modern Particle Physics, Mark Thomson (Ch. 11.6 pg. 302) j.carlton@uky.edu Lepton Universality j.carlton@uky.edu Small discrepency in ge/g\u00b5 and 1 can cause twice as big discrepency in measured Re/\u00b5 and theory Re/\u00b5 Another Test for Lepton Universality Citation: PIONEER Seminar, Tim Gorringe (Slide 9) Fermi constant and new physics, Marciano, Phys Rev. D 60, 093006 j.carlton@uky.edu CKM Unitary Test Citation: Testing Lepton Flavor Universality and CKM Unitarity with Rare Pion Decays in the PIONEER experiment, PIONEER collab (pg. 21) PIONEER Seminar, Tim Gorringe (Slide 12) arXiv:2203.05505 \u25cfPion beta decay gives a precision measurement of Vud \u25cfThese decays are lower rate than \u03c0 \u2192 e\u03bde and \u03c0 \u2192 \u00b5\u03bd\u00b5 \u25cfExperimental measurements do not agree j.carlton@uky.edu Some Information about LXe and NaI \u25cfLXe has singlet and triplet state decay constants: \u25cb\u03c4S = 4.3 \u00b1 0.6 ns \u25cb\u03c4T = 26.9+0.7 \u22121.1 ns \u25cfLXe light yield: \u25cb~29 photons/keV at room temp \u25cfNaI decay constant: \u25cb~ 250 ns \u25cfNaI light yield: \u25cb38 photons/keV at room temp Citations: A measurement of the scintillation decay time constant of nuclear recoils in liquid xenon with the XMASS-I detector, XMASS collab, arxiv 1809.05988 Scintillation yield of liquid xenon at room temperature , XMASS collab, arxiv 0803.2888 Berkeley Nucleonics (https://www.berkeleynucleonics.com/nai-sodium-iodide) Scintillation from excited Xe (Xe*): Scintillation from ionized Xe (Xe+): j.carlton@uky.edu PEN \u25cfSimilar to PIENU \u25cbSegmented \u25cbBetter timing \u25cfMany channels of pure CSI \u25cb240 channels \u25cfActive target Citation:PEN: a low energy test of lepton universality , PENcollab, (arxiv: 1701.05254) j.carlton@uky.edu More ATAR details \u25cfPion and muon decays deposit energy into ATAR \u25cfAllow event types to be distinguished \u25cfMuons decaying in flight can boost positron energy past 53 MeV (big issue!) \u25cbATAR can give information to rebuild event, and correctly classify a muon decay arxiv: 2203.01981 Citation: PSI Ring Cyclotron Proposal R-22-01.1 PIONEER: Studies of Rare Pion Decays, PIONEER collab, (pg. 19 arxiv: 2203.01981) j.carlton@uky.edu Another Calorimeter 3D Render (Liquid Xenon) Citations: PIONeer A next-generation rare pion decay experiment, David Hertzog, (https://pioneer.npl.washington.edu/docdb/0002/000281/001/PIONEER%20Orientation%20an d%20Status%20June%202024.pdf) j.carlton@uky.edu Electronics and Data Rates j.carlton@uky.edu j.carlton@uky.edu Initialism Meaning Example 10GbE 10 Gigabit Ethernet FPGA Field Programmable Gate Array FMC FPGA Mezzanine Card FC7 SFP Interface CPU Central Processing Unit Intel Core i7-12700K GPU Graphics Processing Unit NVIDIA A5000 \u00b5TCA (uTCA) Micro Telecommunications Computing Architecture WFD Waveform Digitizer WFD5 FC Flexible Controller FC7 AMC Advanced Mezzanine Card AMC13 (also FC7 and WFD5) MCH MicroTCA Carrier Hub DDR Double Data Rate DDR3, DDR4 (RAM) PCIe Peripheral Component Interconnect Express PCIe2, PCIe3, ... TTC Timing, Trigger, and Control UART Universal Asynchronous Receiver-Transmitter Initialism Cheatsheet Hardware - Conceptual Diagram \u25cfDifferential signal into WFD5 (Waveform Digitizer) \u25cfTrigger signal into FC7 (Flexible Controller) \u25cfAMC13 (Advanced Mezzanine Card) gathers data, sends over 10GbE (10 Gigabit Ethernet) to desktop \u25cfMCH (MicroTCA Carrier Hub) facilitates Desktop\u2194Crate communication over 1GbE \u25cfDesktop CPU handles event processing \u25cfMeinberg gives trigger timestamp to computer Differential Signal(s) Trigger WFD5(s) FC7 AMC13(s) MCH Desktop Ribbon Cable Optical Pentabus Cable Crate Optical Crate Crate Crate 1GbE Ethernet Red - Data Blue - Trigger Gray - Control Crate Bank Meinberg SMA SMA to D9 To storage Crate components PCIe j.carlton@uky.edu Hardware - Unlabeled Picture j.carlton@uky.edu PIONEER DAQ (in a nascent state) \u25cfPIONEER DAQ \u25cbIn nascent development state \u25cbDesign catered to PIONEER full experiment necessities PIONEER ADC schematic drawings Citation: DAQ electronics status, Lawrence Gibbons (Slide 1) https://pioneer.npl.washington.edu/cgi-bin/private/ShowDocument?docid=245 j.carlton@uky.edu \u201cOlder\u201d PCIe DMA Transfer Rates are Better \u25cfTransfer rates using block ram in a computer with an older OS (CentOS7) \u25cfThere is a leveling off effect at high transfer sizes \u25cfXDMA driver by Xilinx seems to changes with kernel version, causing performance differences j.carlton@uky.edu Average Transfer Rate [MB/s] Transfer Size Transfer Speed Vs. Transfer Size Data Rates (CALO data rates LXe/LYSO dependant) arXiv:2203.01981 \u25cfPIONEER DAQ expects data rate of ~ 3.5GB/s \u25cfConsidering running time, this is ~ 35,000 TB/year \u25cfHow do we compress this in real time? \u25cbFit data, store fit parameters \u25cbCompress and store residuals, throw some out \u25cbGraphics Processing Units (GPUs) used for this operation Citation: PSI Ring Cyclotron Proposal R-22-01.1 PIONEER: Studies of Rare Pion Decays, PIONEER collab (pg. 33) j.carlton@uky.edu PSI Data j.carlton@uky.edu Contributions \u25cfRepurposing g-2 DAQ Software \u25cfFlexible Pipeline for Data Quality Monitor \u25cfBeamtime \u201cLive\u201d DAQ Maintenance \u25cfOnsite preliminary data analysis Examples of preliminary analysis work done at PSI j.carlton@uky.edu LYSO Information \u25cfLYSO \u2013 lutetium\u2013yttrium oxyorthosilicate \u25cbLutetium (73%), Oxygen (18%), Silicon (6%), Yttrium (3%), and a Cerium scintillation dopant ( \u223c 0%) \u25cfDensity = 7.4 g/cm3 \u25cfX0 = 1.14 cm = \u201cRadiation length\u201d = distance for an electron's energy to be reduced by a factor of 1/e \u25cfRM = 2.07 cm = \u201cMoli\u00e9re radius\u201d = radius of a cylinder containing on average 90% of the shower's energy deposition \u25cfLight Yield = 30,000 photons/MeV \u25cfScintillating decay time = 40 ns j.carlton@uky.edu Citation: Measurements of a LYSO crystal array from threshold to 100 MeV, PIONEER collab (arxiv: 2409.14691) Energy Resolution Definition \u25cfEnergy resolution = \u0394E/E \u25cbE is the peak energy \u25cb\u0394E is the width of the peak \u25cfGaussian fit around the peak \u25cba \u201ccrystal ball\u201d fit is used here \u25cbGaussian around center, x-n on \u201csides\u201d where n is a parameter \u25cbGaussian parameter \u03c3 used for \u0394E \u25cfIn this case, p4 = E = 70.80 \u00b1 0.02 MeV \u25cfp3 = \u0394E = 1.098 \u00b1 0.014 MeV \u25cf\u0394E/E = 0.0155 = 1.55% j.carlton@uky.edu Citation: Omar Beesley, LYSO Updates/Answer https://pioneer.npl.washington.edu/docdb/0003/000312/001/LYSO%20Updates _Answers%20%28General%20Meeting%2010_22_24%29.pdf Timing Resolution Definition \u25cfUse the strongest signal in an event as reference signal. \u25cbt0 = time of peak \u25cfIn the same event find all crystal peaks ti \u25cbOnly use peaks above some energy threshold \u25cf\u0394t = t0 - ti \u25cbThe width of a gaussian fit to a histogram of all such measurements gives the timing resolution j.carlton@uky.edu Citation: Omar Beesley, LYSO Updates/Answer https://pioneer.npl.washington.edu/docdb/0003/000312/001/LYSO%20Updates _Answers%20%28General%20Meeting%2010_22_24%29.pdf Results - Energy Resolution \u25cfEnergy resolution is uniform near the center of the lyso array \u25cfTowards the edges the energy resolution decreases due to leakage \u25cbIn this case, into the NaI array Citation: Measurements of a LYSO crystal array from threshold to 100 MeV, PIONEER collab (arxiv: 2409.14691) Vertical (y-axis) Horizontal (x-axis) j.carlton@uky.edu Results - Timing Resolution \u25cfTiming resolution for 70 MeV events expected to be about 122.5 ps \u25cfThis measurement was largely influenced by noise from incorrect high voltage during test beam \u25cbUsing a system of synchronized LEDs, clean, simultaneous signals were generated at UW \u25cbImproved timing resolution to about 60 ps \u25cbAbout that same as LXe j.carlton@uky.edu Citation: Measurements of a LYSO crystal array from threshold to 100 MeV, PIONEER collab (arxiv: 2409.14691) Compression and Entropy j.carlton@uky.edu Data Set Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) \u25cfPSI Test beam, Run 1887 \u25cf70 MeV/c centered on LYSO crystal 4. \u25cfThe data only includes lyso channels (no NaI for instance) \u25cf More details on that run are in this elog (https://maxwell.npl.washington.edu/ elog/pienuxe/R23/124 )0 1 2 3 4 5 9 86 7j.carlton@uky.edu Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) j.carlton@uky.edu Entropy and Lossless Compression \u25cfFor lossless compression, the best possible compression rate is the entropy rate \u25cfTo first order, the entropy of an entire trace is: \u25cf is the random variable for the ADC value of the ith sample in the trace with n samples \u25cfIf we assume independent, then \u25cfBy transforming ( \u2192 fit residuals), becomes approximately independent Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) j.carlton@uky.edu Higher Order Entropy Estimations \u25cfAssume we have N characters (traces) in our alphabet (data set) \u25cfZero order: each character in alphabet is statistically independent \u25cfFirst order: each character in alphabet is statistically independent, pi is the probability of that character to occur \u25cfSecond order: Pj|i is correlation between subsequent characters \u25cfGeneral Model (impractical): Bn represents the first n characters Citation: Coding and Information Theory Class Notes, Dr. Jay Weitzen, University of Massachusetts Lowell https://faculty.uml.edu/jweitzen/16.548/classnotes/Theory%20of%20Data%20Compression.htm#:~:text=When%20the%20 compression%20is%20lossless,rate%20is%20the%20entropy%20rate j.carlton@uky.edu Joint Entropy, Mutual Information Equality only holds if This means if Then we must have and be statistically independent Citation: Joint Entropy, Wikipedia https://en.wikipedia.org/wiki/Joint_entropy j.carlton@uky.edu Joint entropy for Independent Variables Proof Statement: Proof (part 1): (Note: I am lazy, each P(xi) represents a different pdf in general) Citation: Proof from stackexchange https://math.stackexchange.com/questions/3519345/joint-entropy-of-2-independent-random-variables j.carlton@uky.edu Joint entropy for Independent Variables Proof Proof (part 2): Citation: Proof from stackexchange https://math.stackexchange.com/questions/3519345/joint-entropy-of-2-independent-random-variables j.carlton@uky.edu Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) j.carlton@uky.edu Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) j.carlton@uky.edu Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) j.carlton@uky.edu Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) j.carlton@uky.edu Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) j.carlton@uky.edu Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) j.carlton@uky.edu Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) j.carlton@uky.edu Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) j.carlton@uky.edu Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) j.carlton@uky.edu Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) j.carlton@uky.edu Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) j.carlton@uky.edu Mutual Information Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) \u25cfMutual Information: \u25cf no correlation \u25cfTemplate fitting reduces correlations between subsequent samples Sample # Sample # Sample # Sample # Mutual Info Mutual Info Template fitting j.carlton@uky.edu Entropy Estimation Citation: Entropy estimates of PSI test beam data, Sean Foster (slides) \u25cfAverage entropy: \u25cfIn this case N = 800 \u25cfBefore: Havg = 5.22 bits/sample \u25cfAfter: Havg = 3.55 bits/sample \u25cfSome room for improvement(?) Time [c.t] Time [c.t] Template fitting Entropy/sample [bits] Entropy/sample [bits] j.carlton@uky.edu Explanation of Entropy Plot \u25cfThe pedestal is easy to fit, so the variance of the pedestal part of the signal is is just the noise of the WFD5s. \u25cbThis is the minimum possible entropy when using this equipment \u25cfThe signal is harder to fit and therefore has more variance \u25cbEntropy of this part of the trace is therefore larger Time [c.t] Entropy/sample [bits] Entropy Rate of PSI Test Beam Data After Fitting Signal entropy Pedestal entropy Pedestal entropy j.carlton@uky.edu Theoretical Best Compression Calculation Assuming data is sent as 12 bit ADC samples over PCIe at a data rate of 3.5 GB/s: Entropy rate = 3.4 \u2192 New Data Rate \u2248 0.99 GB/s Entropy rate = 5 \u2192 New Data Rate \u2248 1.46 GB/s j.carlton@uky.edu Continuing Support for Test Stand DAQ \u25cfInstitutions that currently use or plan to use the test stand DAQ in some capacity: \u25cbCENPA at University of Washington \u25cbTRIUMF, Canada \u25cbPSI, Switzerland \u25cfMaintaining and developing software to fit specific needs of each institution j.carlton@uky.edu Signal Conditioning \u25cfWant a narrow distribution for compression. Let ri be the numbers we compress \u25cfMethods tried: \u25cbNo conditioning \u25cbDelta encoding: ri = yi+1-yi \u25cbTwice Delta Encoding: ri = yi+2-2yi+1+yi \u25cbDouble Exponential Fit: ri= yi - (A \u22c5exp(ati)+ B \u22c5exp(bti)) \u25cbShape Fit : ri =yi- (A \u22c5T(ti-t0) + B) No Conditioning Shape Fit Frequency Frequency Voltage [Arbitrary Units] Voltage [Arbitrary Units] j.carlton@uky.edu Shape Fitting Algorithm 1.Construct a discrete template from sample pulses 2.Interpolate template to form a continuous Template, T(t) 3.\u201cStretch\u201d and \u201cshift\u201d template to match signal: [Note: a and b can be calculated explicitly given t0] 4.Compute \u03c72 (assuming equal uncertainty on each channel i) 5.Use Euler\u2019s method to minimize \u03c72 j.carlton@uky.edu Lossless Compression Algorithm \u25cfRice-Golomb Encoding \u25cbLet x be number to encode y = \u201cs\u201d+\u201cq\u201d+\u201dr\u201d \u25a0q = x/M (unary) \u25a0r = x%M (binary) \u25a0s = sign(x) \u25cbAny distribution \u25cbClose to optimal for valid choice of M \u25cbOne extra bit to encode negative sign \u25cbSelf-delimiting \u25cbIf quotient too large, we \u201cgive up\u201d and write x in binary with a \u201cgive up\u201d signal in front Value Encoding -1 011 0 000 1 001 2 1000Rice-Golomb Encoding (M=2) Red = sign bit Blue = quotient bit(s) (Unary) Yellow = remainder bit (binary) j.carlton@uky.edu How to choose Rice-Golomb parameter M \u25cfGenerated fake Gaussian data (centered at zero) with variance \u03c32 \u25cfFor random variable X, M \u2248 median(|X|)/2 is a good choice \u25cbThis is the close to the diagonal on the plot \u25cf\u03c3 \u2248 32 for residuals of shape on wavedream data \u2192 M = 16 is a good choice Gaussian Noise \u03c3 MCompression Ratio Determining Optimal M waveDREAM test j.carlton@uky.edu Compression Ratio from Rice-Golomb Encoding \u25cfLossless compression factor of ~2 \u25cfIn agreement with plot from simulated data on last slide \u25cfBest compression ratio we achieved Rice-Golomb Compression on Residuals (M = 16) Compression Ratio Sample Index j.carlton@uky.edu Real Time Compression Algorithm \u25cfWe choose to let the FE\u2019s GPU and CPU handle compression for flexibility CPU GPU Copy initial guess, Y(t0) Allocate memory for X,Y(t0),t0*,t,r,r\u2019c timeCompute initial guess fit Y(t0)Initialization (one time) Data loop (many times) Copy many traces, X (Overwrite) Wait for enough traces\u2026 Launch 1 thread per trace Compute t0*, via \u03c72 minimization, r = X-Y(t0*)Copy r\u2019c, t0*Use header info from r\u2019c to allocate memory for rcAllocate memory for X,Y,t,r\u2019c Golomb encode r \u2192 r\u2019cStitch together rc from r\u2019c Store rc, t0*j.carlton@uky.edu GPU Benchmarking (Timings) \u25cfBlock Size: \u25cbA GPU parameter, number of threads per multiprocessor \u25cfCan compress 226 integers (32-bit) in roughly \u2153 of a second. \u2192 ~ 0.8 GB/s compression rate Time [s] # of 32-bit Integers Fit + Compression Time using A5000 in PCIe4 (Batch Size = 1024) j.carlton@uky.edu GPU Benchmarking (Timings) \u25cfBatch Size: \u25cbHow many integers are compressed by a single GPU thread \u25cfData must be sent to GPU in batches (not a continuous flow) to take full advantage of parallel computation j.carlton@uky.edu",
    "textLength": 5869
  },
  {
    "kind": "presentation",
    "title": "DAQ Progress Report 05_07_2024_2024-04-07_19-33-50.pdf",
    "fileName": "DAQ Progress Report 05_07_2024_2024-04-07_19-33-50.pdf",
    "url": "resources/presentations/DAQ Progress Report 05_07_2024_2024-04-07_19-33-50.pdf",
    "createdDate": "2024-04-07",
    "text": "g-2 Modified DAQ Development Progress \u25cfFinished assembling and debugging DAQ hardware \u25cbFrontend code running and generating data in MIDAS \u25cfDebugging CCC alarm that is shortening our runs alongside rate testing \u25cfRecently received components for second crate UKY test stand MicroTCA crate Rate Limitations (in non-async mode) \u25cfMeinberg card limits rate to ~3kHz \u25cfRemoving the meinberg from the system we can achieve higher rates \u25cfPast ~9kHz we see GPU buffer fill (test beam\u2019s main error) Master frontend caps at 3kHz in \u201cGPS mode\u201d Master frontend \u201ckeeps up\u201d after removing GPS timestamps g-2 Modified DAQ Development Outline \u25cfEstablish communication with all crate modules \u25cfFinish hardware assembly \u25cfGet frontend code and monitoring software running \u25cfDebug (increase) rate capabilities by optimizing frontend code \u25cfAdd second crate to teststand Crate(s) of FC7s and WFDs ...Array of FEs, BE, Midas server ... Rest of Experiment Simplified DAQ Diagram",
    "textLength": 146
  },
  {
    "kind": "presentation",
    "title": "DAQ Progress Report 09_05_2023_2023-09-05_16-46-59.pdf",
    "fileName": "DAQ Progress Report 09_05_2023_2023-09-05_16-46-59.pdf",
    "url": "resources/presentations/DAQ Progress Report 09_05_2023_2023-09-05_16-46-59.pdf",
    "createdDate": "2023-09-05",
    "text": "Current Progress Hardware and Frontend code: \u25cfData properly logged in .mid output files \u25cbMessy output \u25cfAdding scripts for ease of use \u25cfDigitized Waveform sample: All transferred data output Array Index Value 377-> 1785 1790 1789 1791 1788 1794 1787 1794 385-> 1790 1790 1793 1788 1788 1792 1789 1794 393-> 1788 1790 1786 1791 1788 1794 1792 1788 401-> 1788 1790 1790 1792 1787 1792 1790 1790 409-> 1787 1793 1787 1794 1792 1792 1790 1791 417-> 1789 1792 1791 1793 1788 1790 1789 1790 425-> 1788 1795 1785 1792 1790 1790 1784 1788 433-> 1788 1789 1789 1792 1788 1791 1788 1792 Development Steps (Rough Outline) \u25cfCompiled UKY g-2 teststand DAQ (software only) \u25cbUses more recent midas version \u25cfModified AMC13xx frontend code to edit ODB to match configuration file \u25cfCompiled modified g-2 DAQ on Cornell teststand \u25cbConnected and communicated with frontend hardware (AMC13s with FC7s or WFDs) \u25cfSwap out hardware to one crate system \u25cfRemove/replace hard coded references to FC7 crate from frontends \u25cfGenerate data, check \u201cintegrity\u201d of files \u25cfClean up DAQ for easier user control, package with modified midas, distribute Example crate contents configuration file",
    "textLength": 190
  },
  {
    "kind": "presentation",
    "title": "Simulation Workshop July 2025 Summary_2025-07-11_04-11-02.pdf",
    "fileName": "Simulation Workshop July 2025 Summary_2025-07-11_04-11-02.pdf",
    "url": "resources/presentations/Simulation Workshop July 2025 Summary_2025-07-11_04-11-02.pdf",
    "createdDate": "2025-07-11",
    "text": "Simulation Workshop Summary Jack Carlton University of Kentucky July 11th, 2025 Pattern Finding Goals Coming in Proposed goals at the beginning: \u25cfCharacterize failure modes systematically \u25cfDevelop physics metrics to assess pattern finder\u2019s performance \u25cfRefine vertex finding algorithm(s) \u25cf Implement steps to handle latest tracklet finder developments, e.g. \u201cstrands\u201d \u25cf Implement pattern finding framework in a more gaudi-like way This talk will focus on the structure of the new implementation Pattern Finder Still Behaves Like a Pipeline \u25cfMaintain the same \u201cpipeline\u201d behavior \u25cf\u201cStages\u201d are now Gaudi Tools \u25cbHave standard methods that run on Gaudi\u2019s initialization and finalization sequence \u25cbTake Gaudi parameters for configuration \u25cbAllows for more natural configuration in .opts Gaudi Tools \u25cfGaudi\u2019s documentation is a bit dated but the \u201crecipe\u201d for making a tool is the same \u25cfCreated four tool interfaces \u25cbIPFTrackletFormer \u2261 set<PIRECTracklet> \u2192 set<PFTracklet> \u25cbIPFVertexFormer \u2261 set<PFTracklet> \u2192 set<PFVertex> \u25cbIPFPatternFormer \u2261 set<PFVertex> \u2192 set<PFPattern> \u25cbIPFEventFormer \u2261 set<PFPattern> \u2192 set<PFEvent> \u25cfImplementations of each tool are created by deriving from the interface classes and implementing their virtual methods Default Implementations \u25cfPFDefaultTrackletFormer \u25cbCreates thin wrapper class PFTracklet around PIRECTracklets; in particular sets endpoints for KMeans to use \u25cfPFKMeansVertexFormer \u25cb\u201cMeat\u201d of the pattern finder \u25cbUses KMeans to create centroids that cluster endpoints in order to \u201cmatch\u201d tracklets \u25cfPFDefaultPatternFormer \u25cbUses DFS to find all connected vertices \u25cfPFDefaultEventFormer \u25cbCreate event object to access set of patterns PFKMeansVertexFormer Control in Gaudi .opts file \u25cfTool implementations can changed in the options file \u25cbIf not specified, the defaults discussed with be used \u25cfTools can also take their parameters in the options file \u25cbAgain, if not specified the defaults will be used Next Steps \u25cfDevelop new algorithms to improve pattern finder performance \u25cbCan use Pattern Finding Playground python as a workspace to more rapidly develop and test algorithms performance \u25cfAdd python tested new algorithms in C++ Framework \u25cbSimple as making a new class, allows for seamless merging \u25cf(If needed) Convert internal containers to available objects in the root tree \u25cf(If needed) \u201cNormalize\u201d Pattern finder tools so they all derive from one interface \u25cbWould allow use of a \u201c ToolHandlerArray \u201d to define custom sequences in the pattern finder with an arbitrary number of \u201cstages\u201d \u25cbRequires inputless tools. Tools would grab data from Gaudi storage (similar to Josh\u2019s proposal). Auxiliary Slides What is Each Container Class? \u25cfAll these classes are pattern finder \u201cinternal helper container\u201d classes, not mean to be in the TTree \u25cbCan migrate these into TTree in the future \u25cfPFTracklet \u25cbWrapper around PIRECTracklet \u25cfPFVertex \u25cbWrapper around set of PFTracklets \u25cfPFPattern \u25cbWrapper around set of PFVertices \u25cfPFEvent \u25cbWrapper around set of PFPatterns How to Add a New Implementation 1.Derive from interface 2.Write interface method implementation 3.Specify in Gaudi opts file the class name a. This name is grabbed from DECLARE_COMPONENT \u25cfNew adding new tool interfaces is a bit more involved \u25cbMust register the interface in PIAPatternFinder.hh using the ToolHandler PatternFinder.EventFormer = \"PFDefaultEventFormer\"; Simple Example Implementation and How to specify in .opts How to Create a Tool Type \u25cfUse ToolHandle \u25cbTemplate around your custom interface \u25cbGive it a name an optional default implementation \u25cfThat algorithm with ownership can use and configure the tool \u25cfFor a hot swappable list of tools see ToolHandleArray Pattern Finding Playground \u25cfRecently got a new semi-major update \u25cbMore general pipeline, can insert stages arbitrarily to build up an \u201cevent\u201d \u25cfComes with event tools and plotting displays that take in events \u25cfCarries diagnostic data at each stage for additional plotting Example Performance Plot available in Playground",
    "textLength": 578
  },
  {
    "kind": "presentation",
    "title": "DAQ Progress Report 10_03_2023_2023-10-03_20-02-23.pdf",
    "fileName": "DAQ Progress Report 10_03_2023_2023-10-03_20-02-23.pdf",
    "url": "resources/presentations/DAQ Progress Report 10_03_2023_2023-10-03_20-02-23.pdf",
    "createdDate": "2023-10-03",
    "text": "\u25cfFrontends installed on UW machine, run to the point where they need to connect to hardware \u25cbStill need to install meinberg drivers to link to card by hand \u25cbIssue with running mhttpd on my end (unsure why) \u25cfCreated an \u201cmidas event listener\u201d that can pipe data where needed \u25cbNeed to \u201clink\u201d this with Sean\u2019s unpacking code \u25cbNeed to \u201clink\u201d this with Josh\u2019s webpage Current Progress Crude \u201cproof of concept\u201d webpage Development Steps (Rough Outline) Frontend code: \u25cfClean up DAQ for easier user control, package with modified midas, distribute Backend code: \u25cfCorrectly \u201cbin\u201d all header information, trailer information, ADC data, etc. \u25cfHistogram/data reconstruction (offline) \u25cfEstablish Data Quality Monitor (DQM) that links with midas experiment (online) Example crate contents configuration file",
    "textLength": 122
  },
  {
    "kind": "presentation",
    "title": "Simulation Progress Report 5_14_2025_2025-05-14_21-25-54.pdf",
    "fileName": "Simulation Progress Report 5_14_2025_2025-05-14_21-25-54.pdf",
    "url": "resources/presentations/Simulation Progress Report 5_14_2025_2025-05-14_21-25-54.pdf",
    "createdDate": "2025-05-14",
    "text": "Pattern Finding Implementation Jack Carlton University of Kentucky Pattern Finding Framework \u25cfStand-alone C++ example \u25cfWorking implementation in simulation framework \u25cfBased (loosely) off python pattern finding analysis playground \u25cfDivides pattern finding into abstract algorithm steps \u25cbArbitrary number of steps allowed \u25cbCan construct/edit multiple pipelines for different algorithm implementations \u25cf\u201cRe-invents the wheel\u201d, pretty sure Gaudi framework can do exactly what I built Example Reconstruction Accuracy \u25cfResults purely from simulation framework \u25cbNo more python pattern finding stage \u25cbSimilar results to python pattern finding (expected) Another Pattern Finding Approach \u25cfDefine \u201cexpected\u201d vertex types \u25cbEx: pi->e, pi->mu \u25cfEach tracklet gets \u201cscored\u201d based on what vertex it belongs to \u25cbEx. pi tracklet looks for e or mu tracklet to connect to, whichever is closer is scored higher \u25cfBiased \u25cbOnly finds vertices it\u2019s \u201ctold\u201d to look for \u25cfScoring comparisons need to be tuned \u25cbInherently subjective Example list of vertex types Example Reconstruction Accuracy (New Approach) \u25cfPerforms better \u25cbReverse engineered, so it \u201ccheats\u201d \u25cbInaccuracy solely due to Tracklet Finding inaccuracy Potential Issues with New Approach Some remaining puzzles if we choose to go this route: \u25cfWhat additional vertex types to program in? \u25cfHow to tune the \"scoring\" system so it outputs the correct results? \u25cfEvent mixing has the issue where tracklets could be incorrectly attached to other tracklets. The details of this are left ot be figured out by the scoring system. Auxiliary Slides Pi -> e (simulation truth vs simulation reco) New Approach Misclassified events; caused by tracklet stage inaccuracies New approach pi->mu->e using truth tracklets New approach pi->e using truth tracklets",
    "textLength": 263
  }
]
